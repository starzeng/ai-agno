# AgentUI
Source: https://docs.agno.com/agent-os/agent-ui

An Open Source AgentUI for your AgentOS

<Frame>
  <img height="200" src="https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=72cd1f0888dea4f1ec60a67bff5664c4" style={{ borderRadius: '8px' }} data-og-width="5364" data-og-height="2808" data-path="images/agent-ui.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?w=280&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=8a962c7d75c6fd40d37b696f258b69fc 280w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?w=560&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=729e6c42c46d47f9c56c66451576c53a 560w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?w=840&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=cabb3ed5cb4c1934bd3a5a1cba70a2d1 840w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?w=1100&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=d880656a6c120ed2ef06879bb522b840 1100w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?w=1650&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=55b22efc72db2bbb9e26079d46aea5b5 1650w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui.png?w=2500&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=5331541ccf7abdb289f0e213f65c9649 2500w" />
</Frame>

Agno provides a beautiful UI for interacting with your agents, completely open source, free to use and build on top of. It's a simple interface that allows you to chat with your agents, view their memory, knowledge, and more.

<Note>
  The AgentOS only uses data in your database. No data is sent to Agno.
</Note>

The Open Source Agent UI is built with Next.js and TypeScript. After the success of the [Agent AgentOS](/agent-os/introduction), the community asked for a self-hosted alternative and we delivered!

## Get Started with Agent UI

To clone the Agent UI, run the following command in your terminal:

```bash
npx create-agent-ui@latest
```

Enter `y` to create a new project, install dependencies, then run the agent-ui using:

```bash
cd agent-ui && npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to view the Agent UI, but remember to connect to your local agents.

<Frame>
  <img height="200" src="https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=8f6e365622aefac39432083f2ec587df" style={{ borderRadius: '8px' }} data-og-width="3096" data-og-height="1832" data-path="images/agent-ui-homepage.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?w=280&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=f1d2aa67b73246a4d71f84fc9b581cd0 280w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?w=560&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=969732c206fb7c33e7f575aae105294a 560w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?w=840&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=f1cf21fec03209156f4d1eeec6a12163 840w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?w=1100&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=adf49bc5198a1c4283d0bdb9ffcf91f7 1100w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?w=1650&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=438d2965108fb49d808e89f9928613a3 1650w, https://mintcdn.com/agno-v2/QfHdyhk-tu-JEw8s/images/agent-ui-homepage.png?w=2500&fit=max&auto=format&n=QfHdyhk-tu-JEw8s&q=85&s=b02e0c727983bc3329b8046dfa18d3a5 2500w" />
</Frame>

<br />

<Accordion title="Clone the repository manually" icon="github">
  You can also clone the repository manually

  ```bash
  git clone https://github.com/agno-agi/agent-ui.git
  ```

  And run the agent-ui using

  ```bash
  cd agent-ui && pnpm install && pnpm dev
  ```
</Accordion>

## Connect your AgentOS

The Agent UI needs to connect to a AgentOS server, which you can run locally or on any cloud provider.

Let's start with a local AgentOS server. Create a file `agentos.py`

```python agentos.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.db.sqlite import SqliteDb
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

agent_storage: str = "tmp/agents.db"

web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
    # Store the agent sessions in a sqlite database
    db=SqliteDb(db_file=agent_storage),
    # Adds the current date and time to the context
    add_datetime_to_context=True,
    # Adds the history of the conversation to the messages
    add_history_to_context=True,
    # Number of history responses to add to the messages
    num_history_runs=5,
    # Adds markdown formatting to the messages
    markdown=True,
)

finance_agent = Agent(
    name="Finance Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],
    instructions=["Always use tables to display data"],
    db=SqliteDb(db_file=agent_storage),
    add_datetime_to_context=True,
    add_history_to_context=True,
    num_history_runs=5,
    markdown=True,
)

agent_os = AgentOS(agents=[web_agent, finance_agent])
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve("agentos:app", reload=True)
```

In another terminal, run the AgentOS server:

<Steps>
  <Step title="Setup your virtual environment">
    <CodeGroup>
      ```bash Mac
      python3 -m venv .venv
      source .venv/bin/activate
      ```

      ```bash Windows
      python3 -m venv aienv
      aienv/scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install dependencies">
    <CodeGroup>
      ```bash Mac
      pip install -U openai ddgs yfinance sqlalchemy 'fastapi[standard]' agno
      ```

      ```bash Windows
      pip install -U openai ddgs yfinance sqlalchemy 'fastapi[standard]' agno
      ```
    </CodeGroup>
  </Step>

  <Step title="Export your OpenAI key">
    <CodeGroup>
      ```bash Mac
      export OPENAI_API_KEY=sk-***
      ```

      ```bash Windows
      setx OPENAI_API_KEY sk-***
      ```
    </CodeGroup>
  </Step>

  <Step title="Run the AgentOS">
    ```shell
    python agentos.py
    ```
  </Step>
</Steps>

<Tip>Make sure the `serve_agentos_app()` points to the file containing your `AgentOS` app.</Tip>

## View the AgentUI

* Open [http://localhost:3000](http://localhost:3000) to view the Agent UI
* Enter the `localhost:7777` endpoint on the left sidebar and start chatting with your agents and teams!

<video autoPlay muted controls className="w-full aspect-video" src="https://mintcdn.com/agno-v2/APlycdxch1exeM4A/videos/agent-ui-demo.mp4?fit=max&auto=format&n=APlycdxch1exeM4A&q=85&s=646f460d718e8c3d09b479277088fa19" data-path="videos/agent-ui-demo.mp4" />


# AgentOS API
Source: https://docs.agno.com/agent-os/api

Learn how to use the AgentOS API to interact with your agentic system

AgentOS is a RESTful API that provides access to your agentic system.

It allows you to:

* **Run Agents / Teams / Workflows**: Create new runs for your agents, teams and workflows, either with a new session or a existing one.
* **Manage Sessions**: Retrieve, update and delete sessions.
* **Manage Memories**: Retrieve, update and delete memories.
* **Manage Knowledge**: Manage the content of your knowledge base.
* **Manage Evals**: Retrieve, create, delete and update evals.

<Note>
  This is the same API that powers the AgentOS Control Plane. However, the same endpoints can be used to power your own application!
</Note>

See the full [API reference](/reference-api/overview) for more details.

## Authentication

AgentOS supports bearer-token authentication to secure your instance.
When a Security Key is configured, all API routes require an `Authorization: Bearer <token>` header for access. Without a key configured, authentication is disabled.

For more details, see the [AgentOS Security](/agent-os/security) guide.

## Running your Agent / Team / Workflow

The AgentOS API provides endpoints:

* **Run an Agent**: `POST /agents/{agent_id}/runs`  (See the [API reference](/reference-api/schema/agents/create-agent-run))
* **Run a Team**: `POST /teams/{team_id}/runs`  (See the [API reference](/reference-api/schema/teams/create-team-run))
* **Run a Workflow**: `POST /workflows/{workflow_id}/runs`  (See the [API reference](/reference-api/schema/workflows/execute-workflow))

These endpoints support form-based input. Below is an example of how to run an agent with the API:

```bash
curl --location 'http://localhost:7777/agents/agno-agent/runs' \
    --header 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'message=Tell me about Agno.' \
    --data-urlencode 'stream=True' \
    --data-urlencode 'user_id=john@example.com' \
    --data-urlencode 'session_id=session_123'
```

### Passing agent parameters

Agent, Team and Workflow `run()` and `arun()` endpoints all support additional parameters. See the [Agent arun schema](/reference/agents/agent#arun), [Team arun schema](/reference/teams/team#arun), [Workflow arun schema](/reference/workflows/workflow#arun) for more details.

To pass these parameters to your agent, team or workflow, via the AgentOS API, you can simply specify them as form-based parameters.

Below is an example where `dependencies` are passed to the agent:

```python dependencies_to_agent.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.os import AgentOS

# Setup the database
db = PostgresDb(id="basic-db", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Setup basic agents, teams and workflows
story_writer = Agent(
    id="story-writer-agent",
    name="Story Writer Agent",
    db=db,
    markdown=True,
    instructions="You are a story writer. You are asked to write a story about a robot. Always name the robot {robot_name}",
)

# Setup our AgentOS app
agent_os = AgentOS(
    description="Example AgentOS to show how to pass dependencies to an agent",
    agents=[story_writer],
)
app = agent_os.get_app()


if __name__ == "__main__":
    agent_os.serve(app="dependencies_to_agent:app", reload=True)
```

Then to test it, you can run the following command:

```bash
curl --location 'http://localhost:7777/agents/story-writer-agent/runs' \
    --header 'Content-Type: application/x-www-form-urlencoded' \
    --data-urlencode 'message=Write me a 5 line story.' \
    --data-urlencode 'dependencies={"robot_name": "Anna"}'
```

### Cancelling a Run

You can cancel a running agent, team or workflow by using the appropriate endpoint.

For example, to cancel an agent run:

```bash
curl --location 'http://localhost:7777/agents/story-writer-agent/runs/123/cancel'
```

* [Agent API reference](/reference-api/schema/agents/cancel-agent-run)
* [Team API reference](/reference-api/schema/teams/cancel-team-run)
* [Workflow API reference](/reference-api/schema/workflows/cancel-workflow-run)


# Connecting Your AgentOS
Source: https://docs.agno.com/agent-os/connecting-your-os

Step-by-step guide to connect your local AgentOS to the AgentOS Control Plane

## Overview

Connecting your AgentOS is the critical first step to using the AgentOS Control Plane. This process establishes a connection between your running AgentOS instance and the Control Plane, allowing you to manage, monitor, and interact with your agents through the browser.

<Note>
  **Prerequisites**: You need a running AgentOS instance before you can connect
  it to the Control Plane. If you haven't created one yet, check out our [Creating
  Your First OS](/agent-os/creating-your-first-os) guide.
</Note>

See the [AgentOS Control Plan](/agent-os/control-plane) documentation for more information about the Control Plane.

## Step-by-Step Connection Process

### 1. Access the Connection Dialog

In the Agno platform:

1. Click on the team/organization dropdown in the top navigation bar
2. Click the **"+"** (plus) button next to "Add new OS"
3. The "Connect your AgentOS" dialog will open

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/MMgohmDbM-qeNPya/videos/agent-os-connect-os.mp4?fit=max&auto=format&n=MMgohmDbM-qeNPya&q=85&s=c427bf5bbd76c0495540b49aa64f5604" type="video/mp4" data-path="videos/agent-os-connect-os.mp4" />
  </video>
</Frame>

### 2. Choose Your Environment

Select **"Local"** for development or **"Live"** for production:

* **Local**: Connects to an AgentOS running on your local machine
* **Live**: Connects to a production AgentOS running on your infrastructure

<Note>Live AgentOS connections require a PRO subscription.</Note>

### 3. Configure Connection Settings

#### Endpoint URL

* **Default Local**: `http://localhost:7777`
* **Custom Local**: You can change the port if your AgentOS runs on a different port
* **Live**: Enter your production HTTPS URL

<Warning>
  Make sure your AgentOS is actually running on the specified endpoint before
  attempting to connect.
</Warning>

#### OS Name

Give your AgentOS a descriptive name:

* Use clear, descriptive names like "Development OS" or "Production Chat Bot"
* This name will appear in your OS list and help you identify different instances

#### Tags (Optional)

Add tags to organize your AgentOS instances:

* Examples: `development`, `production`, `chatbot`, `research`
* Tags help filter and organize multiple OS instances
* Click the **"+"** button to add multiple tags

### 4. Test and Connect

1. Click the **"CONNECT"** button
2. The platform will attempt to establish a connection to your AgentOS
3. If successful, you'll see your new OS in the organization dashboard

## Verifying Your Connection

Once connected, you should see:

1. **OS Status**: "Running" indicator in the platform
2. **Available Features**: Chat, Knowledge, Memory, Sessions, etc. should be accessible
3. **Agent List**: Your configured agents should appear in the chat interface

## Securing Your Connection

Protect your AgentOS APIs and Control Plane access with bearer-token authentication. Security keys provide essential protection for both development and production environments.

**Key Features:**

* Generate unique security keys per AgentOS instance
* Rotate keys easily through the organization settings
* Configure bearer-token authentication on your server

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/xm93WWN8gg4nzCGE/videos/agentos-security-key.mp4?fit=max&auto=format&n=xm93WWN8gg4nzCGE&q=85&s=0a87c2a894982a3eb075fe282a21c491" type="video/mp4" data-path="videos/agentos-security-key.mp4" />
  </video>
</Frame>

<Note>
  For complete security setup instructions, including environment configuration
  and best practices, see the [Security Key](/agent-os/security) documentation.
</Note>

## Managing Connected OS Instances

### Switching Between OS Instances

1. Use the dropdown in the top navigation bar
2. Select the OS instance you want to work with
3. All platform features will now connect to the selected OS

### Disconnecting an OS

1. Go to the organization settings
2. Find the OS in your list
3. Click the delete option

<Warning>
  Disconnecting an OS doesn't stop the AgentOS instance - it only removes it
  from the platform interface.
</Warning>

## Next Steps

Once your AgentOS is successfully connected:

<CardGroup cols={2}>
  <Card title="Explore the Chat Interface" icon="comment" href="/agent-os/features/chat-interface">
    Start having conversations with your connected agents
  </Card>

  <Card title="Manage Knowledge" icon="brain" href="/agent-os/features/knowledge-management">
    Upload and organize your knowledge bases
  </Card>

  <Card title="Monitor Sessions" icon="chart-line" href="/agent-os/features/session-tracking">
    Track and analyze your agent interactions
  </Card>
</CardGroup>


# Control Plane
Source: https://docs.agno.com/agent-os/control-plane

The main web interface for interacting with and managing your AgentOS instances

The AgentOS Control Plane is your primary web interface for accessing and managing all AgentOS features. This intuitive dashboard serves as the central hub where you interact with your agents, manage knowledge bases, track sessions, monitor performance, and control user access.

<Frame>
  <img src="https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=47cda181dd5fe3e35b00952cc2fc1e85" alt="AgentOS Control Plane Dashboard" style={{ borderRadius: "0.5rem" }} data-og-width="3477" width="3477" data-og-height="2005" height="2005" data-path="images/agentos-full-screenshot.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?w=280&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=64b3f57b511b5082368b71ab2461fc91 280w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?w=560&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=611e80fc18ec8b4d10f2c01711242bea 560w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?w=840&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=d3d30a7be52757d5d2a444385094d2c0 840w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?w=1100&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=e94a89850b6d5f063a1f5b13c9503002 1100w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?w=1650&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=8a17eadbd7c02cdc2fb6f9e234f4ac61 1650w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-full-screenshot.png?w=2500&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=2450b803257dcc93c2621c855964fb2b 2500w" />
</Frame>

## OS Management

Connect and inspect your OS runtimes from a single interface. Switch between local development and live production instances, monitor connection health, and configure endpoints for your different environments.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/CnjZpOWVs1q9bnAO/videos/agentos-select-os.mp4?fit=max&auto=format&n=CnjZpOWVs1q9bnAO&q=85&s=c6514be6950c2e9c7b103f071ac85b11" type="video/mp4" data-path="videos/agentos-select-os.mp4" />
  </video>
</Frame>

## User Management

Manage your organization members and their access to AgentOS features. Configure your organization name, invite team members, and control permissions from a centralized interface.

### Inviting Members

Add new team members to your organization by entering their email addresses. You can invite multiple users at once by separating emails with commas or pressing Enter/Tab between addresses.

### Member Roles

Control what each member can access:

* **Owner**: Full administrative access including billing and member management
* **Member**: Access to AgentOS features and collaboration capabilities

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/CnjZpOWVs1q9bnAO/videos/agentos-invite-member.mp4?fit=max&auto=format&n=CnjZpOWVs1q9bnAO&q=85&s=f54f71b63fd4b2110e211e0d1f0602c6" type="video/mp4" data-path="videos/agentos-invite-member.mp4" />
  </video>
</Frame>

## General Settings

Configure your account preferences and organization settings. Access your profile information, manage billing and subscription details, and adjust organization-wide preferences from a centralized settings interface.

## Feature Access

The control plane provides direct access to all main AgentOS capabilities through an intuitive interface:

<Note>
  **Getting Started Tip**: The control plane is your gateway to all AgentOS
  features. Start by connecting your OS instance, then explore each feature
  section to familiarize yourself with the interface.
</Note>

<CardGroup cols={2}>
  <Card title="Chat Interface" icon="comment" href="/agent-os/features/chat-interface">
    Start conversations with your agents and access multi-agent interactions
  </Card>

  <Card title="Knowledge Management" icon="book" href="/concepts/knowledge/introduction">
    Upload and organize documents with search and browsing capabilities
  </Card>

  <Card title="Memory System" icon="brain" href="/concepts/memory/overview">
    Browse stored memories and search through conversation history
  </Card>

  <Card title="Session Tracking" icon="clock" href="/concepts/agents/sessions">
    Track and analyze agent interactions and performance
  </Card>

  <Card title="Evaluation & Testing" icon="chart-bar" href="/concepts/evals/introduction">
    Test and evaluate agent performance with comprehensive metrics
  </Card>

  <Card title="Metrics & Monitoring" icon="chart-line" href="/concepts/agents/metrics">
    Monitor system performance and usage analytics
  </Card>
</CardGroup>

## Next Steps

Ready to get started with the AgentOS control plane? Here's what you need to do:

<CardGroup cols={2}>
  <Card title="Create Your First OS" icon="plus" href="/agent-os/creating-your-first-os">
    Set up a new AgentOS instance from scratch using our templates
  </Card>

  <Card title="Connect Your AgentOS" icon="link" href="/agent-os/connecting-your-os">
    Learn how to connect your local development environment to the platform
  </Card>
</CardGroup>


# Create Your First AgentOS
Source: https://docs.agno.com/agent-os/creating-your-first-os

Quick setup guide to get your first AgentOS instance running locally

## Overview

Get started with AgentOS by setting up a minimal local instance. This guide will have you running your first agent in minutes, with optional paths to add advanced features through our examples.

## Prerequisites

* Python 3.9+
* An LLM provider API key (e.g., `OPENAI_API_KEY`)

## Installation

Create and activate a virtual environment:

<CodeGroup>
  ```bash Mac
  # Create virtual environment
  python -m venv venv

  # Activate virtual environment
  source venv/bin/activate
  ```

  ```bash Windows
  # Create virtual environment
  python -m venv venv

  # Activate virtual environment
  venv\Scripts\activate
  ```
</CodeGroup>

Install dependencies:

```bash
pip install -U agno fastapi["standard"] uvicorn openai
```

## Minimal Setup

Create `my_os.py`:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS

assistant = Agent(
    name="Assistant",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=["You are a helpful AI assistant."],
    markdown=True,
)

agent_os = AgentOS(
    os_id="my-first-os",
    description="My first AgentOS",
    agents=[assistant],
)

app = agent_os.get_app()

if __name__ == "__main__":
    # Default port is 7777; change with port=...
    agent_os.serve(app="my_os:app", reload=True)
```

## Running Your OS

Start your AgentOS:

```bash
python my_os.py
```

Access your running instance:

* **App Interface**: `http://localhost:7777` - Use this URL when connecting to the AgentOS control plane
* **API Documentation**: `http://localhost:7777/docs` - Interactive API documentation and testing
* **Configuration**: `http://localhost:7777/config` - View AgentOS configuration
* **API Reference**: View the [AgentOS API documentation](/reference-api/overview) for programmatic access

## Connecting to the Control Plane

With your AgentOS now running locally (`http://localhost:7777`), you can connect it to the AgentOS control plane for a enhanced management experience. The control plane provides a centralized interface to interact with your agents, manage knowledge bases, track sessions, and monitor performance.

## Next Steps

<CardGroup cols={2}>
  <Card title="Connect to Control Plane" icon="link" href="/agent-os/connecting-your-os">
    Connect your running OS to the AgentOS control plane interface
  </Card>

  <Card title="Browse Examples" icon="code" href="/examples/agent-os/demo">
    Explore comprehensive examples for advanced AgentOS configurations
  </Card>
</CardGroup>


# AgentOS Configuration
Source: https://docs.agno.com/agent-os/customize/config

Learn how to check and adjust your AgentOS configuration

For most cases, your AgentOS is configured with a default set of settings. However, you can configure your AgentOS to your liking.

## Configuring your AgentOS

What can be configured?

* **Display names**: You can specify the display name for your AgentOS pages (Sessions, Memory, etc). This is very useful when using multiple databases, to clearly communicate to users which data is being displayed.
* **Quick prompts**: You can provide one to three quick prompts for each one of your agents, teams and workflows. These are the prompts that display on the Chat Page when you create a new session.

### Setting your configuration

You can provide your AgentOS configuration in two different ways: with a configuration YAML file, or using the `AgentOSConfig` class.

<Tip>
  See the full reference for the `AgentOSConfig` class [here](/reference/agent-os/configuration).
</Tip>

### Configuration YAML File

1. Create a YAML file with your configuration. For example:

```yaml
chat:
  quick_prompts:
    marketing-agent:
      - "What can you do?"
      - "How is our latest post working?"
      - "Tell me about our active marketing campaigns"
memory:
  dbs:
    - db_id: db-0001
      domain_config:
        display_name: Main app user memories
    - db_id: db-0002
      domain_config:
        display_name: Support flow user memories
```

2. Pass the configuration to your AgentOS using the `config` parameter:

```python
from agno.os import AgentOS

agent_os = AgentOS(
    ...
    config=<path_to_your_config_file>
)
```

### `AgentOSConfig` Class

You can also provide your configuration using the `AgentOSConfig` class:

```python
from agno.os import AgentOS
from agno.os.config import (
    AgentOSConfig,
    ChatConfig,
    DatabaseConfig,
    MemoryConfig,
    MemoryDomainConfig,
)

agent_os = AgentOS(
    ...
    config=AgentOSConfig(
        chat=ChatConfig(
            quick_prompts={
                "marketing-agent": [
                    "What can you do?",
                    "How is our latest post working?",
                    "Tell me about our active marketing campaigns",
                ]
            }
        ),
        memory=MemoryConfig(
            dbs=[
                DatabaseConfig(
                    db_id=marketing_db.id,
                    domain_config=MemoryDomainConfig(
                        display_name="Main app user memories",
                    ),
                ),
                DatabaseConfig(
                    db_id=support_db.id,
                    domain_config=MemoryDomainConfig(
                        display_name="Support flow user memories",
                    ),
                )
            ],
        ),
    ),
)
```

## The /config endpoint

You can use the `/config` endpoint to inspect your AgentOS configuration that is served to the AgentOS Control Plane.

This is the information you will find there:

* **OS ID**: The ID of your AgentOS (automatically generated if not set)
* **Description**: The description of your AgentOS
* **Databases**: The list of IDs of the databases present in your AgentOS
* **Agents**: The list of Agents available in your AgentOS
* **Teams**: The list of Teams available in your AgentOS
* **Workflows**: The list of Workflows available in your AgentOS
* **Interfaces**: The list of Interfaces available in your AgentOS. E.g. WhatsApp, Slack, etc.
* **Chat**: The configuration for the Chat page, which includes the list of quick prompts for each Agent, Team and Workflow in your AgentOS
* **Session**: The configuration for the Session page of your AgentOS
* **Metrics**: The configuration for the Metrics page of your AgentOS
* **Memory**: The configuration for the Memory page of your AgentOS
* **Knowledge**: The configuration for the Knowledge page of your AgentOS
* **Evals**: The configuration for the Evals page of your AgentOS

You will receive a JSON response with your configuration. Using the previous examples, you will receive:

```json
{
	"os_id": "0001",
	"description": "Your AgentOS",
	"databases": [
		"db-0001",
		"db-0002"
	],
	"chat": {
		"quick_prompts": {
			"marketing-agent": [
				"What can you do?",
				"How is our latest post working?",
				"Tell me about our active marketing campaigns"
			]
		}
	},
	"memory": {
		"dbs": [
			{
				"db_id": "db-0001",
				"domain_config": {
					"display_name": "Main app user memories"
				}
			},
			{
				"db_id": "db-0002",
				"domain_config": {
					"display_name": "Support flow user memories"
				}
			}
		]
	},
    ...
}
```

<Tip>
  See the full schema for the `/config` endpoint [here](/reference-api/schema/core/get-os-configuration).
</Tip>


# Bring Your Own FastAPI App
Source: https://docs.agno.com/agent-os/customize/custom-fastapi

Learn how to use your own FastAPI app in your AgentOS

AgentOS is built on FastAPI, which means you can easily integrate your existing FastAPI applications or add custom routes and routers to extend your agent's capabilities.

## Quick Start

The simplest way to bring your own FastAPI app is to pass it to the AgentOS constructor:

```python
from fastapi import FastAPI
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS

# Create your custom FastAPI app
app = FastAPI(title="My Custom App")

# Add your custom routes
@app.get("/status")
async def status_check():
    return {"status": "healthy"}

# Pass your app to AgentOS
agent_os = AgentOS(
    agents=[Agent(id="basic-agent", model=OpenAIChat(id="gpt-5-mini"))],
    fastapi_app=app  # Your custom FastAPI app
)

# Get the combined app with both AgentOS and your routes
app = agent_os.get_app()
```

<Tip>
  Your custom FastAPI app can have its own middleware and dependencies.

  If you have your own CORS middleware, it will be updated to include the AgentOS allowed origins, to make the AgentOS instance compatible with the Control Plane.
  If not then the appropriate CORS middleware will be added to the app.
</Tip>

### Running with FastAPI CLI

AgentOS applications are compatible with the [FastAPI CLI](https://fastapi.tiangolo.com/deployment/manually/) for development.

First, install the FastAPI CLI:

```bash Install FastAPI CLI
pip install "fastapi[standard]"
```

Then run the app:

<CodeGroup>
  ```bash Run with FastAPI CLI
  fastapi run your_app.py
  ```

  ```bash Run with auto-reload
  fastapi run your_app.py --reload
  ```

  ```bash Custom host and port
  fastapi run your_app.py --host 0.0.0.0 --port 8000
  ```
</CodeGroup>

### Running in Production

For production deployments, you can use any ASGI server:

<CodeGroup>
  ```bash Uvicorn
  uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
  ```

  ```bash Gunicorn with Uvicorn workers
  gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
  ```

  ```bash FastAPI CLI (Production)
  fastapi run main.py --host 0.0.0.0 --port 8000
  ```
</CodeGroup>

## Adding Custom Routers

For better organization, use FastAPI routers to group related endpoints:

```python custom_fastapi_app.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.duckduckgo import DuckDuckGoTools
from fastapi import FastAPI

# Setup the database
db = SqliteDb(db_file="tmp/agentos.db")

# Setup basic agents, teams and workflows
web_research_agent = Agent(
    name="Basic Agent",
    model=Claude(id="claude-sonnet-4-0"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
)

# Custom FastAPI app
app: FastAPI = FastAPI(
    title="Custom FastAPI App",
    version="1.0.0",
)

# Add your own routes
@app.post("/customers")
async def get_customers():
    return [
        {
            "id": 1,
            "name": "John Doe",
            "email": "john.doe@example.com",
        },
        {
            "id": 2,
            "name": "Jane Doe",
            "email": "jane.doe@example.com",
        },
    ]


# Setup our AgentOS app by passing your FastAPI app
agent_os = AgentOS(
    description="Example app with custom routers",
    agents=[web_research_agent],
    fastapi_app=app,
)

# Alternatively, add all routes from AgentOS app to the current app
# for route in agent_os.get_routes():
#     app.router.routes.append(route)

app = agent_os.get_app()


if __name__ == "__main__":
    """Run our AgentOS.

    You can see the docs at:
    http://localhost:7777/docs

    """
    agent_os.serve(app="custom_fastapi_app:app", reload=True)
```

## Middleware and Dependencies

You can add middleware and dependencies to your custom FastAPI app:

```python
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer

app = FastAPI()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://yourdomain.com"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security dependency
security = HTTPBearer()

async def verify_token(token: str = Depends(security)):
    if token.credentials != "your-secret-token":
        raise HTTPException(status_code=401, detail="Invalid token")
    return token

# Protected route
@app.get("/protected", dependencies=[Depends(verify_token)])
async def protected_endpoint():
    return {"message": "Access granted"}

# Integrate with AgentOS
agent_os = AgentOS(
    agents=[Agent(id="basic-agent", model=OpenAIChat(id="gpt-5-mini"))], 
    fastapi_app=app
)

app = agent_os.get_app()
```

## Access AgentOS Routes

You can programmatically access and inspect the routes added by AgentOS:

```python
agent_os = AgentOS(agents=[agent])
app = agent_os.get_app()

# Get all routes
routes = agent_os.get_routes()

for route in routes:
    print(f"Route: {route.path}")
    if hasattr(route, 'methods'):
        print(f"Methods: {route.methods}")
```

## Developer Resources

* [AgentOS Reference](/reference/agent-os/agent-os)
* [Full Example](/examples/agent-os/custom/custom-fastapi)
* [FastAPI Documentation](https://fastapi.tiangolo.com/)


# AgentOS Parameters
Source: https://docs.agno.com/agent-os/customize/os/attributes

Learn about the attributes of the AgentOS class

## Attributes of the AgentOS class

You can configure the behaviour of your AgentOS by passing the following parameters to the `AgentOS` class:

* `agents`: List of agents to include in the AgentOS
* `teams`: List of teams to include in the AgentOS
* `workflows`: List of workflows to include in the AgentOS
* `interfaces`: List of interfaces to include in the AgentOS.
  * See the [Interfaces](/agent-os/interfaces) section for more details.
* `config`: Configuration file path or `AgentOSConfig` instance.
  * See the [Configuration](/agent-os/customize/config) page for more details.
* `fastapi_app`: Optional custom FastAPI app to use instead of creating a new one.
  * See the [Custom FastAPI App](/agent-os/customize/custom-fastapi) page for more details.
* `lifespan`: Optional lifespan context manager for the FastAPI app.
  * See below for more details.
* `enable_mcp`: Turn your AgentOS into an MCP server.
  * See the [MCP enabled AgentOS](/agent-os/mcp/mcp) page for more details.
* `replace_routes`: Optionally override the routes of the AgentOS with your own.
  * See below for more details.

See the [AgentOS class reference](/reference/agent-os/agent-os) for more details.


# Custom Middleware
Source: https://docs.agno.com/agent-os/customize/os/custom_middleware

Learn how to add your own middleware to AgentOS

Add custom middleware to your AgentOS application for enhanced functionality like rate limiting, logging, monitoring etc.

See the following example where we add common middleware often used in production systems:

* **Rate Limiting**: Prevents API abuse by limiting requests per IP address
* **Request/Response Logging**: Tracks all incoming requests with timing and metadata

## Code

```python cookbook/agent_os/customize/fastapi_app_with_custom_middleware.py

import time
from collections import defaultdict, deque
from typing import Dict

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.tools.duckduckgo import DuckDuckGoTools
from fastapi import Request, Response
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware


# === Rate Limiting Middleware ===
class RateLimitMiddleware(BaseHTTPMiddleware):
    """
    Rate limiting middleware that limits requests per IP address.
    """

    def __init__(self, app, requests_per_minute: int = 60, window_size: int = 60):
        super().__init__(app)
        self.requests_per_minute = requests_per_minute
        self.window_size = window_size
        # Store request timestamps per IP
        self.request_history: Dict[str, deque] = defaultdict(lambda: deque())

    async def dispatch(self, request: Request, call_next) -> Response:
        # Get client IP
        client_ip = request.client.host if request.client else "unknown"
        current_time = time.time()

        # Clean old requests outside the window
        history = self.request_history[client_ip]
        while history and current_time - history[0] > self.window_size:
            history.popleft()

        # Check if rate limit exceeded
        if len(history) >= self.requests_per_minute:
            return JSONResponse(
                status_code=429,
                content={
                    "detail": f"Rate limit exceeded. Max {self.requests_per_minute} requests per minute."
                },
            )

        # Add current request to history
        history.append(current_time)

        # Add rate limit headers
        response = await call_next(request)
        response.headers["X-RateLimit-Limit"] = str(self.requests_per_minute)
        response.headers["X-RateLimit-Remaining"] = str(
            self.requests_per_minute - len(history)
        )
        response.headers["X-RateLimit-Reset"] = str(
            int(current_time + self.window_size)
        )

        return response


# === Request/Response Logging Middleware ===
class RequestLoggingMiddleware(BaseHTTPMiddleware):
    """
    Request/response logging middleware with timing and basic info.
    """

    def __init__(self, app, log_body: bool = False, log_headers: bool = False):
        super().__init__(app)
        self.log_body = log_body
        self.log_headers = log_headers
        self.request_count = 0

    async def dispatch(self, request: Request, call_next) -> Response:
        self.request_count += 1
        start_time = time.time()

        # Basic request info
        client_ip = request.client.host if request.client else "unknown"
        print(
            f"üîç Request #{self.request_count}: {request.method} {request.url.path} from {client_ip}"
        )

        # Optional: Log headers
        if self.log_headers:
            print(f"üìã Headers: {dict(request.headers)}")

        # Optional: Log request body
        if self.log_body and request.method in ["POST", "PUT", "PATCH"]:
            body = await request.body()
            if body:
                print(f"üìù Body: {body.decode()}")

        # Process request
        response = await call_next(request)

        # Log response info
        duration = time.time() - start_time
        status_emoji = "‚úÖ" if response.status_code < 400 else "‚ùå"
        print(
            f"{status_emoji} Response: {response.status_code} in {duration * 1000:.1f}ms"
        )

        # Add request count to response header
        response.headers["X-Request-Count"] = str(self.request_count)

        return response


# === Setup database and agent ===
db = PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

agent = Agent(
    id="demo-agent",
    name="Demo Agent",
    model=OpenAIChat(id="gpt-4o"),
    db=db,
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent_os = AgentOS(
    description="Essential middleware demo with rate limiting and logging",
    agents=[agent],
)

app = agent_os.get_app()

# Add custom middleware
app.add_middleware(
    RateLimitMiddleware,
    requests_per_minute=10,
    window_size=60,
)

app.add_middleware(
    RequestLoggingMiddleware,
    log_body=False,
    log_headers=False,
)

if __name__ == "__main__":
    """
    Run the essential middleware demo using AgentOS serve method.
    
    Features:
    1. Rate Limiting (10 requests/minute)
    2. Request/Response Logging
    
    Test commands:
    
    1. Test rate limiting:
       for i in {1..15}; do curl http://localhost:7777/config; done
    
    2. Check rate limit headers:
       curl -v http://localhost:7777/config
    
    Look for:
    - Console logs showing request/response info
    - Rate limit headers: X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset
    - Request count header: X-Request-Count
    - 429 errors when rate limit exceeded
    """

    agent_os.serve(
        app="fastapi_app_with_custom_middleware:app",
        host="localhost",
        port=7777,
        reload=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    export DATABASE_URL=postgresql+psycopg://ai:ai@localhost:5532/ai  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai fastapi["standard"] uvicorn sqlalchemy pgvector psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Example">
    ```bash
    python cookbook/agent_os/customize/fastapi_app_with_custom_middleware.py
    ```
  </Step>

  <Step title="Test the Middleware">
    **Basic Request:**

    ```bash
    curl http://localhost:7777/config
    ```

    **Test Rate Limiting (trigger 429 errors):**

    ```bash
    for i in {1..15}; do curl http://localhost:7777/config; done
    ```

    **Check Rate Limit Headers:**

    ```bash
    curl -v http://localhost:7777/config
    ```

    Look for these response headers:

    * `X-RateLimit-Limit`: Maximum requests allowed
    * `X-RateLimit-Remaining`: Remaining requests in window
    * `X-RateLimit-Reset`: When the window resets
    * `X-Request-Count`: Total requests processed
  </Step>
</Steps>


# Lifespan
Source: https://docs.agno.com/agent-os/customize/os/lifespan

Complete AgentOS setup with custom lifespan

Customize the lifespan context manager of the AgentOS.

This allows you to run code before and after the AgentOS is started and stopped.

For example, you can use this to:

* Connect to a database
* Log information
* Setup a monitoring system

## Code

```python cookbook/agent_os/custom_lifespan.py

from contextlib import asynccontextmanager

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.utils.log import log_info

# Setup the database
db = PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Setup basic agents, teams and workflows
agno_support_agent = Agent(
    id="example-agent",
    name="Example Agent",
    model=Claude(id="claude-sonnet-4-0"),
    db=db,
    markdown=True,
)


@asynccontextmanager
async def lifespan(app):
    log_info("Starting My FastAPI App")
    yield
    log_info("Stopping My FastAPI App")


agent_os = AgentOS(
    description="Example app with custom lifespan",
    agents=[agno_support_agent],
    lifespan=lifespan,
)


app = agent_os.get_app()

if __name__ == "__main__":
    """Run your AgentOS.

    You can see test your AgentOS at:
    http://localhost:7777/docs

    """
    # Don't use reload=True here, this can cause issues with the lifespan
    agent_os.serve(app="custom_lifespan:app")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export ANTHROPIC_API_KEY=your_anthropic_api_key
    export DATABASE_URL=postgresql+psycopg://ai:ai@localhost:5532/ai  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic fastapi["standard"] uvicorn sqlalchemy pgvector psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Example with FastAPI CLI">
    ```bash
    fastapi run cookbook/agent_os/custom_lifespan.py
    ```
  </Step>

  <Step title="Run Example with Python">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/custom_lifespan.py
      ```

      ```bash Windows
      python cookbook/agent_os/custom_lifespan.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Override Routes
Source: https://docs.agno.com/agent-os/customize/os/override_routes

Complete AgentOS setup with custom routes

Override the routes of the AgentOS with your own.

This example demonstrates the `replace_routes=False` functionality which allows your
custom routes to take precedence over conflicting AgentOS routes.

When `replace_routes=False`:

* Your custom routes (/, /health) will be preserved
* Conflicting AgentOS routes will be skipped
* Non-conflicting AgentOS routes will still be added

When `replace_routes=True` (default):

* AgentOS routes will override your custom routes
* Warnings will be logged about the conflicts

## Code

```python cookbook/agent_os/override_routes.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.duckduckgo import DuckDuckGoTools
from fastapi import FastAPI
from starlette.middleware.cors import CORSMiddleware

# Setup the database
db = PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

web_research_agent = Agent(
    id="web-research-agent",
    name="Web Research Agent",
    model=Claude(id="claude-sonnet-4-0"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
)

# Custom FastAPI app
app: FastAPI = FastAPI(
    title="Custom FastAPI App",
    version="1.0.0",
)

# Add Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Custom landing page (conflicts with AgentOS home route)
@app.get("/")
async def get_custom_home():
    return {
        "message": "Custom FastAPI App",
        "note": "Using replace_routes=True to preserve custom routes",
    }


# Custom health endpoint (conflicts with AgentOS health route)
@app.get("/health")
async def get_custom_health():
    return {"status": "custom_ok", "note": "This is your custom health endpoint"}


# Setup our AgentOS app by passing your FastAPI app
# Use replace_routes=False to preserve your custom routes over AgentOS routes
agent_os = AgentOS(
    description="Example app with route replacement",
    agents=[web_research_agent],
    fastapi_app=app,
    replace_routes=False,  # Skip conflicting AgentOS routes, keep your custom routes
)

app = agent_os.get_app()

if __name__ == "__main__":
    """Run your AgentOS.

    With replace_routes=True:
    - Your custom routes are preserved: http://localhost:7777/ and http://localhost:7777/health
    - AgentOS routes are available at other paths: http://localhost:7777/sessions, etc.
    - Conflicting AgentOS routes (GET / and GET /health) are skipped
    - API docs: http://localhost:7777/docs

    Try changing replace_routes=False to see AgentOS routes override your custom ones.
    """
    agent_os.serve(app="override_routes:app", reload=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export ANTHROPIC_API_KEY=your_anthropic_api_key
    export DATABASE_URL=postgresql+psycopg://ai:ai@localhost:5532/ai  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic fastapi["standard"] uvicorn sqlalchemy pgvector psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Example with FastAPI CLI">
    ```bash
    fastapi run cookbook/agent_os/override_routes.py
    ```
  </Step>

  <Step title="Run Example with Python">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/override_routes.py
      ```

      ```bash Windows
      python cookbook/agent_os/override_routes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Chat Interface
Source: https://docs.agno.com/agent-os/features/chat-interface

Use AgentOS chat to talk to agents, collaborate with teams, and run workflows

## Overview

The AgentOS chat is the home for day‚Äëto‚Äëday work with your AI system. From one screen you can:

* Chat with individual agents
* Collaborate with agent teams
* Trigger and monitor workflows
* Review sessions, knowledge, memory, and metrics

It‚Äôs designed to feel familiar‚Äîtype a message, attach files, and get live, streaming responses. Each agent, team, and workflow maintains its own context so you can switch between tasks without losing your place.

## Chat Interfaces

### Chat with an Agent

* Select an agent from the right panel.
* Ask a question like ‚ÄúWhat tools do you have access to?‚Äù
* Agents keep their own history, tools, and instructions; switching agents won‚Äôt mix contexts.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/MMgohmDbM-qeNPya/videos/agentos-agent-chat.mp4?fit=max&auto=format&n=MMgohmDbM-qeNPya&q=85&s=45ae6af616b33280bc431ff63f77cabb" type="video/mp4" data-path="videos/agentos-agent-chat.mp4" />
  </video>
</Frame>

<Info>
  **Learn more about Agents**: Dive deeper into agent configuration, tools,
  memory, and advanced features in our [Agents
  Documentation](/concepts/agents/introduction).
</Info>

### Work with a Team

* Switch the top toggle to Teams and pick a team.
* A team delegates tasks to its members and synthesizes their responses into a cohesive response.
* Use the chat stream to watch how the team divides and solves the task.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/CnjZpOWVs1q9bnAO/videos/agentos-teams-chat.mp4?fit=max&auto=format&n=CnjZpOWVs1q9bnAO&q=85&s=b9b6e4ba67bcf79396cef64c58ff7e9a" type="video/mp4" data-path="videos/agentos-teams-chat.mp4" />
  </video>
</Frame>

<Info>
  **Learn more about Teams**: Explore team modes, coordination strategies, and
  multi-agent collaboration in our [Teams
  Documentation](/concepts/teams/introduction).
</Info>

### Run a Workflow

* Switch to Workflows and choose one.
* Provide the input (plain text or structured, depending on the workflow).
* Watch execution live: steps stream as they start, produce output, and finish.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/CnjZpOWVs1q9bnAO/videos/agentos-workflows-chat.mp4?fit=max&auto=format&n=CnjZpOWVs1q9bnAO&q=85&s=6bfc2fbab99d64e53129e80b49a6be8e" type="video/mp4" data-path="videos/agentos-workflows-chat.mp4" />
  </video>
</Frame>

<Info>
  **Learn more about Workflows**: Discover workflow types, advanced patterns,
  and automation strategies in our [Workflows
  Documentation](/concepts/workflows/overview).
</Info>

## Troubleshooting

* The page loads but nothing responds: verify your AgentOS app is running.
* Can‚Äôt see previous chats: you may be in a new session‚Äîopen the Sessions panel and pick an older one.
* File didn‚Äôt attach: try a common format (png, jpg, pdf, csv, docx, txt, mp3, mp4) and keep size reasonable.

## Related Examples

<CardGroup cols={2}>
  <Card title="Demo AgentOS" icon="play" href="/examples/agent-os/demo">
    Comprehensive demo with agents, knowledge, and evaluation system
  </Card>

  <Card title="Advanced Demo" icon="rocket" href="/examples/agent-os/demo">
    Advanced demo with knowledge, storage, and multiple agents
  </Card>

  <Card title="Slack Interface" icon="slack" href="/examples/agent-os/interfaces/slack/basic">
    Deploy agents to Slack channels
  </Card>

  <Card title="WhatsApp Interface" icon="message" href="/examples/agent-os/interfaces/whatsapp/basic">
    Connect agents to WhatsApp messaging
  </Card>
</CardGroup>


# Knowledge Management
Source: https://docs.agno.com/agent-os/features/knowledge-management

Upload, organize, and manage knowledge for your agents in AgentOS

## Overview

Upload files, add web pages, or paste text to build a searchable knowledge base for your agents. AgentOS indexes content and shows processing status so you can track what‚Äôs ready to use.

<Note>
  <strong>Prerequisites</strong>: Your AgentOS must be connected and active. If
  you see ‚ÄúDisconnected‚Äù or ‚ÄúInactive,‚Äù review your{" "}
  <a href="/agent-os/connecting-your-os">connection settings</a>.
</Note>

## Accessing Knowledge

* Open the `Knowledge` section in the sidebar.
* If multiple knowledge databases are configured, select one from the database selector in the header.
* Use the `Refresh` button to sync status and content.

## What You Can Add

* Files: `.pdf`, `.csv`, `.json`, `.txt`, `.doc`, `.docx`
* Web: Website URLs (pages) or direct file links
* Text: Type or paste content directly

<Tip>
  Available processing options (Readers and Chunkers) are provided by your OS
  and may vary by file/URL type.
</Tip>

## Adding Content

1. Start an upload

* Click `ADD NEW CONTENT`, then choose `FILE`, `WEB`, or `TEXT`.

2. FILE

* Drag & drop or select files. You can also add a file URL.
* Add details per item: Name, Description, Metadata, Reader, and optional Chunker.
* Names must be unique across items.
* Save to upload one or many at once.

3. WEB

* Enter one or more URLs and add them to the list.
* Add details per item as above (Name, Description, Metadata, Reader/Chunker).
* Save to upload all listed URLs.

4. TEXT

* Paste or type content.
* Set Name, optional Description/Metadata, and Reader/Chunker.
* Add Content to upload.

## Useful Links

<CardGroup cols={2}>
  <Card title="Agent Knowledge" icon="user" href="/concepts/agents/knowledge">
    Learn how to add knowledge to agents and use RAG
  </Card>

  <Card title="Team Knowledge" icon="users" href="/concepts/teams/knowledge">
    Understand knowledge sharing in team environments
  </Card>
</CardGroup>


# Memories
Source: https://docs.agno.com/agent-os/features/memories

View and manage persistent memory storage for your agents in AgentOS

## Overview

The Memories feature in AgentOS provides a centralized view of information that agents have learned and stored about you as a user. Memory gives agents the ability to recall information about you across conversations, enabling personalized and contextual interactions.

* Memories are created and updated during an agent run
* Each memory is tied to a specific user ID and contains learned information
* Memories include content, topics, timestamps, and the input that generated them
* Agents with memory enabled can learn about you and provide more relevant responses over time

<Note>
  <strong>Prerequisites</strong>: Your AgentOS must be connected and active. If
  you see "Disconnected" or "Inactive," review your{" "}
  <a href="/agent-os/connecting-your-os">connection settings</a>.
</Note>

## Accessing Memories

* Open the `Memory` section in the sidebar.
* View all stored memories in a chronological table format.
* Click the `Refresh` button to sync the latest memory updates.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/04J6ekYOTyb3RbcL/videos/memory-table-usage.mp4?fit=max&auto=format&n=04J6ekYOTyb3RbcL&q=85&s=4afbe866cc00ed3799f270e642fa842f" type="video/mp4" data-path="videos/memory-table-usage.mp4" />
  </video>
</Frame>

## Memory Management

The memory interface allows you to:

1. **Create memories** - Create memories your agents can reference during chat sessions
2. **View by topics** - See memories organized by thematic categories
3. **Edit memories** - Update or correct stored information as needed
4. **Delete memories** - Remove outdated or incorrect information
5. **Monitor memory creation** - See when and from what inputs memories were generated

<Tip>
  Memories are automatically generated from your conversations, but you can also
  manually create, edit, or remove them.
</Tip>

## Privacy and Control

* All memories are tied to a specific user ID and stored in your AgentOS database
* Memories are only accessible to agents within your connected OS instance
* Memory data remains within your deployment and is never shared externally

## Useful Links

<CardGroup cols={2}>
  <Card title="Memory Concepts" icon="brain" href="/concepts/memory/overview">
    Learn how memory works and how agents learn about users
  </Card>

  <Card title="Privacy & Security" icon="shield-check" href="/agent-os/security">
    Understand data protection and privacy features
  </Card>
</CardGroup>


# Session Tracking
Source: https://docs.agno.com/agent-os/features/session-tracking

Monitor, analyze, and manage agent sessions through the AgentOS interface

## Overview

Sessions are durable conversation timelines that bind inputs, model outputs, tools, files, metrics, and summaries under a single `session_id`. AgentOS persists sessions for Agents, Teams, and Workflows so you can resume work, audit behavior, and analyze quality over time.

* A session collects ordered runs (each run contains messages, tool calls, and metrics).
* Summaries and metadata help you search, group, and reason about long histories.
* Token usage can be monitored per session via the metrics tab.
* Inspect details about the agent and models tied to each session.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/xm93WWN8gg4nzCGE/videos/agentos-session-management.mp4?fit=max&auto=format&n=xm93WWN8gg4nzCGE&q=85&s=70dda8ee349f38e48272eff8cdd4719a" type="video/mp4" data-path="videos/agentos-session-management.mp4" />
  </video>
</Frame>

## Accessing Sessions

* Open the `Sessions` section in the sidebar.
* If multiple session databases are configured, pick one from the database selector in the header.
* Switch between `Agents` and `Teams` using the header tabs.
* Click `Reload page` (Refresh) to sync the list and statuses.

## Troubleshooting

* Sessions not loading: Ensure your OS is connected and active, select a session database, then click `Reload page`.
* No sessions yet: Start a conversation to generate sessions.
* Wrong list: Check the `Agents` vs `Teams` tab and sorting.
* Configuration errors: If you see endpoint or database errors, verify your OS endpoint and database settings.

## Useful Links

<CardGroup cols={3}>
  <Card title="Agent Sessions" icon="user" href="/concepts/agents/sessions">
    Learn about Agent sessions and multi-turn conversations
  </Card>

  <Card title="Team Sessions" icon="users" href="/concepts/teams/sessions">
    Understand Team sessions and collaborative workflows
  </Card>

  <Card title="Workflow Session State" icon="sitemap" href="/concepts/workflows/workflow_session_state">
    Master shared state between workflow components
  </Card>
</CardGroup>


# AG-UI
Source: https://docs.agno.com/agent-os/interfaces/ag-ui/introduction

Expose your Agno Agent via the AG-UI protocol

AG-UI, the [Agent-User Interaction Protocol](https://github.com/ag-ui-protocol/ag-ui), standardizes how AI agents connect to front-end applications.

<Note>
  **Migration from Apps**: If you're migrating from `AGUIApp`, see the [v2 migration guide](/how-to/v2-migration#7-apps-interfaces) for complete steps.
</Note>

## Example usage

<Steps>
  <Step title="Install backend dependencies">
    ```bash
    pip install ag-ui-protocol
    ```
  </Step>

  <Step title="Run the backend">
    Expose an Agno Agent through the AG-UI interface using `AgentOS` and `AGUI`.

    ```python basic.py
    from agno.agent.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.os import AgentOS
    from agno.os.interfaces.agui import AGUI

    chat_agent = Agent(model=OpenAIChat(id="gpt-4o"))

    agent_os = AgentOS(agents=[chat_agent], interfaces=[AGUI(agent=chat_agent)])
    app = agent_os.get_app()

    if __name__ == "__main__":
        agent_os.serve(app="basic:app", reload=True)
    ```
  </Step>

  <Step title="Run the frontend">
    Use Dojo (`ag-ui`'s frontend) as an advanced, customizable interface for AG-UI agents.

    1. Clone: `git clone https://github.com/ag-ui-protocol/ag-ui.git`
    2. Install dependencies in `/ag-ui/typescript-sdk`: `pnpm install`
    3. Build the Agno package in `/ag-ui/integrations/agno`: `pnpm run build`
    4. Start Dojo following the instructions in the repository.
  </Step>

  <Step title="Chat with your Agno Agent">
    With Dojo running, open `http://localhost:3000` and select your Agno agent.
  </Step>
</Steps>

You can see more in our [cookbook examples](https://github.com/agno-agi/agno/tree/main/cookbook/agent_os/interfaces/agui/).

## Core Components

* `AGUI` (interface): Wraps an Agno `Agent` or `Team` into an AG-UI compatible FastAPI router.
* `AgentOS.serve`: Serves your FastAPI app (including the AGUI router) with Uvicorn.

`AGUI` mounts protocol-compliant routes on your app.

## `AGUI` interface

Main entry point for AG-UI exposure.

### Initialization Parameters

| Parameter | Type              | Default | Description            |
| --------- | ----------------- | ------- | ---------------------- |
| `agent`   | `Optional[Agent]` | `None`  | Agno `Agent` instance. |
| `team`    | `Optional[Team]`  | `None`  | Agno `Team` instance.  |

Provide `agent` or `team`.

### Key Method

| Method       | Parameters               | Return Type | Description                                              |
| ------------ | ------------------------ | ----------- | -------------------------------------------------------- |
| `get_router` | `use_async: bool = True` | `APIRouter` | Returns the AG-UI FastAPI router and attaches endpoints. |

## Endpoints

Mounted at the interface's route prefix (root by default):

* `POST /agui`: Main entrypoint. Accepts `RunAgentInput` from `ag-ui-protocol`. Streams AG-UI events.
* `GET /status`: Health/status endpoint for the interface.

Refer to `ag-ui-protocol` docs for payload details.

## Serving your AgentOS

Use `AgentOS.serve` to run your app with Uvicorn.

### Parameters

| Parameter | Type                  | Default       | Description                            |
| --------- | --------------------- | ------------- | -------------------------------------- |
| `app`     | `Union[str, FastAPI]` | required      | FastAPI app instance or import string. |
| `host`    | `str`                 | `"localhost"` | Host to bind.                          |
| `port`    | `int`                 | `7777`        | Port to bind.                          |
| `reload`  | `bool`                | `False`       | Enable auto-reload for development.    |

See [cookbook examples](https://github.com/agno-agi/agno/tree/main/cookbook/agent_os/interfaces/agui/) for updated interface patterns.


# Slack
Source: https://docs.agno.com/agent-os/interfaces/slack/introduction

Host agents as Slack Applications.

Use the Slack interface to serve Agents or Teams on Slack. It mounts Slack event routes on a FastAPI app and sends responses back to Slack threads.

## Setup Steps

Follow the Slack setup guide in the [cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_os/interfaces/slack/README.md).

You will need:

* `SLACK_TOKEN` (Bot User OAuth Token)
* `SLACK_SIGNING_SECRET` (App Signing Secret)
* An ngrok tunnel (for local development) and event subscriptions pointing to `/slack/events`

## Example Usage

Create an agent, expose it with the `Slack` interface, and serve via `AgentOS`:

```python basic.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.interfaces.slack import Slack

basic_agent = Agent(
    name="Basic Agent",
    model=OpenAIChat(id="gpt-5-mini"), # Ensure OPENAI_API_KEY is set
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
)

agent_os = AgentOS(
    agents=[basic_agent],
    interfaces=[Slack(agent=basic_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="basic:app", port=8000, reload=True)
```

You can also use the full example at `cookbook/agent_os/interfaces/slack/basic.py`.

## Core Components

* `Slack` (interface): Wraps an Agno `Agent` or `Team` for Slack integration via FastAPI.
* `AgentOS.serve`: Serves the FastAPI app using Uvicorn.

## `Slack` Interface

Main entry point for Agno Slack applications.

### Initialization Parameters

| Parameter | Type              | Default | Description            |
| --------- | ----------------- | ------- | ---------------------- |
| `agent`   | `Optional[Agent]` | `None`  | Agno `Agent` instance. |
| `team`    | `Optional[Team]`  | `None`  | Agno `Team` instance.  |

Provide `agent` or `team`.

### Key Method

| Method       | Parameters               | Return Type | Description                                        |
| ------------ | ------------------------ | ----------- | -------------------------------------------------- |
| `get_router` | `use_async: bool = True` | `APIRouter` | Returns the FastAPI router and attaches endpoints. |

## Endpoints

Mounted under the `/slack` prefix:

### `POST /slack/events`

* Handles all Slack events (URL verification, messages, app mentions)
* Verifies Slack signature on each request
* Uses thread timestamps as session IDs for per-thread context
* Streams responses back into the originating thread (splits long messages)

## Testing the Integration

1. Run your app locally: `python <my-app>.py` (ensure ngrok is running)
2. Invite the bot to a channel: `/invite @YourAppName`
3. Mention the bot in a channel: `@YourAppName hello`
4. Open a DM with the bot and send a message

## Troubleshooting

* Verify `SLACK_TOKEN` and `SLACK_SIGNING_SECRET` are set
* Confirm the bot is installed and invited to the channel
* Check ngrok URL and event subscription path (`/slack/events`)
* Review application logs for signature failures or permission errors


# Whatsapp
Source: https://docs.agno.com/agent-os/interfaces/whatsapp/introduction

Host agents as Whatsapp Applications.

Use the WhatsApp interface to serve Agents or Teams via WhatsApp. It mounts webhook routes on a FastAPI app and sends responses back to WhatsApp users and threads.

## Setup

Follow the WhatsApp setup guide in the [Whatsapp Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_os/interfaces/whatsapp/readme.md).

You will need environment variables:

* `WHATSAPP_ACCESS_TOKEN`
* `WHATSAPP_PHONE_NUMBER_ID`
* `WHATSAPP_VERIFY_TOKEN`
* Optional (production): `WHATSAPP_APP_SECRET` and `APP_ENV=production`

## Example Usage

Create an agent, expose it with the `Whatsapp` interface, and serve via `AgentOS`:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp

image_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"), # Ensure OPENAI_API_KEY is set
    tools=[OpenAITools(image_model="gpt-image-1")],
    markdown=True,
    add_history_to_context=True,
)

agent_os = AgentOS(
    agents=[image_agent],
    interfaces=[Whatsapp(agent=image_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="basic:app", port=8000, reload=True)
```

See more in our [cookbook examples](https://github.com/agno-agi/agno/tree/main/cookbook/agent_os/interfaces/whatsapp/).

## Core Components

* `Whatsapp` (interface): Wraps an Agno `Agent` or `Team` for WhatsApp via FastAPI.
* `AgentOS.serve`: Serves the FastAPI app using Uvicorn.

## `Whatsapp` Interface

Main entry point for Agno WhatsApp applications.

### Initialization Parameters

| Parameter | Type              | Default | Description            |
| --------- | ----------------- | ------- | ---------------------- |
| `agent`   | `Optional[Agent]` | `None`  | Agno `Agent` instance. |
| `team`    | `Optional[Team]`  | `None`  | Agno `Team` instance.  |

Provide `agent` or `team`.

### Key Method

| Method       | Parameters               | Return Type | Description                                        |
| ------------ | ------------------------ | ----------- | -------------------------------------------------- |
| `get_router` | `use_async: bool = True` | `APIRouter` | Returns the FastAPI router and attaches endpoints. |

## Endpoints

Mounted under the `/whatsapp` prefix:

### `GET /whatsapp/status`

* Health/status of the interface.

### `GET /whatsapp/webhook`

* Verifies WhatsApp webhook (`hub.challenge`).
* Returns `hub.challenge` on success; `403` on token mismatch; `500` if `WHATSAPP_VERIFY_TOKEN` missing.

### `POST /whatsapp/webhook`

* Receives WhatsApp messages and events.
* Validates signature (`X-Hub-Signature-256`); bypassed in development mode.
* Processes text, image, video, audio, and document messages via the agent/team.
* Sends replies (splits long messages; uploads and sends generated images).
* Responses: `200 {"status": "processing"}` or `{"status": "ignored"}`, `403` invalid signature, `500` errors.


# What is AgentOS?
Source: https://docs.agno.com/agent-os/introduction

The production runtime and control plane for your agentic systems

## Overview

AgentOS is Agno's production-ready runtime that runs entirely within your own infrastructure, ensuring complete data privacy and control of your agentic system.
Agno also provides a beautiful web interface for managing, monitoring, and interacting with your AgentOS, with no data ever being persisted outside of your environment.

<Note>
  Behind the scenes, AgentOS is a FastAPI app that you can run locally or in your cloud. It is designed to be easy to deploy and scale.
</Note>

## Getting Started

Ready to get started with AgentOS? Here's what you need to do:

<CardGroup cols={2}>
  <Card title="Create Your First OS" icon="plus" href="/agent-os/creating-your-first-os">
    Set up a new AgentOS instance from scratch using our templates
  </Card>

  <Card title="Connect Your AgentOS" icon="link" href="/agent-os/connecting-your-os">
    Learn how to connect your local development environment to the platform
  </Card>
</CardGroup>

## Security & Privacy First

AgentOS is designed with enterprise security and data privacy as foundational principles, not afterthoughts.

<Frame>
  <img src="https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=b13db5d4b3c25eb5508752f7d3474b51" alt="AgentOS Security and Privacy Architecture" style={{ borderRadius: "0.5rem" }} data-og-width="3258" width="3258" data-og-height="1938" height="1938" data-path="images/agentos-secure-infra-illustration.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?w=280&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=c548641b352030a8fee914cd49919417 280w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?w=560&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=9640bb14a9d22619973e7efb20ab1be5 560w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?w=840&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=82645dfaae8f0155bc3912cdfaf656cc 840w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?w=1100&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=ba5cf9921c1b389d58216ba71ef38515 1100w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?w=1650&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=d7ca28c6e75259c18b08783224c1a2e4 1650w, https://mintcdn.com/agno-v2/Is_2Bv3MNVYdZh1v/images/agentos-secure-infra-illustration.png?w=2500&fit=max&auto=format&n=Is_2Bv3MNVYdZh1v&q=85&s=122528a3dc3ecf7789fb1b076be48f08 2500w" />
</Frame>

### Complete Data Ownership

* **Your Infrastructure, Your Data**: AgentOS runs entirely within your cloud environment
* **Zero Data Transmission**: No conversations, logs, or metrics are sent to external services
* **Private by Default**: All processing, storage, and analytics happen locally

To learn more about AgentOS Security, check out the [AgentOS Security](/agent-os/security) page.

## Next Steps

<CardGroup cols={2}>
  <Card title="Control Plane" icon="desktop" href="/agent-os/control-plane">
    Learn how to use the AgentOS control plane to manage and monitor your OSs
  </Card>

  <Card title="Create Your First OS" icon="rocket" href="/agent-os/creating-your-first-os">
    Get started by creating your first AgentOS instance
  </Card>
</CardGroup>


# MCP enabled AgentOS
Source: https://docs.agno.com/agent-os/mcp/mcp

Learn how to enable MCP functionality in your AgentOS

Model Context Protocol (MCP) gives Agents the ability to interact with external systems through a standardized interface.
To turn your AgentOS into an MCP server, you can set `enable_mcp=True` when creating your AgentOS instance.

```python enable_mcp_example.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db = PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Create your agents
web_research_agent = Agent(
    name="Web Research Agent",
    model=Claude(id="claude-sonnet-4-0"),
    db=db,
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Setup AgentOS with MCP enabled
agent_os = AgentOS(
    description="Example app with MCP enabled",
    agents=[web_research_agent],
    enable_mcp=True,  # This enables a LLM-friendly MCP server at /mcp
)

app = agent_os.get_app()

if __name__ == "__main__":
    # Your MCP server will be available at http://localhost:7777/mcp
    agent_os.serve(app="enable_mcp_example:app", reload=True)
```

Once enabled, your AgentOS will expose an MCP server at the `/mcp` endpoint that provides:

* Access to your AgentOS configuration
* Information about available agents, teams, and workflows
* The ability to run agents, teams, and workflows
* The ability to create and delete sessions
* The ability to create, update, and delete memories

See here for a [full example](/examples/agent-os/mcp/enable_mcp_example).


# AgentOS + MCPTools
Source: https://docs.agno.com/agent-os/mcp/tools

Learn how to use MCPTools in your AgentOS

Model Context Protocol (MCP) gives Agents the ability to interact with external systems through a standardized interface.

You can give your agents access to tools from MCP servers using [`MCPTools`](/concepts/tools/mcp).

When using MCPTools within AgentOS, the lifecycle is automatically managed. No need to manually connect or disconnect the `MCPTools` instance.

```python mcp_tools_example.py
from agno.agent import Agent
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# Create MCPTools instance
mcp_tools = MCPTools(
    transport="streamable-http", 
    url="https://docs.agno.com/mcp"
)

# Create MCP-enabled agent
agent = Agent(
    id="agno-agent",
    name="Agno Agent",
    tools=[mcp_tools],
)

# AgentOS manages MCP lifespan
agent_os = AgentOS(
    description="AgentOS with MCP Tools",
    agents=[agent],
)

app = agent_os.get_app()

if __name__ == "__main__":
    # Don't use reload=True with MCP tools to avoid lifespan issues
    agent_os.serve(app="mcp_tools_example:app")
```

<Note>
  If you are using `MCPTools` within AgentOS, you should not use `reload=True` when serving your AgentOS.
  This can break the MCP connection during the FastAPI lifecycle.
</Note>

See here for a [full example](/examples/agent-os/mcp/mcp_tools_example).


# AgentOS Security
Source: https://docs.agno.com/agent-os/security

Learn how to secure your AgentOS instance with a security key

## Overview

AgentOS supports bearer-token authentication to secure your instance. When a Security Key is configured, all API routes require an `Authorization: Bearer <token>` header for access. Without a key configured, authentication is disabled.

<Tip>
  You can generate a security key from the AgentOS Control Plane, which also enables secure communication between your AgentOS and the Control Plane.
</Tip>

## Generate a Security Key

From the AgentOS control plane, generate a security key or set your own.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/xm93WWN8gg4nzCGE/videos/agentos-security-key.mp4?fit=max&auto=format&n=xm93WWN8gg4nzCGE&q=85&s=0a87c2a894982a3eb075fe282a21c491" type="video/mp4" data-path="videos/agentos-security-key.mp4" />
  </video>
</Frame>

<Tip>
  You can also create your own security key and set it on the AgentOS UI.
</Tip>

## Enable Authentication

Set the `OS_SECURITY_KEY` environment variable where your AgentOS server runs. When present, the server automatically enforces bearer authentication on all API routes.

### macOS / Linux (bash or zsh)

```bash
export OS_SECURITY_KEY="OSK_...your_copied_key..."
uvicorn app:app --host 0.0.0.0 --port 8000
```

### Docker Compose

```yaml
services:
  agentos:
    image: your-org/agentos:latest
    environment:
      - OS_SECURITY_KEY=${OS_SECURITY_KEY}
    ports:
      - "8000:8000"
```

<Note>
  **How it works**: AgentOS reads `OS_SECURITY_KEY` into the AgentOS router's
  internal authorization logic. If configured, requests without a valid
  `Authorization: Bearer` header return `401 Unauthorized`.
</Note>

## Key Rotation

1. In the UI, click the **Generate** icon next to "Security Key" to generate a new value
2. Update the server's `OS_SECURITY_KEY` environment variable and reload/redeploy AgentOS
3. Update all clients, workers, and CI/CD systems that call the AgentOS API

## Security Best Practices

* **Environment Isolation**: Use different keys per environment with least-privilege distribution
* **Code Safety**: Never commit keys to version control or print them in logs

## Troubleshooting

* **401 Unauthorized**: Verify the header format is exactly `Authorization: Bearer <key>` and that the server has `OS_SECURITY_KEY` configured
* **Local vs Production**: Confirm your local shell exported `OS_SECURITY_KEY` before starting the application
* **Post-Rotation Failures**: Ensure all clients received the new key. Restart CI/CD runners that may cache environment variables
* **Connection Issues**: Check that your AgentOS instance is running and accessible at the configured endpoint


# Building Agents
Source: https://docs.agno.com/concepts/agents/building-your-agent

Learn how to build an Agno Agent.

When building an Agent, it is important to consider the following:

* **Which model to use?** -> See the [Models](/concepts/models/introduction) documentation.
* **Which tools to use?** -> See the [Tools](/concepts/agents/tools/introduction) documentation.
* **Which instructions to use?** -> See the [Context Engineering](/concepts/agents/context) documentation.
* **Should I enable reasoning?** -> See the [Reasoning](/concepts/agents/reasoning) documentation.
* **Do I need to add knowledge?** -> See the [Knowledge](/concepts/agents/knowledge) documentation.
* **How do I configure storage?** -> See the [Storage](/concepts/agents/storage) documentation.
* **How do I configure memory?** -> See the [Memory](/concepts/agents/memory) documentation.

## The Development Process

It is typical while developing an Agent to use the `Agent.print_response()` method to print the response in the terminal. This is only for convenience during development and not recommended for production use.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

agent.print_response("Tell me a 5 second short story about a robot")

# Or for streaming
agent.print_response("Tell me a 5 second short story about a robot", stream=True)

# Or async
await agent.aprint_response("Tell me a 5 second short story about a robot")

# Or for async streaming
await agent.aprint_response("Tell me a 5 second short story about a robot", stream=True)
```

<Note>
  The `Agent.print_response()` and `Agent.aprint_response()` methods are helper methods that use the `Agent.run()` and `Agent.arun()` methods under the hood.

  See [Running your Agent](/concepts/agents/running-your-agent) for more details.
</Note>

See the full method signature in the [Agent class reference](/reference/agents/agent#print_response).

## Debugging

You can enable debug mode to get more detailed logs.

```python
agent = Agent(model=OpenAIChat(id="gpt-5-mini"), debug_mode=True)

# You can also set it directly on the run
agent.print_response("Tell me a 5 second short story about a robot", debug_mode=True)
```

## Interactive CLI

You can also interact with the agent via a CLI.

```python
agent.cli_app(input="Tell me a 5 second short story about a robot", stream=True)
```

See the [Agent class reference](/reference/agents/agent) for more details.

## Developer Resources

* View the [Agent reference](/reference/agents/agent)
* View [Agent Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/README.md)


# Context Engineering
Source: https://docs.agno.com/concepts/agents/context

Learn how to write prompts and other context engineering techniques for your agents.

Context engineering is the process of designing and controlling the information (context) that is sent to language models to guide their behavior and outputs.
In Agno, this means carefully crafting the system message, which includes the agent's description, instructions, and other relevant settings. By thoughtfully engineering this context, you can:

* Steer the agent toward specific behaviors or roles.
* Constrain or expand the agent's capabilities.
* Ensure outputs are consistent, relevant, and aligned with your application's needs.
* Enable advanced use cases such as multi-step reasoning, tool use, or structured output.

Effective context engineering involves iteratively refining the system message, experimenting with different descriptions and instructions, and leveraging features like input/output schemas or tool integrations.

The context of an Agno agent consists of the following:

* **System message**: The system message is the main context that is sent to the agent, including all additional context
* **User message**: The user message is the message that is sent to the agent.
* **Chat history**: The chat history is the history of the conversation between the agent and the user.
* **Additional input**: Any few-shot examples or other additional input that is added to the context.

## System message context

The following are some key parameters that are used to create the system message:

1. **Description**: A description that guides the overall behaviour of the agent.
2. **Instructions**: A list of precise, task-specific instructions on how to achieve its goal.
3. **Expected Output**: A description of the expected output from the Agent.

The system message is created using `description`, `instructions` and a number of other settings. The `description` is added to the start of the system message and `instructions` are added as a list. For example:

```python
from agno.agent import Agent

agent = Agent(
    description="You are a famous short story writer asked to write for a magazine",
    instructions=["You are a pilot on a plane flying from Hawaii to Japan."],
    markdown=True,
    debug_mode=True,  # Set to True to view the detailed logs and see the compiled system message
)
agent.print_response("Tell me a 2 sentence horror story.", stream=True)
```

Will produce the following system message:

```
You are a famous short story writer asked to write for a magazine
<instructions>
You are a pilot on a plane flying from Hawaii to Japan.
</instructions>

<additional_information>
- Use markdown to format your answers.
</additional_information>
```

### Additional Context

You can add additional context to the end of the system message using the `additional_context` parameter.

In this example, we add additional context to the system message that the agent has access to specific tables in a database.

```python
from textwrap import dedent

from agno.agent import Agent
from agno.models.langdb import LangDB
from agno.tools.duckdb import DuckDbTools

duckdb_tools = DuckDbTools(
    create_tables=False, export_tables=False, summarize_tables=False
)
duckdb_tools.create_table_from_path(
    path="https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    table="movies",
)

agent = Agent(
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    tools=[duckdb_tools],
    markdown=True,
    additional_context=dedent("""\
    You have access to the following tables:
    - movies: contains information about movies from IMDB.
    """),
)
agent.print_response("What is the average rating of movies?", stream=True)
```

### System message Parameters

The Agent creates a default system message that can be customized using the following parameters:

| Parameter                        | Type        | Default | Description                                                                                                                                                                |
| -------------------------------- | ----------- | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `description`                    | `str`       | `None`  | A description of the Agent that is added to the start of the system message.                                                                                               |
| `instructions`                   | `List[str]` | `None`  | List of instructions added to the system prompt in `<instructions>` tags. Default instructions are also created depending on values for `markdown`, `expected_output` etc. |
| `additional_context`             | `str`       | `None`  | Additional context added to the end of the system message.                                                                                                                 |
| `expected_output`                | `str`       | `None`  | Provide the expected output from the Agent. This is added to the end of the system message.                                                                                |
| `markdown`                       | `bool`      | `False` | Add an instruction to format the output using markdown.                                                                                                                    |
| `add_datetime_to_context`        | `bool`      | `False` | If True, add the current datetime to the prompt to give the agent a sense of time. This allows for relative times like "tomorrow" to be used in the prompt                 |
| `add_name_to_context`            | `bool`      | `False` | If True, add the name of the agent to the context.                                                                                                                         |
| `add_location_to_context`        | `bool`      | `False` | If True, add the location of the agent to the context. This allows for location-aware responses and local context.                                                         |
| `add_session_summary_to_context` | `bool`      | `False` | If True, add the session summary to the context. See [sessions](/concepts/agents/sessions) for more information.                                                           |
| `add_memories_to_context`        | `bool`      | `False` | If True, add the user memories to the context. See [memory](/concepts/agents/memory) for more information.                                                                 |
| `add_dependencies_to_context`    | `bool`      | `False` | If True, add the dependencies to the context. See [dependencies](/concepts/agents/dependencies) for more information.                                                      |
| `add_session_state_to_context`   | `bool`      | `False` | If True, add the session state to the context. See [state](/concepts/agents/state) for more information.                                                                   |
| `add_knowledge_to_context`       | `bool`      | `False` | If True, add retrieved knowledge to the context, to enable RAG. See [knowledge](/concepts/agents/knowledge) for more information.                                          |
| `system_message`                 | `str`       | `None`  | Override the default system message.                                                                                                                                       |
| `build_context`                  | `bool`      | `True`  | Optionally disable the building of the context.                                                                                                                            |

See the full [Agent reference](/reference/agents/agent) for more information.

### Set the system message directly

You can manually set the system message using the `system_message` parameter. This will ignore all other settings and use the system message you provide.

```python
from agno.agent import Agent

agent = Agent(system_message="Share a 2 sentence story about")
agent.print_response("Love in the year 12000.")
```

<Tip>
  Some models via some model providers, like `llama-3.2-11b-vision-preview` on
  Groq, require no system message with other messages. To remove the system
  message, set `build_context=False` and `system_message=None`.
  Additionally, if `markdown=True` is set, it will add a system message, so
  either remove it or explicitly disable the system message.
</Tip>

## User message

The `input` sent to the `Agent.run()` or `Agent.print_response()` is used as the user message.

See [dependencies](/concepts/agents/dependencies) for how to do dependency injection for your user message.

## Context Caching

Various model providers support caching of system and user messages. The implementation of caching differs between providers.

Generally the approach is to cache repetitive content and common instructions and on subsequent requests to use cached content from the prefix for your system message.
In other words, if the model supports it, you can reduce the number of tokens sent to the model by putting static content at the start of your system message.

Agno's context construction is designed to put the most probable static content at the start of your system message.\
If you wish to fine-tune this, the recommended approach is to manually set the system message.

Some examples of prompt caching:

* [OpenAI's prompt caching](https://platform.openai.com/docs/guides/prompt-caching)
* [Anthropic prompt caching](https://docs.claude.com/en/docs/build-with-claude/prompt-caching) -> See an [Agno example](/examples/models/anthropic/prompt_caching) of this
* [OpenRouter prompt caching](https://openrouter.ai/docs/features/prompt-caching)

## Chat history

If you have database storage enabled on your agent, session history is automatically stored (see [sessions](/concepts/agents/sessions)).

You can now add the history of the conversation to the context using `add_history_to_context`.

```python
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="chat_history",
    instructions="You are a helpful assistant that can answer questions about space and oceans.",
    add_history_to_context=True,
    num_history_runs=2,  # Optionally limit the number of history responses to add to the context
)

agent.print_response("Where is the sea of tranquility?")

agent.print_response("What was my first question?")
```

This will add the history of the conversation to the context, which can be used to provide context for the next message.

See more details on [sessions](/concepts/agents/sessions#session-history).

## Additional input

You can add entire additional messages to your agent's context using the `additional_input` parameter.
These messages are added to the context as if they were part of the conversation history.

You can give your agent examples of how it should respond (also called "few-shot prompting"):

```python
from agno.agent import Agent
from agno.models.message import Message
from agno.models.openai.chat import OpenAIChat

# Few-shot examples showing good support patterns
support_examples = [
    # Example 1: Simple issue resolution
    Message(role="user", content="I forgot my password and can't log in"),
    Message(
        role="assistant",
        content="""
    I'll help you reset your password right away.

    **Steps to Reset Your Password:**
    . Go to the login page and click "Forgot Password"
    . Enter your email address
    . Check your email for the reset link
    . Follow the link to create a new password
    . Use a strong password with uppercase, lowercase, numbers, and symbols

    f you don't receive the email within 5 minutes, please check your spam folder. Let me know if you need any assistance with these steps!
    """.strip(),
    ),
    # Example 2: Billing issue pattern
    Message(
        role="user",
        content="I've been charged twice for the same order and I'm frustrated!",
    ),
    Message(
        role="assistant",
        content="""
    I sincerely apologize for the billing error and the frustration this has caused you.

    **Immediate Action Plan:**
    1. I'll investigate your account to confirm the duplicate charge
    2. Process a full refund for the duplicate transaction
    3. Ensure this doesn't happen again by checking your payment method settings
    4. Provide you with a confirmation number once the refund is processed

    The refund typically takes 3-5 business days to appear on your statement. As an apology for this inconvenience, I'd also like to offer you a 10% discount on your next order.

    Is there anything else I can help you with regarding this issue?
    """.strip(),
    ),
    # Example 3: Technical support pattern
    Message(role="user", content="Your app keeps crashing when I try to upload photos"),
    Message(
        role="assistant",
        content="""
    I'm sorry you're experiencing crashes with photo uploads. Let me help you troubleshoot this issue.

    **Troubleshooting Steps:**
    1. **Check App Version:** Ensure you have the latest version from the app store
    2. **Restart the App:** Close completely and reopen the application
    3. **Check Storage:** Make sure you have sufficient device storage (at least 1GB free)
    4. **Photo Size:** Try uploading smaller photos (under 10MB each)
    5. **Network Connection:** Ensure you have a stable internet connection

    **If the issue persists:**
    - Try uploading one photo at a time instead of multiple
    - Clear the app cache in your device settings
    - Restart your device

    If none of these steps resolve the issue, please let me know your device type and OS version, and I'll escalate this to our technical team for further investigation.
    """.strip(),
    ),
]

if __name__ == "__main__":
    # Create agent with few-shot learning
    agent = Agent(
        name="Customer Support Specialist",
        model=OpenAIChat(id="gpt-5-mini"),
        add_name_to_context=True,
        additional_input=support_examples,  # few-shot learning examples
        instructions=[
            "You are an expert customer support specialist.",
            "Always be empathetic, professional, and solution-oriented.",
            "Provide clear, actionable steps to resolve customer issues.",
            "Follow the established patterns for consistent, high-quality support.",
        ],
        markdown=True,
    )

    for i, example in enumerate(support_examples, 1):
        print(f"üìû Example {i}: {example}")
        print("-" * 50)
        agent.print_response(example)
```

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/context_management/)


# Custom Loggers
Source: https://docs.agno.com/concepts/agents/custom-logger

Learn how to use custom loggers in your Agno setup.

You can provide your own loggers to Agno, to be used instead of the default ones.

This can be useful if you need your system to log in any specific format.

## Specifying a custom logger

```python
import logging

from agno.agent import Agent
from agno.utils.log import configure_agno_logging, log_info


# Setting up a custom logger
custom_logger = logging.getLogger("custom_logger")
handler = logging.StreamHandler()
formatter = logging.Formatter("[CUSTOM_LOGGER] %(levelname)s: %(message)s")
handler.setFormatter(formatter)
custom_logger.addHandler(handler)
custom_logger.setLevel(logging.INFO)  # Set level to INFO to show info messages
custom_logger.propagate = False


# Configure Agno to use our custom logger. It will be used for all logging.
configure_agno_logging(custom_default_logger=custom_logger)

# Every use of the logging function in agno.utils.log will now use our custom logger.
log_info("This is using our custom logger!")

# Now let's setup an Agent and run it.
# All logging coming from the Agent will use our custom logger.
agent = Agent()
agent.print_response("What can I do to improve my sleep?")
```

## Multiple Loggers

Notice that you can also configure different loggers for your Agents, Teams and Workflows:

```python
configure_agno_logging(
    custom_default_logger=custom_agent_logger,
    custom_agent_logger=custom_agent_logger,
    custom_team_logger=custom_team_logger,
    custom_workflow_logger=custom_workflow_logger,
)
```

## Using Named Loggers

As it's conventional in Python, you can also provide custom loggers just by setting loggers with specific names. This is useful if you want to set them up using configuration files.

* `agno.agent` will be used for all Agent logs
* `agno.team` will be used for all Team logs
* `agno.workflow` will be used for all Workflow logs

These loggers will be automatically picked up if they are set.


# Dependencies
Source: https://docs.agno.com/concepts/agents/dependencies

Learn how to use dependencies in your agents.

**Dependencies** is a way to inject variables into your Agent Context. `dependencies` is a dictionary that contains a set of functions (or static variables) that are resolved before the agent runs.

<Note>
  You can use dependencies to inject memories, dynamic few-shot examples, "retrieved" documents, etc.
</Note>

## Basic usage

You can reference the dependencies in your agent instructions or user message.

```python dependencies.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    dependencies={"name": "John Doe"},
    instructions="You are a story writer. The current user is {name}."
)

agent.print_response("Write a 5 second short story about {name}")
```

<Tip>
  You can set `dependencies` on `Agent` initialization, or pass it to the `run()` and `arun()` methods.
</Tip>

## Using functions as dependencies

You can specify a callable function as a dependency. The dependency will be automatically resolved by the agent at runtime.

```python dependencies.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_top_hackernews_stories() -> str:
    """Fetch and return the top stories from HackerNews.

    Args:
        num_stories: Number of top stories to retrieve (default: 5)
    Returns:
        JSON string containing story details (title, url, score, etc.)
    """
    # Get top stories
    stories = [
        {
            k: v
            for k, v in httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{id}.json"
            )
            .json()
            .items()
            if k != "kids"  # Exclude discussion threads
        }
        for id in httpx.get(
            "https://hacker-news.firebaseio.com/v0/topstories.json"
        ).json()[:num_stories]
    ]
    return json.dumps(stories, indent=4)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Each function in the dependencies is evaluated when the agent is run,
    # think of it as dependency injection for Agents
    dependencies={"top_hackernews_stories": get_top_hackernews_stories},
    # Alternatively, you can manually add the context to the instructions
    instructions=dedent("""\
        You are an insightful tech trend observer! üì∞

        Here are the top stories on HackerNews:
        {top_hackernews_stories}\
    """),
    markdown=True,
)

# Example usage
agent.print_response(
    "Summarize the top stories on HackerNews and identify any interesting trends.",
    stream=True,
)
```

<Check>
  Dependencies are automatically resolved when the agent is run.
</Check>

## Adding dependencies to context

Set `add_dependencies_to_context=True` to add the entire list of dependencies to the user message. This way you don't have to manually add the dependencies to the instructions.

```python dependencies_instructions.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_user_profile() -> str:
    """Fetch and return the user profile for a given user ID.

    Args:
        user_id: The ID of the user to retrieve the profile for
    """

    # Get the user profile from the database (this is a placeholder)
    user_profile = {
      "name": "John Doe",
      "experience_level": "senior",
    }

    return json.dumps(user_profile, indent=4)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    dependencies={"user_profile": get_user_profile},
    # We can add the entire dependencies dictionary to the user message
    add_dependencies_to_context=True,
    markdown=True,
)

agent.print_response(
    "Get the user profile for the user with ID 123 and tell me about their experience level.",
    stream=True,
)
# Optionally pass the dependencies to the print_response method
# agent.print_response(
#     "Get the user profile for the user with ID 123 and tell me about their experience level.",
#     dependencies={"user_profile": get_user_profile},
#     stream=True,
# )
```

<Note>
  This adds the entire dependencies dictionary to the user message between `<additional context>` tags.
  The new user message looks like this:

  ```
  Get the user profile for the user with ID 123 and tell me about their experience level.                                                       
                                                                                                                                                 
  <additional context>                                                                                                                     
  {                                                                                                                                        
  "user_profile": "{\n    \"name\": \"John Doe\",\n    \"experience_level\": \"senior\"\n}"                                              
  }                                                                                                                                        
  </additional context> 
  ```
</Note>

<Tip>
  You can pass `dependencies` and `add_dependencies_to_context` to the `run`, `arun`, `print_response` and `aprint_response` methods.
</Tip>

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/dependencies/)


# Input and Output
Source: https://docs.agno.com/concepts/agents/input-output

Learn how to use structured input and output with Agents for reliable, production-ready systems.

Agno Agents supports various forms of input and output, from simple string-based interactions to structured data validation using Pydantic models.

The most standard pattern is to use `str` input and `str` output:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You write movie scripts.",
)

response = agent.run("Write movie script about a girl living in New York")
print(response.content)
```

<Note>
  For more advanced patterns, see:

  * [Images / Audio / Video / Files as Input](/examples/concepts/multimodal/overview)
  * [List as Input](/examples/concepts/agent/input_and_output/input_as_list)
</Note>

## Structured Output

One of our favorite features is using Agents to generate structured data (i.e. a pydantic model). This is generally called "Structured Output". Use this feature to extract features, classify data, produce fake data etc. The best part is that they work with function calls, knowledge bases and all other features.

Structured output makes agents reliable for production systems that need consistent, predictable response formats instead of unstructured text.

Let's create a Movie Agent to write a `MovieScript` for us.

<Steps>
  <Step title="Structured Output example">
    ```python movie_agent.py
    from typing import List
    from rich.pretty import pprint
    from pydantic import BaseModel, Field
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat

    class MovieScript(BaseModel):
        setting: str = Field(..., description="Provide a nice setting for a blockbuster movie.")
        ending: str = Field(..., description="Ending of the movie. If not available, provide a happy ending.")
        genre: str = Field(
            ..., description="Genre of the movie. If not available, select action, thriller or romantic comedy."
        )
        name: str = Field(..., description="Give a name to this movie")
        characters: List[str] = Field(..., description="Name of characters for this movie.")
        storyline: str = Field(..., description="3 sentence storyline for the movie. Make it exciting!")

    # Agent that uses structured outputs
    structured_output_agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        description="You write movie scripts.",
        output_schema=MovieScript,
    )

    structured_output_agent.print_response("New York")
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python movie_agent.py
    ```
  </Step>
</Steps>

The output is an object of the `MovieScript` class, here's how it looks:

```python
MovieScript(
‚îÇ   setting='In the bustling streets and iconic skyline of New York City.',
‚îÇ   ending='Isabella and Alex, having narrowly escaped the clutches of the Syndicate, find themselves standing at the top of the Empire State Building. As the glow of the setting sun bathes the city, they share a victorious kiss. Newly emboldened and as an unstoppable duo, they vow to keep NYC safe from any future threats.',
‚îÇ   genre='Action Thriller',
‚îÇ   name='The NYC Chronicles',
‚îÇ   characters=['Isabella Grant', 'Alex Chen', 'Marcus Kane', 'Detective Ellie Monroe', 'Victor Sinclair'],
‚îÇ   storyline='Isabella Grant, a fearless investigative journalist, uncovers a massive conspiracy involving a powerful syndicate plotting to control New York City. Teaming up with renegade cop Alex Chen, they must race against time to expose the culprits before the city descends into chaos. Dodging danger at every turn, they fight to protect the city they love from imminent destruction.'
)
```

<Tip>
  Some LLMs are not able to generate structured output. Agno has an option to tell the model to respond as JSON. Although this is typically not as accurate as structured output, it can be useful in some cases.

  If you want to use JSON mode, you can set `use_json_mode=True` on the Agent.

  ```python
  agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
  )
  ```
</Tip>

### Streaming Structured Output

Streaming can be used in combination with `output_schema`. This returns the structured output as a single `RunContent` event in the stream of events.

<Steps>
  <Step title="Streaming Structured Output example">
    ```python streaming_agent.py
    import asyncio
    from typing import Dict, List

    from agno.agent import Agent
    from agno.models.openai.chat import OpenAIChat
    from pydantic import BaseModel, Field


    class MovieScript(BaseModel):
        setting: str = Field(
            ..., description="Provide a nice setting for a blockbuster movie."
        )
        ending: str = Field(
            ...,
            description="Ending of the movie. If not available, provide a happy ending.",
        )
        genre: str = Field(
            ...,
            description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
        )
        name: str = Field(..., description="Give a name to this movie")
        characters: List[str] = Field(..., description="Name of characters for this movie.")
        storyline: str = Field(
            ..., description="3 sentence storyline for the movie. Make it exciting!"
        )
        rating: Dict[str, int] = Field(
            ...,
            description="Your own rating of the movie. 1-10. Return a dictionary with the keys 'story' and 'acting'.",
        )


    # Agent that uses structured outputs with streaming
    structured_output_agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        description="You write movie scripts.",
        output_schema=MovieScript,
    )

    structured_output_agent.print_response(
        "New York", stream=True, stream_intermediate_steps=True
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python streaming_agent.py
    ```
  </Step>
</Steps>

## Structured Input

An agent can be provided with structured input (i.e a pydantic model or a `TypedDict`) by passing it in the `Agent.run()` or `Agent.print_response()` as the `input` parameter.

<Steps>
  <Step title="Structured Input example">
    ```python
    from typing import List

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.hackernews import HackerNewsTools
    from pydantic import BaseModel, Field


    class ResearchTopic(BaseModel):
        """Structured research topic with specific requirements"""

        topic: str
        focus_areas: List[str] = Field(description="Specific areas to focus on")
        target_audience: str = Field(description="Who this research is for")
        sources_required: int = Field(description="Number of sources needed", default=5)

    hackernews_agent = Agent(
        name="Hackernews Agent",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[HackerNewsTools()],
        role="Extract key insights and content from Hackernews posts",
    )

    hackernews_agent.print_response(
        input=ResearchTopic(
            topic="AI",
            focus_areas=["AI", "Machine Learning"],
            target_audience="Developers",
            sources_required=5,
        )
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python structured_input_agent.py
    ```
  </Step>
</Steps>

### Validating the input

You can set `input_schema` on the Agent to validate the input. If you then pass the input as a dictionary, it will be automatically validated against the schema.

<Steps>
  <Step title="Validating the input example">
    ```python validating_input_agent.py
    from typing import List

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.hackernews import HackerNewsTools
    from pydantic import BaseModel, Field


    class ResearchTopic(BaseModel):
        """Structured research topic with specific requirements"""

        topic: str
        focus_areas: List[str] = Field(description="Specific areas to focus on")
        target_audience: str = Field(description="Who this research is for")
        sources_required: int = Field(description="Number of sources needed", default=5)


    # Define agents
    hackernews_agent = Agent(
        name="Hackernews Agent",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[HackerNewsTools()],
        role="Extract key insights and content from Hackernews posts",
        input_schema=ResearchTopic,
    )

    # Pass a dict that matches the input schema
    hackernews_agent.print_response(
        input={
            "topic": "AI",
            "focus_areas": ["AI", "Machine Learning"],
            "target_audience": "Developers",
            "sources_required": "5",
        }
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python validating_input_agent.py
    ```
  </Step>
</Steps>

## Typesafe Agents

When you combine both `input_schema` and `output_schema`, you create a **typesafe agent** with end-to-end type safety - a fully validated data pipeline from input to output.

### Complete Typesafe Research Agent

Here's a comprehensive example showing a fully typesafe agent for research tasks:

<Steps>
  <Step title="Create the typesafe research agent">
    ```python typesafe_research_agent.py
    from typing import List

    from agno.agent import Agent
    from agno.models.anthropic import Claude
    from agno.tools.hackernews import HackerNewsTools
    from pydantic import BaseModel, Field
    from rich.pretty import pprint


    # Define your input schema
    class ResearchTopic(BaseModel):
        topic: str
        sources_required: int = Field(description="Number of sources", default=5)


    # Define your output schema
    class ResearchOutput(BaseModel):
        summary: str = Field(..., description="Executive summary of the research")
        insights: List[str] = Field(..., description="Key insights from posts")
        top_stories: List[str] = Field(
            ..., description="Most relevant and popular stories found"
        )
        technologies: List[str] = Field(
            ..., description="Technologies mentioned"
        )
        sources: List[str] = Field(..., description="Links to the most relevant posts")


    # Define your agent
    hn_researcher_agent = Agent(
        # Model to use
        model=Claude(id="claude-sonnet-4-0"),
        # Tools to use
        tools=[HackerNewsTools()],
        instructions="Research hackernews posts for a given topic",
        # Add your input schema
        input_schema=ResearchTopic,
        # Add your output schema
        output_schema=ResearchOutput,
    )

    # Run the Agent
    response = hn_researcher_agent.run(
        input=ResearchTopic(topic="AI", sources_required=5)
    )

    # Print the response
    pprint(response.content)
    ```
  </Step>

  <Step title="Run the agent">
    Install libraries

    ```shell
    pip install agno anthropic
    ```

    Set your API key

    ```shell
    export ANTHROPIC_API_KEY=xxx
    ```

    Run the agent

    ```shell
    python typesafe_research_agent.py
    ```
  </Step>
</Steps>

The output is a structured `ResearchOutput` object:

```python
ResearchOutput(
    summary='AI development is accelerating with new breakthroughs in...',
    insights=['LLMs are becoming more efficient', 'Open source models gaining traction'],
    top_stories=['GPT-5 rumors surface', 'New Claude model released'],
    technologies=['GPT-4', 'Claude', 'Transformers'],
    sources=['https://news.ycombinator.com/item?id=123', '...']
)
```

## Using a Parser Model

You can use a different model to parse and structure the output from your primary model.
This approach is particularly effective when the primary model is optimized for reasoning tasks, as such models may not consistently produce detailed structured responses.

```python
agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),  # The main processing model
    description="You write movie scripts.",
    output_schema=MovieScript,
    parser_model=OpenAIChat(id="gpt-5-mini"),  # Only used to parse the output
)
```

<Tip>
  Using a parser model can improve output reliability and reduce costs since you can use a smaller, faster model for formatting while keeping a powerful model for the actual response.
</Tip>

You can also provide a custom `parser_model_prompt` to your Parser Model to customize the model's instructions.

## Using an Output Model

You can use a different model to produce the run output of the agent.
This is useful when the primary model is optimized for image analysis, for example, but you want a different model to produce a structured output response.

```python
agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),  # The main processing model
    description="You write movie scripts.",
    output_schema=MovieScript,
    output_model=OpenAIChat(id="gpt-5-mini"),  # Only used to parse the output
)
```

You can also provide a custom `output_model_prompt` to your Output Model to customize the model's instructions.

<Tip>
  Gemini models often reject requests to use tools and produce structured output
  at the same time. Using an Output Model is an effective workaround for this.
</Tip>

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/input_and_output/)


# Agents
Source: https://docs.agno.com/concepts/agents/introduction

Learn about Agno Agents and how they work.

**Agents** at Agno are the building blocks of your agentic system. They are autonomous AI programs that dynamically determine their course of action using a **large language model** (LLM).

The core components of an Agent are:

* **Model:** The LLM that controls the flow of execution. It decides whether to reason, act or respond.
* **Instructions:** How we program the Agent, teaching it how to use tools and respond. This forms part of the "context" of the Agent.
* **Tools:** Enable an Agent to take actions and interact with external systems.
* **Reasoning:** Enables Agents to "think" before responding and "analyze" the results of their actions (i.e. tool calls), this improves reliability and quality of responses.
* **Knowledge:** Domain-specific information that the Agent can **search at runtime** to make better decisions and provide accurate responses (Retrieval-Augmented Generation, or RAG).
* **Storage:** Used by Agents to save session history and state in a database. Model APIs are stateless and storage enables us to continue conversations from where they left off. This enables multi-turn, long-term conversations with Agents.
* **Memory:** Gives Agents the ability to store and recall information from previous interactions, allowing them to learn user preferences and personalize their responses.

<Tip>
  If this is your first time building agents, [start here](/introduction/quickstart) before diving into advanced concepts.
</Tip>

## Guides

<CardGroup cols={2}>
  <Card title="Building your Agent" icon="wrench" iconType="duotone" href="/concepts/agents/building-your-agent">
    Learn how to run your agents.
  </Card>

  <Card title="Running your Agent" icon="user-robot" iconType="duotone" href="/concepts/agents/running-your-agent">
    Learn how to run your agents.
  </Card>

  <Card title="Agent Sessions" icon="comments" iconType="duotone" href="/concepts/agents/sessions">
    Learn about agent sessions.
  </Card>

  <Card title="Input & Output" icon="fire" iconType="duotone" href="/concepts/agents/input-output">
    Learn about input and output for agents.
  </Card>

  <Card title="Context Engineering" icon="file-lines" iconType="duotone" href="/concepts/agents/context">
    Learn about context engineering.
  </Card>

  <Card title="Dependencies" icon="brackets-curly" iconType="duotone" href="/concepts/agents/dependencies">
    Learn about dependency injection in your agent's context.
  </Card>

  <Card title="Agent State" icon="crystal-ball" iconType="duotone" href="/concepts/agents/state">
    Learn about managing agent state.
  </Card>

  <Card title="Agent Storage" icon="database" iconType="duotone" href="/concepts/agents/storage">
    Learn about session storage.
  </Card>

  <Card title="Memory" icon="head-side-brain" iconType="duotone" href="/concepts/agents/memory">
    Learn about adding memory to your agents.
  </Card>

  <Card title="Knowledge" icon="books" iconType="duotone" href="/concepts/agents/knowledge">
    Learn about knowledge in agents.
  </Card>

  <Card title="Tools" icon="wrench" iconType="duotone" href="/concepts/agents/tools">
    Learn about adding tools to your agents.
  </Card>

  <Card title="Agent Metrics" icon="chart-line" iconType="duotone" href="/concepts/agents/metrics">
    Learn how to track agent metrics.
  </Card>
</CardGroup>

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/README.md)


# Knowledge
Source: https://docs.agno.com/concepts/agents/knowledge

Understanding knowledge and how to use it with Agno agents

**Knowledge** stores domain-specific content that can be added to the context of the agent to enable better decision making.

<Note>
  Agno has a generic knowledge solution that supports many forms of content.

  See more details in the [knowledge](/concepts/knowledge/introduction) documentation.
</Note>

The Agent can **search** this knowledge at runtime to make better decisions and provide more accurate responses. This **searching on demand** pattern is called Agentic RAG.

<Tip>
  Example: Say we are building a Text2Sql Agent, we'll need to give the table schemas, column names, data types, example queries, etc to the agent to help it generate the best-possible SQL query.

  It is not viable to put this all in the system message, instead we store this information as knowledge and let the Agent query it at runtime.

  Using this information, the Agent can then generate the best-possible SQL query. This is called **dynamic few-shot learning**.
</Tip>

## Knowledge for Agents

Agno Agents use **Agentic RAG** by default, meaning when we provide `knowledge` to an Agent, it will search this knowledge base, at runtime, for the specific information it needs to achieve its task.

For example:

```python
import asyncio

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db = PostgresDb(
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    knowledge_table="knowledge_contents",
)

# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    contents_db=db,
    vector_db=PgVector(
        table_name="vectors",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        embedder=OpenAIEmbedder(),
    ),
)
# Add from URL to the knowledge base
asyncio.run(
    knowledge.add_content_async(
        name="Recipes",
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        metadata={"user_tag": "Recipes from website"},
    )
)

agent = Agent(
    name="My Agent",
    description="Agno 2.0 Agent Implementation",
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "How do I make chicken and galangal in coconut milk soup?",
    markdown=True,
)
```

We can give our agent access to the knowledge base in the following ways:

* We can set `search_knowledge=True` to add a `search_knowledge_base()` tool to the Agent. `search_knowledge` is `True` **by default** if you add `knowledge` to an Agent.
* We can set `add_knowledge_to_context=True` to automatically add references from the knowledge base to the Agent's context, based in your user message. This is the traditional RAG approach.

## Custom knowledge retrieval

If you need complete control over the knowledge base search, you can pass your own `knowledge_retriever` function with the following signature:

```python
def knowledge_retriever(agent: Agent, query: str, num_documents: Optional[int], **kwargs) -> Optional[list[dict]]:
  ...
```

Example of how to configure an agent with a custom retriever:

```python
def knowledge_retriever(agent: Agent, query: str, num_documents: Optional[int], **kwargs) -> Optional[list[dict]]:
  ...

agent = Agent(
    knowledge_retriever=knowledge_retriever,
    search_knowledge=True,
)
```

This function is called during `search_knowledge_base()` and is used by the Agent to retrieve references from the knowledge base.

<Tip>
  Async retrievers are supported. Simply create an async function and pass it to
  the `knowledge_retriever` parameter.
</Tip>

## Knowledge storage

Knowledge content is tracked in a "Contents DB" and vectorized and stored in a "Vector DB".

### Contents database

The Contents DB is a database that stores the name, description, metadata and other information for any content you add to the knowledge base.

Below is the schema for the Contents DB:

| Field            | Type   | Description                                                                                         |
| ---------------- | ------ | --------------------------------------------------------------------------------------------------- |
| `id`             | `str`  | The unique identifier for the knowledge content.                                                    |
| `name`           | `str`  | The name of the knowledge content.                                                                  |
| `description`    | `str`  | The description of the knowledge content.                                                           |
| `metadata`       | `dict` | The metadata for the knowledge content.                                                             |
| `type`           | `str`  | The type of the knowledge content.                                                                  |
| `size`           | `int`  | The size of the knowledge content. Applicable only to files.                                        |
| `linked_to`      | `str`  | The ID of the knowledge content that this content is linked to.                                     |
| `access_count`   | `int`  | The number of times this content has been accessed.                                                 |
| `status`         | `str`  | The status of the knowledge content.                                                                |
| `status_message` | `str`  | The message associated with the status of the knowledge content.                                    |
| `created_at`     | `int`  | The timestamp when the knowledge content was created.                                               |
| `updated_at`     | `int`  | The timestamp when the knowledge content was last updated.                                          |
| `external_id`    | `str`  | The external ID of the knowledge content. Used when external vector stores are used, like LightRAG. |

This data is best displayed on the [knowledge page of the AgentOS UI](https://os.agno.com/knowledge).

### Vector databases

Vector databases offer the best solution for retrieving relevant results from dense information quickly.

### Adding contents

The typical way content is processed when being added to the knowledge base is:

<Steps>
  <Step title="Parse the content">
    A reader is used to parse the content based on the type of content that is
    being inserted
  </Step>

  <Step title="Chunk the information">
    The content is broken down into smaller chunks to ensure our search query
    returns only relevant results.
  </Step>

  <Step title="Embed each chunk">
    The chunks are converted into embedding vectors and stored in a vector
    database.
  </Step>
</Steps>

For example, to add a PDF to the knowledge base:

```python
...
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    vector_db=vector_db,
    contents_db=contents_db,
)

asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"user_tag": "Engineering Candidates"},
    )
)
```

<Tip>
  See more details on [Loading the Knowledge
  Base](/concepts/knowledge/introduction#loading-the-knowledge).
</Tip>

<Note>
  Knowledge filters are currently supported on the following knowledge base
  types: <b>PDF</b>, <b>PDF\_URL</b>, <b>Text</b>, <b>JSON</b>, and <b>DOCX</b>.
  For more details, see the [Knowledge Filters
  documentation](/concepts/knowledge/filters/introduction).
</Note>

## Example: Agentic RAG Agent

Let's build a **RAG Agent** that answers questions from a PDF.

<Steps>
  <Step title="Set up the database">
    Let's use `Postgres` as both our contents and vector databases.

    Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **Postgres** on port **5532** using:

    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```

    <Note>
      This docker container contains a general purpose Postgres database with the `pgvector` extension installed.
    </Note>

    Install required packages:

    <CodeGroup>
      ```bash Mac
      pip install -U pgvector pypdf psycopg sqlalchemy
      ```

      ```bash Windows
      pip install -U pgvector pypdf psycopg sqlalchemy
      ```
    </CodeGroup>
  </Step>

  <Step title="Do agentic RAG">
    Create a file `agentic_rag.py` with the following contents

    ```python agentic_rag.py
    import asyncio
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.pgvector import PgVector

    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

    db = PostgresDb(
        db_url=db_url,
        knowledge_table="knowledge_contents",
    )

    knowledge = Knowledge(
        contents_db=db,
        vector_db=PgVector(
            table_name="recipes",
            db_url=db_url,
        )
    )

    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        db=db,
        knowledge=knowledge,
        markdown=True,
    )
    if __name__ == "__main__":
        asyncio.run(
            knowledge.add_content_async(
                name="Recipes",
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
                metadata={"user_tag": "Recipes from website"}
            )
        )
        # Create and use the agent
        asyncio.run(
            agent.aprint_response(
                "How do I make chicken and galangal in coconut milk soup?",
                markdown=True,
            )
        )
    ```
  </Step>

  <Step title="Run the agent">
    Run the agent

    ```python
    python agentic_rag.py
    ```
  </Step>
</Steps>

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View the [Knowledge schema](/reference/knowledge/knowledge)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/)


# Memory
Source: https://docs.agno.com/concepts/agents/memory

Memory gives an Agent the ability to recall information about the user.

Memory is a part of the Agent's context that helps it provide the best, most personalized response.

<Tip>
  If the user tells the Agent they like to ski, then future responses can reference this information to provide a more personalized experience.
</Tip>

## User Memories

Here's a simple example of using Memory in an Agent.

```python memory_demo.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.postgres import PostgresDb
from rich.pretty import pprint

user_id = "ava"

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(
  db_url=db_url,
  memory_table="user_memories",  # Optionally specify a table name for the memories
)


# Initialize Agent
memory_agent = Agent(
    model=OpenAIChat(id="gpt-4.1"),
    db=db,
    # Give the Agent the ability to update memories
    enable_agentic_memory=True,
    # OR - Run the MemoryManager automatically after each response
    enable_user_memories=True,
    markdown=True,
)

db.clear_memories()

memory_agent.print_response(
    "My name is Ava and I like to ski.",
    user_id=user_id,
    stream=True,
    stream_intermediate_steps=True,
)
print("Memories about Ava:")
pprint(memory_agent.get_user_memories(user_id=user_id))

memory_agent.print_response(
    "I live in san francisco, where should i move within a 4 hour drive?",
    user_id=user_id,
    stream=True,
    stream_intermediate_steps=True,
)
print("Memories about Ava:")
pprint(memory_agent.get_user_memories(user_id=user_id))
```

<Tip>
  `enable_agentic_memory=True` gives the Agent a tool to manage memories of the
  user, this tool passes the task to the `MemoryManager` class. You may also set
  `enable_user_memories=True` which always runs the `MemoryManager` after each
  user message.
</Tip>

<Note>
  Read more about Memory in the [Memory Overview](/concepts/memory/overview) page.
</Note>

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Examples](/examples/concepts/memory)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/memory/)


# Metrics
Source: https://docs.agno.com/concepts/agents/metrics

Understanding agent run and session metrics in Agno

When you run an agent in Agno, the response you get (**RunOutput**) includes detailed metrics about the run. These metrics help you understand resource usage (like **token usage** and **time**), performance, and other aspects of the model and tool calls.

Metrics are available at multiple levels:

* **Per message**: Each message (assistant, tool, etc.) has its own metrics.
* **Per run**: Each `RunOutput` has its own metrics.
* **Per session**: The `AgentSession` contains aggregated `session_metrics` that are the sum of all `RunOutput.metrics` for the session.

## Example Usage

Suppose you have an agent that performs some tasks and you want to analyze the metrics after running it. Here's how you can access and print the metrics:

You run the following code to create an agent and run it with the following configuration:

```python
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.db.sqlite import SqliteDb
from rich.pretty import pprint

agent = Agent(
    model=Gemini(id="gemini-2.5-flash"),
    tools=[DuckDuckGoTools()],
    db=SqliteDb(db_file="tmp/agents.db"),
    markdown=True,
)

run_response = agent.run(
    "What is current news in the world?"
)

# Print metrics per message
if run_response.messages:
    for message in run_response.messages:
        if message.role == "assistant":
            if message.content:
                print(f"Message: {message.content}")
            elif message.tool_calls:
                print(f"Tool calls: {message.tool_calls}")
            print("---" * 5, "Metrics", "---" * 5)
            pprint(message.metrics.to_dict())
            print("---" * 20)

# Print the aggregated metrics for the whole run
print("---" * 5, "Run Metrics", "---" * 5)
pprint(run_response.metrics.to_dict())
# Print the aggregated metrics for the whole session
print("---" * 5, "Session Metrics", "---" * 5)
pprint(agent.get_session_metrics().to_dict())
```

You'll see the outputs with following information:

* `input_tokens`: The number of tokens sent to the model.
* `output_tokens`: The number of tokens received from the model.
* `total_tokens`: The sum of `input_tokens` and `output_tokens`.
* `audio_input_tokens`: The number of tokens sent to the model for audio input.
* `audio_output_tokens`: The number of tokens received from the model for audio output.
* `audio_total_tokens`: The sum of `audio_input_tokens` and `audio_output_tokens`.
* `cache_read_tokens`: The number of tokens read from the cache.
* `cache_write_tokens`: The number of tokens written to the cache.
* `reasoning_tokens`: The number of tokens used for reasoning.
* `duration`: The duration of the run in seconds.
* `time_to_first_token`: The time taken until the first token was generated.
* `provider_metrics`: Any provider-specific metrics.

## Developer Resources

* View the [RunOutput schema](/reference/agents/run-response)
* View the [Metrics schema](/reference/agents/metrics)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/other/agent_metrics.py)


# Multimodal Agents
Source: https://docs.agno.com/concepts/agents/multimodal



Agno agents support text, image, audio, video and files inputs and can generate text, image, audio, video and files as output.

For a complete overview of multimodal support, please checkout the [multimodal](/concepts/multimodal/overview) documentation.

<Tip>
  Not all models support multimodal inputs and outputs.
  To see which models support multimodal inputs and outputs, please checkout the [compatibility matrix](/concepts/models/compatibility).
</Tip>

## Multimodal inputs to an agent

Let's create an agent that can understand images and make tool calls as needed

### Image Agent

```python image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

Run the agent:

```shell
python image_agent.py
```

Similar to images, you can also use audio and video as an input.

### Audio Agent

```python audio_agent.py
import base64

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-audio-preview", modalities=["text"]),
    markdown=True,
)
agent.print_response(
    "What is in this audio?", audio=[Audio(content=wav_data, format="wav")]
)
```

### Video Agent

<Note>Currently Agno only supports video as an input for Gemini models.</Note>

```python video_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

# Please download "GreatRedSpot.mp4" using
# wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
video_path = Path(__file__).parent.joinpath("GreatRedSpot.mp4")

agent.print_response("Tell me about this video", videos=[Video(filepath=video_path)])
```

## Multimodal outputs from an agent

Similar to providing multimodal inputs, you can also get multimodal outputs from an agent.

### Image Generation

The following example demonstrates how to generate an image using DALL-E with an agent.

```python image_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools

image_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DalleTools()],
    description="You are an AI agent that can generate images using DALL-E.",
    instructions="When the user asks you to create an image, use the `create_image` tool to create the image.",
    markdown=True,
)

image_agent.print_response("Generate an image of a white siamese cat")

images = image_agent.get_images()
if images and isinstance(images, list):
    for image_response in images:
        image_url = image_response.url
        print(image_url)
```

### Audio Response

The following example demonstrates how to obtain both text and audio responses from an agent. The agent will respond with text and audio bytes that can be saved to a file.

```python audio_agent.py
from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)
response: RunOutput = agent.run("Tell me a 5 second scary story")

# Save the response audio to a file
if response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/scary_story.wav"
    )
```

## Multimodal inputs and outputs together

You can create Agents that can take multimodal inputs and return multimodal outputs. The following example demonstrates how to provide a combination of audio and text inputs to an agent and obtain both text and audio outputs.

### Audio input and Audio output

```python audio_agent.py
import base64

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)

agent.run("What's in these recording?", audio=[Audio(content=wav_data, format="wav")])

if agent.run_response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/result.wav"
    )
```


# Cancelling a Run
Source: https://docs.agno.com/concepts/agents/run-cancel

Learn how to cancel an Agent run.

You can cancel a running agent by using the `agent.cancel_run()` function on the agent.

Below is a basic example that starts an agent run in a thread and cancels it from another thread, simulating how it can be done via an API. This is supported via [AgentOS](/agent-os/api#cancelling-a-run) as well.

```python
import threading
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent
from agno.run.base import RunStatus


def long_running_task(agent: Agent, run_id_container: dict):
    """
    Simulate a long-running agent task that can be cancelled.
    """
    # Start the agent run - this simulates a long task
    final_response = None
    content_pieces = []

    for chunk in agent.run(
        "Write a very long story about a dragon who learns to code. "
        "Make it at least 2000 words with detailed descriptions and dialogue. "
        "Take your time and be very thorough.",
        stream=True,
    ):
        if "run_id" not in run_id_container and chunk.run_id:
            run_id_container["run_id"] = chunk.run_id

        if chunk.event == RunEvent.run_content:
            print(chunk.content, end="", flush=True)
            content_pieces.append(chunk.content)
        # When the run is cancelled, a `RunEvent.run_cancelled` event is emitted
        elif chunk.event == RunEvent.run_cancelled:
            print(f"\nüö´ Run was cancelled: {chunk.run_id}")
            run_id_container["result"] = {
                "status": "cancelled",
                "run_id": chunk.run_id,
                "cancelled": True,
                "content": "".join(content_pieces)[:200] + "..."
                if content_pieces
                else "No content before cancellation",
            }
            return
        elif hasattr(chunk, "status") and chunk.status == RunStatus.completed:
            final_response = chunk

    # If we get here, the run completed successfully
    if final_response:
        run_id_container["result"] = {
            "status": final_response.status.value
            if final_response.status
            else "completed",
            "run_id": final_response.run_id,
            "cancelled": final_response.status == RunStatus.cancelled,
            "content": ("".join(content_pieces)[:200] + "...")
            if content_pieces
            else "No content",
        }
    else:
        run_id_container["result"] = {
            "status": "unknown",
            "run_id": run_id_container.get("run_id"),
            "cancelled": False,
            "content": ("".join(content_pieces)[:200] + "...")
            if content_pieces
            else "No content",
        }



def cancel_after_delay(agent: Agent, run_id_container: dict, delay_seconds: int = 3):
    """
    Cancel the agent run after a specified delay.
    """
    print(f"‚è∞ Will cancel run in {delay_seconds} seconds...")
    time.sleep(delay_seconds)

    run_id = run_id_container.get("run_id")
    if run_id:
        print(f"üö´ Cancelling run: {run_id}")
        success = agent.cancel_run(run_id)
        if success:
            print(f"‚úÖ Run {run_id} marked for cancellation")
        else:
            print(
                f"‚ùå Failed to cancel run {run_id} (may not exist or already completed)"
            )
    else:
        print("‚ö†Ô∏è  No run_id found to cancel")


def main():
    # Initialize the agent with a model
    agent = Agent(
        name="StorytellerAgent",
        model=OpenAIChat(id="gpt-5-mini"),  # Use a model that can generate long responses
        description="An agent that writes detailed stories",
    )

    print("üöÄ Starting agent run cancellation example...")
    print("=" * 50)

    # Container to share run_id between threads
    run_id_container = {}

    # Start the agent run in a separate thread
    agent_thread = threading.Thread(
        target=lambda: long_running_task(agent, run_id_container), name="AgentRunThread"
    )

    # Start the cancellation thread
    cancel_thread = threading.Thread(
        target=cancel_after_delay,
        args=(agent, run_id_container, 8),  # Cancel after 5 seconds
        name="CancelThread",
    )

    # Start both threads
    print("üèÉ Starting agent run thread...")
    agent_thread.start()

    print("üèÉ Starting cancellation thread...")
    cancel_thread.start()

    # Wait for both threads to complete
    print("‚åõ Waiting for threads to complete...")
    agent_thread.join()
    cancel_thread.join()

    # Print the results
    print("\n" + "=" * 50)
    print("üìä RESULTS:")
    print("=" * 50)

    result = run_id_container.get("result")
    if result:
        print(f"Status: {result['status']}")
        print(f"Run ID: {result['run_id']}")
        print(f"Was Cancelled: {result['cancelled']}")

        if result.get("error"):
            print(f"Error: {result['error']}")
        else:
            print(f"Content Preview: {result['content']}")

        if result["cancelled"]:
            print("\n‚úÖ SUCCESS: Run was successfully cancelled!")
        else:
            print("\n‚ö†Ô∏è  WARNING: Run completed before cancellation")
    else:
        print("‚ùå No result obtained - check if cancellation happened during streaming")

    print("\nüèÅ Example completed!")


if __name__ == "__main__":
    # Run the main example
    main()
```

For a more complete example, see [Cancel a run](https://github.com/agno-agi/agno/tree/main/cookbook/agents/other/cancel_a_run.py).


# Running Agents
Source: https://docs.agno.com/concepts/agents/running-your-agent

Learn how to run an agent and get the response.

The `Agent.run()` function runs the agent and generates a response, either as a `RunOutput` object or a stream of `RunOutputEvent` objects.

## Running Agents

### Basic Execution

Here's how to run your agent. The response is captured in the `response`.

```python
from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

# Run agent and return the response as a variable
response: RunOutput = agent.run("Tell me a 5 second short story about a robot")

# Print the response in markdown format
pprint_run_response(response, markdown=True)
```

<Tip>
  You can also run the agent asynchronously using the `Agent.arun()` method.
  See the [Async Agent](/examples/concepts/agent/async/basic) example.
</Tip>

### Run Input

The `input` parameter is the input to send to the agent. It can be a string, a list, a dictionary, a message, a pydantic model or a list of messages.

For example:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You write movie scripts.",
)

response = agent.run("Write movie script about a girl living in New York")
pprint_run_response(response, markdown=True)
```

<Tip>
  The `pprint_run_response` utility is a helper function that prints the response on your terminal.
</Tip>

For more information, and to see how to use structured input and output with agents, see the [Input & Output](/concepts/agents/input-output) documentation.

### Run Output

The `Agent.run()` function returns a `RunOutput` object when not streaming. Here are some of the core attributes:

* `run_id`: The id of the run.
* `agent_id`: The id of the agent.
* `agent_name`: The name of the agent.
* `session_id`: The id of the session.
* `user_id`: The id of the user.
* `content`: The response content.
* `content_type`: The type of content. In the case of structured output, this will be the class name of the pydantic model.
* `reasoning_content`: The reasoning content.
* `messages`: The list of messages sent to the model.
* `metrics`: The metrics of the run. For more details see [Metrics](/concepts/agents/metrics).
* `model`: The model used for the run.

See detailed documentation in the [RunOutput](/reference/agents/run-response) documentation.

## Streaming Responses

To enable streaming, set `stream=True` when calling `run()`. This will return an iterator of `RunOutputEvent` objects instead of a single response.

```python
from typing import Iterator
from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-4-mini"))

# Run agent and return the response as a stream
response_stream: Iterator[RunOutputEvent] = agent.run(
    "Tell me a 5 second short story about a lion",
    stream=True
)

# Print the response stream in markdown format
pprint_run_response(response_stream, markdown=True)
```

<Tip>
  You can also run the agent asynchronously using the `Agent.arun()` method.
  See the [Async Agent Streaming](/examples/concepts/agent/async/streaming) example.
</Tip>

### Streaming Intermediate Steps

For even more detailed streaming, you can enable intermediate steps by setting `stream_intermediate_steps=True`. This will provide real-time updates about the agent's internal processes.

```python
# Stream with intermediate steps
response_stream: Iterator[RunOutputEvent] = agent.run(
    "Tell me a 5 second short story about a lion",
    stream=True,
    stream_intermediate_steps=True
)
```

### Handling Events

You can process events as they arrive by iterating over the response stream:

```python
response_stream = agent.run("Tell me a 5 second short story about a lion", stream=True, stream_intermediate_steps=True)

for event in response_stream:
    if event.event == "RunContent":
        print(f"Content: {event.content}")
    elif event.event == "ToolCallStarted":
        print(f"Tool call started: {event.tool}")
    elif event.event == "ReasoningStep":
        print(f"Reasoning step: {event.content}")
    ...
```

You can see this behavior in action in the [AgentOS UI](https://os.agno.com/chat/agents).

### Storing Events

You can store all the events that happened during a run on the `RunOutput` object.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), store_events=True)

response = agent.run("Tell me a 5 second short story about a lion", stream=True, stream_intermediate_steps=True)
pprint_run_response(response)

for event in response.events:
    print(event.event)
```

By default the `RunContentEvent` event is not stored (because it would be very verbose). You can modify which events are skipped by setting the `events_to_skip` parameter.

For example:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), store_events=True, events_to_skip=[RunEvent.run_started])
```

### Event Types

The following events are yielded by the `Agent.run()` and `Agent.arun()` functions depending on the agent's configuration:

#### Core Events

| Event Type               | Description                                                                                                    |
| ------------------------ | -------------------------------------------------------------------------------------------------------------- |
| `RunStarted`             | Indicates the start of a run                                                                                   |
| `RunContent`             | Contains the model's response text as individual chunks                                                        |
| `RunIntermediateContent` | Contains the model's intermediate response text as individual chunks. This is used when `output_model` is set. |
| `RunCompleted`           | Signals successful completion of the run                                                                       |
| `RunError`               | Indicates an error occurred during the run                                                                     |
| `RunCancelled`           | Signals that the run was cancelled                                                                             |

#### Control Flow Events

| Event Type     | Description                                  |
| -------------- | -------------------------------------------- |
| `RunPaused`    | Indicates the run has been paused            |
| `RunContinued` | Signals that a paused run has been continued |

#### Tool Events

| Event Type          | Description                                                    |
| ------------------- | -------------------------------------------------------------- |
| `ToolCallStarted`   | Indicates the start of a tool call                             |
| `ToolCallCompleted` | Signals completion of a tool call, including tool call results |

#### Reasoning Events

| Event Type           | Description                                          |
| -------------------- | ---------------------------------------------------- |
| `ReasoningStarted`   | Indicates the start of the agent's reasoning process |
| `ReasoningStep`      | Contains a single step in the reasoning process      |
| `ReasoningCompleted` | Signals completion of the reasoning process          |

#### Memory Events

| Event Type              | Description                                     |
| ----------------------- | ----------------------------------------------- |
| `MemoryUpdateStarted`   | Indicates that the agent is updating its memory |
| `MemoryUpdateCompleted` | Signals completion of a memory update           |

#### Parser Model events

| Event Type                     | Description                                      |
| ------------------------------ | ------------------------------------------------ |
| `ParserModelResponseStarted`   | Indicates the start of the parser model response |
| `ParserModelResponseCompleted` | Signals completion of the parser model response  |

#### Output Model events

| Event Type                     | Description                                      |
| ------------------------------ | ------------------------------------------------ |
| `OutputModelResponseStarted`   | Indicates the start of the output model response |
| `OutputModelResponseCompleted` | Signals completion of the output model response  |

### Custom Events

If you are using your own custom tools, it will often be useful to be able to yield custom events. Your custom events will be yielded together with the rest of the expected Agno events.

We recommend creating your custom event class extending the built-in `CustomEvent` class:

```python
from dataclasses import dataclass
from agno.run.agent import CustomEvent

@dataclass
class CustomerProfileEvent(CustomEvent):
    """CustomEvent for customer profile."""

    customer_name: Optional[str] = None
    customer_email: Optional[str] = None
    customer_phone: Optional[str] = None
```

You can then yield your custom event from your tool. The event will be handled internally as an Agno event, and you will be able to access it in the same way you would access any other Agno event.

```python
from agno.tools import tool

@tool()
async def get_customer_profile():
    """Example custom tool that simply yields a custom event."""

    yield CustomerProfileEvent(
        customer_name="John Doe",
        customer_email="john.doe@example.com",
        customer_phone="1234567890",
    )
```

See the [full example](/examples/concepts/agent/events/custom_events) for more details.

## Options When Running an Agent

### Specify the User and Session

You can specify which user and session to use when running the agent by passing the `user_id` and `session_id` parameters.  This ensures the current run is associated with the correct user and session.

For example:

```python
agent.run("Tell me a 5 second short story about a robot", user_id="john@example.com", session_id="session_123")
```

For more information see the [Agent Sessions](/concepts/agents/sessions) documentation.

### Passing Images / Audio / Video / Files

You can pass images, audio, video, or files to the agent by passing the `images`, `audio`, `video`, or `files` parameters.

For example:

```python
agent.run("Tell me a 5 second short story about this image", images=[Image(url="https://example.com/image.jpg")])
```

For more information see the [Multimodal Agents](/concepts/multimodal) documentation.

### Pausing and Continuing a Run

An agent run can be paused when a human-in-the-loop flow is initiated. You can then continue the execution of the agent by calling the `Agent.continue_run()` method.

See more details in the [Human-in-the-Loop](/concepts/agents/human-in-the-loop) documentation.

### Cancelling a Run

A run can be cancelled by calling the `Agent.cancel_run()` method.

See more details in the [Cancelling a Run](/concepts/agents/run-cancel) documentation.

## Developer Resources

* View the [Agent reference](/reference/agents/agent)
* View the [RunOutput schema](/reference/agents/run-response)
* View [Agent Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/README.md)


# Agent Sessions
Source: https://docs.agno.com/concepts/agents/sessions

Learn about Agent sessions.

When we call `Agent.run()`, it creates a stateless, singular Agent run.

But what if we want to continue this conversation i.e. have a multi-turn conversation? That's where "Sessions" come in. A session is collection of consecutive runs.

In practice, a session is a multi-turn conversation between a user and an Agent. Using a `session_id`, we can connect the conversation history and state across multiple runs.

Here are the core concepts:

* **Session:** A session is collection of consecutive runs like a multi-turn conversation between a user and an Agent. Sessions are identified by a `session_id` and house all runs, metrics, state and other data that belong to the session.
* **Run:** Every interaction (i.e. chat or turn) with an Agent is called a **run**. Runs are identified by a `run_id` and `Agent.run()` creates a new `run_id` when called.
* **Messages:** are the individual messages sent between the model and the Agent. Messages are the communication protocol between the Agent and model.

See [Session Storage](/concepts/agents/storage) for more details on how sessions are stored.

## Single session

Here we have an example where a single run is created with an Agent. A `run_id` is automatically generated, as well as a `session_id` (because we didn't provide one tot yet associated with a user.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

# Run agent and return the response as a variable
response = agent.run("Tell me a 5 second short story about a robot")
print(response.content)
print(response.run_id)
print(response.session_id)
```

## Multi-Turn Sessions

Each user that is interacting with an Agent gets a unique set of sessions and you can have multiple users interacting with the same Agent at the same time.

Set a `user_id` to connect a user to their sessions with the Agent.

In the example below, we set a `session_id` to demo how to have multi-turn conversations with multiple users at the same time.

<Steps>
  <Step title="Multi-user, multi-session example">
    ```python
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.db.sqlite import SqliteDb

    db = SqliteDb(db_file="tmp/data.db")

    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        db=db,
        add_history_to_context=True,
        num_history_runs=3,
    )

    user_1_id = "user_101"
    user_2_id = "user_102"

    user_1_session_id = "session_101"
    user_2_session_id = "session_102"

    # Start the session with user 1
    agent.print_response(
        "Tell me a 5 second short story about a robot.",
        user_id=user_1_id,
        session_id=user_1_session_id,
    )
    # Continue the session with user 1
    agent.print_response("Now tell me a joke.", user_id=user_1_id, session_id=user_1_session_id)

    # Start the session with user 2
    agent.print_response("Tell me about quantum physics.", user_id=user_2_id, session_id=user_2_session_id)

    # Continue the session with user 2
    agent.print_response("What is the speed of light?", user_id=user_2_id, session_id=user_2_session_id)

    # Ask the agent to give a summary of the conversation, this will use the history from the previous messages (but only for user 1)
    agent.print_response(
        "Give me a summary of our conversation.",
        user_id=user_1_id,
        session_id=user_1_session_id,
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install agno openai
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python multi_user_multi_session.py
    ```
  </Step>
</Steps>

<Note>
  For session history and management, you need to have a database assigned to the agent. See [Storage](/concepts/db/overview) for more details.
</Note>

### History in Context

As in the example above, we can add the history of the conversation to the context using `add_history_to_context`.  You can specify this parameter on the `Agent` or on the `run()` method.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.in_memory import InMemoryDb

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), db=InMemoryDb())

agent.print_response("Hi, I'm John. Nice to meet you!")

agent.print_response("What is my name?", add_history_to_context=True)
```

Learn more in the [Context Engineering](/concepts/agents/context) documentation.

## Session Summaries

The Agent can store a condensed representations of the session, useful when chat histories gets too long. This is called a "Session Summary" in Agno.

To enable session summaries, set `enable_session_summaries=True` on the `Agent`.

<Steps>
  <Step title="Session summary example">
    ```python session_summary.py
    from agno.agent import Agent
    from agno.models.google.gemini import Gemini
    from agno.db.sqlite import SqliteDb

    db = SqliteDb(db_file="tmp/data.db")

    user_id = "jon_hamm@example.com"
    session_id = "1001"

    agent = Agent(
        model=Gemini(id="gemini-2.0-flash-exp"),
        db=db,
        enable_session_summaries=True,
    )

    agent.print_response(
        "What can you tell me about quantum computing?",
        stream=True,
        user_id=user_id,
        session_id=session_id,
    )

    agent.print_response(
        "I would also like to know about LLMs?",
        stream=True,
        user_id=user_id,
        session_id=session_id
    )

    session_summary = agent.get_session_summary(session_id=session_id)
    print(f"Session summary: {session_summary.summary}")
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install google-genai agno
    ```

    Export your key

    ```shell
    export GOOGLE_API_KEY=xxx
    ```

    Run the example

    ```shell
    python session_summary.py
    ```
  </Step>
</Steps>

### Customize Session Summaries

You can adjust the session summaries by providing a custom `session_summary_prompt` to the `Agent`.

The `SessionSummaryManager` class is responsible for handling the model used to create and update session summaries.
You can adjust it to personalize how summaries are created and updated:

```python
from agno.agent import Agent
from agno.session import SessionSummaryManager
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Session Summary Manager, to adjust how summaries are created
session_summary_manager = SessionSummaryManager(
    # Select the model used for session summary creation and updates. If not specified, the agent's model is used by default.
    model=OpenAIChat(id="gpt-5-mini"),
    # You can also overwrite the prompt used for session summary creation
    session_summary_prompt="Create a very succinct summary of the following conversation:",
)

# Now provide the adjusted Memory Manager to your Agent
agent = Agent(
    db=db,
    session_summary_manager=session_summary_manager,
    enable_session_summaries=True,
)
```

## Session history

Agents with storage enabled automatically have access to the message and run history of the session.

You can access these messages using:

* `agent.get_messages_for_session()` -> Gets access to all the messages for the session, for the current agent.
* `agent.get_chat_history()` -> Gets access to all the unique messages for the session.

We can give the Agent access to the chat history in the following ways:

* We can set `add_history_to_context=True` and `num_history_runs=5` to add the messages from the last 5 runs automatically to every message sent to the agent.
* We can set `read_chat_history=True` to provide a `get_chat_history()` tool to your agent allowing it to read any message in the entire chat history.
* **We recommend setting all 3: `add_history_to_context=True`, `num_history_runs=3` and `read_chat_history=True` for the best experience.**
* We can also set `read_tool_call_history=True` to provide a `get_tool_call_history()` tool to your agent allowing it to read tool calls in reverse chronological order.

Take a look at this example:

<Steps>
  <Step title="Session history example">
    ```python session_history.py
    from agno.agent import Agent
    from agno.models.google.gemini import Gemini
    from agno.db.sqlite import SqliteDb

    agent = Agent(
        model=Gemini(id="gemini-2.0-flash-exp"),
        db=SqliteDb(db_file="tmp/data.db"),
        add_history_to_context=True,
        num_history_runs=3,
        read_chat_history=True,
        description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
    )

    agent.print_response("Share a 2 sentence horror story", stream=True)

    agent.print_response("What was my first message?", stream=True)
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install google-genai agno
    ```

    Export your key

    ```shell
    export GOOGLE_API_KEY=xxx
    ```

    Run the example

    ```shell
    python session_history.py
    ```
  </Step>
</Steps>

### Search the session history

In some scenarios, you might want to fetch messages from across multiple sessions to provide context or continuity in conversations.

To enable fetching messages from the last N sessions, you need to use the following flags:

* `search_session_history`: Set this to `True` to allow searching through previous sessions.
* `num_history_sessions`: Specify the number of past sessions to include in the search. In the example below, it is set to `2` to include only the last 2 sessions.

It's advisable to keep this number low (2 or 3), as a larger number might fill up the context length of the model, potentially leading to performance issues.

Here's an example of searching through the last 2 sessions:

```python
# Remove the tmp db file before running the script
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

os.remove("tmp/data.db")

db = SqliteDb(db_file="tmp/data.db")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    user_id="user_1",
    db=db,
    search_session_history=True,  # allow searching previous sessions
    num_history_sessions=2,  # only include the last 2 sessions in the search to avoid context length issues
)

session_1_id = "session_1_id"
session_2_id = "session_2_id"
session_3_id = "session_3_id"
session_4_id = "session_4_id"
session_5_id = "session_5_id"

agent.print_response("What is the capital of South Africa?", session_id=session_1_id)
agent.print_response("What is the capital of China?", session_id=session_2_id)
agent.print_response("What is the capital of France?", session_id=session_3_id)
agent.print_response("What is the capital of Japan?", session_id=session_4_id)
agent.print_response(
    "What did I discuss in my previous conversations?", session_id=session_5_id
)  # It should only include the last 2 sessions
```

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View the [Session schema](/reference/agents/session)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/session/)


# Agent State
Source: https://docs.agno.com/concepts/agents/state

Learn about state in agents.

**State** is any kind of data the Agent needs to maintain throughout runs in a session.

<Check>
  A simple yet common use case for Agents is to manage lists, items and other "information" for a user. For example, a shopping list, a todo list, a wishlist, etc.

  This can be easily managed using the `session_state`. The Agent updates the `session_state` in tool calls and exposes them to the Model via the system message.

  The session state is then persisted in a database and made available across runs and sessions.
</Check>

## State Management

Agno provides a powerful and elegant state management system, here's how it works:

* You can set the `Agent`'s `session_state` parameter with a dictionary of state variables.
* You update the `session_state` dictionary in tool calls or other functions.
* You share the current `session_state` with the LLM via the system message by referencing the state variables in `description` and `instructions`.
* You can also pass `session_state` to the agent on `agent.run()`, overriding any state that was set on Agent initialization.
* The `session_state` is stored with Agent sessions and is persisted in your database. Meaning, it is available across execution cycles. This also means when switching sessions between calls to `agent.run()`, the state is loaded and available.

Here's an example of an Agent managing a shopping list:

```python session_state.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat

# Define a tool that adds an item to the shopping list
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list."""
    session_state["shopping_list"].append(item)
    return f"The shopping list is now {session_state['shopping_list']}"


# Create an Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Database to store the session and session state
    db=SqliteDb(db_file="tmp/agents.db"),
    # Initialize the session state with an empty shopping list
    session_state={"shopping_list": []},
    tools=[add_item],
    # You can use variables from the session state in the instructions
    instructions="Current state (shopping list) is: {shopping_list}",
    markdown=True,
)

# Example usage
agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Final session state: {agent.get_session_state()}")
```

<Note>
  The `session_state` variable is automatically passed to the tool as an
  argument. Any updates to it is automatically reflected in the shared state.
</Note>

<Check>
  Session state is also shared between members of a team when using `Team`. See
  [Teams](/concepts/teams/state) for more information.
</Check>

## Maintaining state across multiple runs

A big advantage of **sessions** is the ability to maintain state across multiple runs. For example, let's say the agent is helping a user keep track of their shopping list.

<Tip>
  You have to configure your storage via the `db` parameter for state to be persisted across runs.
</Tip>

```python shopping_list.py
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat


# Define tools to manage our shopping list
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list and return confirmation."""
    # Add the item if it's not already in the list
    if item.lower() not in [i.lower() for i in session_state["shopping_list"]]:
        session_state["shopping_list"].append(item)  # type: ignore
        return f"Added '{item}' to the shopping list"
    else:
        return f"'{item}' is already in the shopping list"


def remove_item(session_state, item: str) -> str:
    """Remove an item from the shopping list by name."""
    # Case-insensitive search
    for i, list_item in enumerate(session_state["shopping_list"]):
        if list_item.lower() == item.lower():
            session_state["shopping_list"].pop(i)
            return f"Removed '{list_item}' from the shopping list"

    return f"'{item}' was not found in the shopping list"


def list_items(session_state) -> str:
    """List all items in the shopping list."""
    shopping_list = session_state["shopping_list"]

    if not shopping_list:
        return "The shopping list is empty."

    items_text = "\n".join([f"- {item}" for item in shopping_list])
    return f"Current shopping list:\n{items_text}"


# Create a Shopping List Manager Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with an empty shopping list (default session state for all sessions)
    session_state={"shopping_list": []},
    db=SqliteDb(db_file="tmp/example.db"),
    tools=[add_item, remove_item, list_items],
    # You can use variables from the session state in the instructions
    instructions=dedent("""\
        Your job is to manage a shopping list.

        The shopping list starts empty. You can add items, remove items by name, and list all items.

        Current shopping list: {shopping_list}
    """),
    markdown=True,
)

# Example usage
agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response("I got bread", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response("I need apples and oranges", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response("whats on my list?", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response(
    "Clear everything from my list and start over with just bananas and yogurt",
    stream=True,
)
print(f"Session state: {agent.get_session_state()}")

```

## Agentic Session State

Agno provides a way to allow the agent to automatically update the session state.

Simply set the `enable_agentic_state` parameter to `True`.

```python agentic_session_state.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

agent = Agent(
    db=SqliteDb(db_file="tmp/agents.db"),
    model=OpenAIChat(id="gpt-5-mini"),
    session_state={"shopping_list": []},
    add_session_state_to_context=True,  # Required so the agent is aware of the session state
    enable_agentic_state=True,  # Adds a tool to manage the session state
)

agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Session state: {agent.get_session_state()}")
```

<Tip>
  Don't forget to set `add_session_state_to_context=True` to make the session
  state available to the agent's context.
</Tip>

## Using state in instructions

You can reference variables from the session state in your instructions.

<Tip>
  Don't use the f-string syntax in the instructions. Directly use the `{key}`
  syntax, Agno substitutes the values for you.
</Tip>

```python state_in_instructions.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb


agent = Agent(
    db=SqliteDb(db_file="tmp/agents.db"),
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with a variable
    session_state={"user_name": "John"},
    # You can use variables from the session state in the instructions
    instructions="Users name is {user_name}",
    markdown=True,
)

agent.print_response("What is my name?", stream=True)
```

## Changing state on run

When you pass `session_id` to the agent on `agent.run()`, it will switch to the session with the given `session_id` and load any state that was set on that session.

This is useful when you want to continue a session for a specific user.

```python changing_state_on_run.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

agent = Agent(
    db=SqliteDb(db_file="tmp/agents.db"),
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Users name is {user_name} and age is {age}",
)

# Sets the session state for the session with the id "user_1_session_1"
agent.print_response("What is my name?", session_id="user_1_session_1", user_id="user_1", session_state={"user_name": "John", "age": 30})

# Will load the session state from the session with the id "user_1_session_1"
agent.print_response("How old am I?", session_id="user_1_session_1", user_id="user_1")

# Sets the session state for the session with the id "user_2_session_1"
agent.print_response("What is my name?", session_id="user_2_session_1", user_id="user_2", session_state={"user_name": "Jane", "age": 25})

# Will load the session state from the session with the id "user_2_session_1"
agent.print_response("How old am I?", session_id="user_2_session_1", user_id="user_2")
```

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/state/)


# Storage
Source: https://docs.agno.com/concepts/agents/storage

Use Storage to persist Agent sessions and state to a database or file.

**Why do we need Session Storage?**

Agents are ephemeral and stateless. When you run an Agent, no state is persisted automatically. In production environments, we serve (or trigger) Agents via an API and need to continue the same session across multiple requests.

Storage persists the session history and state in a database and allows us to pick up where we left off.

Storage also lets us inspect and evaluate Agent sessions, extract few-shot examples and build internal monitoring tools. It lets us **look at the data** which helps us build better Agents.

Adding storage to an Agent, Team or Workflow is as simple as providing a `DB` driver and Agno handles the rest. You can use Sqlite, Postgres, Mongo or any other database you want.

Here's a simple example that demonstrates persistence across execution cycles:

```python storage.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb
from rich.pretty import pprint

agent = Agent(
     model=OpenAIChat(id="gpt-5-mini"),
    # Fix the session id to continue the same session across execution cycles
    session_id="fixed_id_for_demo",
    db=SqliteDb(db_file="tmp/data.db"),
    # Make the agent aware of the session history
    add_history_to_context=True,
    num_history_runs=3,
)
agent.print_response("What was my last question?")
agent.print_response("What is the capital of France?")
agent.print_response("What was my last question?")
pprint(agent.get_messages_for_session())
```

The first time you run this, the answer to "What was my last question?" will not be available. But run it again and the Agent will able to answer properly. Because we have fixed the session id, the Agent will continue from the same session every time you run the script.

## Benefits of Storage

Storage has typically been an under-discussed part of Agent Engineering -- but we see it as the unsung hero of production agentic applications.

In production, you need storage to:

* Continue sessions: retrieve session history and pick up where you left off.
* Get list of sessions: To continue a previous session, you need to maintain a list of sessions available for that agent.
* Save session state between runs: save the Agent's state to a database or file so you can inspect it later.

But there is so much more:

* Storage saves our Agent's session data for inspection and evaluations, including session metrics.
* Storage helps us extract few-shot examples, which can be used to improve the Agent.
* Storage enables us to build internal monitoring tools and dashboards.

<Warning>
  Storage is such a critical part of your Agentic infrastructure that it should never be offloaded to a third party. You should almost always use your own storage layer for your Agents.
</Warning>

## Session table schema

If you have a `db` configured for your agent, the sessions will be stored in the a sessions table in your database.

The schema for the sessions table is as follows:

| Field           | Type   | Description                                      |
| --------------- | ------ | ------------------------------------------------ |
| `session_id`    | `str`  | The unique identifier for the session.           |
| `session_type`  | `str`  | The type of the session.                         |
| `agent_id`      | `str`  | The agent ID of the session.                     |
| `team_id`       | `str`  | The team ID of the session.                      |
| `workflow_id`   | `str`  | The workflow ID of the session.                  |
| `user_id`       | `str`  | The user ID of the session.                      |
| `session_data`  | `dict` | The data of the session.                         |
| `agent_data`    | `dict` | The data of the agent.                           |
| `team_data`     | `dict` | The data of the team.                            |
| `workflow_data` | `dict` | The data of the workflow.                        |
| `metadata`      | `dict` | The metadata of the session.                     |
| `runs`          | `list` | The runs of the session.                         |
| `summary`       | `dict` | The summary of the session.                      |
| `created_at`    | `int`  | The timestamp when the session was created.      |
| `updated_at`    | `int`  | The timestamp when the session was last updated. |

This data is best displayed on the [sessions page of the AgentOS UI](https://os.agno.com/sessions).

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View [Examples](/examples/concepts/db)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/)


# Tools
Source: https://docs.agno.com/concepts/agents/tools

Learn how to use tools in Agno to build AI agents.

**Agents use tools to take actions and interact with external systems**.

Tools are functions that an Agent can run to achieve tasks. For example: searching the web, running SQL, sending an email or calling APIs. You can use any python function as a tool or use a pre-built Agno **toolkit**.

The general syntax is:

```python
from agno.agent import Agent

agent = Agent(
    # Add functions or Toolkits
    tools=[...],
)
```

## Using a Toolkit

Agno provides many pre-built **toolkits** that you can add to your Agents. For example, let's use the DuckDuckGo toolkit to search the web.

<Tip>
  You can find more toolkits in the [Toolkits](/concepts/tools/toolkits) guide.
</Tip>

<Steps>
  <Step title="Create Web Search Agent">
    Create a file `web_search.py`

    ```python web_search.py
    from agno.agent import Agent
    from agno.tools.duckduckgo import DuckDuckGoTools

    agent = Agent(tools=[DuckDuckGoTools()], markdown=True)
    agent.print_response("Whats happening in France?", stream=True)
    ```
  </Step>

  <Step title="Run the agent">
    Install libraries

    ```shell
    pip install openai ddgs agno
    ```

    Run the agent

    ```shell
    python web_search.py
    ```
  </Step>
</Steps>

## Writing your own Tools

For more control, write your own python functions and add them as tools to an Agent. For example, here's how to add a `get_top_hackernews_stories` tool to an Agent.

```python hn_agent.py
import json
import httpx

from agno.agent import Agent

def get_top_hackernews_stories(num_stories: int = 10) -> str:
    """Use this function to get top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to return. Defaults to 10.
    """

    # Fetch top story IDs
    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')
    story_ids = response.json()

    # Fetch story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        stories.append(story)
    return json.dumps(stories)

agent = Agent(tools=[get_top_hackernews_stories], markdown=True)
agent.print_response("Summarize the top 5 stories on hackernews?", stream=True)
```

Read more about:

* [Available toolkits](/concepts/tools/toolkits)
* [Creating your own tools](/concepts/tools/custom-tools)

### Accessing built-in parameters in tools

You can access agent attributes like `session_state`, `dependencies`, `agent` and `team` in your tools.

For example:

```python
from agno.agent import Agent

def get_shopping_list(session_state: dict) -> str:
    """Get the shopping list."""
    return session_state["shopping_list"]

agent = Agent(tools=[get_shopping_list], session_state={"shopping_list": ["milk", "bread", "eggs"]}, markdown=True)
agent.print_response("What's on my shopping list?", stream=True)
```

See more in the [Tool Built-in Parameters](/concepts/tools/introduction#tool-built-in-parameters) section.

## MCP Tools

Agno supports [Model Context Protocol (MCP)](/concepts/tools/mcp) tools.

The general syntax is:

```python
from agno.agent import Agent
from agno.tools.mcp import MCPTools

async def run_mcp_agent():

    # Initialize the MCP tools
    mcp_tools = MCPTools(command=f"uvx mcp-server-git")

    # Connect to the MCP server
    await mcp_tools.connect()

    agent = Agent(tools=[mcp_tools], markdown=True)
    await agent.aprint_response("What is the license for this project?", stream=True)
    ...
```

<Tip>
  {" "}

  Learn more about MCP tools in the [MCP tools](/concepts/tools/mcp) guide.
</Tip>

## Developer Resources

* View the [Agent schema](/reference/agents/agent)
* View the [Knowledge schema](/reference/knowledge/knowledge)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/)


# DynamoDB
Source: https://docs.agno.com/concepts/db/dynamodb

Learn to use DynamoDB as a database for your Agents

Agno supports using [DynamoDB](https://aws.amazon.com/dynamodb/) as a database with the `DynamoDb` class.

## Usage

To connect to DynamoDB, you will need valid AWS credentials. You can set them as environment variables:

* `AWS_REGION`: The AWS region to connect to.
* `AWS_ACCESS_KEY_ID`: Your AWS access key id.
* `AWS_SECRET_ACCESS_KEY`: Your AWS secret access key.

```python dynamo_for_agent.py
from agno.db.dynamo import DynamoDb

# Setup your Database
db = DynamoDb()

# Setup your Agent with the Database
agent = Agent(db=db)
```

## Params

<Snippet file="db-dynamodb-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/dynamodb/dynamo_for_agent.py)


# Firestore
Source: https://docs.agno.com/concepts/db/firestore

Learn to use Firestore as a database for your Agents

Agno supports using [Firestore](https://cloud.google.com/firestore) as a database with the `FirestoreDb` class.

You can get started with Firestore following their [Get Started guide](https://firebase.google.com/docs/firestore/quickstart).

## Usage

You need to provide a `project_id` parameter to the `FirestoreDb` class. Firestore will connect automatically using your Google Cloud credentials.

```python firestore_for_agent.py
from agno.agent import Agent
from agno.db.firestore import FirestoreDb

PROJECT_ID = "agno-os-test"  # Use your project ID here

# Setup the Firestore database
db = FirestoreDb(project_id=PROJECT_ID)

# Setup your Agent with the Database
agent = Agent(db=db)
```

## Prerequisites

1. Ensure your gcloud project is enabled with Firestore. Reference [Firestore documentation](https://cloud.google.com/firestore/docs/create-database-server-client-library)
2. Install dependencies: `pip install openai google-cloud-firestore agno`
3. Make sure your gcloud project is set up and you have the necessary permissions to access Firestore

## Params

<Snippet file="db-firestore-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/firestore/firestore_for_agent.py)


# JSON files as database, on Google Cloud Storage (GCS)
Source: https://docs.agno.com/concepts/db/gcs



Agno supports using [Google Cloud Storage (GCS)](https://cloud.google.com/storage) as a database with the `GcsJsonDb` class.
Session data will be stored as JSON blobs in a GCS bucket.

You can get started with GCS following their [Get Started guide](https://cloud.google.com/docs/get-started).

## Usage

```python gcs_for_agent.py
import uuid
import google.auth
from agno.agent import Agent
from agno.db.gcs_json import GcsJsonDb

# Obtain the default credentials and project id from your gcloud CLI session.
credentials, project_id = google.auth.default()

# Generate a unique bucket name using a base name and a UUID4 suffix.
base_bucket_name = "example-gcs-bucket"
unique_bucket_name = f"{base_bucket_name}-{uuid.uuid4().hex[:12]}"
print(f"Using bucket: {unique_bucket_name}")

# Initialize GCSJsonDb with explicit credentials, unique bucket name, and project.
db = GcsJsonDb(
    bucket_name=unique_bucket_name,
    prefix="agent/",
    project=project_id,
    credentials=credentials,
)

# Setup your Agent with the Database
agent = Agent(db=db)
```

## Params

<Snippet file="db-gcs-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/gcs/gcs_json_for_agent.py)
* see full example [here](/examples/concepts/db/gcs/gcs_for_agent)


# In-Memory Storage
Source: https://docs.agno.com/concepts/db/in_memory



Agno supports using In-Memory storage with the `InMemoryDb` class. By doing this, you will be able to use all features that depend on having a database, without having to set one up.

<Warning>
  Using the In-Memory storage is not recommended for production applications.
  Use it for demos, testing and any other use case where you don't want to setup a database.
</Warning>

## Usage

```python
from agno.agent import Agent
from agno.db.in_memory import InMemoryDb

# Setup in-memory database
db = InMemoryDb()

# Create agent with database
agent = Agent(db=db)
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/in_memory/in_memory_storage_for_agent.py)


# JSON Files as Database
Source: https://docs.agno.com/concepts/db/json



Agno supports using local JSON files as a "database" with the `JsonDb` class.
This is a simple way to store your Agent's session data without having to setup a database.

<Warning>
  Using JSON files as a database is not recommended for production applications.
  Use it for demos, testing and any other use case where you don't want to setup a database.
</Warning>

## Usage

```python json_for_agent.py
from agno.agent import Agent
from agno.db.json import JsonDb

# Setup the JSON database
db = JsonDb(db_path="tmp/json_db")

# Setup your Agent with the Database
agent = Agent(db=db)
```

## Params

<Snippet file="db-json-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/json/json_for_agent.py)


# MongoDB Database
Source: https://docs.agno.com/concepts/db/mongodb

Learn to use MongoDB as a database for your Agents

Agno supports using [MongoDB](https://www.mongodb.com/) as a database with the `MongoDb` class.

<Tip>
  **v2 Migration Support**: If you're upgrading from Agno v1, MongoDB is fully supported in the v2 migration script. See the [migration guide](/how-to/v2-migration) for details.
</Tip>

## Usage

```python mongodb_for_agent.py
from agno.agent import Agent
from agno.db.mongo import MongoDb

# MongoDB connection settings
db_url = "mongodb://localhost:27017"

db = MongoDb(db_url=db_url)

# Setup your Agent with the Database
agent = Agent(db=db)
```

### Run MongoDB

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MongoDB** on port **27017** using:

```bash
docker run -d \
  --name local-mongo \
  -p 27017:27017 \
  -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
  -e MONGO_INITDB_ROOT_PASSWORD=secret \
  mongo
```

## Params

<Snippet file="db-mongo-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/mongo/mongodb_for_agent.py)


# MySQL
Source: https://docs.agno.com/concepts/db/mysql

Learn to use MySQL as a database for your Agents

Agno supports using [MySQL](https://www.mysql.com/) as a database with the `MySQLDb` class.

## Usage

```python mysql_for_agent.py
from agno.agent import Agent
from agno.db.mysql import MySQLDb

# Setup your Database
db = MySQLDb(db_url="mysql+pymysql://ai:ai@localhost:3306/ai")

# Setup your Agent with the Database
agent = Agent(db=db)
```

### Run MySQL

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MySQL** on port **3306** using:

```bash
docker run -d \
  --name mysql \
  -e MYSQL_ROOT_PASSWORD=ai \
  -e MYSQL_DATABASE=ai \
  -e MYSQL_USER=ai \
  -e MYSQL_PASSWORD=ai \
  -p 3306:3306 \
  -d mysql:8
```

## Params

<Snippet file="db-mysql-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/mysql/mysql_for_agent.py)


# Neon
Source: https://docs.agno.com/concepts/db/neon

Learn to use Neon as a database provider for your Agents

Agno supports using [Neon](https://neon.com/) with the `PostgresDb` class.

You can get started with Neon following their [Get Started guide](https://neon.com/docs/get-started/signing-up).

You can also read more about the [`PostgresDb` class](/concepts/db/postgres) in its section.

## Usage

```python neon_for_agent.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from os import getenv

# Get your Neon database URL
NEON_DB_URL = getenv("NEON_DB_URL")

# Setup the Neon database
db = PostgresDb(db_url=NEON_DB_URL)

# Setup your Agent with the Database
agent = Agent(db=db)
```

## Params

<Snippet file="db-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/postgres/postgres_for_agent.py)


# What is Storage?
Source: https://docs.agno.com/concepts/db/overview

Enable your Agents to store and access their session history using a database.

Using **Storage**, you can enable your Agents to remember previous messages.

It works by equipping your Agents with a database that they will use to store and retrieve their [sessions](/concepts/agents/sessions) from.

<Tip>
  **When should I use Storage?**

  Agents are ephemeral by default. They won't remember previous conversations.

  But in production environments, you will often need to continue the same session across multiple requests. Storage is the way to persist the session history and state in a database, enabling us to pick up where we left off.

  Storage also lets us inspect and evaluate Agent sessions, extract few-shot examples and build internal monitoring tools. In general, it lets you **keep track of the data**, to build better Agents.
</Tip>

## Usage

To provide your Agents with Storage, just setup a database and provide it to the Agent:

```python
from agno.agent import Agent
from agno.db.sqlite import SQLiteDb

# Setup your database
db = SQLiteDb(db_file="agno.db")

# Initialize your Agent passing the database
agent = Agent(db=db)
```

Agents with a `db` will persist their [sessions](/concepts/agents/sessions) in the database. You can also automatically add the persisted history to the context, effectively enabling Agents to persist sessions:

```python
from agno.agent import Agent
from agno.db.sqlite import SQLiteDb

# Setup your database
db = SQLiteDb(db_file="agno.db")

# Setup your Agent with the database and add the session history to the context
agent = Agent(
    db=db,
    add_history_to_context=True, # Automatically add the persisted session history to the context
    num_history_runs=3, # Specify how many messages to add to the context
)
```

## Where are sessions stored?

By default, sessions are stored in the `agno_sessions` table of the database.

If the table or collection doesn't exist, it is created automatically when first storing a session.

You can specify where the sessions are stored exactly using the `session_table` parameter:

```python
from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup your database
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    session_table="my_session_table", # Specify the table to store sessions
)

# Setup your Agent with the database
agent = Agent(db=db)

# Run the Agent. This will store a session in our "my_session_table"
agent.print_response("What is the capital of France?")
```

## Retrieving sessions

You can manually retrieve stored sessions using the `get_session` method. This also works for `Teams` and `Workflows`:

```python
from agno.agent import Agent
from agno.db.sqlite import SQLiteDb

# Setup your database
db = SQLiteDb(db_file="agno.db")

# Setup your Agent with the database
agent = Agent(db=db)

# Run the Agent, effectively creating and persisting a session
agent.print_response("What is the capital of France?", session_id="123")

# Retrieve our freshly created session
session_history = agent.get_session(session_id="123")
```

## Benefits of Using Storage

When building production-ready agentic applications, storage will often be a very important feature. This is because it enables to:

* Continue a session: retrieve previous messages and enable users to pick up a conversation where they left off.
* Keep a record of sessions: enable users to inspect their past conversations.
* Data ownership: keeping sessions in your own database gives you full control over the data.

<Warning>
  Storage is a critical part of your Agentic infrastructure. We recommend to
  never offload it to a third-party service. You should almost always use your
  own storage layer for your Agents.
</Warning>

## Storage for Teams and Workflows

Storage also works with Teams and Workflows, providing persistent memory for your more complex agentic applications.

Similarly to Agents, you simply need to provide your Team or Workflow with a database for sessions to be persisted:

```python
from agno.team import Team
from agno.workflow import Workflow
from agno.db.sqlite import SQLiteDb

# Setup your database
db = SQLiteDb(db_file="agno.db")

# Setup your Team
team = Team(db=db, ...)

# Setup your Workflow
workflow = Workflow(db=db, ...)
```

<Note>
  Learn more about [Teams](/concepts/teams/introduction) and
  [Workflows](/concepts/workflows/overview), Agno abstractions to build
  multi-agent systems.
</Note>

## Supported databases

This is the list of the databases we currently support:

* [DynamoDB](/concepts/db/dynamodb)
* [FireStore](/concepts/db/firestore)
* [JSON](/concepts/db/json)
* [JSON on GCS](/concepts/db/gcs)
* [MongoDB](/concepts/db/mongodb)
* [MySQL](/concepts/db/mysql)
* [Neon](/concepts/db/neon)
* [PostgreSQL](/concepts/db/postgres)
* [Redis](/concepts/db/redis)
* [SingleStore](/concepts/db/singlestore)
* [SQLite](/concepts/db/sqlite)
* [Supabase](/concepts/db/supabase)

We also support using an [In-Memory](/concepts/db/in_memory) database. This is not recommended for production, but perfect for demos and testing.

You can see a detailed list of [examples](/examples/concepts/db) for all supported databases.


# PostgreSQL
Source: https://docs.agno.com/concepts/db/postgres

Learn to use PostgreSQL as a database for your Agents

Agno supports using [PostgreSQL](https://www.postgresql.org/) as a database with the `PostgresDb` class.

## Usage

```python postgres_for_agent.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai" # Replace with your own connection string

# Setup your Database
db = PostgresDb(db_url=db_url)

# Setup your Agent with the Database
agent = Agent(db=db)
```

### Run Postgres (with PgVector)

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

## Params

<Snippet file="db-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/postgres/postgres_for_agent.py)


# Redis
Source: https://docs.agno.com/concepts/db/redis

Learn to use Redis as a database for your Agents

Agno supports using [Redis](https://redis.io/) as a database with the `RedisDb` class.

## Usage

### Run Redis

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **Redis** on port **6379** using:

```bash
docker run -d \
  --name my-redis \
  -p 6379:6379 \
  redis
```

```python redis_for_agent.py
from agno.agent import Agent
from agno.db.redis import RedisDb

# Initialize Redis db (use the right db_url for your setup)
db = RedisDb(db_url="redis://localhost:6379")

# Create agent with Redis db
agent = Agent(db=db)
```

## Params

<Snippet file="db-redis-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/redis/redis_for_agent.py)


# Singlestore
Source: https://docs.agno.com/concepts/db/singlestore

Learn to use Singlestore as a database for your Agents

Agno supports using [Singlestore](https://www.singlestore.com/) as a database with the `SingleStoreDb` class.

You can get started with Singlestore following their [documentation](https://docs.singlestore.com/db/v9.0/introduction/).

## Usage

```python singlestore_for_agent.py
from os import getenv

from agno.agent import Agent
from agno.db.singlestore import SingleStoreDb

# Configure SingleStore DB connection
USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)

# Setup your Database
db = SingleStoreDb(db_url=db_url)

# Create an agent with SingleStore db
agent = Agent(db=db)
```

## Params

<Snippet file="db-singlestore-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/singlestore/singlestore_for_agent.py)


# SQLite
Source: https://docs.agno.com/concepts/db/sqlite

Learn to use Sqlite as a database for your Agents

Agno supports using [Sqlite](https://www.sqlite.org) as a database with the `SqliteDb` class.

## Usage

```python sqlite_for_agent.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup the SQLite database
db = SqliteDb(db_file="tmp/data.db")

# Setup a basic agent with the SQLite database
agent = Agent(db=db)
```

## Params

<Snippet file="db-sqlite-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/sqlite/sqlite_for_agent.py)


# Supabase
Source: https://docs.agno.com/concepts/db/supabase

Learn to use Supabase as a database provider for your Agents

Agno supports using [Supabase](https://supabase.com/) with the `PostgresDb` class.

You can get started with Supabase following their [Get Started guide](https://supabase.com/docs/guides/getting-started).

You can read more about the [`PostgresDb` class](/concepts/db/postgres) in its section.

## Usage

```python supabase_for_agent.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from os import getenv

# Get your Supabase project and password
SUPABASE_PROJECT = getenv("SUPABASE_PROJECT")
SUPABASE_PASSWORD = getenv("SUPABASE_PASSWORD")

SUPABASE_DB_URL = (
    f"postgresql://postgres:{SUPABASE_PASSWORD}@db.{SUPABASE_PROJECT}:5432/postgres"
)

# Setup the Supabase database
db = PostgresDb(db_url=SUPABASE_DB_URL)

# Setup your Agent with the Database
agent = Agent(db=db)
```

## Params

<Snippet file="db-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/postgres/postgres_for_agent.py)


# Human-in-the-Loop in Agents
Source: https://docs.agno.com/concepts/hitl/overview

Learn how to control the flow of an agent's execution in Agno.

Human-in-the-Loop (HITL) in Agno enable you to implement patterns where human oversight and input are required during agent execution. This is crucial for:

* Validating sensitive operations
* Reviewing tool calls before execution
* Gathering user input for decision-making
* Managing external tool execution

## Types of Human-in-the-Loop

Agno supports four main types of human-in-the-loop flows:

1. **User Confirmation**: Require explicit user approval before executing tool calls
2. **User Input**: Gather specific information from users during execution
3. **Dynamic User Input**: Have the agent collect user input as it needs it
4. **External Tool Execution**: Execute tools outside of the agent's control

<Note>
  Currently Agno only supports user control flows for `Agent`. `Team` and `Workflow` will be supported in the near future!
</Note>

## Pausing Agent Execution

Human-in-the-loop flows interrupt the agent's execution and require human oversight. The run can then be continued by calling the `continue_run` method.

For example:

```python
run_response = agent.run("Perform sensitive operation")

if run_response.is_paused:
    # The agent will pause while human input is provided
    # ... perform other tasks, update the tools if needed

    # The user can then continue the run
    response = agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
    # or response = await agent.acontinue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
```

The `continue_run` method continues with the state of the agent at the time of the pause.  You can also pass the `RunOutput` of a specific run to the `continue_run` method, or pass the `run_id` and list of updated tools in the `updated_tools` parameter.

## User Confirmation

User confirmation allows you to pause execution and require explicit user approval before proceeding with tool calls. This is useful for:

* Sensitive operations
* API calls that modify data
* Actions with significant consequences

The following example shows how to implement user confirmation.

```python
from agno.tools import tool
from agno.agent import Agent
from agno.models.openai import OpenAIChat

@tool(requires_confirmation=True)
def sensitive_operation(data: str) -> str:
    """Perform a sensitive operation that requires confirmation."""
    # Implementation here
    return "Operation completed"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[sensitive_operation],
)

# Run the agent
run_response = agent.run("Perform sensitive operation")

# Handle confirmation
if run_response.is_paused:
    for tool in run_response.tools_requiring_confirmation:
        # Get user confirmation
        print(f"Tool {tool.tool_name}({tool.tool_args}) requires confirmation")
        confirmed = input(f"Confirm? (y/n): ").lower() == "y"
        tool.confirmed = confirmed

  # Continue execution
  response = agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
```

You can also specify which tools in a toolkit require confirmation.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils import pprint

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(requires_confirmation_tools=["duckduckgo_search"])],
)

run_response = agent.run("What is the latest news on AI?")
if run_response.is_paused:
    for tool in run_response.tools_requiring_confirmation:
        print(f"Tool {tool.tool_name}({tool.tool_args}) requires confirmation")
        confirmed = input(f"Confirm? (y/n): ").lower() == "y"

        if confirmed == False:
            tool.confirmed = False
        else:
            # We update the tools in place
            tool.confirmed = True

    run_response = agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
    pprint.pprint_run_response(run_response)
```

## User Input

User input flows allow you to gather specific information from users during execution. This is useful for:

* Collecting required parameters
* Getting user preferences
* Gathering missing information

In the example below, we require all the input for the `send_email` tool from the user.

```python
from typing import List
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.function import UserInputField

# We still provide a docstring to the tool; This will be used to populate the `user_input_schema`
@tool(requires_user_input=True)
def send_email(to: str, subject: str, body: str) -> dict:
    """Send an email to the user.

    Args:
        to (str): The address to send the email to.
        subject (str): The subject of the email.
        body (str): The body of the email.
    """
    # Implementation here
    return f"Email sent to {to} with subject {subject} and body {body}"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
)

run_response = agent.run("Send an email please to my friend John, make up the subject and body")
if run_response.is_paused:
    for tool in run_response.tools_requiring_user_input:
        input_schema: List[UserInputField] = tool.user_input_schema

        for field in input_schema:
            # Display field information to the user
            print(f"\nField: {field.name} ({field.field_type.__name__}) -> {field.description}")

            # Get user input
            user_value = input(f"Please enter a value for {field.name}: ")

            # Update the field value
            field.value = user_value

    run_response = (
        agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
    )
```

The `RunOutput` object has a list of tools. In the case of `requires_user_input`, the tools that require input will have `user_input_schema` populated.
This is a list of `UserInputField` objects.

```python
class UserInputField:
    name: str  # The name of the field
    field_type: Type  # The required type of the field
    description: Optional[str] = None  # The description of the field
    value: Optional[Any] = None  # The value of the field. Populated by the agent or the user.
```

You can also specify which fields should be filled by the user while the agent will provide the rest of the fields.

```python
# You can either specify the user_input_fields or leave empty for all fields to be provided by the user
@tool(requires_user_input=True, user_input_fields=["to_address"])
def send_email(subject: str, body: str, to_address: str) -> str:
    """
    Send an email.

    Args:
        subject (str): The subject of the email.
        body (str): The body of the email.
        to_address (str): The address to send the email to.
    """
    return f"Sent email to {to_address} with subject {subject} and body {body}"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
)

run_response = agent.run("Send an email with the subject 'Hello' and the body 'Hello, world!'")
if run_response.is_paused:
    for tool in run_response.tools_requiring_user_input:
        input_schema: List[UserInputField] = tool.user_input_schema

        for field in input_schema:
            # Display field information to the user
            print(f"\nField: {field.name} ({field.field_type.__name__}) -> {field.description}")

            # Get user input (if the value is not set, it means the user needs to provide the value)
            if field.value is None:
                user_value = input(f"Please enter a value for {field.name}: ")
                field.value = user_value
            else:
                print(f"Value provided by the agent: {field.value}")

    run_response = (
        agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
    )
```

## Dynamic User Input

This pattern provides the agent with tools to indicate when it needs user input. It's ideal for cases:

* Where it is unknown how the user will interact with the agent
* When you want a form-like interaction with the user

In the following example, we use a specialized tool to allow the agent to collect user feedback when it needs it.

```python
from typing import Any, Dict

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.toolkit import Toolkit
from agno.tools.user_control_flow import UserControlFlowTools
from agno.utils import pprint

# Example toolkit for handling emails
class EmailTools(Toolkit):
    def __init__(self, *args, **kwargs):
        super().__init__(
            name="EmailTools", tools=[self.send_email, self.get_emails], *args, **kwargs
        )

    def send_email(self, subject: str, body: str, to_address: str) -> str:
        """Send an email to the given address with the given subject and body.

        Args:
            subject (str): The subject of the email.
            body (str): The body of the email.
            to_address (str): The address to send the email to.
        """
        return f"Sent email to {to_address} with subject {subject} and body {body}"

    def get_emails(self, date_from: str, date_to: str) -> str:
        """Get all emails between the given dates.

        Args:
            date_from (str): The start date.
            date_to (str): The end date.
        """
        return [
            {
                "subject": "Hello",
                "body": "Hello, world!",
                "to_address": "test@test.com",
                "date": date_from,
            },
            {
                "subject": "Random other email",
                "body": "This is a random other email",
                "to_address": "john@doe.com",
                "date": date_to,
            },
        ]


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[EmailTools(), UserControlFlowTools()],
    markdown=True,
    debug_mode=True,
)

run_response = agent.run("Send an email with the body 'How is it going in Tokyo?'")

# We use a while loop to continue the running until the agent is satisfied with the user input
while run_response.is_paused:
    for tool in run_response.tools_requiring_user_input:
        input_schema: List[UserInputField] = tool.user_input_schema

        for field in input_schema:
            # Display field information to the user
            print(f"\nField: {field.name} ({field.field_type.__name__}) -> {field.description}")

            # Get user input (if the value is not set, it means the user needs to provide the value)
            if field.value is None:
                user_value = input(f"Please enter a value for {field.name}: ")
                field.value = user_value
            else:
                print(f"Value provided by the agent: {field.value}")

    run_response = agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)

    # If the agent is not paused for input, we are done
    if not run_response.is_paused:
        pprint.pprint_run_response(run_response)
        break
```

## External Tool Execution

External tool execution allows you to execute tools outside of the agent's control. This is useful for:

* External service calls
* Database operations

```python
import subprocess

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint


# We have to create a tool with the correct name, arguments and docstring for the agent to know what to call.
@tool(external_execution=True)
def execute_shell_command(command: str) -> str:
    """Execute a shell command.

    Args:
        command (str): The shell command to execute

    Returns:
        str: The output of the shell command
    """
    return subprocess.check_output(command, shell=True).decode("utf-8")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[execute_shell_command],
    markdown=True,
)

run_response = agent.run("What files do I have in my current directory?")
if run_response.is_paused:
    for tool in run_response.tools_awaiting_external_execution:
        if tool.tool_name == execute_shell_command.name:
            print(f"Executing {tool.tool_name} with args {tool.tool_args} externally")

            # We execute the tool ourselves. You can execute any function or process here and use the tool_args as input.
            result = execute_shell_command.entrypoint(**tool.tool_args)
            # We have to set the result on the tool execution object so that the agent can continue
            tool.result = result

    run_response = agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)
    pprint.pprint_run_response(run_response)
```

## Best Practices

1. **Sanitise user input**: Validate and sanitize user input to prevent security vulnerabilities
2. **Error Handling**: Implement proper error handling for user input and external calls
3. **Input Validation**: Validate user input before processing

## Developer Resources

* View more [Examples](/examples/concepts/agent/human_in_the_loop/)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/human_in_the_loop)


# Agentic Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/agentic-chunking



Agentic chunking is an intelligent method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text. Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

## Usage

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.agentic import AgenticChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_agentic_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Agentic Chunking Reader",
        chunking_strategy=AgenticChunking(),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Agentic Chunking Params

<Snippet file="chunking-agentic.mdx" />


# CSV Row Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/csv-row-chunking



CSV row chunking is a method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text. Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.row import RowChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.csv_reader import CSVReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="imdb_movies_row_chunking", db_url=db_url),
)

asyncio.run(knowledge_base.add_content_async(
    url="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    reader=CSVReader(
        chunking_strategy=RowChunking(),
    ),
))  

# Initialize the Agent with the knowledge_base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Use the agent 
agent.print_response("Tell me about the movie Guardians of the Galaxy", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/csv_row_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/csv_row_chunking.py 
      ```
    </CodeGroup>
  </Step>
</Steps>

## CSV Row Chunking Params

<Snippet file="chunking-csv-row.mdx" />


# Custom Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/custom-chunking



Custom chunking allows you to implement your own chunking strategy by creating a class that inherits from `ChunkingStrategy`. This is useful when you need to split documents based on specific separators, apply custom logic, or handle domain-specific content formats.

```python
from typing import List
from agno.knowledge.chunking.base import ChunkingStrategy
from agno.knowledge.content import Document

class CustomChunking(ChunkingStrategy):
    def __init__(self, separator: str = "---", **kwargs):
        self.separator = separator

    def chunk(self, document: Document) -> List[Document]:
        # Split by custom separator
        chunks = document.content.split(self.separator)

        result = []
        for i, chunk_content in enumerate(chunks):
            chunk_content = self.clean_text(chunk_content)  # Use inherited method
            if chunk_content:
                meta_data = document.meta_data.copy()
                meta_data["chunk"] = i + 1
                result.append(Document(
                    id=f"{document.id}_{i+1}" if document.id else None,
                    name=document.name,
                    meta_data=meta_data,
                    content=chunk_content
                ))
        return result
```

## Usage

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_custom_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Custom Chunking Reader",
        chunking_strategy=CustomChunking(separator="---"),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Custom Chunking Params

<Snippet file="chunking-custom.mdx" />


# Document Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/document-chunking



Document chunking is a method of splitting documents into smaller chunks based on document structure like paragraphs and sections. It analyzes natural document boundaries rather than splitting at fixed character counts. This is useful when you want to process large documents while preserving semantic meaning and context.

## Usage

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.document import DocumentChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_document_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Document Chunking Reader",
        chunking_strategy=DocumentChunking(),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Document Chunking Params

<Snippet file="chunking-document.mdx" />


# Fixed Size Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/fixed-size-chunking



Fixed size chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks. This is useful when you want to process large documents in smaller, manageable pieces.

## Usage

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.fixed import FixedSizeChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_fixed_size_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Fixed Size Chunking Reader",
        chunking_strategy=FixedSizeChunking(),
    ),
))
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Fixed Size Chunking Params

<Snippet file="chunking-fixed-size.mdx" />


# What is Chunking?
Source: https://docs.agno.com/concepts/knowledge/chunking/introduction

Chunking is the process of breaking down large documents into smaller pieces for effective vector search and retrieval.

Chunking is the process of dividing content into manageable pieces before converting them into embeddings and storing them in vector databases. The chunking strategy you choose directly impacts search quality and retrieval accuracy.

Different chunking strategies serve different purposes. For example, when processing a recipe book, different strategies produce different results:

* **Fixed Size**: Splits text every 500 characters (which may break recipes mid-instruction)
* **Semantic**: Keeps complete recipes together based on meaning
* **Document**: Each page becomes a chunk

The strategy affects whether you get complete, relevant results or fragmented pieces.

## Available Chunking Strategies

<CardGroup cols={2}>
  <Card title="Fixed Size Chunking" icon="ruler" href="/concepts/knowledge/chunking/fixed-size-chunking">
    Split content into uniform chunks with specified size and overlap.
  </Card>

  <Card title="Semantic Chunking" icon="brain" href="/concepts/knowledge/chunking/semantic-chunking">
    Use semantic similarity to identify natural breakpoints in content.
  </Card>

  <Card title="Recursive Chunking" icon="sitemap" href="/concepts/knowledge/chunking/recursive-chunking">
    Recursively split content using multiple separators for hierarchical processing.
  </Card>

  <Card title="Document Chunking" icon="file-text" href="/concepts/knowledge/chunking/document-chunking">
    Preserve document structure by treating sections as individual chunks.
  </Card>

  <Card title="CSV Row Chunking" icon="table" href="/concepts/knowledge/chunking/csv-row-chunking">
    Splits CSV files by treating each row as an individual chunk. Only compatible with CSVs.
  </Card>

  <Card title="Markdown Chunking" icon="markdown" href="/concepts/knowledge/chunking/markdown-chunking">
    Split markdown content while preserving heading structure and hierarchy. Only compatible with Markdown files.
  </Card>

  <Card title="Agentic Chunking" icon="robot" href="/concepts/knowledge/chunking/agentic-chunking">
    Use AI to intelligently determine optimal chunk boundaries.
  </Card>

  <Card title="Custom Chunking" icon="code" href="/concepts/knowledge/chunking/custom-chunking">
    Build your own chunking strategy for specialized use cases.
  </Card>
</CardGroup>

## Using Chunking Strategies

Chunking strategies are configured when setting up readers for your knowledge base:

```python
from agno.knowledge.chunking.semantic import SemanticChunking
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.db.postgres import PostgresDb

# Configure chunking strategy with a reader
reader = PDFReader(
    chunking_strategy=SemanticChunking(similarity_threshold=0.7)
)

# Set up ContentsDB - tracks content metadata
contents_db = PostgresDb(
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    knowledge_table="knowledge_contents"
)

# Set up vector database - stores embeddings
vector_db = PgVector(
    table_name="documents",
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
)

# Create Knowledge with both databases
knowledge = Knowledge(
    name="Chunking Knowledge Base",
    vector_db=vector_db,
    contents_db=contents_db
)

# Add content with chunking applied
knowledge.add_content(
    path="documents/cookbook.pdf",
    reader=reader,
)
```

## Choosing a Strategy

The choice of chunking strategy depends on your content type and use case:

* **Text documents**: Semantic chunking maintains context and meaning
* **Structured documents**: Document or Markdown chunking preserves hierarchy
* **Tabular data**: CSV Row chunking treats each row as a separate entity
* **Mixed content**: Recursive chunking provides flexibility with multiple separators
* **Uniform processing**: Fixed Size chunking ensures consistent chunk dimensions

Each reader has a default chunking strategy that works well for its content type, but you can override it by specifying a `chunking_strategy` parameter when configuring the reader.

<Note>
  Consider your specific use case and performance requirements when choosing a chunking strategy, since different strategies vary in processing time and memory usage.
</Note>


# Markdown Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/markdown-chunking



Markdown chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks. This is useful when you want to process large documents in smaller, manageable pieces.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.markdown import MarkdownChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.markdown_reader import MarkdownReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_markdown_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://github.com/agno-agi/agno/blob/main/README.md",
    reader=MarkdownReader(
        name="Markdown Chunking Reader",
        chunking_strategy=MarkdownChunking(),
    ),
))
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("What is Agno?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/markdown_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/markdown_chunking.py 
      ```
    </CodeGroup>
  </Step>
</Steps>

## Markdown Chunking Params

<Snippet file="chunking-markdown.mdx" />


# Recursive Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/recursive-chunking



Recursive chunking is a method of splitting documents into smaller chunks by recursively applying a chunking strategy. This is useful when you want to process large documents in smaller, manageable pieces.

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.recursive import RecursiveChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_recursive_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Recursive Chunking Reader",
        chunking_strategy=RecursiveChunking(),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Recursive Chunking Params

<Snippet file="chunking-recursive.mdx" />


# Semantic Chunking
Source: https://docs.agno.com/concepts/knowledge/chunking/semantic-chunking



Semantic chunking is a method of splitting documents into smaller chunks by analyzing semantic similarity between text segments using embeddings. It uses the chonkie library to identify natural breakpoints where the semantic meaning changes significantly, based on a configurable similarity threshold. This helps preserve context and meaning better than fixed-size chunking by ensuring semantically related content stays together in the same chunk, while splitting occurs at meaningful topic transitions.

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.semantic import SemanticChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_semantic_chunking", db_url=db_url),
)
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Semantic Chunking Reader",
        chunking_strategy=SemanticChunking(similarity_threshold=0.5),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## Semantic Chunking Params

<Snippet file="chunking-semantic.mdx" />


# Knowledge Contents DB
Source: https://docs.agno.com/concepts/knowledge/content_db

Learn how to add a Content DB to your Knowledge.

The Contents Database (Contents DB) is an optional component that enhances Knowledge with content tracking and management features. It acts as a control layer that maintains detailed records of all content added to your `Knowledge`.

## What is Contents DB?

Contents DB is a table in your database that keeps track of what content you've added to your Knowledge base.
While your vector database stores the actual content for search, this table tracks what you've added, when you added it, and its processing status.

* **Vector Database**: Stores embeddings and chunks for semantic search
* **Contents Database**: Tracks content metadata, status, and when coupled with [AgentOS Knowledge](/agent-os/features/knowledge-management), provides management of your knowledge via API.

## Why Use ContentsDB?

### Content Visibility and Control

Without ContentsDB, managing your knowledge and vectors is difficult - you can search it, but you can't manage individual pieces of content or alter all the vectors created from a single piece of content.

With ContentsDB, you gain full visibility:

* See all content that has been added
* Track processing status of each item
* View metadata and file information
* Monitor access patterns and usage

### Powerful Management Capabilities

* **Edit names, descriptions and metadata** for existing content
* **Delete specific content** and automatically clean up associated vectors
* **Update content** without rebuilding the entire knowledge base
* **Batch operations** for managing multiple content items
* **Status tracking** to monitor processing success/failure

### Required for AgentOS

If you're using AgentOS, ContentsDB is **mandatory** for the Knowledge page functionality. The AgentOS web interface relies on ContentsDB to display and manage your knowledge content.

## Setting Up ContentsDB

### Choose Your Database

Agno supports multiple database backends for ContentsDB:

* **[PostgreSQL](/concepts/db/postgres)** - Recommended for production
* **[SQLite](/concepts/db/sqlite)** - Great for development and single-user applications
* **[MySQL](/concepts/db/mysql)** - Enterprise-ready relational database
* **[MongoDB](/concepts/db/mongodb)** - Document-based NoSQL option
* **[Redis](/concepts/db/redis)** - In-memory option for high performance
* **[In-Memory](/concepts/db/in_memory)** - Temporary storage for testing
* **Cloud Options** - [DynamoDB](/concepts/db/dynamodb), [Firestore](/concepts/db/firestore), [GCS](/concepts/db/gcs)

### Basic Setup Example

```python
from agno.knowledge import Knowledge
from agno.db.postgres import PostgresDb
from agno.vectordb.pgvector import PgVector

# Set up ContentsDB - tracks content metadata
contents_db = PostgresDb(
    db_url="postgresql+psycopg://user:pass@localhost:5432/db",
    knowledge_table="knowledge_contents"  # Optional: custom table name
)

# Set up vector database - stores embeddings
vector_db = PgVector(
    table_name="vectors",
    db_url="postgresql+psycopg://user:pass@localhost:5432/db"
)

# Create Knowledge with both databases
knowledge = Knowledge(
    name="My Knowledge Base",
    vector_db=vector_db,
    contents_db=contents_db  # This enables content tracking!
)
```

### Alternative Database Examples

```python
# SQLite for development
from agno.db.sqlite import SqliteDb
contents_db = SqliteDb(db_file="my_knowledge.db")

# MongoDB for document-based storage
from agno.db.mongo import MongoDb
contents_db = MongoDb(
    uri="mongodb://localhost:27017",
    database="agno_db"
)

# In-memory for testing
from agno.db.in_memory import InMemoryDb
contents_db = InMemoryDb()
```

## Core Functionality

### Contents DB Schema

If you have a Contents DB configured for your Knowledge, the content metadata will be stored in a contents table in your database.

The schema for the contents table is as follows:

| Field            | Type   | Description                                                                               |
| ---------------- | ------ | ----------------------------------------------------------------------------------------- |
| `id`             | `str`  | The unique identifier for the content.                                                    |
| `name`           | `str`  | The name of the content.                                                                  |
| `description`    | `str`  | The description of the content.                                                           |
| `metadata`       | `dict` | The metadata for the content.                                                             |
| `type`           | `str`  | The type of the content.                                                                  |
| `size`           | `int`  | The size of the content. Applicable only to files.                                        |
| `linked_to`      | `str`  | The ID of the content that this content is linked to.                                     |
| `access_count`   | `int`  | The number of times this content has been accessed.                                       |
| `status`         | `str`  | The status of the content.                                                                |
| `status_message` | `str`  | The message associated with the status of the content.                                    |
| `created_at`     | `int`  | The timestamp when the content was created.                                               |
| `updated_at`     | `int`  | The timestamp when the content was last updated.                                          |
| `external_id`    | `str`  | The external ID of the content. Used when external vector stores are used, like LightRAG. |

This data is best displayed on the [knowledge page of the AgentOS UI](https://os.agno.com/knowledge).

### Content Metadata Tracking

```python
# When you add content
knowledge.add_content(
    name="Product Manual",
    path="docs/manual.pdf",
    metadata={"department": "engineering", "version": "2.1"}
)

# ContentsDB automatically stores all the fields from the schema above
# - External IDs for cloud integrations
```

### Content Retrieval and Management

```python
# Get all content with pagination
contents, total_count = knowledge.get_content(
    limit=20,
    page=1,
    sort_by="created_at",
    sort_order="desc"
)

# Get specific content by ID
content = knowledge.get_content_by_id(content_id)

# Each content object includes:
print(content.name)         # Content name
print(content.description)  # Description
print(content.metadata)     # Custom metadata
print(content.file_type)    # File type (.pdf, .txt, etc.)
print(content.size)         # File size in bytes
print(content.status)       # Processing status
print(content.created_at)   # When it was added
print(content.updated_at)   # Last modification
```

## Management Features

### Content Deletion with Vector Cleanup

Delete content and automatically clean up associated vectors:

This automatically:

1. Removes the content metadata from ContentsDB
2. Deletes associated vectors from the vector database
3. Maintains consistency between both databases

```python
# Delete specific content
knowledge.remove_content_by_id(content_id)

# Delete all content
knowledge.remove_all_content()
```

### Filtering and Search

ContentsDB enables powerful filtering capabilities:

```python
# The knowledge base tracks valid filter keys
valid_filters = knowledge.get_filters()

# Filter content during search
results = knowledge.search(
    query="technical documentation",
    filters={"department": "engineering", "version": "2.1"}
)
```

## AgentOS Integration

### Required Setup for AgentOS

When using AgentOS, ContentsDB is mandatory for the Knowledge management interface:

```python
from agno.os import AgentOS
from agno.db.postgres import PostgresDb
from agno.agent import Agent

# ContentsDB is required for AgentOS Knowledge page
contents_db = PostgresDb(
    db_url="postgresql+psycopg://user:pass@localhost:5432/db"
)

vector_db = PgVector(table_name="vectors", db_url="http://my-postgress:5432")


knowledge = Knowledge(
    vector_db=vector_db,
    contents_db=contents_db  # Must be provided for AgentOS
)

knowledge_agent = Agent(
    name="Knowledge Agent",
    knowledge=knowledge
)

# Create AgentOS app
app = AgentOS(
    description="Example app for basic agent with knowledge capabilities",
    os_id="knowledge-demo",
    agents=[knowledge_agent],
)
```

### AgentOS Features Enabled by ContentsDB

With ContentsDB, the AgentOS Knowledge page provides:

* **Content Browser**: View all uploaded content with metadata
* **Upload Interface**: Add new content through the web UI
* **Status Monitoring**: Real-time processing status updates
* **Metadata Editor**: Update content metadata through forms
* **Content Management**: Delete or modify content entries
* **Search and Filtering**: Find content by metadata attributes
* **Bulk Operations**: Manage multiple content items at once

Check out the [AgentOS Knowledge](/agent-os/features/knowledge-management) page for more in-depth information.

## Next Steps

* **[Vector Databases](/concepts/knowledge/vectordb/introduction)** - Understand the embedding storage layer
* **[AgentOS](/agent-os/introduction)** - Use your Knowledge in Agno AgentOS
* **[Database Setup](/concepts/db/overview)** - Detailed database configuration guides


# Knowledge Content Types
Source: https://docs.agno.com/concepts/knowledge/content_types



Agno Knowledge uses `content` as the building block of any piece of knowledge.
Content can be added to knowledge from different sources.

| Content Origin | Description                                                           |
| -------------- | --------------------------------------------------------------------- |
| Path           | Local files or directories containing files                           |
| Url            | Direct links to files or other sites                                  |
| Text           | Raw text content                                                      |
| Topic          | Search topics from repositories like Arxiv or Wikipedia               |
| Remote Content | Content stored in remote repositories like S3 or Google Cloud Storage |

Knowledge content needs to be read and chunked before it can be passed to any VectorDB for embedding, storage and ultimately, retrieval.
When content is added to Knowledge, a default reader is selected. Readers are used to parse content from the origin and then chunk it into smaller
pieces that will then be embedded by the VectorDB.

Custom readers or an override to the default reader and/or its settings can be passed when adding the content. In the below example, an instance of the standard `PDFReader` class is created
but we update the chunk\_size. Similarly, we can update the `chunking_strategy` and other parameters that will influence how content is ingested and processed.

```python
from agno.knowledge.reader.pdf_reader import PDFReader

reader = PDFReader(
    chunk_size=1000,
)

knowledge_base = Knowledge(
    vector_db=vector_db,
)

asyncio.run(
        knowledge_base.add_content_async(
            path="data/pdf",
            reader=reader
        )
    )
```

For more information about the different readers and their capabilities checkout the [Readers](../knowledge/readers/) page.


# Implementing a Custom Retriever
Source: https://docs.agno.com/concepts/knowledge/custom_retriever

Learn how to implement a custom retriever for precise control over document retrieval in your knowledge base.

In some cases, you may need complete control over how your agent retrieves information from the knowledge base. This can be achieved by implementing a custom retriever function. A custom retriever allows you to define the logic for searching and retrieving documents from your vector database.

## Setup

Follow the instructions in the [Qdrant Setup Guide](https://qdrant.tech/documentation/guides/installation/) to install Qdrant locally. Here is a guide to get API keys: [Qdrant API Keys](https://qdrant.tech/documentation/cloud/authentication/).

### Example: Custom Retriever for `Knowledge`

Below is a detailed example of how to implement a custom retriever function using the `agno` library. This example demonstrates how to set up a knowledge base with PDF documents, define a custom retriever, and use it with an agent.

```python
from typing import Optional
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from qdrant_client import QdrantClient

# ---------------------------------------------------------
# This section loads the knowledge base. Skip if your knowledge base was populated elsewhere.
# Define the embedder
embedder = OpenAIEmbedder(id="text-embedding-3-small")
# Initialize vector database connection
vector_db = Qdrant(collection="thai-recipes", url="http://localhost:6333", embedder=embedder)
# Load the knowledge base
knowledge_base = Knowledge(
    vector_db=vector_db,
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)


# Define the custom retriever
# This is the function that the agent will use to retrieve documents
def retriever(
    query: str, agent: Optional[Agent] = None, num_documents: int = 5, **kwargs
) -> Optional[list[dict]]:
    """
    Custom retriever function to search the vector database for relevant documents.

    Args:
        query (str): The search query string
        agent (Agent): The agent instance making the query
        num_documents (int): Number of documents to retrieve (default: 5)
        **kwargs: Additional keyword arguments

    Returns:
        Optional[list[dict]]: List of retrieved documents or None if search fails
    """
    try:
        qdrant_client = QdrantClient(url="http://localhost:6333")
        query_embedding = embedder.get_embedding(query)
        results = qdrant_client.query_points(
            collection_name="thai-recipes",
            query=query_embedding,
            limit=num_documents,
        )
        results_dict = results.model_dump()
        if "points" in results_dict:
            return results_dict["points"]
        else:
            return None
    except Exception as e:
        print(f"Error during vector database search: {str(e)}")
        return None

def main():
    """Main function to demonstrate agent usage."""
    # Initialize agent with custom retriever
    # Remember to set search_knowledge=True to use agentic_rag or add_reference=True for traditional RAG
    # search_knowledge=True is default when you add a knowledge base but is needed here
    agent = Agent(
        knowledge_retriever=retriever,
        search_knowledge=True,
        instructions="Search the knowledge base for information",
    )

    # Example query
    query = "List down the ingredients to make Massaman Gai"
    agent.print_response(query, markdown=True)

if __name__ == "__main__":
    main()
```

#### Asynchronous Implementation

```python
import asyncio
from typing import Optional
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from qdrant_client import AsyncQdrantClient

# ---------------------------------------------------------
# Knowledge base setup (same as synchronous example)
embedder = OpenAIEmbedder(id="text-embedding-3-small")
vector_db = Qdrant(collection="thai-recipes", url="http://localhost:6333", embedder=embedder)
knowledge_base = Knowledge(
    vector_db=vector_db,
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)
# ---------------------------------------------------------

# Define the custom async retriever
async def retriever(
    query: str, agent: Optional[Agent] = None, num_documents: int = 5, **kwargs
) -> Optional[list[dict]]:
    """
    Custom async retriever function to search the vector database for relevant documents.
    """
    try:
        qdrant_client = AsyncQdrantClient(path="tmp/qdrant")
        query_embedding = embedder.get_embedding(query)
        results = await qdrant_client.query_points(
            collection_name="thai-recipes",
            query=query_embedding,
            limit=num_documents,
        )
        results_dict = results.model_dump()
        if "points" in results_dict:
            return results_dict["points"]
        else:
            return None
    except Exception as e:
        print(f"Error during vector database search: {str(e)}")
        return None

async def main():
    """Async main function to demonstrate agent usage."""
    agent = Agent(
        knowledge_retriever=retriever,
        search_knowledge=True,
        instructions="Search the knowledge base for information",
    )
    # Example query
    query = "List down the ingredients to make Massaman Gai"
    await agent.aprint_response(query, markdown=True)

if __name__ == "__main__":
    asyncio.run(main())
```

### Explanation

1. **Embedder and Vector Database Setup**: We start by defining an embedder and initializing a connection to a vector database. This setup is crucial for converting queries into embeddings and storing them in the database.

2. **Loading the Knowledge Base**: The knowledge base is loaded with PDF documents. This step involves converting the documents into embeddings and storing them in the vector database.

3. **Custom Retriever Function**: The `retriever` function is defined to handle the retrieval of documents. It takes a query, converts it into an embedding, and searches the vector database for relevant documents.

4. **Agent Initialization**: An agent is initialized with the custom retriever. The agent uses this retriever to search the knowledge base and retrieve information.

5. **Example Query**: The `main` function demonstrates how to use the agent to perform a query and retrieve information from the knowledge base.

## Developer Resources

* View [Sync Retriever](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/custom/retriever.py)
* View [Async Retriever](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/custom/async_retriever.py)


# AWS Bedrock Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/aws_bedrock



The `AwsBedrockEmbedder` class is used to embed text data into vectors using the AWS Bedrock API. By default, it uses the Cohere Embed Multilingual V3 model for generating embeddings.

# Setup

## Set your AWS credentials

```bash
export AWS_ACCESS_KEY_ID = xxx
export AWS_SECRET_ACCESS_KEY = xxx
export AWS_REGION = xxx
```

<Note>
  By default, this embedder uses the `cohere.embed-multilingual-v3` model. You must enable access to this model from the AWS Bedrock model catalog before using this embedder.
</Note>

## Run PgVector

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

# Usage

```python cookbook/embedders/aws_bedrock_embedder.py
import asyncio
from agno.knowledge.embedder.aws_bedrock import AwsBedrockEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

embeddings = AwsBedrockEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)
# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        embedder=AwsBedrockEmbedder(),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        chunk_size=2048
    ),  # Required because cohere has a fixed size of 2048
)
```

# Params

| Parameter               | Type                       | Default                          | Description                                                                                                                   |
| ----------------------- | -------------------------- | -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| `id`                    | `str`                      | `"cohere.embed-multilingual-v3"` | The model ID to use. You need to enable this model in your AWS Bedrock model catalog.                                         |
| `dimensions`            | `int`                      | `1024`                           | The dimensionality of the embeddings generated by the model(1024 for Cohere models).                                          |
| `input_type`            | `str`                      | `"search_query"`                 | Prepends special tokens to differentiate types. Options: 'search\_document', 'search\_query', 'classification', 'clustering'. |
| `truncate`              | `Optional[str]`            | `None`                           | How to handle inputs longer than the maximum token length. Options: 'NONE', 'START', 'END'.                                   |
| `embedding_types`       | `Optional[List[str]]`      | `None`                           | Types of embeddings to return . Options: 'float', 'int8', 'uint8', 'binary', 'ubinary'.                                       |
| `aws_region`            | `Optional[str]`            | `None`                           | The AWS region to use. If not provided, falls back to AWS\_REGION env variable.                                               |
| `aws_access_key_id`     | `Optional[str]`            | `None`                           | The AWS access key ID. If not provided, falls back to AWS\_ACCESS\_KEY\_ID env variable.                                      |
| `aws_secret_access_key` | `Optional[str]`            | `None`                           | The AWS secret access key. If not provided, falls back to AWS\_SECRET\_ACCESS\_KEY env variable.                              |
| `session`               | `Optional[Session]`        | `None`                           | A boto3 Session object to use for authentication.                                                                             |
| `request_params`        | `Optional[Dict[str, Any]]` | `None`                           | Additional parameters to pass to the API requests.                                                                            |
| `client_params`         | `Optional[Dict[str, Any]]` | `None`                           | Additional parameters to pass to the boto3 client.                                                                            |
| `client`                | `Optional[AwsClient]`      | `None`                           | An instance of the AWS Bedrock client to use for making API requests.                                                         |

# Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/aws_bedrock_embedder.py)


# Azure OpenAI Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/azure_openai



The `AzureOpenAIEmbedder` class is used to embed text data into vectors using the Azure OpenAI API. Get your key from [here](https://ai.azure.com/).

## Setup

### Set your API keys

```bash
export AZURE_EMBEDDER_OPENAI_API_KEY=xxx
export AZURE_EMBEDDER_OPENAI_ENDPOINT=xxx
export AZURE_EMBEDDER_DEPLOYMENT=xxx
```

### Run PgVector

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

## Usage

```python cookbook/embedders/azure_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder

# Embed sentence in database
embeddings = AzureOpenAIEmbedder(id="text-embedding-3-small").get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(id="text-embedding-3-small"),
    ),
    max_results=2,
)
```

## Params

| Parameter                 | Type                          | Default                    | Description                                                                      |
| ------------------------- | ----------------------------- | -------------------------- | -------------------------------------------------------------------------------- |
| `model`                   | `str`                         | `"text-embedding-ada-002"` | The name of the model used for generating embeddings.                            |
| `dimensions`              | `int`                         | `1536`                     | The dimensionality of the embeddings generated by the model.                     |
| `encoding_format`         | `Literal['float', 'base64']`  | `"float"`                  | The format in which the embeddings are encoded. Options are "float" or "base64". |
| `user`                    | `str`                         | -                          | The user associated with the API request.                                        |
| `api_key`                 | `str`                         | -                          | The API key used for authenticating requests.                                    |
| `api_version`             | `str`                         | `"2024-02-01"`             | The version of the API to use for the requests.                                  |
| `azure_endpoint`          | `str`                         | -                          | The Azure endpoint for the API requests.                                         |
| `azure_deployment`        | `str`                         | -                          | The Azure deployment name for the API requests.                                  |
| `base_url`                | `str`                         | -                          | The base URL for the API endpoint.                                               |
| `azure_ad_token`          | `str`                         | -                          | The Azure Active Directory token for authentication.                             |
| `azure_ad_token_provider` | `Any`                         | -                          | The provider for obtaining the Azure AD token.                                   |
| `organization`            | `str`                         | -                          | The organization associated with the API request.                                |
| `request_params`          | `Optional[Dict[str, Any]]`    | -                          | Additional parameters to include in the API request. Optional.                   |
| `client_params`           | `Optional[Dict[str, Any]]`    | -                          | Additional parameters for configuring the API client. Optional.                  |
| `openai_client`           | `Optional[AzureOpenAIClient]` | -                          | An instance of the AzureOpenAIClient to use for making API requests. Optional.   |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/azure_embedder.py)


# Cohere Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/cohere



The `CohereEmbedder` class is used to embed text data into vectors using the Cohere API. You can get started with Cohere from [here](https://docs.cohere.com/reference/about)

Get your key from [here](https://dashboard.cohere.com/api-keys).

## Usage

```python cookbook/embedders/cohere_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.cohere import CohereEmbedder

# Add embedding to database
embeddings = CohereEmbedder(id="embed-english-v3.0").get_embedding("The quick brown fox jumps over the lazy dog.")
# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="cohere_embeddings",
        embedder=CohereEmbedder(id="embed-english-v3.0"),
    ),
    max_results=2,
)
```

## Params

| Parameter         | Type                       | Default                | Description                                                                                                                    |
| ----------------- | -------------------------- | ---------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| `model`           | `str`                      | `"embed-english-v3.0"` | The name of the model used for generating embeddings.                                                                          |
| `input_type`      | `str`                      | `search_query`         | The type of input to embed. You can find more details [here](https://docs.cohere.com/docs/embeddings#the-input_type-parameter) |
| `embedding_types` | `Optional[List[str]]`      | -                      | The type of embeddings to generate. Optional.                                                                                  |
| `api_key`         | `str`                      | -                      | The Cohere API key used for authenticating requests.                                                                           |
| `request_params`  | `Optional[Dict[str, Any]]` | -                      | Additional parameters to include in the API request. Optional.                                                                 |
| `client_params`   | `Optional[Dict[str, Any]]` | -                      | Additional parameters for configuring the API client. Optional.                                                                |
| `cohere_client`   | `Optional[CohereClient]`   | -                      | An instance of the CohereClient to use for making API requests. Optional.                                                      |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/cohere_embedder.py)


# Fireworks Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/fireworks



The `FireworksEmbedder` can be used to embed text data into vectors using the Fireworks API. Fireworks uses the OpenAI API specification, so the `FireworksEmbedder` class is similar to the `OpenAIEmbedder` class, incorporating adjustments to ensure compatibility with the Fireworks platform. Get your key from [here](https://fireworks.ai/account/api-keys).

## Usage

```python cookbook/embedders/fireworks_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.fireworks import FireworksEmbedder

# Embed sentence in database
embeddings = FireworksEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="fireworks_embeddings",
        embedder=FireworksEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter    | Type  | Default                                   | Description                                                  |
| ------------ | ----- | ----------------------------------------- | ------------------------------------------------------------ |
| `model`      | `str` | `"nomic-ai/nomic-embed-text-v1.5"`        | The name of the model used for generating embeddings.        |
| `dimensions` | `int` | `768`                                     | The dimensionality of the embeddings generated by the model. |
| `api_key`    | `str` | -                                         | The API key used for authenticating requests.                |
| `base_url`   | `str` | `"https://api.fireworks.ai/inference/v1"` | The base URL for the API endpoint.                           |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/fireworks_embedder.py)


# Gemini Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/gemini



The `GeminiEmbedder` class is used to embed text data into vectors using the Gemini API. You can get one from [here](https://ai.google.dev/aistudio).

## Usage

```python cookbook/embedders/gemini_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.google import GeminiEmbedder

# Embed sentence in database
embeddings = GeminiEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="gemini_embeddings",
        embedder=GeminiEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter        | Type                       | Default                     | Description                                                 |
| ---------------- | -------------------------- | --------------------------- | ----------------------------------------------------------- |
| `dimensions`     | `int`                      | `768`                       | The dimensionality of the generated embeddings              |
| `model`          | `str`                      | `models/text-embedding-004` | The name of the Gemini model to use                         |
| `task_type`      | `str`                      | -                           | The type of task for which embeddings are being generated   |
| `title`          | `str`                      | -                           | Optional title for the embedding task                       |
| `api_key`        | `str`                      | -                           | The API key used for authenticating requests.               |
| `request_params` | `Optional[Dict[str, Any]]` | -                           | Optional dictionary of parameters for the embedding request |
| `client_params`  | `Optional[Dict[str, Any]]` | -                           | Optional dictionary of parameters for the Gemini client     |
| `gemini_client`  | `Optional[Client]`         | -                           | Optional pre-configured Gemini client instance              |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/gemini_embedder.py)


# HuggingFace Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/huggingface



The `HuggingfaceCustomEmbedder` class is used to embed text data into vectors using the Hugging Face API. You can get one from [here](https://huggingface.co/settings/tokens).

## Usage

```python cookbook/embedders/huggingface_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.huggingface import HuggingfaceCustomEmbedder

# Embed sentence in database
embeddings = HuggingfaceCustomEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="huggingface_embeddings",
        embedder=HuggingfaceCustomEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter            | Type                       | Default            | Description                                                  |
| -------------------- | -------------------------- | ------------------ | ------------------------------------------------------------ |
| `dimensions`         | `int`                      | -                  | The dimensionality of the generated embeddings               |
| `model`              | `str`                      | `all-MiniLM-L6-v2` | The name of the HuggingFace model to use                     |
| `api_key`            | `str`                      | -                  | The API key used for authenticating requests                 |
| `client_params`      | `Optional[Dict[str, Any]]` | -                  | Optional dictionary of parameters for the HuggingFace client |
| `huggingface_client` | `Any`                      | -                  | Optional pre-configured HuggingFace client instance          |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/huggingface_embedder.py)


# What are Embedders?
Source: https://docs.agno.com/concepts/knowledge/embedder/introduction

Learn how to use embedders with Agno to convert complex information into vector representations.

An Embedder converts complex information into vector representations, allowing it to be stored in a vector database. By transforming data into embeddings, the embedder enables efficient searching and retrieval of contextually relevant information. This process enhances the responses of language models by providing them with the necessary business context, ensuring they are context-aware. Agno uses the `OpenAIEmbedder` as the default embedder, but other embedders are supported as well. Here is an example:

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.openai import OpenAIEmbedder

# Create knowledge
knowledge = Knowledge(
    vector_db=PgVector(
        db_url=db_url,
        table_name=embeddings_table,
        embedder=OpenAIEmbedder(),
    ),
    # 2 references are added to the prompt
    max_results=2,
)

# Add content to knowledge
knowledge.add_content(
    text_content="The sky is blue"
)

# Add the knowledge to the Agent
agent = Agent(knowledge=knowledge)
```

The following embedders are supported:

* [OpenAI](/concepts/knowledge/embedder/openai)
* [Gemini](/concepts/knowledge/embedder/gemini)
* [Ollama](/concepts/knowledge/embedder/ollama)
* [Voyage AI](/concepts/knowledge/embedder/voyageai)
* [Azure OpenAI](/concepts/knowledge/embedder/azure_openai)
* [Mistral](/concepts/knowledge/embedder/mistral)
* [Fireworks](/concepts/knowledge/embedder/fireworks)
* [Together](/concepts/knowledge/embedder/together)
* [HuggingFace](/concepts/knowledge/embedder/huggingface)
* [Qdrant FastEmbed](/concepts/knowledge/embedder/qdrant_fastembed)


# Mistral Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/mistral



The `MistralEmbedder` class is used to embed text data into vectors using the Mistral API. Get your key from [here](https://console.mistral.ai/api-keys/).

## Usage

```python cookbook/embedders/mistral_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.mistral import MistralEmbedder

# Embed sentence in database
embeddings = MistralEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="mistral_embeddings",
        embedder=MistralEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter        | Type                       | Default           | Description                                                                |
| ---------------- | -------------------------- | ----------------- | -------------------------------------------------------------------------- |
| `model`          | `str`                      | `"mistral-embed"` | The name of the model used for generating embeddings.                      |
| `dimensions`     | `int`                      | `1024`            | The dimensionality of the embeddings generated by the model.               |
| `request_params` | `Optional[Dict[str, Any]]` | -                 | Additional parameters to include in the API request. Optional.             |
| `api_key`        | `str`                      | -                 | The API key used for authenticating requests.                              |
| `endpoint`       | `str`                      | -                 | The endpoint URL for the API requests.                                     |
| `max_retries`    | `Optional[int]`            | -                 | The maximum number of retries for API requests. Optional.                  |
| `timeout`        | `Optional[int]`            | -                 | The timeout duration for API requests. Optional.                           |
| `client_params`  | `Optional[Dict[str, Any]]` | -                 | Additional parameters for configuring the API client. Optional.            |
| `mistral_client` | `Optional[MistralClient]`  | -                 | An instance of the MistralClient to use for making API requests. Optional. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/mistral_embedder.py)


# Ollama Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/ollama



The `OllamaEmbedder` can be used to embed text data into vectors locally using Ollama.

<Note>The model used for generating embeddings needs to run locally. In this case it is `openhermes` so you have to [install `ollama`](https://ollama.com/download) and run `ollama pull openhermes` in your terminal.</Note>

## Usage

```python cookbook/embedders/ollama_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.ollama import OllamaEmbedder

# Embed sentence in database
embeddings = OllamaEmbedder(id="openhermes").get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="ollama_embeddings",
        embedder=OllamaEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter       | Type                       | Default        | Description                                                               |
| --------------- | -------------------------- | -------------- | ------------------------------------------------------------------------- |
| `model`         | `str`                      | `"openhermes"` | The name of the model used for generating embeddings.                     |
| `dimensions`    | `int`                      | `4096`         | The dimensionality of the embeddings generated by the model.              |
| `host`          | `str`                      | -              | The host address for the API endpoint.                                    |
| `timeout`       | `Any`                      | -              | The timeout duration for API requests.                                    |
| `options`       | `Any`                      | -              | Additional options for configuring the API request.                       |
| `client_kwargs` | `Optional[Dict[str, Any]]` | -              | Additional keyword arguments for configuring the API client. Optional.    |
| `ollama_client` | `Optional[OllamaClient]`   | -              | An instance of the OllamaClient to use for making API requests. Optional. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/ollama_embedder.py)


# OpenAI Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/openai



Agno uses the `OpenAIEmbedder` as the default embeder for the vector database. The `OpenAIEmbedder` class is used to embed text data into vectors using the OpenAI API. Get your key from [here](https://platform.openai.com/api-keys).

## Usage

```python cookbook/embedders/openai_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.openai import OpenAIEmbedder

# Embed sentence in database
embeddings = OpenAIEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter         | Type                         | Default                    | Description                                                                      |
| ----------------- | ---------------------------- | -------------------------- | -------------------------------------------------------------------------------- |
| `model`           | `str`                        | `"text-embedding-ada-002"` | The name of the model used for generating embeddings.                            |
| `dimensions`      | `int`                        | `1536`                     | The dimensionality of the embeddings generated by the model.                     |
| `encoding_format` | `Literal['float', 'base64']` | `"float"`                  | The format in which the embeddings are encoded. Options are "float" or "base64". |
| `user`            | `str`                        | -                          | The user associated with the API request.                                        |
| `api_key`         | `str`                        | -                          | The API key used for authenticating requests.                                    |
| `organization`    | `str`                        | -                          | The organization associated with the API request.                                |
| `base_url`        | `str`                        | -                          | The base URL for the API endpoint.                                               |
| `request_params`  | `Optional[Dict[str, Any]]`   | -                          | Additional parameters to include in the API request.                             |
| `client_params`   | `Optional[Dict[str, Any]]`   | -                          | Additional parameters for configuring the API client.                            |
| `openai_client`   | `Optional[OpenAIClient]`     | -                          | An instance of the OpenAIClient to use for making API requests.                  |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/embedders/openai_embedder.py)


# Qdrant FastEmbed Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/qdrant_fastembed



The `FastEmbedEmbedder` class is used to embed text data into vectors using the [FastEmbed](https://qdrant.github.io/fastembed/).

## Usage

```python cookbook/embedders/qdrant_fastembed.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.fastembed import FastEmbedEmbedder

# Embed sentence in database
embeddings = FastEmbedEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="qdrant_embeddings",
        embedder=FastEmbedEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter    | Type  | Default                  | Description                                    |
| ------------ | ----- | ------------------------ | ---------------------------------------------- |
| `dimensions` | `int` | -                        | The dimensionality of the generated embeddings |
| `model`      | `str` | `BAAI/bge-small-en-v1.5` | The name of the qdrant\_fastembed model to use |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/embedders/qdrant_fastembed.py)


# SentenceTransformers Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/sentencetransformers



The `SentenceTransformerEmbedder` class is used to embed text data into vectors using the [SentenceTransformers](https://www.sbert.net/) library.

## Usage

```python cookbook/embedders/sentence_transformer_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.sentence_transformer import SentenceTransformerEmbedder

# Embed sentence in database
embeddings = SentenceTransformerEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="sentence_transformer_embeddings",
        embedder=SentenceTransformerEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter                     | Type               | Default             | Description                                                  |
| ----------------------------- | ------------------ | ------------------- | ------------------------------------------------------------ |
| `dimensions`                  | `int`              | -                   | The dimensionality of the generated embeddings               |
| `model`                       | `str`              | `all-mpnet-base-v2` | The name of the SentenceTransformers model to use            |
| `sentence_transformer_client` | `Optional[Client]` | -                   | Optional pre-configured SentenceTransformers client instance |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/sentence_transformer_embedder.py)


# Together Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/together



The `TogetherEmbedder` can be used to embed text data into vectors using the Together API. Together uses the OpenAI API specification, so the `TogetherEmbedder` class is similar to the `OpenAIEmbedder` class, incorporating adjustments to ensure compatibility with the Together platform. Get your key from [here](https://api.together.xyz/settings/api-keys).

## Usage

```python cookbook/embedders/together_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.together import TogetherEmbedder

# Embed sentence in database
embeddings = TogetherEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="together_embeddings",
        embedder=TogetherEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter    | Type  | Default                                  | Description                                                  |
| ------------ | ----- | ---------------------------------------- | ------------------------------------------------------------ |
| `model`      | `str` | `"nomic-ai/nomic-embed-text-v1.5"`       | The name of the model used for generating embeddings.        |
| `dimensions` | `int` | `768`                                    | The dimensionality of the embeddings generated by the model. |
| `api_key`    | `str` |                                          | The API key used for authenticating requests.                |
| `base_url`   | `str` | `"https://api.Together.ai/inference/v1"` | The base URL for the API endpoint.                           |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/together_embedder.py)


# Voyage AI Embedder
Source: https://docs.agno.com/concepts/knowledge/embedder/voyageai



The `VoyageAIEmbedder` class is used to embed text data into vectors using the Voyage AI API. Get your key from [here](https://dash.voyageai.com/api-keys).

## Usage

```python cookbook/embedders/voyageai_embedder.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.knowledge.embedder.voyageai import VoyageAIEmbedder

# Embed sentence in database
embeddings = VoyageAIEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="voyageai_embeddings",
        embedder=VoyageAIEmbedder(),
    ),
    max_results=2,
)
```

## Params

| Parameter        | Type                       | Default                                    | Description                                                         |
| ---------------- | -------------------------- | ------------------------------------------ | ------------------------------------------------------------------- |
| `model`          | `str`                      | `"voyage-2"`                               | The name of the model used for generating embeddings.               |
| `dimensions`     | `int`                      | `1024`                                     | The dimensionality of the embeddings generated by the model.        |
| `request_params` | `Optional[Dict[str, Any]]` | -                                          | Additional parameters to include in the API request. Optional.      |
| `api_key`        | `str`                      | -                                          | The API key used for authenticating requests.                       |
| `base_url`       | `str`                      | `"https://api.voyageai.com/v1/embeddings"` | The base URL for the API endpoint.                                  |
| `max_retries`    | `Optional[int]`            | -                                          | The maximum number of retries for API requests. Optional.           |
| `timeout`        | `Optional[float]`          | -                                          | The timeout duration for API requests. Optional.                    |
| `client_params`  | `Optional[Dict[str, Any]]` | -                                          | Additional parameters for configuring the API client. Optional.     |
| `voyage_client`  | `Optional[Client]`         | -                                          | An instance of the Client to use for making API requests. Optional. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/knowledge/embedders/voyageai_embedder.py)


# null
Source: https://docs.agno.com/concepts/knowledge/filters/agentic-filters



# Agentic Knowledge Filters

Agentic filtering lets the Agent automatically extract filter criteria from your query text, making the experience more natural and interactive.

## Step 1: Attach Metadata

There are two ways to attach metadata to your documents:

1. **Attach Metadata When Initializing the Knowledge Base**

   ```python
   knowledge_base = Knowledge(
       vector_db=vector_db,
   )

   knowledge_base.add_contents(
       [
           {
               "path": "path/to/cv1.pdf",
               "metadata": {
                   "user_id": "jordan_mitchell",
                   "document_type": "cv",
                   "year": 2025,
               },
           },
           # ... more documents ...
       ]
   )

   ```

2. **Attach Metadata When Loading Documents One by One**

   ```python
   # Initialize Knowledge
   knowledge_base = Knowledge(
       vector_db=vector_db,
       max_results=5,
   )

   # Load first document with user_1 metadata
   knowledge_base.add_content(
       path=path/to/cv1.pdf,
       metadata={"user_id": "jordan_mitchell", "document_type": "cv", "year": 2025},
   )

   # Load second document with user_2 metadata
   knowledge_base.add_content(
       path=path/to/cv2.pdf,
       metadata={"user_id": "taylor_brooks", "document_type": "cv", "year": 2025},
   )
   ```

***

## How It Works

When you enable agentic filtering (`enable_agentic_knowledge_filters=True`), the Agent analyzes your query and applies filters based on the metadata it detects.

**Example:**

```python
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
    enable_agentic_knowledge_filters=True,
)
agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills with jordan_mitchell as user id and document type cv",
    markdown=True,
)
```

In this example, the Agent will automatically use:

* `user_id = "jordan_mitchell"`
* `document_type = "cv"`

***

## üåü See Agentic Filters in Action!

Experience how agentic filters automatically extract relevant metadata from your query.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2bf046e2fb9607b1db6e8a1b5ee0ead0" alt="Agentic Filters in Action" data-og-width="1740" width="1740" data-og-height="715" height="715" data-path="images/agentic_filters.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0245d20f27f0679692757ba76db108bc 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=24d9bd1af34e8846247939e2d74b27ac 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=04efcadbf12c4616ef040032fb9b33ff 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=1a905546407daa3fc8a19a2972bc4153 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=b86573d2610c92c819677f366619146e 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/agentic_filters.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=46ae6ac18ae5b147a8c7eee02c45cfff 2500w" />

*The Agent intelligently narrows down results based on your query.*

***

## When to Use Agentic Filtering

* When you want a more conversational, user-friendly experience.
* When users may not know the exact filter syntax.

## Try It Out!

* Enable `enable_agentic_knowledge_filters=True` on your Agent.
* Ask questions naturally, including filter info in your query.
* See how the Agent narrows down results automatically!

***

## Developer Resources

* [Agentic filtering](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/filters/pdf/agentic_filtering.py)


# null
Source: https://docs.agno.com/concepts/knowledge/filters/introduction



# Knowledge Filters

Knowledge filters allow you to restrict and refine searches within your knowledge base using metadata such as user IDs, document types, years, and more. This feature is especially useful when you have a large collection of documents and want to retrieve information relevant to specific users or contexts.

## Why Use Knowledge Filters?

* **Personalization:** Retrieve information for a specific user or group.
* **Security:** Restrict access to sensitive documents.
* **Efficiency:** Reduce noise by narrowing down search results.

## How Do Knowledge Filters Work?

When you load documents into your knowledge base, you can attach metadata (like user ID, document type, year, etc.). Later, when querying, you can specify filters to only search documents matching certain criteria.

**Example Metadata:**

```python
{
    "user_id": "jordan_mitchell",
    "document_type": "cv",
    "year": 2025,
}
```

## Ways to Apply Filters

You can apply knowledge filters in two main ways:

1. **Manual Filters:** Explicitly pass filters when querying.
2. **Agentic Filters:** Let the Agent automatically extract filters from your query.

> **Tip:** You can combine multiple filters for more precise results!

## Filters in Traditional RAG vs. Agentic RAG

When configuring your Agent it is important to choose the right approach for your use case. There are two broad approaches to RAG with Agno agents: traditional RAG and agentic RAG. With a traditional RAG approach you set `add_knowledge_to_context=True` to ensure that references are included in the system message sent to the LLM. For Agentic RAG, you set `search_knowledge=True` to leverage the agent's ability search the knowledge base directly.

Example:

```python
agent = Agent(
    name="KnowledgeFilterAgent",
    search_knowledge=False,  # Do not use agentic search
    add_knowledge_to_context=True,     # Add knowledge base references to the system prompt
    knowledge_filters={"user_id": "jordan_mitchell"}, # Pass filters like this
)
```

<Check>
  Remember to use only one of these configurations at a time, setting the other to false. By default, `search_knowledge=True` is preferred as it offers a more dynamic and interactive experience.
  Checkout an example [here](/examples/concepts/knowledge/filters/filtering) of how to set up knowledge filters in a Traditional RAG system
</Check>

## Best Practices

* Make your prompts descriptive (e.g., include user names, document types, years).
* Use agentic filtering for interactive applications or chatbots.

## Manual vs. Agentic Filtering

| Manual Filtering         | Agentic Filtering                |
| ------------------------ | -------------------------------- |
| Explicit filters in code | Filters inferred from query text |
| Full control             | More natural, less code          |
| Good for automation      | Good for user-facing apps        |

<Note>
  üö¶ **Currently, knowledge filtering is supported on the following vector databases:**

  * **Qdrant**
  * **LanceDB**
  * **PgVector**
  * **MongoDB**
  * **Pinecone**
  * **Weaviate**
  * **ChromaDB**
  * **Milvus**
</Note>


# null
Source: https://docs.agno.com/concepts/knowledge/filters/manual-filters



# Manual Knowledge Filters

Manual filtering gives you full control over which documents are searched by specifying filters directly in your code.

## Step 1: Attach Metadata

There are two ways to attach metadata to your documents:

1. **Attach Metadata When Initializing the Knowledge Base**

   ```python
   knowledge_base = Knowledge(
       vector_db=vector_db,
   )
   knowledge_base.add_contents(
       [
           {
               "path": "path/to/cv1.pdf",
               "metadata": {
                   "user_id": "jordan_mitchell",
                   "document_type": "cv",
                   "year": 2025,
               },
           },
           # ... more documents ...
       ]
   )
   ```

2. **Attach Metadata When Loading Documents One by One**

   ```python
   # Initialize Knowledge
   knowledge_base = Knowledge(
       vector_db=vector_db,
       max_results=5,
   )

   # Load first document with user_1 metadata
   knowledge_base.add_content(
       path=path/to/cv1.pdf,
       metadata={"user_id": "jordan_mitchell", "document_type": "cv", "year": 2025},
   )

   # Load second document with user_2 metadata
   knowledge_base.add_content(
       path=path/to/cv2.pdf,
       metadata={"user_id": "taylor_brooks", "document_type": "cv", "year": 2025},
   )
   ```

***

> üí° **Tips:**\
> ‚Ä¢ Use **Option 1** if you have all your documents and metadata ready at once.\
> ‚Ä¢ Use **Option 2** if you want to add documents incrementally or as they become available.

## Step 2: Query with Filters

You can pass filters in two ways:

### 1. On the Agent (applies to all queries)

```python
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
    knowledge_filters={"user_id": "jordan_mitchell"},
)
agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    markdown=True,
)
```

### 2. On Each Query (overrides Agent filters for that run)

```python
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)
```

<Note>If you pass filters both on the Agent and on the query, the query-level filters take precedence.</Note>

## Combining Multiple Filters

You can filter by multiple fields:

```python
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
    knowledge_filters={
        "user_id": "jordan_mitchell",
        "document_type": "cv",
        "year": 2025,
    }
)
agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    markdown=True,
)
```

## Try It Yourself!

* Load documents with different metadata.
* Query with different filter combinations.
* Observe how the results change!

***

## Developer Resources

* [Manual filtering](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/filters/pdf/filtering.py)
* [Manual filtering on load](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge/filters/pdf/filtering_on_load.py)


# Hybrid Search- Combining Keyword and Vector Search
Source: https://docs.agno.com/concepts/knowledge/hybrid_search

Understanding Hybrid Search and its benefits in combining keyword and vector search for better results.

With Hybrid search, you can get the precision of exact matching with the intelligence of semantic understanding. Combining both approaches will deliver more comprehensive and relevant results in many cases.

## What exactly is Hybrid Search?

**Hybrid search** is a retrieval technique that combines the strengths of both **vector search** (semantic search) and **keyword search** (lexical search) to find the most relevant results for a query.

* Vector search uses embeddings (dense vectors) to capture the semantic meaning of text, enabling the system to find results that are similar in meaning, even if the exact words don‚Äôt match.
* Keyword search (BM25, TF-IDF, etc.) matches documents based on the presence and frequency of exact words or phrases in the query.

Hybrid search blends these approaches, typically by scoring and/or ranking results from both methods, to maximize both precision and recall.

## Keyword Search vs Vector Search vs Hybrid Search

| Feature       | Keyword Search                  | Vector Search                             | Hybrid Search                             |
| ------------- | ------------------------------- | ----------------------------------------- | ----------------------------------------- |
| Based On      | Lexical matching (BM25, TF-IDF) | Embedding similarity (cosine, dot)        | Both                                      |
| Strength      | Exact matches, relevance        | Contextual meaning                        | Balanced relevance + meaning              |
| Weakness      | No semantic understanding       | Misses exact keywords                     | Slightly heavier in compute               |
| Example Match | "chicken soup" = *chicken soup* | "chicken soup" = *hot broth with chicken* | Both literal and related concepts         |
| Best Use Case | Legal docs, structured data     | Chatbots, Q\&A, semantic search           | Multimodal, real-world messy user queries |

<Note>
  Why Hybrid Search might be better for your application-

  * **Improved Recall**: Captures more relevant results missed by pure keyword or vector search.
  * **Balanced Precision**: Exact matches get priority while also including semantically relevant results.
  * **Robust to Ambiguity**: Handles spelling variations, synonyms, and fuzzy user intent.
  * **Best of Both Worlds**: Keywords matter when they should, and meaning matters when needed.

  **Perfect for **real-world apps** like recipe search, customer support, legal discovery, etc.**
</Note>

## Vector DBs in Agno that Support Hybrid Search

The following vector databases support hybrid search natively or via configurations:

| Database   | Hybrid Search Support       |
| ---------- | --------------------------- |
| `pgvector` | ‚úÖ Yes                       |
| `milvus`   | ‚úÖ Yes                       |
| `lancedb`  | ‚úÖ Yes                       |
| `qdrantdb` | ‚úÖ Yes                       |
| `weaviate` | ‚úÖ Yes                       |
| `mongodb`  | ‚úÖ Yes (Atlas Vector Search) |

***

## Example: Hybrid Search using `pgvector`

```python
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector, SearchType

# Database URL
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Initialize hybrid vector DB
hybrid_db = PgVector(
    table_name="recipes",
    db_url=db_url,
    search_type=SearchType.hybrid  # Hybrid Search
)

# Load PDF knowledge base using hybrid search
knowledge_base = Knowledge(
    vector_db=hybrid_db,
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

# Run a hybrid search query
results = hybrid_db.search("chicken coconut soup", limit=5)
print("Hybrid Search Results:", results)
```

## See More Examples

For hands-on code and advanced usage, check out these hybrid search examples for each supported vector database [here](/examples/concepts/vectordb/lance-db/lance-db-hybrid-search)


# What is Knowledge?
Source: https://docs.agno.com/concepts/knowledge/introduction

Knowledge is domain-specific information that the Agent can search at runtime to make better decisions (dynamic few-shot learning) and provide accurate responses (agentic RAG).

Knowledge is stored in a vector db and this searching on demand pattern is called Agentic RAG.

<Accordion title="Dynamic Few-Shot Learning: Text2Sql Agent" icon="database">
  Example: If we're building a Text2Sql Agent, we'll need to give the table schemas, column names, data types, example queries, common "gotchas" to help it generate the best-possible SQL query.

  We're obviously not going to put this all in the system prompt, instead we store this information in a vector database and let the Agent query it at runtime.

  Using this information, the Agent can then generate the best-possible SQL query. This is called dynamic few-shot learning.
</Accordion>

**Agno Agents use Agentic RAG** by default, meaning if you add `knowledge` to an Agent, it will search this knowledge, at runtime, for the specific information it needs to achieve its task.

The pseudo steps for adding knowledge to an Agent are:

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
import asyncio

# Create a knowledge instance for the Agent
knowledge = Knowledge(vector_db=...)

# Add some knowledge content
asyncio.run(
    knowledge.add_content_async(
        text_content="The sky is blue",
    )
)

# Add the Knowledge to the Agent and
# give it a tool to search its knowledge as needed
agent = Agent(knowledge=knowledge, search_knowledge=True)
```

<Tip>
  If you need complete control over the knowledge base search, you can pass your own `knowledge_retriever` function with the following signature:

  ```python
  def knowledge_retriever(
      agent: Agent, query: str, num_documents: Optional[int] = 5, **kwargs
  ) -> Optional[list[dict]]:
    ...

  my_retriever = knowledge_retriever(...)
  agent = Agent(
    knowledge_retriever=my_retriever
  )
  ```

  This function is called during `search_knowledge_base()` and is used by the Agent to retrieve references from the knowledge.
  For more details check out the [Custom Retriever](../knowledge/custom_retriever) page.
</Tip>

## Vector Databases

While any type of storage can be used for knowledge, vector databases offer the best solution for retrieving relevant results from dense information quickly. Here's how vector databases are used with Agents:

<Steps>
  <Step title="Chunk the information">
    Break down the knowledge content into smaller chunks to ensure our search query
    returns only relevant results.
  </Step>

  <Step title="Load the knowledge">
    Convert the chunks into embedding vectors and store them in a vector
    database.
  </Step>

  <Step title="Search the knowledge">
    When the user sends a message, we convert the input message into an
    embedding and "search" for nearest neighbors in the vector database.
  </Step>
</Steps>

## Loading the Knowledge

Before you can use knowledge, it needs to be loaded with embeddings that will be used for retrieval.

### Asynchronous Loading

Many vector databases support asynchronous operations, which can significantly improve performance when loading large amounts of contents into knowledge. You can leverage this capability using the `aload()` method:

```python
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant

COLLECTION_NAME = "pdf-documents"

vector_db = Qdrant(collection=COLLECTION_NAME, url="http://localhost:6333")

# Create a knowledge instance using Qdrant vector storage
knowledge = Knowledge(
    vector_db=vector_db,
)


# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

if __name__ == "__main__":
    # Asynchronously add the content of the PDF file to the knowledge.
    asyncio.run(
        knowledge.add_content_async(
            path="data/pdf",
        )
    )

    # Create and use the agent
    asyncio.run(agent.aprint_response("How to make Thai curry?", markdown=True))
```

The `add_content()` function is sync. You can also call `add_content_async()` for async usage.
Using `add_content_async()` ensures you take full advantage of the non-blocking operations, concurrent processing, and reduced latency that async vector database operations offer. We recommend this approach, which is especially valuable in production environments with high throughput requirements.

For more details on vector database async capabilities, see the [Vector Database Introduction](../knowledge/vectordb/introduction).

Knowledge content needs to be read before it can be passed to any VectorDB for chunking, embedding and storage.
For more details on readers, auto selection and content types, see the [Content Types](../knowledge/content_types) page.


# Readers
Source: https://docs.agno.com/concepts/knowledge/readers

Learn how to use readers to convert raw data into searchable knowledge for your Agents.

Readers are the first step in the process of creating Knowledge from content.
They transform raw content from various sources into structured `Document` objects that can be embedded, chunked, and stored in vector databases.

## What are Readers?

A **Reader** is a specialized component that knows how to parse and extract content from specific data sources or file formats. Think of readers as translators that convert different content formats into a standardized format that Agno can work with.

Every piece of content that enters your knowledge base must pass through a reader first. The reader's job is to:

1. **Parse** the raw content from its original format
2. **Extract** the meaningful text and metadata
3. **Structure** the content into `Document` objects
4. **Apply chunking** strategies to break large content into manageable pieces

## How Readers Work

All readers inherit from the base `Reader` class and follow a consistent pattern:

```python
# Every reader implements these core methods
class Reader:
    def read(self, obj, name=None) -> List[Document]:
        """Synchronously read and process content"""
        pass

    async def async_read(self, obj, name=None) -> List[Document]:
        """Asynchronously read and process content"""
        pass
```

### The Reading Process

When a reader processes content, it follows these steps:

1. **Content Ingestion**: The reader receives raw content (file, URL, text, etc.)
2. **Parsing**: Extract text and metadata using format-specific logic
3. **Document Creation**: Convert parsed content into `Document` objects
4. **Chunking**: Apply chunking strategies to break content into smaller pieces
5. **Return**: Provide a list of processed documents ready for embedding

### Content Types and Specialization

Each reader specializes in handling specific content types:

```python
@classmethod
def get_supported_content_types(cls) -> List[ContentType]:
    """Returns the content types this reader can handle"""
    return [ContentType.PDF]  # Example for PDFReader
```

This specialization allows each reader to:

* Use format-specific parsing libraries
* Extract relevant metadata
* Handle format-specific challenges (encryption, encoding, etc.)
* Optimize processing for that content type

## Reader Configuration

Readers are highly configurable to meet different processing needs:

### Chunking Control

```python
reader = PDFReader(
    chunk=True,                    # Enable/disable chunking
    chunk_size=1000,              # Size of each chunk
    chunking_strategy=MyStrategy() # Custom chunking logic
)
```

### Content Processing Options

```python
reader = PDFReader(
    split_on_pages=True,          # Create separate documents per page
    password="secret123",         # Handle encrypted PDFs
    read_images=True             # Extract text from images via OCR
)
```

### Encoding Control

For text-based readers, you can override the file encoding:

```python
reader = TextReader(
    encoding="utf-8"              # Override default encoding
)

reader = CSVReader(
    encoding="latin-1"            # Handle files with specific encodings
)

reader = MarkdownReader(
    encoding="cp1252"             # Windows-specific encoding
)
```

### Metadata and Naming

```python
documents = reader.read(
    file_path,
    name="custom_document_name",  # Override default naming
    password="file_password"      # Runtime password override
)
```

## The Document Output

Readers convert raw content into `Document` objects with this structure:

```python
Document(
    content="The extracted text content...",
    id="unique_document_identifier",
    name="document_name",
    meta_data={
        "page": 1,                # Page number for PDFs
        "url": "https://...",     # Source URL for web content
        "author": "...",          # Document metadata
    },
    size=len(content)             # Content size in characters
)
```

## Chunking Integration

One of the most important features of readers is their integration with chunking strategies:

### Automatic Chunking

When `chunk=True`, readers automatically apply chunking strategies to break large documents into smaller, more manageable pieces:

```python
# Large PDF gets broken into multiple documents
pdf_reader = PDFReader(chunk=True, chunk_size=1000)
documents = pdf_reader.read("large_document.pdf")
# Returns: [Document(chunk1), Document(chunk2), Document(chunk3), ...]
```

### Chunking Strategy Support

Different readers support different chunking strategies based on their content type:

```python
@classmethod
def get_supported_chunking_strategies(cls) -> List[ChunkingStrategyType]:
    return [
        ChunkingStrategyType.DOCUMENT_CHUNKING,  # Respect document structure
        ChunkingStrategyType.FIXED_SIZE_CHUNKING, # Fixed character/token limits
        ChunkingStrategyType.SEMANTIC_CHUNKING,   # Semantic boundaries
        ChunkingStrategyType.AGENTIC_CHUNKING,    # AI-powered chunking
    ]
```

## Reader Factory and Auto-Selection

Agno provides intelligent reader selection through the `ReaderFactory`:

```python
# Automatic reader selection based on file extension
reader = ReaderFactory.get_reader_for_extension(".pdf")  # Returns PDFReader
reader = ReaderFactory.get_reader_for_extension(".csv")  # Returns CSVReader

# URL-based reader selection
reader = ReaderFactory.get_reader_for_url("https://youtube.com/watch?v=...")  # YouTubeReader
reader = ReaderFactory.get_reader_for_url("https://example.com/doc.pdf")     # PDFReader
```

## Supported Readers

The following readers are currently supported:

| Reader Name     | Description                                           |
| --------------- | ----------------------------------------------------- |
| ArxivReader     | Fetches and processes academic papers from arXiv      |
| CSVReader       | Parses CSV files and converts rows to documents       |
| FirecrawlReader | Uses Firecrawl API to scrape and crawl web content    |
| JSONReader      | Processes JSON files and converts them into documents |
| MarkdownReader  | Reads and parses Markdown files                       |
| PDFReader       | Reads and extracts text from PDF files                |
| TextReader      | Handles plain text files                              |
| WebsiteReader   | Crawls entire websites following links recursively    |
| WebSearchReader | Searches and reads web search results                 |
| WikipediaReader | Searches and reads Wikipedia articles                 |
| YouTubeReader   | Extracts transcripts and metadata from YouTube videos |

## Async Processing

All readers support asynchronous processing for better performance:

```python
# Synchronous reading
documents = reader.read("file.pdf")

# Asynchronous reading - better for I/O intensive operations
documents = await reader.async_read("file.pdf")

# Batch processing with async
tasks = [reader.async_read(file) for file in file_list]
all_documents = await asyncio.gather(*tasks)
```

## Usage in Knowledge

Readers integrate seamlessly with Agno Knowledge:

```python
from agno.knowledge.reader.pdf_reader import PDFReader

# Custom reader configuration
reader = PDFReader(
    chunk_size=1000,
    chunking_strategy=SemanticChunking(),
)

knowledge_base = Knowledge(
    vector_db=vector_db,
)

# Use custom reader
knowledge_base.add_content(
    path="data/documents",
    reader=reader  # Override default reader
)
```

## Best Practices

### Choose the Right Reader

* Use specialized readers for better extraction quality
* Consider format-specific features (PDF encryption, CSV delimiters, etc.)

### Configure Chunking Appropriately

* Smaller chunks for precise retrieval
* Larger chunks for maintaining context
* Use semantic chunking for structured documents

### Optimize for Performance

* Use async readers for I/O-heavy operations
* Batch process multiple files when possible
* Cache readers through ReaderFactory when processing many files

### Handle Errors Gracefully

* Readers return empty lists for failed processing
* Check reader logs for debugging information
* Provide fallback readers for unknown formats

## Next Steps

Now that you understand how readers work, check out the [Examples Section](https://docs.agno.com/examples/introduction).


# Agentic Search
Source: https://docs.agno.com/concepts/knowledge/search



Using an Agent to iteratively search for information is called **Agentic Search** and the process of **searching, reasoning and responding** is known as **Agentic RAG**.

The model interprets your query, generates relevant keywords and searches its knowledge.

<Tip>
  The Agent's response is only as good as its search. **Better search = Better responses**
</Tip>

You can use semantic search, keyword search or hybrid search. We recommend using **hybrid search with reranking** for best in class agentic search.

Because the Agent is searching for the information it needs, this pattern is called **Agentic Search** and is becoming very popular with Agent builders.

<Check>
  Let's build some examples to see Agentic Search in action.
</Check>

## Agentic RAG

When we add a knowledge base to an Agent, behind the scenes, we give the model a tool to search that knowledge base for the information it needs.

The Model generates a set of keywords and calls the `search_knowledge_base()` tool to retrieve the relevant information or few-shot examples.

Here's a working example that uses Hybrid Search + Reranking:

<Tip>
  You may remove the reranking step if you don't need it.
</Tip>

```python agentic_rag.py
"""This cookbook shows how to implement Agentic RAG using Hybrid Search and Reranking.
1. Run: `pip install agno anthropic cohere lancedb tantivy sqlalchemy` to install the dependencies
2. Export your ANTHROPIC_API_KEY and CO_API_KEY
3. Run: `python cookbook/agent_concepts/agentic_search/agentic_rag.py` to run the agent
"""

from agno.agent import Agent
from agno.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.anthropic import Claude
from agno.reranker.cohere import CohereReranker
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge base, loaded with documents from a URL
knowledge_base = Knowledge(
    # Use LanceDB as the vector database, store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.
    knowledge=knowledge_base,
    # search_knowledge=True gives the Agent the ability to search on demand
    # search_knowledge is True by default
    search_knowledge=True,
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
        "Only include the output in your response. No other text.",
    ],
    markdown=True,
)

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://docs.agno.com/introduction/agents.md",
    )
    agent.print_response("What are Agents?", stream=True)
```

## Agentic RAG with Reasoning

We can further improve the Agents search capabilities by giving it the ability to reason about the search results.

By adding reasoning, the Agent "thinks" first about what to search and then "analyzes" the results of the search.

Here's an example of an Agentic RAG Agent that uses reasoning to improve the quality of the search results.

```python agentic_rag_reasoning.py
"""This cookbook shows how to implement Agentic RAG with Reasoning.
1. Run: `pip install agno anthropic cohere lancedb tantivy sqlalchemy` to install the dependencies
2. Export your ANTHROPIC_API_KEY and CO_API_KEY
3. Run: `python cookbook/agent_concepts/agentic_search/agentic_rag_with_reasoning.py` to run the agent
"""

from agno.agent import Agent
from agno.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.anthropic import Claude
from agno.reranker.cohere import CohereReranker
from agno.tools.reasoning import ReasoningTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge base, loaded with documents from a URL
knowledge_base = Knowledge(
    # Use LanceDB as the vector database, store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.
    knowledge=knowledge_base,
    # search_knowledge=True gives the Agent the ability to search on demand
    # search_knowledge is True by default
    search_knowledge=True,
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
        "Only include the output in your response. No other text.",
    ],
    markdown=True,
)

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://docs.agno.com/introduction/agents.md",
    )

    agent.print_response(
        "What are Agents?",
        stream=True,
        show_full_reasoning=True,
        stream_intermediate_steps=True,
    )
```


# Azure Cosmos DB MongoDB vCore Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/azure_cosmos_mongodb



## Setup

Follow the instructions in the [Azure Cosmos DB Setup Guide](https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore) to get the connection string.

Install MongoDB packages:

```shell
pip install "pymongo[srv]"
```

## Example

```python agent_with_knowledge.py
import urllib.parse
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.mongodb import MongoDb

# Azure Cosmos DB MongoDB connection string
"""
Example connection strings:
"mongodb+srv://<username>:<encoded_password>@cluster0.mongocluster.cosmos.azure.com/?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000"
"""
mdb_connection_string = f"mongodb+srv://<username>:<encoded_password>@cluster0.mongocluster.cosmos.azure.com/?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000"

knowledge_base = Knowledge(
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
        search_index_name="recipes",
        cosmos_compatibility=True,
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

# Create and use the agent
agent = Agent(knowledge=knowledge_base)
agent.print_response("How to make Thai curry?", markdown=True)
```

## MongoDB Params

* `collection_name`: The name of the collection in the database.
* `db_url`: The connection string for the MongoDB database.
* `search_index_name`: The name of the search index to use.
* `cosmos_compatibility`: Set to `True` for Azure Cosmos DB compatibility.

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/mongo_db/cosmos_mongodb_vcore.py)


# Cassandra Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/cassandra



## Setup

Install cassandra packages

```shell
pip install cassandra-driver
```

Run cassandra

```shell
docker run -d \
  --name cassandra-db \
  -p 9042:9042 \
  cassandra:latest
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.cassandra import Cassandra
from agno.knowledge.embedder.mistral import MistralEmbedder
from agno.models.mistral import MistralChat
from cassandra.cluster import Cluster

# (Optional) Set up your Cassandra DB

cluster = Cluster()

session = cluster.connect()
session.execute(
    """
    CREATE KEYSPACE IF NOT EXISTS testkeyspace
    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }
    """
)

knowledge_base = Knowledge(
    vector_db=Cassandra(table_name="recipes", keyspace="testkeyspace", session=session, embedder=MistralEmbedder()),
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=MistralChat(provider="mistral-large-latest", api_key=os.getenv("MISTRAL_API_KEY")),
    knowledge=knowledge_base,
)

agent.print_response(
    "What are the health benefits of Khao Niew Dam Piek Maphrao Awn?", markdown=True, show_full_reasoning=True
)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Cassandra also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_cassandra.py
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.embedder.mistral import MistralEmbedder
    from agno.knowledge.knowledge import Knowledge
    from agno.models.mistral import MistralChat
    from agno.vectordb.cassandra import Cassandra

    try:
        from cassandra.cluster import Cluster  # type: ignore
    except (ImportError, ModuleNotFoundError):
        raise ImportError(
            "Could not import cassandra-driver python package.Please install it with pip install cassandra-driver."
        )

    cluster = Cluster()

    session = cluster.connect()
    session.execute(
        """
        CREATE KEYSPACE IF NOT EXISTS testkeyspace
        WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }
        """
    )

    knowledge_base = Knowledge(
        vector_db=Cassandra(
            table_name="recipes",
            keyspace="testkeyspace",
            session=session,
            embedder=MistralEmbedder(),
        ),
    )


    agent = Agent(
        model=MistralChat(),
        knowledge=knowledge_base,
    )

    if __name__ == "__main__":
        asyncio.run(knowledge_base.add_content_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
            )
        )

        # Create and use the agent
        asyncio.run(
            agent.aprint_response(
                "What are the health benefits of Khao Niew Dam Piek Maphrao Awn?",
                markdown=True,
            )
        )
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/cassandra_db/cassandra_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/cassandra_db/async_cassandra_db.py)


# ChromaDB Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/chroma



## Setup

```shell
pip install chromadb
```

## Example

```python agent_with_knowledge.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.chroma import ChromaDb

# Create Knowledge Instance with ChromaDB
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with ChromaDB",
    vector_db=ChromaDb(
        collection="vectors", path="tmp/chromadb", persistent_client=True
    ),
)

asyncio.run(
    knowledge.add_content_async(
        name="Recipes",
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        metadata={"doc_type": "recipe_book"},
    )
)

# Create and use the agent
agent = Agent(knowledge=knowledge)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)

# Delete operations examples
vector_db = knowledge.vector_db
vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"user_tag": "Recipes from website"})
```

### For hosted ChromaDB (Chroma Cloud)

```python
from chromadb.config import Settings

vector_db = ChromaDb(
    collection="vectors",
    settings=Settings(
        chroma_api_impl="chromadb.api.fastapi.FastAPI",
        chroma_server_host="your-tenant-id.api.trychroma.com",
        chroma_server_http_port=443,
        chroma_server_ssl_enabled=True,
        chroma_client_auth_provider="chromadb.auth.token_authn.TokenAuthClientProvider",
        chroma_client_auth_credentials="your-api-key"
    )
)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      ChromaDB also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_chroma_db.py
    # install chromadb - `pip install chromadb`

    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.chroma import ChromaDb

    # Initialize ChromaDB
    vector_db = ChromaDb(collection="recipes", path="tmp/chromadb", persistent_client=True)

    # Create knowledge base
    knowledge = Knowledge(
        vector_db=vector_db,
    )

    # Create and use the agent
    agent = Agent(knowledge=knowledge)

    if __name__ == "__main__":
        # Comment out after first run
        asyncio.run(
            knowledge.add_content_async(url="https://docs.agno.com/introduction/agents.md")
        )

        # Create and use the agent
        asyncio.run(
            agent.aprint_response("What is the purpose of an Agno Agent?", markdown=True)
        )
    ```

    <Tip className="mt-4">
      Use <code>add\_content\_async()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## ChromaDb Params

<Snippet file="vectordb_chromadb_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/chroma_db/chroma_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/chroma_db/async_chroma_db.py)


# Clickhouse Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/clickhouse



## Setup

```shell
docker run -d \
  -e CLICKHOUSE_DB=ai \
  -e CLICKHOUSE_USER=ai \
  -e CLICKHOUSE_PASSWORD=ai \
  -e CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1 \
  -v clickhouse_data:/var/lib/clickhouse/ \
  -v clickhouse_log:/var/log/clickhouse-server/ \
  -p 8123:8123 \
  -p 9000:9000 \
  --ulimit nofile=262144:262144 \
  --name clickhouse-server \
  clickhouse/clickhouse-server
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.db.sqlite import SqliteDb
from agno.vectordb.clickhouse import Clickhouse

knowledge=Knowledge(
    vector_db=Clickhouse(
        table_name="recipe_documents",
        host="localhost",
        port=8123,
        username="ai",
        password="ai",
    ),
)

knowledge.add_content(
  url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    db=SqliteDb(db_file="agno.db"),
    knowledge=knowledge,
    # Enable the agent to search the knowledge base
    search_knowledge=True,
    # Enable the agent to read the chat history
    read_chat_history=True,
)
# Comment out after first run
agent.knowledge.load(recreate=False)  # type: ignore

agent.print_response("How do I make pad thai?", markdown=True)
agent.print_response("What was my last question?", stream=True)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Clickhouse also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_clickhouse.py
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.db.sqlite import SqliteDb
    from agno.vectordb.clickhouse import Clickhouse

    agent = Agent(
        db=SqliteDb(db_file="agno.db"),
        knowledge=Knowledge(
            vector_db=Clickhouse(
                table_name="recipe_documents",
                host="localhost",
                port=8123,
                username="ai",
                password="ai",
            ),
        ),
        # Enable the agent to search the knowledge base
        search_knowledge=True,
        # Enable the agent to read the chat history
        read_chat_history=True,
    )

    if __name__ == "__main__":
        # Comment out after first run
        asyncio.run(agent.knowledge.add_content_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
          )
        )

        # Create and use the agent
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/clickhouse_db/clickhouse.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/clickhouse_db/async_clickhouse.py)


# Couchbase Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/couchbase



## Setup

### Local Setup (Docker)

Run Couchbase locally using Docker:

```shell
docker run -d --name couchbase-server \
  -p 8091-8096:8091-8096 \
  -p 11210:11210 \
  -e COUCHBASE_ADMINISTRATOR_USERNAME=Administrator \
  -e COUCHBASE_ADMINISTRATOR_PASSWORD=password \
  couchbase:latest
```

1. Access the Couchbase UI at: [http://localhost:8091](http://localhost:8091)
2. Login with username: `Administrator` and password: `password`
3. Create a bucket named `recipe_bucket`, a scope `recipe_scope`, and a collection `recipes`

### Managed Setup (Capella)

For a managed cluster, use [Couchbase Capella](https://cloud.couchbase.com/):

* Follow Capella's UI to create a database, bucket, scope, and collection

### Environment Variables

Set up your environment variables:

```shell
export COUCHBASE_USER="Administrator"
export COUCHBASE_PASSWORD="password" 
export COUCHBASE_CONNECTION_STRING="couchbase://localhost"
export OPENAI_API_KEY=xxx
```

For Capella, set `COUCHBASE_CONNECTION_STRING` to your Capella connection string.

### Install Dependencies

```shell
pip install couchbase
```

## Example

```python agent_with_knowledge.py
import os
import time
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.couchbase import CouchbaseSearch
from couchbase.options import ClusterOptions, KnownConfigProfiles
from couchbase.auth import PasswordAuthenticator
from couchbase.management.search import SearchIndex

# Couchbase connection settings
username = os.getenv("COUCHBASE_USER")
password = os.getenv("COUCHBASE_PASSWORD")
connection_string = os.getenv("COUCHBASE_CONNECTION_STRING")

# Create cluster options with authentication
auth = PasswordAuthenticator(username, password)
cluster_options = ClusterOptions(auth)
cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)


knowledge_base = Knowledge(
    vector_db=CouchbaseSearch(
        bucket_name="recipe_bucket",
        scope_name="recipe_scope",
        collection_name="recipes",
        couchbase_connection_string=connection_string,
        cluster_options=cluster_options,
        search_index="vector_search_fts_index",
        embedder=OpenAIEmbedder(
            id="text-embedding-3-large", 
            dimensions=3072, 
            api_key=os.getenv("OPENAI_API_KEY")
        ),
        wait_until_index_ready=60,
        overwrite=True
    ),
)

# Load the knowledge base
knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

# Wait for the vector index to sync with KV
time.sleep(20)

# Create and use the agent
agent = Agent(knowledge=knowledge_base)
agent.print_response("How to make Thai curry?", markdown=True)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Couchbase also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_couchbase.py
    import asyncio
    import os
    import time
    from agno.agent import Agent
    from agno.embedder.openai import OpenAIEmbedder
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.couchbase import CouchbaseSearch
    from couchbase.options import ClusterOptions, KnownConfigProfiles
    from couchbase.auth import PasswordAuthenticator
    from couchbase.management.search import SearchIndex

    # Couchbase connection settings
    username = os.getenv("COUCHBASE_USER")
    password = os.getenv("COUCHBASE_PASSWORD")
    connection_string = os.getenv("COUCHBASE_CONNECTION_STRING")

    # Create cluster options with authentication
    auth = PasswordAuthenticator(username, password)
    cluster_options = ClusterOptions(auth)
    cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)

    knowledge_base = Knowledge(
        vector_db=CouchbaseSearch(
            bucket_name="recipe_bucket",
            scope_name="recipe_scope",
            collection_name="recipes",
            couchbase_connection_string=connection_string,
            cluster_options=cluster_options,
            search_index="vector_search_fts_index",
            embedder=OpenAIEmbedder(
                id="text-embedding-3-large", 
                dimensions=3072, 
                api_key=os.getenv("OPENAI_API_KEY")
            ),
            wait_until_index_ready=60,
            overwrite=True
        ),
    )

    # Create and use the agent
    agent = Agent(knowledge=knowledge_base)

    async def run_agent():
        await knowledge_base.add_content_async(
          url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        )
        time.sleep(5)  # Wait for the vector index to sync with KV
        await agent.aprint_response("How to make Thai curry?", markdown=True)

    if __name__ == "__main__":
        asyncio.run(run_agent())
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## Key Configuration Notes

### Connection Profiles

Use `KnownConfigProfiles.WanDevelopment` for both local and cloud deployments to handle network latency and timeouts appropriately.

## Couchbase Params

<Snippet file="vectordb_couchbase_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/couchbase_db/couchbase_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/couchbase_db/async_couchbase_db.py)


# What are Vector Databases?
Source: https://docs.agno.com/concepts/knowledge/vectordb/introduction

Vector databases enable us to store information as embeddings and search for "results similar" to our input query using cosine similarity or full text search. These results are then provided to the Agent as context so it can respond in a context-aware manner using Retrieval Augmented Generation (RAG).

Here's how vector databases are used with Agents:

<Steps>
  <Step title="Chunk the information">
    Break down the knowledge into smaller chunks to ensure our search query
    returns only relevant results.
  </Step>

  <Step title="Load the knowledge base">
    Convert the chunks into embedding vectors and store them in a vector
    database.
  </Step>

  <Step title="Search the knowledge base">
    When the user sends a message, we convert the input message into an
    embedding and "search" for nearest neighbors in the vector database.
  </Step>
</Steps>

Many vector databases also support hybrid search, which combines the power of vector similarity search with traditional keyword-based search. This approach can significantly improve the relevance and accuracy of search results, especially for complex queries or when dealing with diverse types of data.

Hybrid search typically works by:

1. Performing a vector similarity search to find semantically similar content.
2. Conducting a keyword-based search to identify exact or close matches.
3. Combining the results using a weighted approach to provide the most relevant information.

This capability allows for more flexible and powerful querying, often yielding better results than either method alone.

<Card title="‚ö° Asynchronous Operations">
  <p>Several vector databases support asynchronous operations, offering improved performance through non-blocking operations, concurrent processing, reduced latency, and seamless integration with FastAPI and async agents.</p>

  <Tip className="mt-4">
    When building with Agno, use the <code>aload</code> methods for async knowledge base loading in production environments.
  </Tip>
</Card>

## Supported Vector Databases

The following VectorDb are currently supported:

* [PgVector](../vectordb/pgvector)\*
* [Cassandra](../vectordb/cassandra)
* [ChromaDb](../vectordb/chroma)
* [Couchbase](../vectordb/couchbase)\*
* [Clickhouse](../vectordb/clickhouse)
* [LanceDb](../vectordb/lancedb)\*
* [LightRAG](../vectordb/lightrag)
* [Milvus](../vectordb/milvus)
* [MongoDb](../vectordb/mongodb)
* [Pinecone](../vectordb/pinecone)\*
* [Qdrant](../vectordb/qdrant)
* [Singlestore](../vectordb/singlestore)
* [Weaviate](../vectordb/weaviate)

\*hybrid search supported

Each of these databases has its own strengths and features, including varying levels of support for hybrid search and async operations. Be sure to check the specific documentation for each to understand how to best leverage their capabilities in your projects.


# LanceDB Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/lancedb



## Setup

```shell
pip install lancedb
```

## Example

```python agent_with_knowledge.py
import typer
from typing import Optional
from rich.prompt import Prompt

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.lancedb import LanceDb
from agno.vectordb.search import SearchType

# LanceDB Vector DB
vector_db = LanceDb(
    table_name="recipes",
    uri="/tmp/lancedb",
    search_type=SearchType.keyword,
)

# Knowledge Base
knowledge_base = Knowledge(
    vector_db=vector_db,
)

def lancedb_agent(user: str = "user"):
    agent = Agent(
        knowledge=knowledge_base,
        debug_mode=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message, session_id=f"{user}_session")

if __name__ == "__main__":
    # Comment out after first run
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    typer.run(lancedb_agent)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      LanceDB also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_lance_db.py
    # install lancedb - `pip install lancedb`
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.lancedb import LanceDb

    # Initialize LanceDB
    vector_db = LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",  # You can change this path to store data elsewhere
    )

    # Create knowledge base
    knowledge_base = Knowledge(
        vector_db=vector_db,
    )
    agent = Agent(knowledge=knowledge_base, debug_mode=True)

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Create and use the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## LanceDb Params

<Snippet file="vectordb_lancedb_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/lance_db/lance_db.py)


# LightRAG Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/lightrag



## Setup

## Example

## LightRAG Params

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/lance_db/lance_db.py)
* View [Cookbook (Hybrid Search)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/lance_db/lance_db_hybrid_search.py)


# Milvus Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/milvus



## Setup

```shell
pip install pymilvus
```

## Initialize Milvus

Set the uri and token for your Milvus server.

* If you only need a local vector database for small scale data or prototyping, setting the uri as a local file, e.g.`./milvus.db`, is the most convenient method, as it automatically utilizes [Milvus Lite](https://milvus.io/docs/milvus_lite.md) to store all data in this file.
* If you have large scale data, say more than a million vectors, you can set up a more performant Milvus server on [Docker or Kubernetes](https://milvus.io/docs/quickstart.md).
  In this setup, please use the server address and port as your uri, e.g.`http://localhost:19530`. If you enable the authentication feature on Milvus, use `your_username:your_password` as the token, otherwise don't set the token.
* If you use [Zilliz Cloud](https://zilliz.com/cloud), the fully managed cloud service for Milvus, adjust the `uri` and `token`, which correspond to the [Public Endpoint and API key](https://docs.zilliz.com/docs/on-zilliz-cloud-console#cluster-details) in Zilliz Cloud.

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.milvus import Milvus

vector_db = Milvus(
    collection="recipes",
    uri="./milvus.db",
)
# Create knowledge base
knowledge_base = Knowledge(
    vector_db=vector_db,
)

# Create and use the agent
agent = Agent(knowledge=knowledge_base)

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    agent.print_response("How to make Tom Kha Gai", markdown=True)
    agent.print_response("What was my last question?", stream=True)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Milvus also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_milvus_db.py
    # install pymilvus - `pip install pymilvus`
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.milvus import Milvus

    # Initialize Milvus with local file
    vector_db = Milvus(
        collection="recipes",
        uri="tmp/milvus.db",  # For local file-based storage
    )

    # Create knowledge base
    knowledge_base = Knowledge(
        vector_db=vector_db,
    )

    # Create agent with knowledge base
    agent = Agent(knowledge=knowledge_base)

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Query the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## Milvus Params

<Snippet file="vectordb_milvus_params.mdx" />

Advanced options can be passed as additional keyword arguments to the `MilvusClient` constructor.

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/milvus_db/milvus_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/milvus_db/async_milvus_db.py)


# MongoDB Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/mongodb



## Setup

Follow the instructions in the [MongoDB Setup Guide](https://www.mongodb.com/docs/atlas/getting-started/) to get connection string

Install MongoDB packages

```shell
pip install "pymongo[srv]"
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.mongodb import MongoDb

# MongoDB Atlas connection string
"""
Example connection strings:
"mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority"
"mongodb://localhost/?directConnection=true"
"""
mdb_connection_string = ""

knowledge_base = Knowledge(
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
        wait_until_index_ready=60,
        wait_after_insert=300
    ),
)  # adjust wait_after_insert and wait_until_index_ready to your needs

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    agent = Agent(knowledge=knowledge_base)
    agent.print_response("How to make Thai curry?", markdown=True)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      MongoDB also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_mongodb.py
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.mongodb import MongoDb

    # MongoDB Atlas connection string
    """
    Example connection strings:
    "mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority"
    "mongodb://localhost:27017/agno?authSource=admin"
    """
    mdb_connection_string = "mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority"

    knowledge_base = Knowledge(
        vector_db=MongoDb(
            collection_name="recipes",
            db_url=mdb_connection_string,
        ),
    )

    # Create and use the agent
    agent = Agent(knowledge=knowledge_base)

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Create and use the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Thai curry?", markdown=True))
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## MongoDB Params

<Snippet file="vectordb_mongodb_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/mongo_db/mongo_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/mongo_db/async_mongo_db.py)


# PgVector Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/pgvector



## Setup

```shell
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.hybrid),
)

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        knowledge=knowledge_base,
        # Add a tool to read chat history.
        read_chat_history=True,
        markdown=True,
        # debug_mode=True,
    )
    agent.print_response("How do I make chicken and galangal in coconut milk soup", stream=True)
    agent.print_response("What was my last question?", stream=True)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      PgVector also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_pgvector.py
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.pgvector import PgVector

    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

    vector_db = PgVector(table_name="recipes", db_url=db_url)

    knowledge_base = Knowledge(
        vector_db=vector_db,
    )

    agent = Agent(knowledge=knowledge_base)

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Create and use the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## PgVector Params

<Snippet file="vectordb_pgvector_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/pgvector/pgvector_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/pgvector/async_pg_vector.py)


# Pinecone Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/pinecone



## Setup

Follow the instructions in the [Pinecone Setup Guide](https://docs.pinecone.io/guides/get-started/quickstart) to get started quickly with Pinecone.

```shell
pip install pinecone
```

<Info>
  We do not yet support Pinecone v6.x.x. We are actively working to achieve
  compatibility. In the meantime, we recommend using **Pinecone v5.4.2** for the
  best experience.
</Info>

## Example

```python agent_with_knowledge.py
import os
import typer
from typing import Optional
from rich.prompt import Prompt

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pineconedb import PineconeDb

api_key = os.getenv("PINECONE_API_KEY")
index_name = "thai-recipe-hybrid-search"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
    use_hybrid_search=True,
    hybrid_alpha=0.5,
)

knowledge_base = Knowledge(
    vector_db=vector_db,
)

def pinecone_agent(user: str = "user"):
    agent = Agent(
        knowledge=knowledge_base,
        debug_mode=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    # Comment out after first run
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    typer.run(pinecone_agent)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Pinecone also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_pinecone.py
    import asyncio
    from os import getenv

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.pineconedb import PineconeDb

    api_key = getenv("PINECONE_API_KEY")
    index_name = "thai-recipe-index"

    vector_db = PineconeDb(
        name=index_name,
        dimension=1536,
        metric="cosine",
        spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
        api_key=api_key,
    )

    knowledge_base = Knowledge(
        vector_db=vector_db,
    )

    agent = Agent(
        knowledge=knowledge_base,
        # Enable the agent to search the knowledge base
        search_knowledge=True,
        # Enable the agent to read the chat history
        read_chat_history=True,
    )

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Create and use the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Use <code>aload()</code> and <code>aprint\_response()</code> methods with <code>asyncio.run()</code> for non-blocking operations in high-throughput applications.
    </Tip>
  </div>
</Card>

## PineconeDb Params

<Snippet file="vectordb_pineconedb_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py)


# Qdrant Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/qdrant



## Setup

Follow the instructions in the [Qdrant Setup Guide](https://qdrant.tech/documentation/guides/installation/) to install Qdrant locally. Here is a guide to get API keys: [Qdrant API Keys](https://qdrant.tech/documentation/cloud/authentication/).

## Example

```python agent_with_knowledge.py
import os
import typer
from typing import Optional
from rich.prompt import Prompt

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant

api_key = os.getenv("QDRANT_API_KEY")
qdrant_url = os.getenv("QDRANT_URL")
collection_name = "thai-recipe-index"

vector_db = Qdrant(
    collection=collection_name,
    url=qdrant_url,
    api_key=api_key,
)

knowledge_base = Knowledge(
    vector_db=vector_db,
)

def qdrant_agent(user: str = "user"):
    agent = Agent(
        knowledge=knowledge_base,
        debug_mode=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    typer.run(qdrant_agent)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Qdrant also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_qdrant_db.py
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.qdrant import Qdrant

    COLLECTION_NAME = "thai-recipes"

    # Initialize Qdrant with local instance
    vector_db = Qdrant(
        collection=COLLECTION_NAME, 
        url="http://localhost:6333"
    )

    # Create knowledge base
    knowledge_base = Knowledge(
        vector_db=vector_db,
    )

    agent = Agent(knowledge=knowledge_base)

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Create and use the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Using <code>aload()</code> and <code>aprint\_response()</code> with asyncio provides non-blocking operations, making your application more responsive under load.
    </Tip>
  </div>
</Card>

## Qdrant Params

<Snippet file="vectordb_qdrant_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/qdrant_db/qdrant_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/qdrant_db/async_qdrant_db.py)


# SingleStore Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/singlestore



## Setup

```shell
docker run -d --name singlestoredb \
  -p 3306:3306 \
  -p 8080:8080 \
  -e ROOT_PASSWORD=admin \
  -e SINGLESTORE_DB=AGNO \
  -e SINGLESTORE_USER=root \
  -e SINGLESTORE_PASSWORD=password \
  singlestore/cluster-in-a-box

docker start singlestoredb
```

After running the container, set the environment variables:

```shell
export SINGLESTORE_HOST="localhost"
export SINGLESTORE_PORT="3306"
export SINGLESTORE_USERNAME="root"
export SINGLESTORE_PASSWORD="admin"
export SINGLESTORE_DATABASE="AGNO"
```

SingleStore supports both cloud-based and local deployments. For step-by-step guidance on setting up your cloud deployment, please refer to the [SingleStore Setup Guide](https://docs.singlestore.com/cloud/connect-to-singlestore/connect-with-mysql/connect-with-mysql-client/connect-to-singlestore-helios-using-tls-ssl/).

## Example

```python agent_with_knowledge.py
import typer
from typing import Optional
from os import getenv

from sqlalchemy.engine import create_engine

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.singlestore import SingleStore

USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

db_engine = create_engine(db_url)

knowledge_base = Knowledge(
    vector_db=SingleStore(
        collection="recipes",
        db_engine=db_engine,
        schema=DATABASE,
    ),
)

def pdf_assistant(user: str = "user"):
    run_id: Optional[str] = None

    agent = Agent(
        user_id=user,
        knowledge=knowledge_base,
        # Uncomment the following line to use traditional RAG
        # add_knowledge_to_context=True,
    )
    if run_id is None:
        run_id = agent.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        agent.cli_app(markdown=True)

if __name__ == "__main__":
    # Comment out after first run
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    typer.run(pdf_assistant)
```

## SingleStore Params

<Snippet file="vectordb_singlestore_params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py)


# SurrealDB Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/surrealdb



## Setup

```shell
docker run --rm \
  --pull always \
  -p 8000:8000 \
  surrealdb/surrealdb:latest \
  start \
  --user root \
  --pass root
```

or

```shell
./cookbook/scripts/run_surrealdb.sh
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.surrealdb import SurrealDb
from surrealdb import Surreal

# SurrealDB connection parameters
SURREALDB_URL = "ws://localhost:8000"
SURREALDB_USER = "root"
SURREALDB_PASSWORD = "root"
SURREALDB_NAMESPACE = "test"
SURREALDB_DATABASE = "test"

# Create a client
client = Surreal(url=SURREALDB_URL)
client.signin({"username": SURREALDB_USER, "password": SURREALDB_PASSWORD})
client.use(namespace=SURREALDB_NAMESPACE, database=SURREALDB_DATABASE)

surrealdb = SurrealDb(
    client=client,
    collection="recipes",  # Collection name for storing documents
    efc=150,  # HNSW construction time/accuracy trade-off
    m=12,  # HNSW max number of connections per element
    search_ef=40,  # HNSW search time/accuracy trade-off
)


def sync_demo():
    """Demonstrate synchronous usage of SurrealDb"""
    knowledge_base = Knowledge(
        vector_db=surrealdb,
        embedder=OpenAIEmbedder(),
    )

    # Load data synchronously
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    # Create agent and query synchronously
    agent = Agent(knowledge=knowledge_base)
    agent.print_response(
        "What are the 3 categories of Thai SELECT is given to restaurants overseas?",
        markdown=True,
    )


if __name__ == "__main__":
    # Run synchronous demo
    print("Running synchronous demo...")
    sync_demo()
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      SurrealDB also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_surrealdb_db.py
    import asyncio

    from agno.agent import Agent
    from agno.embedder.openai import OpenAIEmbedder
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.surrealdb import SurrealDb
    from surrealdb import AsyncSurreal

    # SurrealDB connection parameters
    SURREALDB_URL = "ws://localhost:8000"
    SURREALDB_USER = "root"
    SURREALDB_PASSWORD = "root"
    SURREALDB_NAMESPACE = "test"
    SURREALDB_DATABASE = "test"

    # Create a client
    client = AsyncSurreal(url=SURREALDB_URL)

    surrealdb = SurrealDb(
    async_client=client,
    collection="recipes",  # Collection name for storing documents
    efc=150,  # HNSW construction time/accuracy trade-off
    m=12,  # HNSW max number of connections per element
    search_ef=40,  # HNSW search time/accuracy trade-off
    )


    async def async_demo():
    """Demonstrate asynchronous usage of SurrealDb"""

    await client.signin({"username": SURREALDB_USER, "password": SURREALDB_PASSWORD})
    await client.use(namespace=SURREALDB_NAMESPACE, database=SURREALDB_DATABASE)

    knowledge_base = Knowledge(
        vector_db=surrealdb,
        embedder=OpenAIEmbedder(),
    )

    await knowledge_base.add_content_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    agent = Agent(knowledge=knowledge_base)
    await agent.aprint_response(
        "What are the 3 categories of Thai SELECT is given to restaurants overseas?",
        markdown=True,
    )


    if __name__ == "__main__":
    # Run asynchronous demo
    print("\nRunning asynchronous demo...")
    asyncio.run(async_demo())
    ```

    <Tip className="mt-4">
      Using <code>aload()</code> and <code>aprint\_response()</code> with asyncio provides non-blocking operations, making your application more responsive under load.
    </Tip>
  </div>
</Card>

## SurrealDB Params

<Snippet file="vector_db_surrealdb_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/surrealdb/surreal_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/surrealdb/async_surreal_db.py)


# Weaviate Agent Knowledge
Source: https://docs.agno.com/concepts/knowledge/vectordb/weaviate



Follow steps mentioned in [Weaviate setup guide](https://weaviate.io/developers/weaviate/quickstart) to setup Weaviate.

## Setup

Install weaviate packages

```shell
pip install weaviate-client
```

Run weaviate

```shell
docker run -d \
  -p 8080:8080 \
  -p 50051:50051 \
  --name weaviate \
  cr.weaviate.io/semitechnologies/weaviate:1.28.4 
```

or

```shell
./cookbook/scripts/run_weaviate.sh
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.search import SearchType
from agno.vectordb.weaviate import Distance, VectorIndex, Weaviate

vector_db = Weaviate(
    collection="recipes",
    search_type=SearchType.hybrid,
    vector_index=VectorIndex.HNSW,
    distance=Distance.COSINE,
    local=True,  # Set to False if using Weaviate Cloud and True if using local instance
)
# Create knowledge base
knowledge_base = Knowledge(
    vector_db=vector_db,
)

# Create and use the agent
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

if __name__ == "__main__":
    knowledge_base.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    agent.print_response("How to make Thai curry?", markdown=True)
```

<Card title="Async Support ‚ö°">
  <div className="mt-2">
    <p>
      Weaviate also supports asynchronous operations, enabling concurrency and leading to better performance.
    </p>

    ```python async_weaviate_db.py
    import asyncio

    from agno.agent import Agent
    from agno.knowledge.knowledge import Knowledge
    from agno.vectordb.search import SearchType
    from agno.vectordb.weaviate import Distance, VectorIndex, Weaviate

    vector_db = Weaviate(
        collection="recipes_async",
        search_type=SearchType.hybrid,
        vector_index=VectorIndex.HNSW,
        distance=Distance.COSINE,
        local=True,  # Set to False if using Weaviate Cloud and True if using local instance
    )

    # Create knowledge base
    knowledge_base = Knowledge(
        vector_db=vector_db,
    )

    agent = Agent(
        knowledge=knowledge_base,
        search_knowledge=True,
    )

    if __name__ == "__main__":
        # Load knowledge base asynchronously
        asyncio.run(knowledge_base.add_content_async(
                url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
            )
        )

        # Create and use the agent asynchronously
        asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
    ```

    <Tip className="mt-4">
      Weaviate's async capabilities leverage <code>WeaviateAsyncClient</code> to provide non-blocking vector operations. This is particularly valuable for applications requiring high concurrency and throughput.
    </Tip>
  </div>
</Card>

## Weaviate Params

<Snippet file="vectordb_weaviate_params.mdx" />

## Developer Resources

* View [Cookbook (Sync)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/weaviate_db/weaviate_db.py)
* View [Cookbook (Async)](https://github.com/agno-agi/agno/blob/main/cookbook/knowledge/vector_db/weaviate_db/async_weaviate_db.py)


# Advanced Memory Usage
Source: https://docs.agno.com/concepts/memory/advanced

Learn what else is doable with Memory.

## Customizing the Memory Manager

The `MemoryManager` class is responsible for handling the LLM used to create and update memories.
You can adjust it to personalize how memories are created and updated:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.memory import MemoryManager
from agno.models.openai import OpenAIChat

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Memory Manager, to adjust how memories are created
memory_manager = MemoryManager(
    db=db,
    # Select the model used for memory creation and updates. If unset, the default model of the Agent is used.
    model=OpenAIChat(id="gpt-5-mini"),
    # You can also provide additional instructions
    additional_instructions="Don't store the user's real name",
)

# Now provide the adjusted Memory Manager to your Agent
agent = Agent(
    db=db,
    memory_manager=memory_manager,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")

agent.print_response("What's do I do in weekends?")
```

## Memories and Context

When using Memory with your Agents, memories about the current user will be added to the agent's context by default.

If you want your Agent to create and update memories, but not have them added to the context of each request to the model, you can use the `add_memories_to_context` flag:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Agent with Memory
agent = Agent(
    db=db,
    enable_user_memories=True, # This enables Memory for the Agent
    add_memories_to_context=False, # This disables adding memories to the context
)
```

## Accessing Memories with tools

You can give your Agents access to memories via `MemoryTools`.

This is useful when you:

* Want your agent to reason about memory operations and analyze the results
* Want to have more control over the operations your agent can perform on the memories

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.memory import MemoryTools

# Create a database connection
db = SqliteDb(
    db_file="tmp/memory.db"
)

memory_tools = MemoryTools(
    db=db,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[memory_tools],
    markdown=True,
)

if __name__ == "__main__":
    agent.print_response(
        "My name is John Doe and I like to hike in the mountains on weekends. "
        "I like to travel to new places and experience different cultures. "
        "I am planning to travel to Africa in December. ",
        user_id="john_doe@example.com",
        stream=True
    )

    # This won't use the session history, but instead will use the memory tools to get the memories
    agent.print_response("What have you remembered about me?", stream=True, user_id="john_doe@example.com")
```

See the [Memory Tools](/concepts/tools/reasoning_tools/memory-tools) documentation for more details.

## Sharing Memory Between Agents

Often, you will want multiple Agents to share the same memories.
To achieve this, you just need to provide the same database to those agents.
All Agents will then have access to the same memories for a given user:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Agents with the same database and Memory enabled
agent_1 = Agent(db=db, enable_user_memories=True)
agent_2 = Agent(db=db, enable_user_memories=True)

# The first Agent will create a Memory about the user name here:
agent_1.print_response("Hi! My name is John Doe")

# The second Agent will be able to retrieve the Memory about the user name here:
agent_2.print_response("What is my name?")
```


# What is Memory?
Source: https://docs.agno.com/concepts/memory/overview

Memory gives an Agent the ability to recall information about the user.

Using **Memory**, you can enable your Agents to recall information about the user.

When relevant information about the user is available in the conversation, an Agent with Memory will store it in the database. It will later be able to retrieve that information when relevant, effectively **learning about the user**!

## Usage

To get started, let's setup a basic Agent with Memory. For that, you will need to setup a database and configure your Agent as follows:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Agent with Memory
agent = Agent(
    db=db,
    enable_user_memories=True, # This enables Memory for the Agent
)
```

### Agentic Memory

When configuring your Agent with `enable_user_memories=True`, memories will be automatically created/updated after each run.

You can also give the Agent full control over the memory management by using `enable_agentic_memory=True`:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Agent with Memory
agent = Agent(
    db=db,
    enable_agentic_memory=True, # This enables Agentic Memory for the Agent
)
```

In this case, the Agent will be equipped with a tool to create, update or delete memories when it deems it relevant.

## Where are memories stored?

Memories are stored in the database you provide to the Agent. In the [Storage](/concepts/db/overview) section, you can read more about adding a database to your Agent and which databases are supported.

By default, memories are stored in the `agno_memories` table of the database.

If the table or collection doesn't exist, it is created automatically when first storing a memory.

```python
from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup your database
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    memory_table="my_memory_table", # Specify the table to store memories
)

# Setup your Agent with the database
agent = Agent(db=db, enable_user_memories=True)

# Run the Agent. This will store a session in our "my_memory_table"
agent.print_response("Hi! My name is John Doe and I like to play basketball on the weekends.")

agent.print_response("What are my hobbies?")
```

### Retrieval

You can manually retrieve memories about a certain user from the database using the `get_user_memories` method:

```python
from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup your database
db = PostgresDb(
    db_url="postgresql://user:password@localhost:5432/my_database",
    memory_table="my_memory_table", # Specify the table to store memories
)

# Setup your Agent with the database
agent = Agent(db=db)

# Run the Agent. This will store a memory in our "my_memory_table"
agent.print_response("I love sushi!", user_id="123")

# Retrieve the memories about the user
memories = agent.get_user_memories(user_id="123")
print(memories)
```

## Data Model

These are the fields stored in the database when using Memory:

| Field        | Type   | Description                                     |
| ------------ | ------ | ----------------------------------------------- |
| `memory_id`  | `str`  | The unique identifier for the memory.           |
| `memory`     | `dict` | The memory data, stored as a JSON object.       |
| `topics`     | `list` | The topics of the memory.                       |
| `input`      | `str`  | The input that generated the memory.            |
| `user_id`    | `str`  | The user ID of the memory.                      |
| `agent_id`   | `str`  | The agent ID of the memory.                     |
| `team_id`    | `str`  | The team ID of the memory.                      |
| `updated_at` | `int`  | The timestamp when the memory was last updated. |

This data is best displayed on the [Memories page of the AgentOS UI](https://os.agno.com/memory).

## Developer Resources

* View [Examples](/examples/concepts/memory)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/memory/)


# AI/ML API
Source: https://docs.agno.com/concepts/models/aimlapi

Learn how to use AI/ML API with Agno.

AI/ML API is a platform providing unified access to 300+ AI models including **Deepseek**, **Gemini**, **ChatGPT**, and more ‚Äî with production-grade uptime and high rate limits.

## Authentication

Set your `AIMLAPI_API_KEY` environment variable. Get your key at [aimlapi.com](https://aimlapi.com/?utm_source=agno\&utm_medium=github\&utm_campaign=integration).

<CodeGroup>
  ```bash Mac
  export AIMLAPI_API_KEY=***
  ```

  ```bash Windows
  setx AIMLAPI_API_KEY ***
  ```
</CodeGroup>

## Example

Use `AI/ML API` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.aimlapi import AIMLAPI

  agent = Agent(
      model=AIMLAPI(id="meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo"),
      markdown=True,
  )

  agent.print_response("Explain how black holes are formed.")
  ```
</CodeGroup>

## Params

<Snippet file="model-aimlapi-params.mdx" />

`AIMLAPI` also supports the params of [OpenAI](/reference/models/openai), where applicable.


# Anthropic Claude
Source: https://docs.agno.com/concepts/models/anthropic

Learn how to use Anthropic Claude models in Agno.

Claude is a family of foundational AI models by Anthropic that can be used in a variety of applications.
See their model comparisons [here](https://docs.anthropic.com/en/docs/about-claude/models#model-comparison-table).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `claude-sonnet-4-20250514` model is good for most use-cases and supports image input.
* `claude-opus-4-1-20250805` model is their best model.
* `claude-3-5-haiku-20241022` model is their fastest model.

Anthropic has rate limits on their APIs. See the [docs](https://docs.anthropic.com/en/api/rate-limits#response-headers) for more information.

## Authentication

Set your `ANTHROPIC_API_KEY` environment. You can get one [from Anthropic here](https://console.anthropic.com/settings/keys).

<CodeGroup>
  ```bash Mac
  export ANTHROPIC_API_KEY=***
  ```

  ```bash Windows
  setx ANTHROPIC_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Claude` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.anthropic import Claude

  agent = Agent(
      model=Claude(id="claude-3-5-sonnet-20240620"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```

  ## Prompt caching

  You can enable system prompt caching with our `Claude` model by setting `cache_system_prompt` to `True`:

  ```python
  from agno.agent import Agent
  from agno.models.anthropic import Claude

  agent = Agent(
      model=Claude(
          id="claude-3-5-sonnet-20241022",
          cache_system_prompt=True,
      ),
  )
  ```

  Read more about prompt caching with Agno's `Claude` model [here](https://docs.agno.com/examples/models/anthropic/prompt_caching).
</CodeGroup>

<Note> View more examples [here](/examples/models/anthropic/basic). </Note>

## Params

<Snippet file="model-claude-params.mdx" />

`Claude` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# AWS Bedrock
Source: https://docs.agno.com/concepts/models/aws-bedrock

Learn how to use AWS Bedrock with Agno.

Use AWS Bedrock to access various foundation models on AWS. Manage your access to models [on the portal](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/model-catalog).

See all the [AWS Bedrock foundational models](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html). Not all Bedrock models support all features. See the [supported features for each model](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* For a Mistral model with generally good performance, look at `mistral.mistral-large-2402-v1:0`.
* You can play with Amazon Nova models. Use `amazon.nova-pro-v1:0` for general purpose tasks.
* For Claude models, see our [Claude integration](/concepts/models/aws-claude).

<Warning>
  Async usage of AWS Bedrock is not yet supported. When using `AwsBedrock` with
  an `Agent`, you can only use `agent.run` and `agent.print_response`.
</Warning>

## Authentication

Set your `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and `AWS_REGION` environment variables.

Get your keys from [here](https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/home).

<CodeGroup>
  ```bash Mac
  export AWS_ACCESS_KEY_ID=***
  export AWS_SECRET_ACCESS_KEY=***
  export AWS_REGION=***
  ```

  ```bash Windows
  setx AWS_ACCESS_KEY_ID ***
  setx AWS_SECRET_ACCESS_KEY ***
  setx AWS_REGION ***
  ```
</CodeGroup>

## Example

Use `AwsBedrock` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.aws import AwsBedrock

  agent = Agent(
      model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/aws/bedrock/basic). </Note>

## Parameters

<Snippet file="model-aws-params.mdx" />

`AwsBedrock` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# AWS Claude
Source: https://docs.agno.com/concepts/models/aws-claude

Learn how to use AWS Claude models in Agno.

Use Claude models through AWS Bedrock. This provides a native Claude integration optimized for AWS infrastructure.

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `anthropic.claude-3-5-sonnet-20241022-v2:0` model is good for most use-cases and supports image input.
* `anthropic.claude-3-5-haiku-20241022-v2:0` model is their fastest model.

## Authentication

Set your `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and `AWS_REGION` environment variables.

Get your keys from [here](https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/home).

<CodeGroup>
  ```bash Mac
  export AWS_ACCESS_KEY_ID=***
  export AWS_SECRET_ACCESS_KEY=***
  export AWS_REGION=***
  ```

  ```bash Windows
  setx AWS_ACCESS_KEY_ID ***
  setx AWS_SECRET_ACCESS_KEY ***
  setx AWS_REGION ***
  ```
</CodeGroup>

## Example

Use `Claude` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.aws import Claude

  agent = Agent(
      model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/aws/claude/basic). </Note>

## Parameters

<Snippet file="model-aws-claude-params.mdx" />

`Claude` is a subclass of [`AnthropicClaude`](/concepts/models/anthropic) and has access to the same params.


# Azure AI Foundry
Source: https://docs.agno.com/concepts/models/azure-ai-foundry

Learn how to use Azure AI Foundry models in Agno.

Use various open source models hosted on Azure's infrastructure. Learn more [here](https://learn.microsoft.com/azure/ai-services/models).

Azure AI Foundry provides access to models like `Phi`, `Llama`, `Mistral`, `Cohere` and more.

## Authentication

Navigate to Azure AI Foundry on the [Azure Portal](https://portal.azure.com/) and create a service. Then set your environment variables:

<CodeGroup>
  ```bash Mac
  export AZURE_API_KEY=***
  export AZURE_ENDPOINT=***  # Of the form https://<your-host-name>.<your-azure-region>.models.ai.azure.com/models
  # Optional:
  # export AZURE_API_VERSION=***
  ```

  ```bash Windows
  setx AZURE_API_KEY ***  # Of the form https://<your-host-name>.<your-azure-region>.models.ai.azure.com/models
  setx AZURE_ENDPOINT ***
  # Optional:
  # setx AZURE_API_VERSION ***
  ```
</CodeGroup>

## Example

Use `AzureAIFoundry` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.azure import AzureAIFoundry

  agent = Agent(
      model=AzureAIFoundry(id="Phi-4"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Advanced Examples

View more examples [here](/examples/models/azure/ai_foundry/basic).

## Parameters

<Snippet file="model-azure-ai-foundry-params.mdx" />

`AzureAIFoundry` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Azure OpenAI
Source: https://docs.agno.com/concepts/models/azure-openai

Learn how to use Azure OpenAI models in Agno.

Use OpenAI models through Azure's infrastructure. Learn more [here](https://learn.microsoft.com/azure/ai-services/openai/overview).

Azure OpenAI provides access to OpenAI's models like `GPT-4o`, `gpt-5-mini`, and more.

## Authentication

Navigate to Azure OpenAI on the [Azure Portal](https://portal.azure.com/) and create a service. Then, using the Azure AI Studio portal, create a deployment and set your environment variables:

<CodeGroup>
  ```bash Mac
  export AZURE_OPENAI_API_KEY=***
  export AZURE_OPENAI_ENDPOINT=***  # Of the form https://<your-resource-name>.openai.azure.com/openai/deployments/<your-deployment-name>
  # Optional:
  # export AZURE_OPENAI_DEPLOYMENT=***
  ```

  ```bash Windows
  setx AZURE_OPENAI_API_KEY ***  # Of the form https://<your-resource-name>.openai.azure.com/openai/deployments/<your-deployment-name>
  setx AZURE_OPENAI_ENDPOINT ***
  # Optional:
  # setx AZURE_OPENAI_DEPLOYMENT ***
  ```
</CodeGroup>

## Example

Use `AzureOpenAI` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.azure import AzureOpenAI
  from os import getenv

  agent = Agent(
      model=AzureOpenAI(id="gpt-5-mini"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Prompt caching

Prompt caching will happen automatically using our `AzureOpenAI` model. You can read more about how OpenAI handle caching in [their docs](https://platform.openai.com/docs/guides/prompt-caching).

## Advanced Examples

View more examples [here](/examples/models/azure/openai/basic).

## Parameters

<Snippet file="model-azure-openai-params.mdx" />

`AzureOpenAI` also supports the parameters of [OpenAI](/reference/models/openai).


# Cerebras
Source: https://docs.agno.com/concepts/models/cerebras

Learn how to use Cerebras models in Agno.

[Cerebras Inference](https://inference-docs.cerebras.ai/introduction) provides high-speed, low-latency AI model inference powered by Cerebras Wafer-Scale Engines and CS-3 systems. Agno integrates directly with the Cerebras Python SDK, allowing you to use state-of-the-art Llama models with a simple interface.

## Prerequisites

To use Cerebras with Agno, you need to:

1. **Install the required packages:**

   ```shell
   pip install cerebras-cloud-sdk
   ```

2. **Set your API key:**
   The Cerebras SDK expects your API key to be available as an environment variable:
   ```shell
   export CEREBRAS_API_KEY=your_api_key_here
   ```

## Basic Usage

Here's how to use a Cerebras model with Agno:

```python
from agno.agent import Agent
from agno.models.cerebras import Cerebras

agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story")
```

## Supported Models

Cerebras currently supports the following models (see [docs](https://inference-docs.cerebras.ai/introduction) for the latest list):

| Model Name                      | Model ID                       | Parameters  | Knowledge     |
| ------------------------------- | ------------------------------ | ----------- | ------------- |
| Llama 4 Scout                   | llama-4-scout-17b-16e-instruct | 109 billion | August 2024   |
| Llama 3.1 8B                    | llama3.1-8b                    | 8 billion   | March 2023    |
| Llama 3.3 70B                   | llama-3.3-70b                  | 70 billion  | December 2023 |
| DeepSeek R1 Distill Llama 70B\* | deepseek-r1-distill-llama-70b  | 70 billion  | December 2023 |

\* DeepSeek R1 Distill Llama 70B is available in private preview.

## Configuration Options

The `Cerebras` class accepts the following parameters:

| Parameter        | Type                       | Description                                               | Default      |
| ---------------- | -------------------------- | --------------------------------------------------------- | ------------ |
| `id`             | str                        | Model identifier (e.g., "llama-4-scout-17b-16e-instruct") | **Required** |
| `name`           | str                        | Display name for the model                                | "Cerebras"   |
| `provider`       | str                        | Provider name                                             | "Cerebras"   |
| `api_key`        | Optional\[str]             | API key (falls back to `CEREBRAS_API_KEY` env var)        | None         |
| `max_tokens`     | Optional\[int]             | Maximum tokens in the response                            | None         |
| `temperature`    | float                      | Sampling temperature                                      | 0.7          |
| `top_p`          | float                      | Top-p sampling value                                      | 1.0          |
| `request_params` | Optional\[Dict\[str, Any]] | Additional request parameters                             | None         |

## Resources

* [Cerebras Inference Documentation](https://inference-docs.cerebras.ai/introduction)
* [Cerebras API Reference](https://inference-docs.cerebras.ai/api-reference/chat-completions)

### SDK Examples

* View more examples [here](/examples/models/cerebras/basic).


# Cerebras OpenAI
Source: https://docs.agno.com/concepts/models/cerebras_openai

Learn how to use Cerebras OpenAI with Agno.

## OpenAI-Compatible Integration

Cerebras can also be used via an OpenAI-compatible interface, making it easy to integrate with tools and libraries that expect the OpenAI API.

### Using the OpenAI-Compatible Class

The `CerebrasOpenAI` class provides an OpenAI-style interface for Cerebras models:

First, install openai:

```shell
pip install openai
```

```python
from agno.agent import Agent
from agno.models.cerebras import CerebrasOpenAI

agent = Agent(
    model=CerebrasOpenAI(
        id="llama-4-scout-17b-16e-instruct",  # Model ID to use
        # base_url="https://api.cerebras.ai", # Optional: default endpoint for Cerebras
    ),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story")
```

### Configuration Options

The `CerebrasOpenAI` class accepts the following parameters:

| Parameter  | Type | Description                                                     | Default                                              |
| ---------- | ---- | --------------------------------------------------------------- | ---------------------------------------------------- |
| `id`       | str  | Model identifier (e.g., "llama-4-scout-17b-16e-instruct")       | **Required**                                         |
| `name`     | str  | Display name for the model                                      | "Cerebras"                                           |
| `provider` | str  | Provider name                                                   | "Cerebras"                                           |
| `api_key`  | str  | API key (falls back to CEREBRAS\_API\_KEY environment variable) | None                                                 |
| `base_url` | str  | URL of the Cerebras OpenAI-compatible endpoint                  | "[https://api.cerebras.ai](https://api.cerebras.ai)" |

`CerebrasOpenAI` also supports the parameters of [OpenAI](/reference/models/openai).

### Examples

* View more examples [here](/examples/models/cerebras_openai/basic).


# Cohere
Source: https://docs.agno.com/concepts/models/cohere

Learn how to use Cohere models in Agno.

Leverage Cohere's powerful command models and more.

[Cohere](https://cohere.com) has a wide range of models and is really good for fine-tuning. See their library of models [here](https://docs.cohere.com/v2/docs/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `command` model is good for most basic use-cases.
* `command-light` model is good for smaller tasks and faster inference.
* `command-r7b-12-2024` model is good with RAG tasks, complex reasoning and multi-step tasks.

Cohere also supports fine-tuning models. Here is a [guide](https://docs.cohere.com/v2/docs/fine-tuning) on how to do it.

Cohere has tier-based rate limits. See the [docs](https://docs.cohere.com/v2/docs/rate-limits) for more information.

## Authentication

Set your `CO_API_KEY` environment variable. Get your key from [here](https://dashboard.cohere.com/api-keys).

<CodeGroup>
  ```bash Mac
  export CO_API_KEY=***
  ```

  ```bash Windows
  setx CO_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Cohere` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.cohere import Cohere

  agent = Agent(
      model=Cohere(id="command-r-08-2024"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/cohere/basic). </Note>

## Params

<Snippet file="model-cohere-params.mdx" />

`Cohere` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# CometAPI
Source: https://docs.agno.com/concepts/models/cometapi

Learn how to use CometAPI models in Agno.

CometAPI is a platform for providing endpoints for Large Language models.

See all CometAPI supported models and pricing [here](https://api.cometapi.com/pricing).

## Authentication

Set your `COMETAPI_KEY` environment variable. Get your API key from [here](https://api.cometapi.com/console/token).

<CodeGroup>
  ```bash Mac
  export COMETAPI_KEY=***
  ```

  ```bash Windows
  setx COMETAPI_KEY ***
  ```
</CodeGroup>

## Example

Use `CometAPI` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.cometapi import CometAPI

  agent = Agent(model=CometAPI(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Explain quantum computing in simple terms")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/cometapi/basic). </Note>

## Params

<Snippet file="model-cometapi-params.mdx" />

`CometAPI` also supports the params of [OpenAI](/reference/models/openai).


# Models Compatibility
Source: https://docs.agno.com/concepts/models/compatibility



<Snippet file="compatibility-matrix.mdx" />


# DashScope
Source: https://docs.agno.com/concepts/models/dashscope

Learn how to use DashScope models in Agno.

Leverage DashScope's powerful command models and more.

[DashScope](https://dashscope.aliyun.com/) supports a wide range of models

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `qwen-plus` model is good for most use-cases.

## Authentication

Set your `DASHSCOPE_API_KEY` environment variable. Get your key from [here](https://dashscope.aliyun.com/api-keys).

<CodeGroup>
  ```bash Mac
  export DASHSCOPE_API_KEY=***
  ```

  ```bash Windows
  setx DASHSCOPE_API_KEY ***
  ```
</CodeGroup>

## Example

Use `DashScope` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.dashscope import DashScope

  agent = Agent(
      model=DashScope(id="qwen-plus"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/dashscope/basic). </Note>

## Params

<Snippet file="model-dashscope-params.mdx" />

`DashScope` also supports the parameters of [OpenAI](/reference/models/openai).


# DeepInfra
Source: https://docs.agno.com/concepts/models/deepinfra

Learn how to use DeepInfra models in Agno.

Leverage DeepInfra's powerful command models and more.

[DeepInfra](https://deepinfra.com) supports a wide range of models. See their library of models [here](https://deepinfra.com/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `deepseek-ai/DeepSeek-R1-Distill-Llama-70B` model is good for reasoning.
* `meta-llama/Llama-2-70b-chat-hf` model is good for basic use-cases.
* `meta-llama/Llama-3.3-70B-Instruct` model is good for multi-step tasks.

DeepInfra has rate limits. See the [docs](https://deepinfra.com/docs/advanced/rate-limits) for more information.

## Authentication

Set your `DEEPINFRA_API_KEY` environment variable. Get your key from [here](https://deepinfra.com/dash/api_keys).

<CodeGroup>
  ```bash Mac
  export DEEPINFRA_API_KEY=***
  ```

  ```bash Windows
  setx DEEPINFRA_API_KEY ***
  ```
</CodeGroup>

## Example

Use `DeepInfra` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.deepinfra import DeepInfra

  agent = Agent(
      model=DeepInfra(id="meta-llama/Llama-2-70b-chat-hf"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/deepinfra/basic). </Note>

## Params

<Snippet file="model-deepinfra-params.mdx" />

`DeepInfra` also supports the parameters of [OpenAI](/reference/models/openai).


# DeepSeek
Source: https://docs.agno.com/concepts/models/deepseek

Learn how to use DeepSeek models in Agno.

DeepSeek is a platform for providing endpoints for Large Language models.
See their library of models [here](https://api-docs.deepseek.com/quick_start/pricing).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `deepseek-chat` model is good for most basic use-cases.
* `deepseek-reasoner` model is good for complex reasoning and multi-step tasks.

DeepSeek does not have rate limits. See their [docs](https://api-docs.deepseek.com/quick_start/rate_limit) for information about how to deal with slower responses during high traffic.

## Authentication

Set your `DEEPSEEK_API_KEY` environment variable. Get your key from [here](https://platform.deepseek.com/api_keys).

<CodeGroup>
  ```bash Mac
  export DEEPSEEK_API_KEY=***
  ```

  ```bash Windows
  setx DEEPSEEK_API_KEY ***
  ```
</CodeGroup>

## Example

Use `DeepSeek` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.deepseek import DeepSeek

  agent = Agent(model=DeepSeek(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/deepseek/basic). </Note>

## Params

<Snippet file="model-deepseek-params.mdx" />

`DeepSeek` also supports the params of [OpenAI](/reference/models/openai).


# Fireworks
Source: https://docs.agno.com/concepts/models/fireworks

Learn how to use Fireworks models in Agno.

Fireworks is a platform for providing endpoints for Large Language models.

## Authentication

Set your `FIREWORKS_API_KEY` environment variable. Get your key from [here](https://fireworks.ai/account/api-keys).

<CodeGroup>
  ```bash Mac
  export FIREWORKS_API_KEY=***
  ```

  ```bash Windows
  setx FIREWORKS_API_KEY ***
  ```
</CodeGroup>

## Prompt caching

Prompt caching will happen automatically using our `Fireworks` model. You can read more about how Fireworks handle caching in [their docs](https://docs.fireworks.ai/guides/prompt-caching#using-prompt-caching).

## Example

Use `Fireworks` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.fireworks import Fireworks

  agent = Agent(
      model=Fireworks(id="accounts/fireworks/models/firefunction-v2"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/fireworks/basic). </Note>

## Params

<Snippet file="model-fireworks-params.mdx" />

`Fireworks` also supports the params of [OpenAI](/reference/models/openai).


# Gemini
Source: https://docs.agno.com/concepts/models/google

Learn how to use Gemini models in Agno.

Use Google's Gemini models through [Google AI Studio](https://ai.google.dev/gemini-api/docs) or [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) - platforms that provide access to large language models and other services.

We recommend experimenting to find the best-suited model for your use case. Here are some general recommendations in the Gemini `2.x` family of models:

* `gemini-2.0-flash` is good for most use-cases.
* `gemini-2.0-flash-lite` is the most cost-effective model.
* `gemini-2.5-pro-exp-03-25` is the strongest multi-modal model.

Refer to the [Google AI Studio documentation](https://ai.google.dev/gemini-api/docs/models) and the [Vertex AI documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) for information on available model versions.

## Authentication

You can use Gemini models through either Google AI Studio or Google Cloud's Vertex AI:

### Google AI Studio

Set the `GOOGLE_API_KEY` environment variable. You can get one [from Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key).

<CodeGroup>
  ```bash Mac
  export GOOGLE_API_KEY=***
  ```

  ```bash Windows
  setx GOOGLE_API_KEY ***
  ```
</CodeGroup>

### Vertex AI

To use Vertex AI in Google Cloud:

1. Refer to the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/start/cloud-environment) to set up a project and development environment.

2. Install the `gcloud` CLI and authenticate (refer to the [quickstart](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal) for more details):

```bash
gcloud auth application-default login
```

3. Enable Vertex AI API and set the project ID environment variable (alternatively, you can set `project_id` in the `Agent` config):

Export the following variables:

```bash
export GOOGLE_GENAI_USE_VERTEXAI="true"
export GOOGLE_CLOUD_PROJECT="your-gcloud-project-id"
export GOOGLE_CLOUD_LOCATION="your-gcloud-location"
```

Or update your Agent configuration:

```python
agent = Agent(
    model=Gemini(
        id="gemini-1.5-flash",
        vertexai=True,
        project_id="your-gcloud-project-id",
        location="your-gcloud-location",
    ),
)
```

## Example

Use `Gemini` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.google import Gemini

  # Using Google AI Studio
  agent = Agent(
      model=Gemini(id="gemini-2.0-flash"),
      markdown=True,
  )

  # Or using Vertex AI
  agent = Agent(
      model=Gemini(
          id="gemini-2.0-flash",
          vertexai=True,
          project_id="your-project-id",  # Optional if GOOGLE_CLOUD_PROJECT is set
          location="us-central1",  # Optional
      ),
      markdown=True,
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/gemini/basic). </Note>

## Grounding and Search

Gemini models support grounding and search capabilities through optional parameters. This automatically sends tools for grounding or search to Gemini. See more details [here](https://ai.google.dev/gemini-api/docs/grounding?lang=python).

To enable these features, set the corresponding parameter when initializing the Gemini model:

To use grounding:

<CodeGroup>
  ```python
  from agno.agent import Agent
  from agno.models.google import Gemini

  agent = Agent(
      model=Gemini(id="gemini-2.0-flash", grounding=True),
      markdown=True,
  )

  agent.print_response("Any news from USA?")
  ```
</CodeGroup>

To use search:

<CodeGroup>
  ```python
  from agno.agent import Agent
  from agno.models.google import Gemini

  agent = Agent(
      model=Gemini(id="gemini-2.0-flash", search=True),
      markdown=True,
  )

  agent.print_response("What's happening in France?")
  ```
</CodeGroup>

## Parameters

<Snippet file="model-google-params.mdx" />

`Gemini` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Groq
Source: https://docs.agno.com/concepts/models/groq

Learn how to use Groq with Agno.

Groq offers blazing-fast API endpoints for large language models.

See all the Groq supported models [here](https://console.groq.com/docs/models).

* We recommend using `llama-3.3-70b-versatile` for general use
* We recommend `llama-3.1-8b-instant` for a faster result.
* We recommend using `llama-3.2-90b-vision-preview` for image understanding.

#### Multimodal Support

With Groq we support `Image` as input

## Authentication

Set your `GROQ_API_KEY` environment variable. Get your key from [here](https://console.groq.com/keys).

<CodeGroup>
  ```bash Mac
  export GROQ_API_KEY=***
  ```

  ```bash Windows
  setx GROQ_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Groq` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.groq import Groq

  agent = Agent(
      model=Groq(id="llama-3.3-70b-versatile"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/groq/basic). </Note>

## Params

<Snippet file="model-groq-params.mdx" />

`Groq` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# HuggingFace
Source: https://docs.agno.com/concepts/models/huggingface

Learn how to use HuggingFace models in Agno.

Hugging Face provides a wide range of state-of-the-art language models tailored to diverse NLP tasks,
including text generation, summarization, translation, and question answering.
These models are available through the Hugging Face Transformers library and are widely
adopted due to their ease of use, flexibility, and comprehensive documentation.

Explore HuggingFace‚Äôs language models [here](https://huggingface.co/docs/text-generation-inference/en/supported_models).

## Authentication

Set your `HF_TOKEN` environment. You can get one [from HuggingFace here](https://huggingface.co/settings/tokens).

<CodeGroup>
  ```bash Mac
  export HF_TOKEN=***
  ```

  ```bash Windows
  setx HF_TOKEN ***
  ```
</CodeGroup>

## Example

Use `HuggingFace` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.huggingface import HuggingFace

  agent = Agent(
      model=HuggingFace(
          id="meta-llama/Meta-Llama-3-8B-Instruct",
          max_tokens=4096,
      ),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/huggingface/basic). </Note>

## Params

<Snippet file="model-hf-params.mdx" />

`HuggingFace` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# IBM WatsonX
Source: https://docs.agno.com/concepts/models/ibm-watsonx

Learn how to use IBM WatsonX models in Agno.

IBM WatsonX provides access to powerful foundation models through IBM's cloud platform.

See all the IBM WatsonX supported models [here](https://www.ibm.com/products/watsonx-ai/foundation-models).

* We recommend using `meta-llama/llama-3-3-70b-instruct` for general use
* We recommend `ibm/granite-20b-code-instruct` for code-related tasks
* We recommend using `meta-llama/llama-3-2-11b-vision-instruct` for image understanding

#### Multimodal Support

With WatsonX we support `Image` as input

## Authentication

Set your `IBM_WATSONX_API_KEY` and `IBM_WATSONX_PROJECT_ID` environment variables. Get your credentials from [IBM Cloud](https://cloud.ibm.com/).
You can also set the `IBM_WATSONX_URL` environment variable to the URL of the WatsonX API you want to use. It defaults to `https://eu-de.ml.cloud.ibm.com`.

<CodeGroup>
  ```bash Mac
  export IBM_WATSONX_API_KEY=***
  export IBM_WATSONX_PROJECT_ID=***
  ```

  ```bash Windows
  setx IBM_WATSONX_API_KEY ***
  setx IBM_WATSONX_PROJECT_ID ***
  ```
</CodeGroup>

## Example

Use `WatsonX` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.ibm import WatsonX

  agent = Agent(
      model=WatsonX(id="meta-llama/llama-3-3-70b-instruct"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/ibm/basic). </Note>

## Params

<Snippet file="model-ibm-watsonx-params.mdx" />

`WatsonX` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# What are Models?
Source: https://docs.agno.com/concepts/models/introduction

Language Models are machine-learning programs that are trained to understand natural language and code.

When we discuss Models, we are normally referring to Large Language Models (LLMs).

These models act as the **brain** of your Agents - enabling them to reason, act, and respond to the user. The better the model, the smarter the Agent.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="Share 15 minute healthy recipes.",
    markdown=True,
)
agent.print_response("Share a breakfast recipe.", stream=True)
```

## Error handling

You can set `exponential_backoff` to `True` on the `Agent` to automatically retry requests that fail due to third-party model provider errors.

```python
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    exponential_backoff=True,
    retries=2,
    retry_delay=1,
)
```

## Supported Models

Agno supports the following model providers:

* [AI/ML API](/concepts/models/aimlapi)
* [Anthropic](/concepts/models/anthropic)
* [AWS Bedrock](/concepts/models/aws-bedrock)
* [Azure AI Foundry](/concepts/models/azure-ai-foundry)
* [Azure OpenAI](/concepts/models/azure-openai)
* [Claude via AWS Bedrock](/concepts/models/aws-claude)
* [Cerebras](/concepts/models/cerebras)
* [Cerebras OpenAI](/concepts/models/cerebras_openai)
* [Cohere](/concepts/models/cohere)
* [CometAPI](/concepts/models/cometapi)
* [DashScope](/concepts/models/dashscope)
* [DeepInfra](/concepts/models/deepinfra)
* [DeepSeek](/concepts/models/deepseek)
* [Fireworks](/concepts/models/fireworks)
* [Google Gemini](/concepts/models/google)
* [Groq](/concepts/models/groq)
* [Hugging Face](/concepts/models/huggingface)
* [LangDB](/concepts/models/langdb)
* [LiteLLM](/concepts/models/litellm)
* [LiteLLM OpenAI](/concepts/models/litellm_openai)
* [LlamaCpp](/concepts/models/llama_cpp)
* [LM Studio](/concepts/models/lmstudio)
* [Meta](/concepts/models/meta)
* [Mistral](/concepts/models/mistral)
* [Nebius AI Studio](/concepts/models/nebius)
* [Nexus](/concepts/models/nexus)
* [NVIDIA](/concepts/models/nvidia)
* [Ollama](/concepts/models/ollama)
* [OpenAI](/concepts/models/openai)
* [OpenAI Like](/concepts/models/openai-like)
* [OpenAI Responses](/concepts/models/openai-responses)
* [OpenRouter](/concepts/models/openrouter)
* [Perplexity](/concepts/models/perplexity)
* [Portkey](/concepts/models/portkey)
* [Sambanova](/concepts/models/sambanova)
* [SiliconFlow](/concepts/models/siliconflow)
* [Together](/concepts/models/together)
* [Vercel](/concepts/models/vercel)
* [VLLM](/concepts/models/vllm)
* [xAI](/concepts/models/xai)

Each provider offers a different set of models, with different capabilities and features. By default, Agno supports all models provided by the mentioned providers.


# LangDB
Source: https://docs.agno.com/concepts/models/langdb



[LangDB](https://langdb.ai/) is an AI Gateway for seamless access to 350+ LLMs. Secure, govern, and optimize AI Traffic across LLMs using OpenAI-Compatible APIs.

For detailed integration instructions, see the [LangDB Agno documentation](https://docs.langdb.ai/getting-started/working-with-agent-frameworks/working-with-agno).

## Authentication

Set your `LANGDB_API_KEY` environment variable. Get your key from [here](https://app.langdb.ai/settings/api_keys).

<CodeGroup>
  ```bash Mac
  export LANGDB_API_KEY=***
  export LANGDB_PROJECT_ID=***

  ```

  ```bash Windows
  setx LANGDB_API_KEY ***
  setx LANGDB_PROJECT_ID ***
  ```
</CodeGroup>

## Example

Use `LangDB` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.langdb import LangDB

  agent = Agent(
      model=LangDB(id="gpt-5-mini"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

## Params

<Snippet file="model-langdb-params.mdx" />

`LangDB` also supports the params of [OpenAI](/reference/models/openai).


# LiteLLM
Source: https://docs.agno.com/concepts/models/litellm

Integrate LiteLLM with Agno for a unified LLM experience.

[LiteLLM](https://docs.litellm.ai/docs/) provides a unified interface for various LLM providers, allowing you to use different models with the same code.

Agno integrates with LiteLLM in two ways:

1. **Direct SDK integration** - Using the LiteLLM Python SDK
2. **Proxy Server integration** - Using LiteLLM as an OpenAI-compatible proxy

## Prerequisites

For both integration methods, you'll need:

```shell
# Install required packages
pip install agno litellm
```

Set up your API key:
Regardless of the model used(OpenAI, Hugging Face, or XAI) the API key is referenced as `LITELLM_API_KEY`.

```shell
export LITELLM_API_KEY=your_api_key_here
```

## SDK Integration

The `LiteLLM` class provides direct integration with the LiteLLM Python SDK.

### Basic Usage

```python
from agno.agent import Agent
from agno.models.litellm import LiteLLM

# Create an agent with GPT-4o
agent = Agent(
    model=LiteLLM(
        id="gpt-5-mini",  # Model ID to use
        name="LiteLLM",  # Optional display name
    ),
    markdown=True,
)

# Get a response
agent.print_response("Share a 2 sentence horror story")
```

### Using Hugging Face Models

LiteLLM can also work with Hugging Face models:

```python
from agno.agent import Agent
from agno.models.litellm import LiteLLM

agent = Agent(
    model=LiteLLM(
        id="huggingface/mistralai/Mistral-7B-Instruct-v0.2",
        top_p=0.95,
    ),
    markdown=True,
)

agent.print_response("What's happening in France?")
```

### Configuration Options

The `LiteLLM` class accepts the following parameters:

| Parameter        | Type                       | Description                                                                               | Default      |
| ---------------- | -------------------------- | ----------------------------------------------------------------------------------------- | ------------ |
| `id`             | str                        | Model identifier (e.g., "gpt-5-mini" or "huggingface/mistralai/Mistral-7B-Instruct-v0.2") | "gpt-5-mini" |
| `name`           | str                        | Display name for the model                                                                | "LiteLLM"    |
| `provider`       | str                        | Provider name                                                                             | "LiteLLM"    |
| `api_key`        | Optional\[str]             | API key (falls back to LITELLM\_API\_KEY environment variable)                            | None         |
| `api_base`       | Optional\[str]             | Base URL for API requests                                                                 | None         |
| `max_tokens`     | Optional\[int]             | Maximum tokens in the response                                                            | None         |
| `temperature`    | float                      | Sampling temperature                                                                      | 0.7          |
| `top_p`          | float                      | Top-p sampling value                                                                      | 1.0          |
| `request_params` | Optional\[Dict\[str, Any]] | Additional request parameters                                                             | None         |

### SDK Examples

<Note> View more examples [here](/examples/models/litellm/basic). </Note>


# LiteLLM OpenAI
Source: https://docs.agno.com/concepts/models/litellm_openai

Use LiteLLM with Agno with an openai-compatible proxy server.

## Proxy Server Integration

LiteLLM can also be used as an OpenAI-compatible proxy server, allowing you to route requests to different models through a unified API.

### Starting the Proxy Server

First, install LiteLLM with proxy support:

```shell
pip install 'litellm[proxy]'
```

Start the proxy server:

```shell
litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
```

### Using the Proxy

The `LiteLLMOpenAI` class connects to the LiteLLM proxy using an OpenAI-compatible interface:

```python
from agno.agent import Agent
from agno.models.litellm import LiteLLMOpenAI

agent = Agent(
    model=LiteLLMOpenAI(
        id="gpt-5-mini",  # Model ID to use
    ),
    markdown=True,
)

agent.print_response("Share a 2 sentence horror story")
```

### Configuration Options

The `LiteLLMOpenAI` class accepts the following parameters:

| Parameter  | Type | Description                                                    | Default                                      |
| ---------- | ---- | -------------------------------------------------------------- | -------------------------------------------- |
| `id`       | str  | Model identifier                                               | "gpt-5-mini"                                 |
| `name`     | str  | Display name for the model                                     | "LiteLLM"                                    |
| `provider` | str  | Provider name                                                  | "LiteLLM"                                    |
| `api_key`  | str  | API key (falls back to LITELLM\_API\_KEY environment variable) | None                                         |
| `base_url` | str  | URL of the LiteLLM proxy server                                | "[http://0.0.0.0:4000](http://0.0.0.0:4000)" |

## Examples

Check out these examples in the cookbook:

### Proxy Examples

<Note> View more examples [here](/examples/models/litellm_openai/basic). </Note>


# LlamaCpp
Source: https://docs.agno.com/concepts/models/llama_cpp

Learn how to use LlamaCpp with Agno.

Run Large Language Models locally with LLaMA CPP

[LlamaCpp](https://github.com/ggerganov/llama.cpp) is a powerful tool for running large language models locally with efficient inference. LlamaCpp supports multiple open-source models and provides an OpenAI-compatible API server.

LlamaCpp supports a wide variety of models in GGML format. You can find models on HuggingFace, including the default `ggml-org/gpt-oss-20b-GGUF` used in the examples below.

We recommend experimenting to find the best model for your use case. Here are some popular model recommendations:

### Google Gemma Models

* `google/gemma-2b-it-GGUF` - Lightweight 2B parameter model, great for resource-constrained environments
* `google/gemma-7b-it-GGUF` - Balanced 7B model with strong performance for general tasks
* `ggml-org/gemma-3-1b-it-GGUF` - Latest Gemma 3 series, efficient for everyday use

### Meta Llama Models

* `Meta-Llama-3-8B-Instruct` - Popular 8B parameter model with excellent instruction following
* `Meta-Llama-3.1-8B-Instruct` - Enhanced version with improved capabilities and 128K context
* `Meta-Llama-3.2-3B-Instruct` - Compact 3B model for faster inference

### Default Options

* `ggml-org/gpt-oss-20b-GGUF` - Default model for general use cases
* Models with different quantizations (Q4\_K\_M, Q8\_0, etc.) for different speed/quality tradeoffs
* Choose models based on your hardware constraints and performance requirements

## Set up LlamaCpp

### Install LlamaCpp

First, install LlamaCpp following the [official installation guide](https://github.com/ggerganov/llama.cpp):

```bash install
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
make
```

Or using package managers:

```bash brew install
# macOS with Homebrew
brew install llama.cpp
```

### Download a Model

Download a model in GGUF format following the [llama.cpp model download guide](https://github.com/ggerganov/llama.cpp#obtaining-and-using-the-facebook-llama-2-model). For the examples below, we use `ggml-org/gpt-oss-20b-GGUF`.

### Start the Server

Start the LlamaCpp server with your model:

```bash start server
llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
```

This starts the server at `http://127.0.0.1:8080` with an OpenAI Chat compatible endpoints

## Example

After starting the LlamaCpp server, use the `LlamaCpp` model class to access it:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.llama_cpp import LlamaCpp

  agent = Agent(
      model=LlamaCpp(id="ggml-org/gpt-oss-20b-GGUF"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Configuration

The `LlamaCpp` model supports customizing the server URL and model ID:

<CodeGroup>
  ```python custom_config.py
  from agno.agent import Agent
  from agno.models.llama_cpp import LlamaCpp

  # Custom server configuration
  agent = Agent(
      model=LlamaCpp(
          id="your-custom-model",
          base_url="http://localhost:8080/v1",  # Custom server URL
      ),
      markdown=True
  )
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/llama_cpp/basic). </Note>

## Params

<Snippet file="model-llama-cpp-params.mdx" />

`LlamaCpp` is a subclass of the [OpenAILike](/concepts/models/openai-like) class and has access to the same params.

## Server Configuration

The LlamaCpp server supports many configuration options:

### Common Server Options

* `--ctx-size`: Context size (0 for unlimited)
* `--batch-size`, `-b`: Batch size for prompt processing
* `--ubatch-size`, `-ub`: Physical batch size for prompt processing
* `--threads`, `-t`: Number of threads to use
* `--host`: IP address to listen on (default: 127.0.0.1)
* `--port`: Port to listen on (default: 8080)

### Model Options

* `--model`, `-m`: Model file path
* `--hf-repo`: HuggingFace model repository
* `--jinja`: Use Jinja templating for chat formatting

For a complete list of server options, run `llama-server --help`.

## Performance Optimization

### Hardware Acceleration

LlamaCpp supports various acceleration backends:

```bash gpu acceleration
# NVIDIA GPU (CUDA)
make LLAMA_CUDA=1

# Apple Metal (macOS)
make LLAMA_METAL=1

# OpenCL
make LLAMA_CLBLAST=1
```

### Model Quantization

Use quantized models for better performance:

* `Q4_K_M`: Balanced size and quality
* `Q8_0`: Higher quality, larger size
* `Q2_K`: Smallest size, lower quality

## Troubleshooting

### Server Connection Issues

Ensure the LlamaCpp server is running and accessible:

```bash check server
curl http://127.0.0.1:8080/v1/models
```

### Model Loading Problems

* Verify the model file exists and is in GGML format
* Check available memory for large models
* Ensure the model is compatible with your LlamaCpp version

### Performance Issues

* Adjust batch sizes (`-b`, `-ub`) based on your hardware
* Use GPU acceleration if available
* Consider using quantized models for faster inference


# LM Studio
Source: https://docs.agno.com/concepts/models/lmstudio

Learn how to use LM Studio with Agno.

Run Large Language Models locally with LM Studio

[LM Studio](https://lmstudio.ai) is a fantastic tool for running models locally.

LM Studio supports multiple open-source models. See the library [here](https://lmstudio.ai/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `llama3.3` models are good for most basic use-cases.
* `qwen` models perform specifically well with tool use.
* `deepseek-r1` models have strong reasoning capabilities.
* `phi4` models are powerful, while being really small in size.

## Set up a model

Install [LM Studio](https://lmstudio.ai), download the model you want to use, and run it.

## Example

After you have the model locally, use the `LM Studio` model class to access it

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.lmstudio import LMStudio

  agent = Agent(
      model=LMStudio(id="qwen2.5-7b-instruct-1m"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/lmstudio/basic). </Note>

## Params

<Snippet file="model-lmstudio-params.mdx" />

`LM Studio` also supports the params of [OpenAI](/reference/models/openai).


# Meta
Source: https://docs.agno.com/concepts/models/meta

Learn how to use Meta models in Agno.

Meta offers a suite of powerful multi-modal language models known for their strong performance across a wide range of tasks, including superior text understanding and visual intelligence.

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `Llama-4-Scout-17B`: Excellent performance for most general tasks, including multi-modal scenarios.
* `Llama-3.3-70B`: Powerful instruction-following model for complex reasoning tasks.

Explore all the models [here](https://llama.developer.meta.com/docs/models).

## Authentication

Set your `LLAMA_API_KEY` environment variable:

<CodeGroup>
  `bash Mac export LLAMA_API_KEY=YOUR_API_KEY ` `bash Windows setx
    LLAMA_API_KEY YOUR_API_KEY `
</CodeGroup>

## Example

Use `Llama` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.meta import Llama

  agent = Agent(
  model=Llama(
  id="Llama-4-Maverick-17B-128E-Instruct-FP8",
  ),
  markdown=True
  )

  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/meta/basic). </Note>

## Parameters

<Snippet file="model-meta-params.mdx" />

### OpenAI-like Parameters

`LlamaOpenAI` supports all parameters from [OpenAI Like](/reference/models/openai_like).

## Resources

* [Meta AI Models](https://llama.developer.meta.com/docs/models)
* [Llama API Documentation](https://llama.developer.meta.com/docs/overview)

```
```


# Mistral
Source: https://docs.agno.com/concepts/models/mistral

Learn how to use Mistral models in Agno.

Mistral is a platform for providing endpoints for Large Language models.
See their library of models [here](https://docs.mistral.ai/getting-started/models/models_overview/).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `codestral` model is good for code generation and editing.
* `mistral-large-latest` model is good for most use-cases.
* `open-mistral-nemo` is a free model that is good for most use-cases.
* `pixtral-12b-2409` is a vision model that is good for OCR, transcribing documents, and image comparison. It is not always capable at tool calling.

Mistral has tier-based rate limits. See the [docs](https://docs.mistral.ai/deployment/laplateforme/tier/) for more information.

## Authentication

Set your `MISTRAL_API_KEY` environment variable. Get your key from [here](https://console.mistral.ai/api-keys/).

<CodeGroup>
  ```bash Mac
  export MISTRAL_API_KEY=***
  ```

  ```bash Windows
  setx MISTRAL_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Mistral` with your `Agent`:

<CodeGroup>
  ```python agent.py
  import os

  from agno.agent import Agent, RunOutput
  from agno.models.mistral import MistralChat

  mistral_api_key = os.getenv("MISTRAL_API_KEY")

  agent = Agent(
      model=MistralChat(
          id="mistral-large-latest",
          api_key=mistral_api_key,
      ),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/mistral/basic). </Note>

## Params

<Snippet file="model-mistral-params.mdx" />

`MistralChat` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Nebius
Source: https://docs.agno.com/concepts/models/nebius

Learn how to use Nebius models in Agno.

Nebius AI Studio is a platform from Nebius that simplifies the process of building applications using AI models. It provides a suite of tools and services for developers to easily test, integrate and fine-tune various AI models, including those for text and image generation.
You can checkout the list of available models [here](https://studio.nebius.com/).

We recommend experimenting to find the best-suited-model for your use-case.

## Authentication

Set your `NEBIUS_API_KEY` environment variable. Get your key [from Nebius AI Studio here](https://studio.nebius.com/?modals=create-api-key).

<CodeGroup>
  ```bash Mac
  export NEBIUS_API_KEY=***
  ```

  ```bash Windows
  setx NEBIUS_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Nebius` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.nebius import Nebius

  agent = Agent(
       model=Nebius(
          id="meta-llama/Llama-3.3-70B-Instruct",
          api_key=os.getenv("NEBIUS_API_KEY")
      ),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/nebius/basic). </Note>

## Params

<Snippet file="model-nebius-params.mdx" />


# Nexus
Source: https://docs.agno.com/concepts/models/nexus

Learn how to use Nexus models in Agno.

Nexus is a routing platform that provides endpoints for various Large Language Models through a unified API interface.

Explore Nexus's capabilities and documentation [here](https://nexusrouter.com/).

## Authentication

Nexus requires API keys for the underlying model providers. Set the appropriate environment variables for the models you plan to use:

<CodeGroup>
  ```bash Mac
  export OPENAI_API_KEY=***
  export ANTHROPIC_API_KEY=***
  ```

  ```bash Windows
  setx OPENAI_API_KEY ***
  setx ANTHROPIC_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Nexus` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.nexus import Nexus

  agent = Agent(model=Nexus(id="anthropic/claude-sonnet-4-20250514"), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/nexus/basic). </Note>

## Params

<Snippet file="model-nexus-params.mdx" />

`Nexus` also supports the params of [OpenAI](/reference/models/openai).


# Nvidia
Source: https://docs.agno.com/concepts/models/nvidia

Learn how to use Nvidia models in Agno.

NVIDIA offers a suite of high-performance language models optimized for advanced NLP tasks.
These models are part of the NeMo framework, which provides tools for training, fine-tuning
and deploying state-of-the-art models efficiently. NVIDIA‚Äôs language models are designed to
handle large-scale workloads with GPU acceleration for faster inference and training.
We recommend experimenting with NVIDIA‚Äôs models to find the best fit for your application.

Explore NVIDIA‚Äôs models [here](https://build.nvidia.com/models).

## Authentication

Set your `NVIDIA_API_KEY` environment variable. Get your key [from Nvidia here](https://build.nvidia.com/explore/discover).

<CodeGroup>
  ```bash Mac
  export NVIDIA_API_KEY=***
  ```

  ```bash Windows
  setx NVIDIA_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Nvidia` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.nvidia import Nvidia

  agent = Agent(model=Nvidia(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/nvidia/basic). </Note>

## Params

<Snippet file="model-nvda-params.mdx" />

`Nvidia` also supports the params of [OpenAI](/reference/models/openai).


# Ollama
Source: https://docs.agno.com/concepts/models/ollama

Learn how to use Ollama with Agno.

Run large language models with Ollama, either locally or through Ollama Cloud.

[Ollama](https://ollama.com) is a fantastic tool for running models both locally and in the cloud.

**Local Usage**: Run models on your own hardware using the Ollama client.

**Cloud Usage**: Access cloud-hosted models via [Ollama Cloud](https://ollama.com) with an API key.

Ollama supports multiple open-source models. See the library [here](https://ollama.com/library).

Experiment with different models to find the best fit for your use case. Here are some general recommendations:

* `gpt-oss:120b-cloud` is an excellent general-purpose cloud model for most tasks.
* `llama3.3` models are good for most basic use-cases.
* `qwen` models perform specifically well with tool use.
* `deepseek-r1` models have strong reasoning capabilities.
* `phi4` models are powerful, while being really small in size.

## Authentication (Ollama Cloud Only)

To use Ollama Cloud, set your `OLLAMA_API_KEY` environment variable. You can get an API key from [Ollama Cloud](https://ollama.com).

<CodeGroup>
  ```bash Mac
  export OLLAMA_API_KEY=***
  ```

  ```bash Windows
  setx OLLAMA_API_KEY ***
  ```
</CodeGroup>

When using Ollama Cloud, the host is automatically set to `https://ollama.com`. For local usage, no API key is required.

## Set up a model

### Local Usage

Install [ollama](https://ollama.com) and run a model:

```bash run model
ollama run llama3.1
```

This starts an interactive session with the model.

To download the model for use in an Agno agent:

```bash pull model
ollama pull llama3.1
```

### Cloud Usage

For Ollama Cloud, no local Ollama server installation is required. Install the Ollama library, set up your API key as described in the Authentication section above, and access cloud-hosted models directly.

## Examples

### Local Usage

Once the model is available locally, use the `Ollama` model class to access it:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.ollama import Ollama

  agent = Agent(
      model=Ollama(id="llama3.1"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

### Cloud Usage

<Note>When using Ollama Cloud with an API key, the host is automatically set to `https://ollama.com`. You can omit the `host` parameter.</Note>

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.ollama import Ollama

  agent = Agent(
      model=Ollama(id="gpt-oss:120b-cloud"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/ollama/basic). </Note>

## Params

<Snippet file="model-ollama-params.mdx" />

`Ollama` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# OpenAI
Source: https://docs.agno.com/concepts/models/openai

Learn how to use OpenAI models in Agno.

The GPT models are the best in class LLMs and used as the default LLM by **Agents**. OpenAI supports a variety of world-class models. See their models [here](https://platform.openai.com/docs/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `gpt-5-mini` is good for most general use-cases.
* `gpt-5-nano` model is good for smaller tasks and faster inference.
* `o1` models are good for complex reasoning and multi-step tasks.
* `gpt-5-mini` is a strong reasoning model with support for tool-calling and structured outputs, but at a much lower cost.

OpenAI have tier based rate limits. See the [docs](https://platform.openai.com/docs/guides/rate-limits/usage-tiers) for more information.

## Authentication

Set your `OPENAI_API_KEY` environment variable. You can get one [from OpenAI here](https://platform.openai.com/account/api-keys).

<CodeGroup>
  ```bash Mac
  export OPENAI_API_KEY=sk-***
  ```

  ```bash Windows
  setx OPENAI_API_KEY sk-***
  ```
</CodeGroup>

## Example

Use `OpenAIChat` with your `Agent`:

<CodeGroup>
  ```python agent.py

  from agno.agent import Agent
  from agno.models.openai import OpenAIChat

  agent = Agent(
      model=OpenAIChat(id="gpt-5-mini"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```

  ## Prompt caching

  Prompt caching will happen automatically using our `OpenAIChat` model. You can read more about how OpenAI handle caching in [their docs](https://platform.openai.com/docs/guides/prompt-caching).
</CodeGroup>

<Note> View more examples [here](/examples/models/openai/chat/basic). </Note>

## Params

For more information, please refer to the [OpenAI docs](https://platform.openai.com/docs/api-reference/chat/create) as well.

<Snippet file="model-openai-params.mdx" />

`OpenAIChat` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# OpenAI Like
Source: https://docs.agno.com/concepts/models/openai-like

Learn how to use OpenAI-like models in Agno.

Many providers like Together, Groq, Nebius, Sambanova, xAI, etc support the OpenAI API format. Use the `OpenAILike` model to access them by replacing the `base_url`.

## Example

<CodeGroup>
  ```python agent.py
  from os import getenv
  from agno.agent import Agent
  from agno.models.openai.like import OpenAILike

  agent = Agent(
      model=OpenAILike(
          id="mistralai/Mixtral-8x7B-Instruct-v0.1",
          api_key=getenv("TOGETHER_API_KEY"),
          base_url="https://api.together.xyz/v1",
      )
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Params

<Snippet file="model-openai-like-reference.mdx" />

`OpenAILike` also support all the params of [OpenAIChat](/reference/models/openai)


# OpenAI Responses
Source: https://docs.agno.com/concepts/models/openai-responses

Learn how to use OpenAI Responses with Agno.

`OpenAIResponses` is a class for interacting with OpenAI models using the Responses API. This class provides a streamlined interface for working with OpenAI's newer Responses API, which is distinct from the traditional Chat API. It supports advanced features like tool use, file processing, and knowledge retrieval.

## Authentication

Set your `OPENAI_API_KEY` environment variable. You can get one [from OpenAI here](https://platform.openai.com/account/api-keys).

<CodeGroup>
  ```bash Mac
  export OPENAI_API_KEY=sk-***
  ```

  ```bash Windows
  setx OPENAI_API_KEY sk-***
  ```
</CodeGroup>

## Example

Use `OpenAIResponses` with your `Agent`:

<CodeGroup>
  ```python agent.py

  from agno.agent import Agent
  from agno.media import File
  from agno.models.openai.responses import OpenAIResponses

  agent = Agent(
      model=OpenAIResponses(id="gpt-5-mini"),
      tools=[{"type": "file_search"}, {"type": "web_search_preview"}],
      markdown=True,
  )

  agent.print_response(
      "Summarize the contents of the attached file and search the web for more information.",
      files=[File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf")],
  )

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/openai/responses/basic). </Note>

## Params

For more information, please refer to the [OpenAI Responses docs](https://platform.openai.com/docs/api-reference/responses) as well.

<Snippet file="model-openai-responses-params.mdx" />

`OpenAIResponses` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# OpenRouter
Source: https://docs.agno.com/concepts/models/openrouter

Learn how to use OpenRouter with Agno.

OpenRouter is a platform for providing endpoints for Large Language models.

## Authentication

Set your `OPENROUTER_API_KEY` environment variable. Get your key from [here](https://openrouter.ai/settings/keys).

<CodeGroup>
  ```bash Mac
  export OPENROUTER_API_KEY=***
  ```

  ```bash Windows
  setx OPENROUTER_API_KEY ***
  ```
</CodeGroup>

## Example

Use `OpenRouter` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.openrouter import OpenRouter

  agent = Agent(
      model=OpenRouter(id="gpt-5-mini"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

## Params

<Snippet file="model-openrouter-params.mdx" />

`OpenRouter` also supports the params of [OpenAI](/reference/models/openai).

## Prompt caching

Prompt caching will happen automatically using our `OpenRouter` model, when the used provider supports it. In other cases you can activate it via the `cache_control` header.
You can read more about prompt caching with OpenRouter in [their docs](https://openrouter.ai/docs/features/prompt-caching).


# Perplexity
Source: https://docs.agno.com/concepts/models/perplexity

Learn how to use Perplexity with Agno.

Perplexity offers powerful language models with built-in web search capabilities, enabling advanced research and Q\&A functionality.

Explore Perplexity‚Äôs models [here](https://docs.perplexity.ai/guides/model-cards).

## Authentication

Set your `PERPLEXITY_API_KEY` environment variable. Get your key [from Perplexity here](https://www.perplexity.ai/settings/api).

<CodeGroup>
  ```bash Mac
  export PERPLEXITY_API_KEY=***
  ```

  ```bash Windows
  setx PERPLEXITY_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Perplexity` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.perplexity import Perplexity

  agent = Agent(model=Perplexity(id="sonar-pro"), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/perplexity/basic). </Note>

## Params

<Snippet file="model-perplexity-params.mdx" />

`Perplexity` also supports the params of [OpenAI](/reference/models/openai).


# Portkey
Source: https://docs.agno.com/concepts/models/portkey

Learn how to use models through the Portkey AI Gateway in Agno.

Portkey is an AI Gateway that provides a unified interface to access multiple AI providers with advanced features like routing, load balancing, retries, and observability. Use Portkey to build production-ready AI applications with better reliability and cost optimization.

With Portkey, you can:

* Route requests across multiple AI providers
* Implement fallback mechanisms for better reliability
* Monitor and analyze your AI usage
* Cache responses for cost optimization
* Apply rate limiting and usage controls

## Authentication

You need both a Portkey API key and a virtual key for model routing. Get them [from Portkey here](https://app.portkey.ai/).

<CodeGroup>
  ```bash Mac
  export PORTKEY_API_KEY=***
  export PORTKEY_VIRTUAL_KEY=***
  ```

  ```bash Windows
  setx PORTKEY_API_KEY ***
  setx PORTKEY_VIRTUAL_KEY ***
  ```
</CodeGroup>

## Example

Use `Portkey` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.portkey import Portkey

  agent = Agent(
      model=Portkey(id="gpt-5-mini"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("What is Portkey and why would I use it as an AI gateway?")
  ```
</CodeGroup>

## Advanced Configuration

You can configure Portkey with custom routing and retry policies:

```python
from agno.agent import Agent
from agno.models.portkey import Portkey

config = {
    "strategy": {
        "mode": "fallback"
    },
    "targets": [
        {"virtual_key": "openai-key"},
        {"virtual_key": "anthropic-key"}
    ]
}

agent = Agent(
    model=Portkey(
        id="gpt-5-mini",
        config=config,
    ),
)
```

<Note> View more examples [here](/examples/models/portkey/basic). </Note>

## Params

<Snippet file="model-portkey-params.mdx" />

`Portkey` also supports the params of [OpenAI](/reference/models/openai).


# Sambanova
Source: https://docs.agno.com/concepts/models/sambanova

Learn how to use Sambanova with Agno.

Sambanova is a platform for providing endpoints for Large Language models. Note that Sambanova currently does not support function calling.

## Authentication

Set your `SAMBANOVA_API_KEY` environment variable. Get your key from [here](https://cloud.sambanova.ai/apis).

<CodeGroup>
  ```bash Mac
  export SAMBANOVA_API_KEY=***
  ```

  ```bash Windows
  setx SAMBANOVA_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Sambanova` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.sambanova import Sambanova

  agent = Agent(model=Sambanova(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

## Params

<Snippet file="model-sambanova-params.mdx" />

`Sambanova` also supports the params of [OpenAI](/reference/models/openai).


# SiliconFlow
Source: https://docs.agno.com/concepts/models/siliconflow

Learn how to use Siliconflow models in Agno.

Siliconflow is a platform for providing endpoints for Large Language models.

Explore Siliconflow‚Äôs models [here](https://siliconflow.ai/models).

## Authentication

Set your `SILICONFLOW_API_KEY` environment variable. Get your key [from Siliconflow here](https://siliconflow.ai).

<CodeGroup>
  ```bash Mac
  export SILICONFLOW_API_KEY=***
  ```

  ```bash Windows
  setx SILICONFLOW_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Siliconflow` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.siliconflow import Siliconflow

  agent = Agent(model=Siliconflow(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/siliconflow/basic). </Note>

## Params

<Snippet file="model-siliconflow-params.mdx" />

`Siliconflow` also supports the params of [OpenAI](/reference/models/openai).


# Together
Source: https://docs.agno.com/concepts/models/together

Learn how to use Together with Agno.

Together is a platform for providing endpoints for Large Language models.
See their library of models [here](https://www.together.ai/models).

We recommend experimenting to find the best-suited model for your use-case.

Together have tier based rate limits. See the [docs](https://docs.together.ai/docs/rate-limits) for more information.

## Authentication

Set your `TOGETHER_API_KEY` environment variable. Get your key [from Together here](https://api.together.xyz/settings/api-keys).

<CodeGroup>
  ```bash Mac
  export TOGETHER_API_KEY=***
  ```

  ```bash Windows
  setx TOGETHER_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Together` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.together import Together

  agent = Agent(
      model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/together/basic). </Note>

## Params

<Snippet file="model-together-params.mdx" />

`Together` also supports the params of [OpenAI](/reference/models/openai).


# Vercel v0
Source: https://docs.agno.com/concepts/models/vercel

Learn how to use Vercel v0 models with Agno.

The Vercel v0 API provides large language models, designed for building modern web applications. It supports text and image inputs, provides fast streaming responses, and is compatible with the OpenAI Chat Completions API format. It is optimized for frontend and full-stack web development code generation.

For more details, refer to the [official Vercel v0 API documentation](https://vercel.com/docs/v0/api).

## Authentication

Set your `V0_API_KEY` environment variable. You can create an API key on [v0.dev](https://v0.dev/chat/settings/keys).

<CodeGroup>
  ```bash Mac
  export V0_API_KEY=your-v0-api-key
  ```

  ```bash Windows
  setx V0_API_KEY your-v0-api-key
  ```
</CodeGroup>

## Example

Use `V0` with your `Agent`. The following example assumes you have the `V0` Python class (as you provided) located at `agno/models/vercel.py`.

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.vercel import V0

  agent = Agent(
      model=V0(id="v0-1.0-md"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Create a simple web app that displays a random number between 1 and 100.")

  # agent.print_response("Create a webapp to fetch the weather of a city and display humidity, temperature, and wind speed in cards, use shadcn components and tailwind css")

  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/vercel/basic). </Note>

## Params

<Snippet file="model-v0-params.mdx" />

V0 also supports the params of [OpenAI](/reference/models/openai).


# vLLM
Source: https://docs.agno.com/concepts/models/vllm



[vLLM](https://docs.vllm.ai/en/latest/) is a fast and easy-to-use library for LLM inference and serving, designed for high-throughput and memory-efficient LLM serving.

## Prerequisites

Install vLLM and start serving a model:

```bash install vLLM
pip install vllm
```

```bash start vLLM server
vllm serve Qwen/Qwen2.5-7B-Instruct \
    --enable-auto-tool-choice \
    --tool-call-parser hermes \
    --dtype float16 \
    --max-model-len 8192 \
    --gpu-memory-utilization 0.9
```

This spins up the vLLM server with an OpenAI-compatible API.

<Note>The default vLLM server URL is `http://localhost:8000/`</Note>

## Example

Basic Agent

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent
  from agno.models.vllm import VLLM

  agent = Agent(
      model=VLLM(
          id="meta-llama/Llama-3.1-8B-Instruct",
          base_url="http://localhost:8000/",
      ),
      markdown=True
  )

  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Advanced Usage

### With Tools

vLLM models work seamlessly with Agno tools:

```python with_tools.py
from agno.agent import Agent
from agno.models.vllm import VLLM
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=VLLM(id="meta-llama/Llama-3.1-8B-Instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True
)

agent.print_response("What's the latest news about AI?")
```

<Note> View more examples [here](/examples/models/vllm/basic). </Note>

For the full list of supported models, see the [vLLM documentation](https://docs.vllm.ai/en/latest/models/supported_models.html).

## Params

<Snippet file="model-vllm-params.mdx" />

`VLLM` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# xAI
Source: https://docs.agno.com/concepts/models/xai

Learn how to use xAI with Agno.

xAI is a platform for providing endpoints for Large Language models.
See their list of models [here](https://docs.x.ai/docs/models).

We recommend experimenting to find the best-suited model for your use-case. The `grok-3` model is good for most use-cases.

## Authentication

Set your `XAI_API_KEY` environment variable. You can get one [from xAI here](https://console.x.ai/).

<CodeGroup>
  ```bash Mac
  export XAI_API_KEY=sk-***
  ```

  ```bash Windows
  setx XAI_API_KEY sk-***
  ```
</CodeGroup>

## Example

Use `xAI` with your `Agent`:

<CodeGroup>
  ```python agent.py

  from agno.agent import Agent
  from agno.models.xai import xAI

  agent = Agent(
      model=xAI(id="grok-3"),
      markdown=True
  )

  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Live Search

xAI models support live search capabilities that can access real-time information:

<CodeGroup>
  ```python live_search.py
  from agno.agent import Agent
  from agno.models.xai import xAI

  agent = Agent(
      model=xAI(
          id="grok-3",
          search_parameters={
              "mode": "on",
              "max_search_results": 20,
              "return_citations": True,
          },
      ),
      markdown=True,
  )

  agent.print_response("What's the latest news about AI developments?")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/xai/basic). </Note>

## Params

<Snippet file="model-xai-params.mdx" />

`xAI` also supports the params of [OpenAI](/reference/models/openai).


# Multimodal Agents
Source: https://docs.agno.com/concepts/multimodal/overview

Learn how to create multimodal agents in Agno.

Agno agents support text, image, audio and video inputs and can generate text, image, audio and video outputs. For a complete overview, please checkout the [compatibility matrix](/concepts/models/compatibility#multimodal-support).

<Tip>
  To get started, feel free to checkout the [multimodal
  examples](/examples/concepts/multimodal/).
</Tip>

## Multimodal inputs to an agent

Let's create an agent that can understand images and make tool calls as needed

### Agent with Image Understanding

```python image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

Run the agent:

```shell
python image_agent.py
```

Similar to images, you can also use audio and video as an input.

### Agent with Audio Understanding

```python audio_agent.py
import base64

import requests
from agno.agent import Agent, RunOutput  # noqa
from agno.media import Audio
from agno.models.openai import OpenAIChat

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-audio-preview", modalities=["text"]),
    markdown=True,
)
agent.print_response(
    "What is in this audio?", audio=[Audio(content=wav_data, format="wav")]
)
```

<Note>
  For applications like Audio to Text (Transcribe) you can either use models which support audio input like Gemini and
  OpenAI or use tools like OpenAI, GroqTools.
</Note>

Examples of ways to do Audio to Text (Transcribe) are:

* [Using Gemini model](/examples/concepts/multimodal/audio-to-text)
* [Using OpenAI Model](/examples/concepts/agent/multimodal/audio_input_output)
* [Using `OpenAI Tool`](/concepts/tools/toolkits/models/openai#1-transcribing-audio)
* [Using `Groq Tool`](/concepts/tools/toolkits/models/groq#1-transcribing-audio)

### Agent with Video Understanding

```python video_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    markdown=True,
)

# Please download "GreatRedSpot.mp4" using
# wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
video_path = Path(__file__).parent.joinpath("GreatRedSpot.mp4")

agent.print_response("Tell me about this video", videos=[Video(filepath=video_path)])
```

## Multimodal outputs from an agent

Similar to providing multimodal inputs, you can also get multimodal outputs from an agent.

You can either use tools to generate image/audio/video or use the agent's model to generate them (if the model supports this capability).

### Image Generation using a tool

The following example demonstrates how to generate an image using an OpenAI tool with an agent.

```python image_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.openai import OpenAITools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[OpenAITools(image_model="gpt-image-1")],
    markdown=True,
)

response = agent.run(
    "Generate a photorealistic image of a cozy coffee shop interior",
)

if response.images and response.images[0].content:
    save_base64_data(str(response.images[0].content), "tmp/coffee_shop.png")
```

<Check>
  The output of the tool generating a media also goes to the model's input as a
  message so it has access to the media (image, audio, video) and can use it in
  the response. For example, if you say "Generate an image of a dog and tell me
  its color." the model will have access to the image and can use it to describe
  the dog's color in the response in the same run.
</Check>

### Image Model Response

The following example demonstrates how some models can directly generate images as part of their response.

```python image_agent.py
from io import BytesIO

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini
from PIL import Image

# No system message should be provided
agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash-exp-image-generation",
        response_modalities=["Text", "Image"], # This means to generate both images and text
    )
)

# Print the response in the terminal
run_response = agent.run("Make me an image of a cat in a tree.")

if run_response and isinstance(run_response, RunOutput) and run_response.images:
    for image_response in run_response.images:
        image_bytes = image_response.content
        if image_bytes:
            image = Image.open(BytesIO(image_bytes))
            image.show()
            # Save the image to a file
            # image.save("generated_image.png")
else:
    print("No images found in run response")
```

<Check>You can find all generated images in the `RunOutput.images` list.</Check>

### Audio Generation using a tool

The following example demonstrates how to generate an audio using the ElevenLabs tool with an agent. See [Eleven Labs](https://elevenlabs.io/) for more details.

```python audio_agent.py
import base64

from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.eleven_labs import ElevenLabsTools
from agno.utils.media import save_base64_data

audio_agent = Agent(
    model=Gemini(id="gemini-2.5-pro"),
    tools=[
        ElevenLabsTools(
            voice_id="21m00Tcm4TlvDq8ikWAM",
            model_id="eleven_multilingual_v2",
            target_directory="audio_generations",
        )
    ],
    description="You are an AI agent that can generate audio using the ElevenLabs API.",
    instructions=[
        "When the user asks you to generate audio, use the `generate_audio` tool to generate the audio.",
        "You'll generate the appropriate prompt to send to the tool to generate audio.",
        "You don't need to find the appropriate voice first, I already specified the voice to user."
        "Return the audio file name in your response. Don't convert it to markdown.",
        "The audio should be long and detailed.",
    ],
    markdown=True,
)

response = audio_agent.run(
    "Generate a very long audio of history of french revolution and tell me which subject it belongs to.",
    debug_mode=True,
)

if response.audio:
    print("Agent response:", response.content)
    base64_audio = base64.b64encode(response.audio[0].content).decode("utf-8")
    save_base64_data(base64_audio, "tmp/french_revolution.mp3")
    print("Successfully saved generated speech to tmp/french_revolution.mp3")


audio_agent.print_response("Generate a kick sound effect")
```

### Audio Model Response

The following example demonstrates how some models can directly generate audio as part of their response.

```python audio_agent.py
from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)
response: RunOutput = agent.run("Tell me a 5 second scary story")

# Save the response audio to a file
if response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/scary_story.wav"
    )
```

### Video Generation using a tool

The following example demonstrates how to generate a video using `FalTools` with an agent. See [FAL](https://fal.ai/video) for more details.

```python video_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

fal_agent = Agent(
    name="Fal Video Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        FalTools(
            model="fal-ai/hunyuan-video",
            enable_generate_media=True,
        )
    ],
    description="You are an AI agent that can generate videos using the Fal API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
)

fal_agent.print_response("Generate video of balloon in the ocean")

```

## Multimodal inputs and outputs together

You can create agents that can take multimodal inputs and return multimodal outputs. The following example demonstrates how to provide a combination of audio and text inputs to an agent and obtain both text and audio outputs.

### Audio input and Audio output

```python audio_agent.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from rich.pretty import pprint

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
    markdown=True,
)

run_response = agent.run(
    "What's in these recording?",
    audio=[Audio(content=wav_data, format="wav")],
)

if run_response.response_audio is not None:
    pprint(run_response.content)
    write_audio_to_file(
        audio=run_response.response_audio.content, filename="tmp/result.wav"
    )
```

## Developer Resources

* View more [Examples](/examples/concepts/multimodal/audio-input-output)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agents/multimodal)


# Speech-to-Text
Source: https://docs.agno.com/concepts/multimodal/speech-to-text

Learn how to transcribe audio with Agno agents.

Agno agents can transcribe audio files using different tools and models. You can use native capabilities of OpenAI or fully multimodal Gemini models.

<Tip>
  Examples of ways to do Audio to Text (Transcribe) are:

  * [Using Gemini model](/examples/concepts/agent/multimodal/audio_to_text)
  * [Using the OpenAI Toolkit](/concepts/tools/toolkits/models/openai#1-transcribing-audio)
</Tip>

## Using OpenAI Whisper (Cloud)

The following agent uses OpenAI Whisper API for audio transcription.

```python cookbook/tools/models/openai_tools.py
import base64
from pathlib import Path

from agno.agent import Agent
from agno.run.agent import RunOutput
from agno.tools.openai import OpenAITools
from agno.utils.media import download_file, save_base64_data

# Example 1: Transcription
url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

local_audio_path = Path("tmp/sample_conversation.wav")
print(f"Downloading file to local path: {local_audio_path}")
download_file(url, local_audio_path)

transcription_agent = Agent(
    tools=[OpenAITools(transcription_model="gpt-4o-transcribe")],
    markdown=True,
)
transcription_agent.print_response(
    f"Transcribe the audio file for this file: {local_audio_path}"
)
```

**Best for**: High accuracy, cloud processing

## Using Multimodal Models

Multimodal models like Gemini can transcribe audio directly without additional tools.

```python cookbook/agents/multimodal/audio_to_text.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"

response = requests.get(url)
audio_content = response.content

# Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.

agent.print_response(
    "Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

**Best for**: Direct model integration, conversation understanding

## Team-Based Transcription

Teams can handle complex audio processing workflows with multiple specialized agents.

```python cookbook/teams/multimodal/audio_to_text.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini
from agno.team import Team

transcription_specialist = Agent(
    name="Transcription Specialist",
    role="Convert audio to accurate text transcriptions",
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Transcribe audio with high accuracy",
        "Identify speakers clearly as Speaker A, Speaker B, etc.",
        "Maintain conversation flow and context",
    ],
)

content_analyzer = Agent(
    name="Content Analyzer",
    role="Analyze transcribed content for insights",
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Analyze transcription for key themes and insights",
        "Provide summaries and extract important information",
    ],
)

# Create a team for collaborative audio-to-text processing
audio_team = Team(
    name="Audio Analysis Team",
    model=Gemini(id="gemini-2.0-flash-exp"),
    members=[transcription_specialist, content_analyzer],
    instructions=[
        "Work together to transcribe and analyze audio content.",
        "Transcription Specialist: First convert audio to accurate text with speaker identification.",
        "Content Analyzer: Analyze transcription for insights and key themes.",
    ],
    markdown=True,
)

url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"

response = requests.get(url)
audio_content = response.content

audio_team.print_response(
    "Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

**Best for**: Complex workflows, multiple processing steps

## Developer Resources

* View [Multimodal Examples](/examples/concepts/agent/multimodal/audio_to_text)
* View [Team Examples](/examples/concepts/teams/multimodal/audio_to_text)
* View [OpenAI Toolkit](/concepts/tools/toolkits/models/openai)


# What is Reasoning?
Source: https://docs.agno.com/concepts/reasoning/introduction

Reasoning gives Agents the ability to "think" before responding and "analyze" the results of their actions (i.e. tool calls), greatly improving the Agents' ability to solve problems that require sequential tool calls.

Reasoning Agents go through an internal chain of thought before responding, working through different ideas, validating and correcting as needed.

## ReAct: Reason and Act

At the core of effective reasoning lies the **ReAct** (Reason and Act) methodology - a paradigm where agents alternate between reasoning about a problem and taking actions (like calling tools) to gather information or execute tasks. This iterative process allows agents to break down complex problems into manageable steps, validate their assumptions through action, and adjust their approach based on real-world feedback.

In Agno, ReAct principles are embedded throughout our reasoning implementations.
Whether an agent is using reasoning models to think through a problem, or employing reasoning tools to structure their thought process, they follow this fundamental pattern of reasoning ‚Üí acting ‚Üí observing ‚Üí reasoning again until reaching a solution.

Agno supports 3 approaches to reasoning:

1. [Reasoning Models](#reasoning-models)
2. [Reasoning Tools](#reasoning-tools)
3. [Reasoning Agents](#reasoning-agents)

Which approach works best will depend on your use case, we recommend trying them all and immersing yourself in this new era of Reasoning Agents!

## Reasoning Models

Reasoning models are a separate class of large language models pre-trained to think before they answer. They produce an internal chain of thought before responding. Examples of reasoning models include OpenAI o-series, Claude 3.7 sonnet in extended-thinking mode, Gemini 2.0 flash thinking and DeepSeek-R1.

Reasoning at the model layer is all about what the model does **before it starts generating a final response**. Reasoning models excel at single-shot use-cases. They're perfect for solving hard problems (coding, math, physics) that don't require multiple turns, or calling tools sequentially.

You can try any supported Agno model and if that model has reasoning capabilities, it will be used to reason about the problem.

### Example

```python o3_mini.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Setup your Agent using a reasoning model
agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

# Run the Agent
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. Include an ASCII diagram of your solution.",
    stream=True,
    show_full_reasoning=True,
)
```

Read more about reasoning models in the [Reasoning Models Guide](/concepts/reasoning/reasoning-models).

## Reasoning Model + Response Model

What if we wanted to use a Reasoning Model to reason but a different model to generate the response? It is well known that reasoning models are great at solving problems but not that great at responding in a natural way (like Claude Sonnet or GPT-4o).

By using a model to generate the response, and a different one for reasoning, we can have the best of both worlds:

### Example

Let's use DeepSeek-R1 from Groq for reasoning and Claude Sonnet for a natural response.

```python deepseek_plus_claude.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.groq import Groq

# Setup your Agent using Claude as main model, and DeepSeek as reasoning model
claude_with_deepseek_reasoner = Agent(
    model=Claude(id="claude-3-7-sonnet-20250219"),
    reasoning_model=Groq(
        id="deepseek-r1-distill-llama-70b", temperature=0.6, max_tokens=1024, top_p=0.95
    ),
)

# Run the Agent
claude_with_deepseek_reasoner.print_response(
    "9.11 and 9.9 -- which is bigger?",
    stream=True,
    show_full_reasoning=True,
)
```

## Reasoning Tools

By giving a model **reasoning tools**, we can greatly improve its reasoning capabilities by providing a dedicated space for structured thinking. This is a simple, yet effective approach to add reasoning to non-reasoning models.

The research was first published by Anthropic in [this blog post](https://www.anthropic.com/engineering/claude-think-tool) but has been practiced by many AI Engineers (including our own team) long before it was published.

### Example

```python claude_reasoning_tools.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.reasoning import ReasoningTools

# Setup our Agent with the reasoning tools
reasoning_agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    tools=[
        ReasoningTools(add_instructions=True),
    ],
    instructions="Use tables where possible",
    markdown=True,
)

# Run the Agent
reasoning_agent.print_response(
    "Write a report on NVDA. Only the report, no other text.",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

Read more about reasoning tools in the [Reasoning Tools Guide](/concepts/reasoning/reasoning-tools).

## Reasoning Agents

Reasoning Agents are a new type of multi-agent system developed by Agno that combines chain of thought reasoning with tool use.

You can enable reasoning on any Agent by setting `reasoning=True`.

When an Agent with `reasoning=True` is given a task, a separate "Reasoning Agent" first solves the problem using chain-of-thought. At each step, it calls tools to gather information, validate results, and iterate until it reaches a final answer. Once the Reasoning Agent has a final answer, it hands the results back to the original Agent to validate and provide a response.

### Example

```python reasoning_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Setup our Agent with reasoning enabled
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True,
    markdown=True,
)

# Run the Agent
reasoning_agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. Include an ASCII diagram of your solution.",
    stream=True,
    show_full_reasoning=True,
)
```

Read more about reasoning agents in the [Reasoning Agents Guide](/concepts/reasoning/reasoning-agents).


# Reasoning Agents
Source: https://docs.agno.com/concepts/reasoning/reasoning-agents



Reasoning Agents are a new type of multi-agent system developed by Agno that combines chain of thought reasoning with tool use.

You can enable reasoning on any Agent by setting `reasoning=True`.

When an Agent with `reasoning=True` is given a task, a separate "Reasoning Agent" first solves the problem using chain-of-thought. At each step, it calls tools to gather information, validate results, and iterate until it reaches a final answer. Once the Reasoning Agent has a final answer, it hands the results back to the original Agent to validate and provide a response.

### Example

```python reasoning_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Setup our Agent with reasoning enabled
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True,
    markdown=True,
)

# Run the Agent
reasoning_agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. Include an ASCII diagram of your solution.",
    stream=True,
    show_full_reasoning=True,
)
```

## Enabling Agentic Reasoning

To enable Agentic Reasoning, set `reasoning=True` or set the `reasoning_model` to a model that supports structured outputs.

If `reasoning_model` is not set, the primary `Agent` model will be used for reasoning.

### Reasoning Model Requirements

The `reasoning_model` must be able to handle structured outputs, this includes models like gpt-5-mini and claude-3-7-sonnet that support structured outputs natively or gemini models that support structured outputs using JSON mode.

### Using a Reasoning Model that supports native Reasoning

If you set `reasoning_model` to a model that supports native Reasoning like gpt-5-mini or deepseek-r1, the reasoning model will be used to reason and the primary `Agent` model will be used to respond. See [Reasoning Models + Response Models](/concepts/reasoning/reasoning-models#reasoning-model-%2B-response-model) for more information.

## Reasoning with tools

You can also use tools with a reasoning agent. Lets create a finance agent that can reason.

```python finance_reasoning.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup our Agent with reasoning enabled
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=["Use tables to show data"],
    markdown=True,
    reasoning=True,
)

# Run the Agent
reasoning_agent.print_response("What is going in Paris?", stream=True, show_full_reasoning=True)
```

## More Examples

### Logical puzzles

```python logical_puzzle.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "Three missionaries and three cannibals need to cross a river. "
    "They have a boat that can carry up to two people at a time. "
    "If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. "
    "How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram"
)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"), reasoning=True, markdown=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

### Mathematical proofs

```python mathematical_proof.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "Prove that for any positive integer n, the sum of the first n odd numbers is equal to n squared. Provide a detailed proof."
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"), reasoning=True, markdown=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

### Scientific research

```python scientific_research.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "Read the following abstract of a scientific paper and provide a critical evaluation of its methodology,"
    "results, conclusions, and any potential biases or flaws:\n\n"
    "Abstract: This study examines the effect of a new teaching method on student performance in mathematics. "
    "A sample of 30 students was selected from a single school and taught using the new method over one semester. "
    "The results showed a 15% increase in test scores compared to the previous semester. "
    "The study concludes that the new teaching method is effective in improving mathematical performance among high school students."
)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"), reasoning=True, markdown=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

### Ethical dilemma

```python ethical_dilemma.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "You are a train conductor faced with an emergency: the brakes have failed, and the train is heading towards "
    "five people tied on the track. You can divert the train onto another track, but there is one person tied there. "
    "Do you divert the train, sacrificing one to save five? Provide a well-reasoned answer considering utilitarian "
    "and deontological ethical frameworks. "
    "Provide your answer also as an ascii art diagram."
)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"), reasoning=True, markdown=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

### Planning an itinerary

```python planning_itinerary.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "Plan an itinerary from Los Angeles to Las Vegas"
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"), reasoning=True, markdown=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

### Creative writing

```python creative_writing.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "Write a short story about life in 5000000 years"
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"), reasoning=True, markdown=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

## Developer Resources

* View [Reasoning Agent Examples](/examples/concepts/reasoning/agents/basic-cot)
* View [Reasoning Agent Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/reasoning/agents)
* View [Reasoning Team Examples](/examples/concepts/reasoning/teams/finance_team_chain_of_thought)
* View [Reasoning Team Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/reasoning/teams)


# Reasoning Models
Source: https://docs.agno.com/concepts/reasoning/reasoning-models



Reasoning models are a new class of large language models pre-trained to think before they answer. They produce a long internal chain of thought before responding. Examples of reasoning models include:

* OpenAI o1-pro and gpt-5-mini
* Claude 3.7 sonnet in extended-thinking mode
* Gemini 2.0 flash thinking
* DeepSeek-R1

Reasoning models deeply consider and think through a plan before taking action. Its all about what the model does **before it starts generating a response**. Reasoning models excel at single-shot use-cases. They're perfect for solving hard problems (coding, math, physics) that don't require multiple turns, or calling tools sequentially.

## Examples

### gpt-5-mini

```python o3_mini.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Setup your Agent using a reasoning model
agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

# Run the Agent
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. Include an ASCII diagram of your solution.",
    stream=True,
    show_full_reasoning=True,
)
```

### gpt-5-mini with tools

```python o3_mini_with_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup your Agent using a reasoning model
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Run the Agent
agent.print_response("What is the best basketball team in the NBA this year?", stream=True)
```

### gpt-5-mini with reasoning effort

```python o3_mini_with_reasoning_effort.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup your Agent using a reasoning model with high reasoning effort
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini", reasoning_effort="high"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Run the Agent
agent.print_response("What is the best basketball team in the NBA this year?", stream=True)
```

### DeepSeek-R1 using Groq

```python deepseek_r1_using_groq.py
from agno.agent import Agent
from agno.models.groq import Groq

# Setup your Agent using a reasoning model
agent = Agent(
    model=Groq(
        id="deepseek-r1-distill-llama-70b", temperature=0.6, max_tokens=1024, top_p=0.95
    ),
    markdown=True,
)

# Run the Agent
agent.print_response("9.11 and 9.9 -- which is bigger?", stream=True)
```

## Reasoning Model + Response Model

When you run the DeepSeek-R1 Agent above, you'll notice that the response is not that great. This is because DeepSeek-R1 is great at solving problems but not that great at responding in a natural way (like claude sonnet or gpt-4.5).

What if we wanted to use a Reasoning Model to reason but a different model to generate the response?

Great news! Agno allows you to use a Reasoning Model and a different Response Model together. By using a separate model for reasoning and a different model for responding, we can have the best of both worlds.

### DeepSeek-R1 + Claude Sonnet

```python deepseek_plus_claude.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.groq import Groq

# Setup your Agent using an extra reasoning model
deepseek_plus_claude = Agent(
    model=Claude(id="claude-3-7-sonnet-20250219"),
    reasoning_model=Groq(
        id="deepseek-r1-distill-llama-70b", temperature=0.6, max_tokens=1024, top_p=0.95
    ),
)

# Run the Agent
deepseek_plus_claude.print_response("9.11 and 9.9 -- which is bigger?", stream=True)
```

## Developer Resources

* View [Examples](/examples/concepts/reasoning/models)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/reasoning/models)


# Reasoning Tools
Source: https://docs.agno.com/concepts/reasoning/reasoning-tools



A new class of research is emerging where giving models tools for structured thinking, like a scratchpad, greatly improves their reasoning capabilities.

For example, by giving a model **reasoning tools**, we can greatly improve its reasoning capabilities by providing a dedicated space for working through the problem. This is a simple, yet effective approach to add reasoning to non-reasoning models.

First published by Anthropic in [this blog post](https://www.anthropic.com/engineering/claude-think-tool), this technique has been practiced by many AI Engineers (including our own team) long before it was published.

## Reasoning Tools

The first version of the Reasoning Tools, previously known as Thikning tools, was published by Anthropic in [this blog post](https://www.anthropic.com/engineering/claude-think-tool).

```python claude_reasoning_tools.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.reasoning import ReasoningTools
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup our Agent with the reasoning tools
reasoning_agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    tools=[
        ReasoningTools(add_instructions=True),
        DuckDuckGoTools(),
    ],
    instructions="Use tables where possible",
    markdown=True,
)

# Run the Agent
reasoning_agent.print_response(
    "What are the fastest cars in the market? Only the report, no other text.",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

See the [Reasoning Tools](/concepts/tools/reasoning_tools/reasoning-tools) documentation for more details.

## Knowledge Tools

The Knowledge Tools take the Reasoning Tools one step further by allowing the Agent to **search** a knowledge base and **analyze** the results of their actions.

**KnowledgeTools = `think` + `search` + `analyze`**

```python knowledge_tools.py
import os
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.tools.knowledge import KnowledgeTools
from agno.vectordb.lancedb import LanceDb, SearchType


agno_docs = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)


knowledge_tools = KnowledgeTools(
    knowledge=agno_docs,
    think=True,
    search=True,
    analyze=True,
    add_few_shot=True,
)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[knowledge_tools],
    markdown=True,
)


agno_docs.add_content(
    url="https://docs.agno.com/llms-full.txt"
)


agent.print_response("How do I build multi-agent teams with Agno?", stream=True)
```

See the [Knowledge Tools](/concepts/tools/reasoning_tools/knowledge-tools) documentation for more details.

## Memory Tools

The Memory Tools allow the Agent to use memories to reason about the question and work through it step by step.

```python memory_tools.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.memory import MemoryTools

# Create a database connection
db = SqliteDb(
    db_file="tmp/memory.db"
)

memory_tools = MemoryTools(
    db=db,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[memory_tools],
    markdown=True,
)

agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends. "
    "I like to travel to new places and experience different cultures. "
    "I am planning to travel to Africa in December. ",
    user_id="john_doe@example.com",
    stream=True
)

# This won't use the session history, but instead will use the memory tools to get the memories
agent.print_response("What have you remembered about me?", stream=True, user_id="john_doe@example.com")
```

See the [Memory Tools](/concepts/tools/reasoning_tools/memory-tools) documentation for more details.

## Workflow Tools

The Workflow Tools allow the Agent to execute a workflow and reason about the results.

```python workflow_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.workflow import WorkflowTools

# Create your workflow
# ...

workflow_tools = WorkflowTools(
    workflow=blog_post_workflow,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[workflow_tools],
    markdown=True,
)

agent.print_response("Create a blog post on the topic: AI trends in 2024", stream=True)
```

See the [Workflow Tools](/concepts/tools/reasoning_tools/workflow-tools) documentation for more details.

## Developer Resources

* View [Agents with Reasoning Tools Examples](/examples/concepts/reasoning/tools)
* View [Agents with Reasoning Tools Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/reasoning/tools)
* View [Teams with Reasoning Tools Examples](/examples/concepts/reasoning/teams/reasoning-finance-team)
* View [Teams with Reasoning Tools Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/reasoning/teams)


# Context Engineering
Source: https://docs.agno.com/concepts/teams/context

Learn how to write prompts and other context engineering techniques for your teams.

Context engineering is the process of designing and controlling the information (context) that is sent to language models to guide their behavior and outputs.
In Agno, this means carefully crafting the system message, which includes the team's description, instructions, and other relevant settings. By thoughtfully engineering this context, you can:

* Steer the team toward specific behaviors or roles.
* Constrain or expand the team's capabilities.
* Ensure outputs are consistent, relevant, and aligned with your application's needs.
* Enable advanced use cases such as multi-step reasoning, tool use, or structured output for your team.

Effective context engineering involves iteratively refining the system message, experimenting with different descriptions and instructions, and leveraging features like input/output schemas or tool integrations.

The context of an Agno team consists of the following:

* **System message**: The system message is the main context that is sent to the team, including all additional context
* **User message**: The user message is the message that is sent to the team.
* **Chat history**: The chat history is the history of the conversation between the team and the user.
* **Additional input**: Any few-shot examples or other additional input that is added to the context.

See [Agent Context Engineering](/concepts/agents/context) for more information.

## System message context

The following are some key parameters that are used to create the system message:

1. **Description**: A description that guides the overall behaviour of the agent.
2. **Instructions**: A list of precise, task-specific instructions on how to achieve its goal.
3. **Expected Output**: A description of the expected output from the Agent.

The system message is created using `description`, `instructions` and a number of other settings. The `description` is added to the start of the system message and `instructions` are added as a list. For example:

```python instructions.py
from agno.agent import Agent
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools

web_agent = Agent(
    name="Web Researcher",
    role="You are a web researcher that can find information on the web.",
    instructions=[
        "Use your web search tool to find information on the web.",
        "Provide a summary of the information found.",
    ],
    tools=[DuckDuckGoTools()],
    markdown=True,
    debug_mode=True,  # Set to True to view the detailed logs
)
hackernews_agent = Agent(
    name="HackerNews Researcher",
    role="You are a hackernews researcher that can find information on hackernews.",
    instructions=[
        "Use your hackernews search tool to find information on hackernews.",
        "Provide a summary of the information found.",
    ],
    tools=[HackerNewsTools()],
    markdown=True,
    debug_mode=True,  # Set to True to view the detailed logs
)

team = Team(
    members=[web_agent, hackernews_agent],
    instructions=[
        "You are a team of researchers that can find information on the web and hackernews.",
        "After finding information about the topic, compile a joint report."
    ],
    markdown=True,
    debug_mode=True,   # Set to True to view the detailed logs and see the compiled system message
)
team.print_response("What is the latest news on the crypto market?", stream=True)
```

Will produce the following system message:

```
You are the leader of a team and sub-teams of AI Agents.
Your task is to coordinate the team to complete the user's request.

Here are the members in your team:
<team_members>
- Agent 1:
    - ID: web-researcher
    - Name: Web Researcher
    - Role: You are a web researcher that can find information on the web.
    - Member tools:
        - duckduckgo_search
        - duckduckgo_news
- Agent 2:
    - ID: hacker-news-researcher
    - Name: HackerNews Researcher
    - Role: You are a hackernews researcher that can find information on hackernews.
    - Member tools:
        - get_top_hackernews_stories
        - get_user_details
</team_members>

<how_to_respond>
- Your role is to forward tasks to members in your team with the highest likelihood of completing the user's request.
- Carefully analyze the tools available to the members and their roles before delegating tasks.
- You cannot use a member tool directly. You can only delegate tasks to members.
- When you delegate a task to another member, make sure to include:
    - member_id (str): The ID of the member to delegate the task to. Use only the ID of the member, not the ID of the team followed by the ID of the
member.
    - task_description (str): A clear description of the task.
    - expected_output (str): The expected output.
- You can delegate tasks to multiple members at once.
- You must always analyze the responses from members before responding to the user.
- After analyzing the responses from the members, if you feel the task has been completed, you can stop and respond to the user.
- If you are not satisfied with the responses from the members, you should re-assign the task.
- For simple greetings, thanks, or questions about the team itself, you should respond directly.
- For all work requests, tasks, or questions requiring expertise, route to appropriate team members.
</how_to_respond>

<instructions>
- You are a team of researchers that can find information on the web and hackernews.
- After finding information about the topic, compile a joint report.
</instructions>

<additional_information>
- Use markdown to format your answers.
</additional_information>
```

### Additional Context

You can add additional context to the end of the system message using the `additional_context` parameter.

In this example, we add additional context to the system message that the agent has access to specific tables in a database.

```python
from textwrap import dedent

from agno.agent import Agent
from agno.team import Team
from agno.models.langdb import LangDB
from agno.tools.duckdb import DuckDbTools
from agno.tools.duckduckgo import DuckDuckGoTools

duckdb_tools = DuckDbTools(
    create_tables=False, export_tables=False, summarize_tables=False
)
duckdb_tools.create_table_from_path(
    path="https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    table="movies",
)

web_researcher = Agent(
    name="Web Researcher",
    role="You are a web researcher that can find information on the web.",
    tools=[DuckDuckGoTools()],
    instructions=[
        "Use your web search tool to find information on the web.",
        "Provide a summary of the information found.",
    ],
)

team = Team(
    members=[web_researcher],
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    tools=[duckdb_tools],
    markdown=True,
    additional_context=dedent("""\
    You have access to the following tables:
    - movies: contains information about movies from IMDB.
    """),
)
team.print_response("What is the average rating of movies?", stream=True)
```

### System message Parameters

The Team leader creates a default system message that can be customized using the following parameters:

| Parameter                        | Type        | Default | Description                                                                                                                                                                |
| -------------------------------- | ----------- | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `description`                    | `str`       | `None`  | A description of the Team that is added to the start of the system message.                                                                                                |
| `instructions`                   | `List[str]` | `None`  | List of instructions added to the system prompt in `<instructions>` tags. Default instructions are also created depending on values for `markdown`, `expected_output` etc. |
| `additional_context`             | `str`       | `None`  | Additional context added to the end of the system message.                                                                                                                 |
| `expected_output`                | `str`       | `None`  | Provide the expected output from the Team. This is added to the end of the system message.                                                                                 |
| `markdown`                       | `bool`      | `False` | Add an instruction to format the output using markdown.                                                                                                                    |
| `add_datetime_to_context`        | `bool`      | `False` | If True, add the current datetime to the prompt to give the team a sense of time. This allows for relative times like "tomorrow" to be used in the prompt                  |
| `add_name_to_context`            | `bool`      | `False` | If True, add the name of the team to the context.                                                                                                                          |
| `add_location_to_context`        | `bool`      | `False` | If True, add the location of the team to the context. This allows for location-aware responses and local context.                                                          |
| `add_session_summary_to_context` | `bool`      | `False` | If True, add the session summary to the context. See [sessions](/concepts/teams/sessions) for more information.                                                            |
| `add_memories_to_context`        | `bool`      | `False` | If True, add the user memories to the context. See [memory](/concepts/teams/memory) for more information.                                                                  |
| `add_dependencies_to_context`    | `bool`      | `False` | If True, add the dependencies to the context. See [dependencies](/concepts/teams/dependencies) for more information.                                                       |
| `add_session_state_to_context`   | `bool`      | `False` | If True, add the session state to the context. See [state](/concepts/teams/state) for more information.                                                                    |
| `add_knowledge_to_context`       | `bool`      | `False` | If True, add retrieved knowledge to the context, to enable RAG. See [knowledge](/concepts/teams/knowledge) for more information.                                           |
| `system_message`                 | `str`       | `None`  | Override the default system message.                                                                                                                                       |

See the full [Team reference](/reference/teams/team) for more information.

### Set the system message directly

You can manually set the system message using the `system_message` parameter. This will ignore all other settings and use the system message you provide.

```python
from agno.team import Team

team = Team(members=[], system_message="Share a 2 sentence story about")
team.print_response("Love in the year 12000.")
```

## User message

The `input` sent to the `Team.run()` or `Team.print_response()` is used as the user message.

See [dependencies](/concepts/teams/dependencies) for how to do dependency injection for your user message.

## Chat history

If you have database storage enabled on your team, session history is automatically stored (see [sessions](/concepts/teams/sessions)).

You can now add the history of the conversation to the context using `add_history_to_context`.

```python
from agno.agent import Agent
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

web_researcher = Agent(
    name="Web Researcher",
    role="You are a web researcher that can find information on the web.",
    tools=[DuckDuckGoTools()],
    instructions=[
        "Use your web search tool to find information on the web.",
        "Provide a summary of the information found.",
    ],
)

team = Team(
    members=[web_researcher],
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="chat_history",
    instructions="You are a helpful assistant that can answer questions about space and oceans.",
    add_history_to_context=True,
    num_history_runs=2,  # Optionally limit the number of history responses to add to the context
)

team.print_response("Where is the sea of tranquility?")

team.print_response("What was my first question?")
```

This will add the history of the conversation to the context, which can be used to provide context for the next message.

See more details on [sessions](/concepts/teams/sessions#session-history).

<Note>All team member runs are added to the team session history.</Note>

## Additional input

You can add entire additional messages to your team's context using the `additional_input` parameter.
These messages are added to the context as if they were part of the conversation history.

You can give your team examples of how it should respond (also called "few-shot prompting"):

```python
from agno.team import Team
from agno.models.message import Message
from agno.models.openai.chat import OpenAIChat

# Few-shot examples showing good support patterns
support_examples = [
    # Example 1: Simple issue resolution
    Message(role="user", content="I forgot my password and can't log in"),
    Message(
        role="assistant",
        content="""
    I'll help you reset your password right away.

    **Steps to Reset Your Password:**
    . Go to the login page and click "Forgot Password"
    . Enter your email address
    . Check your email for the reset link
    . Follow the link to create a new password
    . Use a strong password with uppercase, lowercase, numbers, and symbols

    f you don't receive the email within 5 minutes, please check your spam folder. Let me know if you need any assistance with these steps!
    """.strip(),
    ),
    # Example 2: Billing issue pattern
    Message(
        role="user",
        content="I've been charged twice for the same order and I'm frustrated!",
    ),
    Message(
        role="assistant",
        content="""
    I sincerely apologize for the billing error and the frustration this has caused you.

    **Immediate Action Plan:**
    1. I'll investigate your account to confirm the duplicate charge
    2. Process a full refund for the duplicate transaction
    3. Ensure this doesn't happen again by checking your payment method settings
    4. Provide you with a confirmation number once the refund is processed

    The refund typically takes 3-5 business days to appear on your statement. As an apology for this inconvenience, I'd also like to offer you a 10% discount on your next order.

    Is there anything else I can help you with regarding this issue?
    """.strip(),
    ),
    # Example 3: Technical support pattern
    Message(role="user", content="Your app keeps crashing when I try to upload photos"),
    Message(
        role="assistant",
        content="""
    I'm sorry you're experiencing crashes with photo uploads. Let me help you troubleshoot this issue.

    **Troubleshooting Steps:**
    1. **Check App Version:** Ensure you have the latest version from the app store
    2. **Restart the App:** Close completely and reopen the application
    3. **Check Storage:** Make sure you have sufficient device storage (at least 1GB free)
    4. **Photo Size:** Try uploading smaller photos (under 10MB each)
    5. **Network Connection:** Ensure you have a stable internet connection

    **If the issue persists:**
    - Try uploading one photo at a time instead of multiple
    - Clear the app cache in your device settings
    - Restart your device

    If none of these steps resolve the issue, please let me know your device type and OS version, and I'll escalate this to our technical team for further investigation.
    """.strip(),
    ),
]

if __name__ == "__main__":
    # Create agent with few-shot learning
    team = Team(
        members=[...],
        name="Customer Support Team",
        model=OpenAIChat(id="gpt-5-mini"),
        add_name_to_context=True,
        additional_input=support_examples,  # few-shot learning examples
        instructions=[
            "You are an expert customer support specialist.",
            "Always be empathetic, professional, and solution-oriented.",
            "Provide clear, actionable steps to resolve customer issues.",
            "Follow the established patterns for consistent, high-quality support.",
        ],
        markdown=True,
    )

    for i, example in enumerate(support_examples, 1):
        print(f"üìû Example {i}: {example}")
        print("-" * 50)
        team.print_response(example)
```

## Developer Resources

* View the [Team schema](/reference/teams/team)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/basic/)


# Custom Loggers
Source: https://docs.agno.com/concepts/teams/custom-logger

Learn how to use custom loggers in your Agno setup.

You can provide your own loggers to Agno, to be used instead of the default ones.

This can be useful if you need your system to log in any specific format.

## Example

```python
import logging

from agno.agent import Agent
from agno.team import Team
from agno.utils.log import configure_agno_logging, log_info


# Setting up a custom logger
custom_logger = logging.getLogger("custom_logger")
handler = logging.StreamHandler()
formatter = logging.Formatter("[CUSTOM_LOGGER] %(levelname)s: %(message)s")
handler.setFormatter(formatter)
custom_logger.addHandler(handler)
custom_logger.setLevel(logging.INFO)  # Set level to INFO to show info messages
custom_logger.propagate = False


# Configure Agno to use our custom logger. It will be used for all logging.
configure_agno_logging(custom_default_logger=custom_logger)

# Every use of the logging function in agno.utils.log will now use our custom logger.
log_info("This is using our custom logger!")

# Setting up an example Agent
agent = Agent()

# Now let's setup an example Team and run it.
# All logging will use our custom logger.
team = Team(members=[agent])
team.print_response("What can I do to improve my sleep?")
```

## Multiple Loggers

Notice that you can also configure different loggers for your Agents, Teams and Workflows:

```python
configure_agno_logging(
    custom_default_logger=custom_agent_logger,
    custom_agent_logger=custom_agent_logger,
    custom_team_logger=custom_team_logger,
    custom_workflow_logger=custom_workflow_logger,
)
```

## Using Named Loggers

As it's conventional in Python, you can also provide custom loggers just by setting loggers with specific names. This is useful if you want to set them up using configuration files.

* `agno.agent` will be used for all Agent logs
* `agno.team` will be used for all Team logs
* `agno.workflow` will be used for all Workflow logs

These loggers will be automatically picked up if they are set.


# Delegation
Source: https://docs.agno.com/concepts/teams/delegation

Teams can delegate tasks to members in different ways.

A `Team` internally has a team-leader agent that delegates tasks to the members.  When you call `run` or `arun` on a team, the team leader agent uses a model to determine which member to delegate the task to.

The basic flow is:

1. The team receives user input
2. A Team Leader analyzes the input and decides how to break it down into subtasks
3. The Team Leader delegates specific tasks to appropriate team members
4. Team members complete their assigned tasks and return their results
5. The Team Leader synthesizes all outputs into a final, cohesive response

Below are some examples of how to change the behaviour of how tasks are delegated to the members.

## Determine input for members

When a team is run, by default the team leader will determine the "task" to give a specific member. This then becomes the `input` when that member is run.

If you set `determine_input_for_members` to `False`, the team leader will send the user-provided input directly to the member agent(s).  The team leader still determines the appropriate member to delegate the task to.

<Tip>
  This feature is particularly useful when you have specialized agents with distinct expertise areas and want to automatically direct queries to the right specialist.
</Tip>

In the example below, we want to send stuctured pydantic input directly to the member agent.  We don't want the team leader to ingest this input and determine a task to give to the member agent.

<Steps>
  <Step title="Create Team">
    Create a file `determine_input_for_members.py`

    ```python determine_input_for_members.py
    from typing import List

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.team.team import Team
    from agno.tools.hackernews import HackerNewsTools
    from pydantic import BaseModel, Field


    class ResearchTopic(BaseModel):
        """Structured research topic with specific requirements."""

        topic: str = Field(description="The main research topic")
        focus_areas: List[str] = Field(description="Specific areas to focus on")
        target_audience: str = Field(description="Who this research is for")
        sources_required: int = Field(description="Number of sources needed", default=5)


    # Create specialized Hacker News research agent
    hackernews_agent = Agent(
        name="Hackernews Agent",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[HackerNewsTools()],
        role="Extract key insights and content from Hackernews posts",
        instructions=[
            "Search Hacker News for relevant articles and discussions",
            "Extract key insights and summarize findings",
            "Focus on high-quality, well-discussed posts",
        ],
    )

    # Create collaborative research team
    team = Team(
        name="Hackernews Research Team",
        model=OpenAIChat(id="gpt-5-mini"),
        members=[hackernews_agent],
        determine_input_for_members=False,  # The member gets the input directly, without the team leader synthesizing it
        instructions=[
            "Conduct thorough research based on the structured input",
            "Address all focus areas mentioned in the research topic",
            "Tailor the research to the specified target audience",
            "Provide the requested number of sources",
        ],
        show_members_responses=True,
    )

    # Use Pydantic model as structured input
    research_request = ResearchTopic(
        topic="AI Agent Frameworks",
        focus_areas=["AI Agents", "Framework Design", "Developer Tools", "Open Source"],
        target_audience="Software Developers and AI Engineers",
        sources_required=7,
    )
    # Execute research with structured input
    team.print_response(input=research_request)
    ```
  </Step>

  <Step title="Run the team">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Run the team

    ```shell
    python determine_input_for_members.py
    ```
  </Step>
</Steps>

## Respond directly

During normal team execution, the team leader will process the responses from the members and return a single response to the user.

If instead you want to return the response of members directly, you can set `respond_directly` to `True`.

<Tip>
  It can make sense to use this feature in combination with `determine_input_for_members=False`.
</Tip>

<Steps>
  <Step title="Create Multi Language Team">
    Create a file `multi_language_team.py`

    ```python multi_language_team.py
    from agno.agent import Agent
    from agno.models.anthropic import Claude
    from agno.models.deepseek import DeepSeek
    from agno.models.openai import OpenAIChat
    from agno.team.team import Team

    english_agent = Agent(
        name="English Agent",
        role="You can only answer in English",
        model=OpenAIChat(id="gpt-4.5-preview"),
        instructions=[
            "You must only respond in English",
        ],
    )

    japanese_agent = Agent(
        name="Japanese Agent",
        role="You can only answer in Japanese",
        model=DeepSeek(id="deepseek-chat"),
        instructions=[
            "You must only respond in Japanese",
        ],
    )
    chinese_agent = Agent(
        name="Chinese Agent",
        role="You can only answer in Chinese",
        model=DeepSeek(id="deepseek-chat"),
        instructions=[
            "You must only respond in Chinese",
        ],
    )
    spanish_agent = Agent(
        name="Spanish Agent",
        role="You can only answer in Spanish",
        model=OpenAIChat(id="gpt-4.5-preview"),
        instructions=[
            "You must only respond in Spanish",
        ],
    )

    german_agent = Agent(
        name="German Agent",
        role="You can only answer in German",
        model=Claude("claude-3-5-sonnet-20241022"),
        instructions=[
            "You must only respond in German",
        ],
    )
    multi_language_team = Team(
        name="Multi Language Team",
        model=OpenAIChat("gpt-4.5-preview"),
        respond_directly=True,
        members=[
            english_agent,
            spanish_agent,
            japanese_agent,
            german_agent,
            chinese_agent,
        ],
        markdown=True,
        instructions=[
            "You are a language router that directs questions to the appropriate language agent.",
            "If the user asks in a language whose agent is not a team member, respond in English with:",
            "'I can only answer in the following languages: English, Spanish, Japanese, and German. Please ask your question in one of these languages.'",
            "Always check the language of the user's input before routing to an agent.",
            "For unsupported languages like Italian, respond in English with the above message.",
        ],
        show_members_responses=True,
    )


    # Ask "How are you?" in all supported languages
    multi_language_team.print_response(
        "How are you?", stream=True  # English
    )

    multi_language_team.print_response(
        "‰Ω†Â•ΩÂêóÔºü", stream=True  # Chinese
    )

    multi_language_team.print_response(
        "„ÅäÂÖÉÊ∞ó„Åß„Åô„Åã?", stream=True  # Japanese
    )
    ```
  </Step>

  <Step title="Run the team">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Run the team

    ```shell
    python multi_language_team.py
    ```
  </Step>
</Steps>

<Note>
  This is not compatible with `delegate_task_to_all_members`.
</Note>

## Delegate task to all members

When you set `delegate_task_to_all_members` to `True`, the team leader will delegate the task to all members simultaneously, instead of one by one.  When running async (using `arun`) members will run concurrently.

<Steps>
  <Step title="Create a collaborate mode team">
    Create a file `discussion_team.py`

    ```python discussion_team.py
    import asyncio
    from textwrap import dedent

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.team.team import Team
    from agno.tools.arxiv import ArxivTools
    from agno.tools.duckduckgo import DuckDuckGoTools
    from agno.tools.googlesearch import GoogleSearchTools
    from agno.tools.hackernews import HackerNewsTools

    reddit_researcher = Agent(
        name="Reddit Researcher",
        role="Research a topic on Reddit",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[DuckDuckGoTools()],
        add_name_to_context=True,
        instructions=dedent("""
        You are a Reddit researcher.
        You will be given a topic to research on Reddit.
        You will need to find the most relevant posts on Reddit.
        """),
    )

    hackernews_researcher = Agent(
        name="HackerNews Researcher",
        model=OpenAIChat("gpt-5-mini"),
        role="Research a topic on HackerNews.",
        tools=[HackerNewsTools()],
        add_name_to_context=True,
        instructions=dedent("""
        You are a HackerNews researcher.
        You will be given a topic to research on HackerNews.
        You will need to find the most relevant posts on HackerNews.
        """),
    )

    academic_paper_researcher = Agent(
        name="Academic Paper Researcher",
        model=OpenAIChat("gpt-5-mini"),
        role="Research academic papers and scholarly content",
        tools=[GoogleSearchTools(), ArxivTools()],
        add_name_to_context=True,
        instructions=dedent("""
        You are a academic paper researcher.
        You will be given a topic to research in academic literature.
        You will need to find relevant scholarly articles, papers, and academic discussions.
        Focus on peer-reviewed content and citations from reputable sources.
        Provide brief summaries of key findings and methodologies.
        """),
    )

    twitter_researcher = Agent(
        name="Twitter Researcher",
        model=OpenAIChat("gpt-5-mini"),
        role="Research trending discussions and real-time updates",
        tools=[DuckDuckGoTools()],
        add_name_to_context=True,
        instructions=dedent("""
        You are a Twitter/X researcher.
        You will be given a topic to research on Twitter/X.
        You will need to find trending discussions, influential voices, and real-time updates.
        Focus on verified accounts and credible sources when possible.
        Track relevant hashtags and ongoing conversations.
        """),
    )


    agent_team = Team(
        name="Discussion Team",
        model=OpenAIChat("gpt-5-mini"),
        members=[
            reddit_researcher,
            hackernews_researcher,
            academic_paper_researcher,
            twitter_researcher,
        ],
        instructions=[
            "You are a discussion master.",
            "You have to stop the discussion when you think the team has reached a consensus.",
        ],
        delegate_task_to_all_members=True,
        markdown=True,
        show_members_responses=True,
    )

    if __name__ == "__main__":
        asyncio.run(
            agent_team.aprint_response(
                message="Start the discussion on the topic: 'What is the best way to learn to code?'",
                stream=True,
                stream_intermediate_steps=True,
            )
        )

    ```
  </Step>

  <Step title="Run the team">
    Install libraries

    ```shell
    pip install openai ddgs arxiv pypdf googlesearch-python pycountry
    ```

    Run the team

    ```shell
    python discussion_team.py
    ```
  </Step>
</Steps>

## Developer Resources

* View the [Team reference](/reference/teams/team)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/README.md)


# Dependencies
Source: https://docs.agno.com/concepts/teams/dependencies

Learn how to use dependencies in your teams.

**Dependencies** is a way to inject variables into your Team Context. `dependencies` is a dictionary that contains a set of functions (or static variables) that are resolved before the team runs.

<Note>
  You can use dependencies to inject memories, dynamic few-shot examples, "retrieved" documents, etc.
</Note>

```python dependencies.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team


def get_user_profile() -> dict:
    """Get user profile information that can be referenced in responses."""
    profile = {
        "name": "John Doe",
        "preferences": {
            "communication_style": "professional",
            "topics_of_interest": ["AI/ML", "Software Engineering", "Finance"],
            "experience_level": "senior",
        },
        "location": "San Francisco, CA",
        "role": "Senior Software Engineer",
    }

    return profile


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    from datetime import datetime

    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }


profile_agent = Agent(
    name="ProfileAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze user profiles and provide personalized recommendations.",
)

context_agent = Agent(
    name="ContextAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze current context and timing to provide relevant insights.",
)

team = Team(
    name="PersonalizationTeam",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[profile_agent, context_agent],
    dependencies={
        "user_profile": get_user_profile,
        "current_context": get_current_context,
    },
    instructions=[
        "You are a personalization team that provides personalized recommendations based on the user's profile and context.",
        "Here is the user profile: {user_profile}",
        "Here is the current context: {current_context}",
    ],
    debug_mode=True,
    markdown=True,
)

team.print_response(
    "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
)
```

<Check>
  Dependencies are automatically resolved when the team is run.
</Check>

## Adding the entire context to the user message

Set `add_dependencies_to_context=True` to add the entire list of dependencies to the user message. This way you don't have to manually add the dependencies to the instructions.

```python dependencies_instructions.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team


def get_user_profile() -> dict:
    """Get user profile information that can be referenced in responses."""
    profile = {
        "name": "John Doe",
        "preferences": {
            "communication_style": "professional",
            "topics_of_interest": ["AI/ML", "Software Engineering", "Finance"],
            "experience_level": "senior",
        },
        "location": "San Francisco, CA",
        "role": "Senior Software Engineer",
    }

    return profile


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    from datetime import datetime

    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }


profile_agent = Agent(
    name="ProfileAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze user profiles and provide personalized recommendations.",
)

context_agent = Agent(
    name="ContextAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze current context and timing to provide relevant insights.",
)

team = Team(
    name="PersonalizationTeam",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[profile_agent, context_agent],
    markdown=True,
)

team.print_response(
    "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
    dependencies={
        "user_profile": get_user_profile,
        "current_context": get_current_context,
    },
    add_dependencies_to_context=True,
)
```

<Tip>
  You can pass `dependencies` and `add_dependencies_to_context` to the `run`, `arun`, `print_response` and `aprint_response` methods.
</Tip>

## Developer Resources

* View the [Team schema](/reference/teams/team)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/dependencies)


# Input and Output
Source: https://docs.agno.com/concepts/teams/input-output

Learn how to use structured input and output with Teams for reliable, production-ready systems.

Agno Teams support various forms of input and output, from simple string-based interactions to structured data validation using Pydantic models.

The most standard pattern is to use `str` input and `str` output:

```python
from agno.models.openai import OpenAIChat
from agno.team import Team

team = Team(
    members=[],
    model=OpenAIChat(id="gpt-5-mini"),
    description="You write movie scripts.",
)

response = team.run("Write movie script about a girl living in New York")
print(response.content)
```

## Structured Output

One of our favorite features is using Teams to generate structured data (i.e. a pydantic model). This is generally called "Structured Output". Use this feature to extract features, classify data, produce fake data etc. The best part is that they work with function calls, knowledge bases and all other features.

Structured output makes teams reliable for production systems that need consistent, predictable response formats instead of unstructured text.

Let's create a Stock Research Team to generate a structured `StockReport` for us.

<Steps>
  <Step title="Structured Output example">
    ```python structured_output_team.py
    from pydantic import BaseModel
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.team import Team
    from agno.tools.duckduckgo import DuckDuckGoTools
    from agno.utils.pprint import pprint_run_response


    class StockAnalysis(BaseModel):
        symbol: str
        company_name: str
        analysis: str

    class CompanyAnalysis(BaseModel):
        company_name: str
        analysis: str

    stock_searcher = Agent(
        name="Stock Searcher",
        model=OpenAIChat("gpt-5-mini"),
        output_schema=StockAnalysis,
        role="Searches for information on stocks and provides price analysis.",
        tools=[
            DuckDuckGoTools()
        ],
    )

    company_info_agent = Agent(
        name="Company Info Searcher",
        model=OpenAIChat("gpt-5-mini"),
        role="Searches for information about companies and recent news.",
        output_schema=CompanyAnalysis,
        tools=[
            DuckDuckGoTools()
        ],
    )

    class StockReport(BaseModel):
        symbol: str
        company_name: str
        analysis: str

    team = Team(
        name="Stock Research Team",
        model=OpenAIChat("gpt-5-mini"),
        members=[stock_searcher, company_info_agent],
        output_schema=StockReport,
        markdown=True,
    )

    # This should delegate to the stock_searcher
    response = team.run("What is the current stock price of NVDA?")
    assert isinstance(response.content, StockReport)
    pprint_run_response(response)
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno ddgs
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python structured_output_team.py
    ```
  </Step>
</Steps>

The output is an object of the `StockReport` class, here's how it looks:

```python
StockReport(
‚îÇ   "symbol": "NVDA",                                                                                                                                     ‚îÇ
‚îÇ   "company_name": "NVIDIA Corp",                                                                                                                        ‚îÇ
‚îÇ   "analysis": "NVIDIA Corp (NVDA) remains a leading player in the AI chip market, ..."
)
```

<Tip>
  Some LLMs are not able to generate structured output. Agno has an option to tell the model to respond as JSON. Although this is typically not as accurate as structured output, it can be useful in some cases.

  If you want to use JSON mode, you can set `use_json_mode=True` on the Agent.

  ```python
  team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    description="You write stock reports.",
    output_schema=StockReport,
    use_json_mode=True,
  )
  ```
</Tip>

### Streaming Structured Output

Streaming can be used in combination with `output_schema`. This returns the structured output as a single `RunContent` event in the stream of events.

<Steps>
  <Step title="Streaming Structured Output example">
    ```python streaming_structured_output_team.py
    import asyncio
    from typing import Dict, List

    from agno.agent import Agent
    from agno.models.openai.chat import OpenAIChat
    from pydantic import BaseModel, Field


    class MovieScript(BaseModel):
        setting: str = Field(
            ..., description="Provide a nice setting for a blockbuster movie."
        )
        ending: str = Field(
            ...,
            description="Ending of the movie. If not available, provide a happy ending.",
        )
        genre: str = Field(
            ...,
            description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
        )
        name: str = Field(..., description="Give a name to this movie")
        characters: List[str] = Field(..., description="Name of characters for this movie.")
        storyline: str = Field(
            ..., description="3 sentence storyline for the movie. Make it exciting!"
        )
        rating: Dict[str, int] = Field(
            ...,
            description="Your own rating of the movie. 1-10. Return a dictionary with the keys 'story' and 'acting'.",
        )


    # Agent that uses structured outputs with streaming
    structured_output_team = Team(
        members=[],
        model=OpenAIChat(id="gpt-5-mini"),
        description="You write movie scripts.",
        output_schema=MovieScript,
    )

    structured_output_team.print_response(
        "New York", stream=True, stream_intermediate_steps=True
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno ddgs
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python streaming_structured_output_team.py
    ```
  </Step>
</Steps>

## Structured Input

A team can be provided with structured input (i.e a pydantic model) by passing it in the `Team.run()` or `Team.print_response()` as the `input` parameter.

<Steps>
  <Step title="Structured Input example">
    ```python structured_input_team.py
    from typing import List

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.team.team import Team
    from agno.tools.duckduckgo import DuckDuckGoTools
    from agno.tools.hackernews import HackerNewsTools
    from pydantic import BaseModel, Field


    class ResearchProject(BaseModel):
        """Structured research project with validation requirements."""

        project_name: str = Field(description="Name of the research project")
        research_topics: List[str] = Field(
            description="List of topics to research", min_items=1
        )
        target_audience: str = Field(description="Intended audience for the research")
        depth_level: str = Field(
            description="Research depth level", pattern="^(basic|intermediate|advanced)$"
        )
        max_sources: int = Field(
            description="Maximum number of sources to use", ge=3, le=20, default=10
        )
        include_recent_only: bool = Field(
            description="Whether to focus only on recent sources", default=True
        )


    # Create research agents
    hackernews_agent = Agent(
        name="HackerNews Researcher",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[HackerNewsTools()],
        role="Research trending topics and discussions on HackerNews",
        instructions=[
            "Search for relevant discussions and articles",
            "Focus on high-quality posts with good engagement",
            "Extract key insights and technical details",
        ],
    )

    web_researcher = Agent(
        name="Web Researcher",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[DuckDuckGoTools()],
        role="Conduct comprehensive web research",
        instructions=[
            "Search for authoritative sources and documentation",
            "Find recent articles and blog posts",
            "Gather diverse perspectives on the topics",
        ],
    )

    # Create team with input_schema for automatic validation
    research_team = Team(
        name="Research Team with Input Validation",
        model=OpenAIChat(id="gpt-5-mini"),
        members=[hackernews_agent, web_researcher],
        instructions=[
            "Conduct thorough research based on the validated input",
            "Coordinate between team members to avoid duplicate work",
            "Ensure research depth matches the specified level",
            "Respect the maximum sources limit",
            "Focus on recent sources if requested",
        ],
    )

    research_request = ResearchProject(
        project_name="Blockchain Development Tools",
        research_topics=["Ethereum", "Solana", "Web3 Libraries"],
        target_audience="Blockchain Developers",
        depth_level="advanced",
        max_sources=12,
        include_recent_only=False,
    )

    research_team.print_response(input=research_request)
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno ddgs
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python structured_input_team.py
    ```
  </Step>
</Steps>

### Validating the input

You can set `input_schema` on the Team to validate the input.  If you then pass the input as a dictionary, it will be automatically validated against the schema.

<Steps>
  <Step title="Validating the input example">
    ```python validating_input_team.py
    from typing import List

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.team.team import Team
    from agno.tools.duckduckgo import DuckDuckGoTools
    from agno.tools.hackernews import HackerNewsTools
    from pydantic import BaseModel, Field


    class ResearchProject(BaseModel):
        """Structured research project with validation requirements."""

        project_name: str = Field(description="Name of the research project")
        research_topics: List[str] = Field(
            description="List of topics to research", min_items=1
        )
        target_audience: str = Field(description="Intended audience for the research")
        depth_level: str = Field(
            description="Research depth level", pattern="^(basic|intermediate|advanced)$"
        )
        max_sources: int = Field(
            description="Maximum number of sources to use", ge=3, le=20, default=10
        )
        include_recent_only: bool = Field(
            description="Whether to focus only on recent sources", default=True
        )


    # Create research agents
    hackernews_agent = Agent(
        name="HackerNews Researcher",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[HackerNewsTools()],
        role="Research trending topics and discussions on HackerNews",
        instructions=[
            "Search for relevant discussions and articles",
            "Focus on high-quality posts with good engagement",
            "Extract key insights and technical details",
        ],
    )

    web_researcher = Agent(
        name="Web Researcher",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[DuckDuckGoTools()],
        role="Conduct comprehensive web research",
        instructions=[
            "Search for authoritative sources and documentation",
            "Find recent articles and blog posts",
            "Gather diverse perspectives on the topics",
        ],
    )

    # Create team with input_schema for automatic validation
    research_team = Team(
        name="Research Team with Input Validation",
        model=OpenAIChat(id="gpt-5-mini"),
        members=[hackernews_agent, web_researcher],
        input_schema=ResearchProject,
        instructions=[
            "Conduct thorough research based on the validated input",
            "Coordinate between team members to avoid duplicate work",
            "Ensure research depth matches the specified level",
            "Respect the maximum sources limit",
            "Focus on recent sources if requested",
        ],
    )

    research_team.print_response(
        input={
            "project_name": "AI Framework Comparison 2024",
            "research_topics": ["LangChain", "CrewAI", "AutoGen", "Agno"],
            "target_audience": "AI Engineers and Developers",
            "depth_level": "intermediate",
            "max_sources": 15,
            "include_recent_only": True,
        }
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno ddgs
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python validating_input_team.py
    ```
  </Step>
</Steps>

## Typesafe Teams

For complete type safety with both input and output validation, Teams work similarly to Agents. You can combine `input_schema` and `output_schema` to create fully typesafe teams that validate inputs and guarantee structured outputs.

For detailed examples and patterns of typesafe implementations, see the [Agent Input and Output documentation](/concepts/agents/input-output#typesafe-agents), which demonstrates the same concepts that apply to Teams.

## Using a Parser Model

You can use a different model to parse and structure the output from your primary model.
This approach is particularly effective when the primary model is optimized for reasoning tasks, as such models may not consistently produce detailed structured responses.

```python
team = Team(
    model=Claude(id="claude-sonnet-4-20250514"),  # The main processing model
    members=[...],
    description="You write movie scripts.",
    output_schema=MovieScript,
    parser_model=OpenAIChat(id="gpt-5-mini"),  # Only used to parse the output
)
```

<Tip>
  Using a parser model can improve output reliability and reduce costs since you can use a smaller, faster model for formatting while keeping a powerful model for the actual response.
</Tip>

You can also provide a custom `parser_model_prompt` to your Parser Model to customize the model's instructions.

## Using an Output Model

You can use a different model to produce the run output of the team.
This is useful when the primary model is optimized for image analysis, for example, but you want a different model to produce a structured output response.

```python
team = Team(
    model=Gemini(id="gemini-2.0-flash-001"),  # The main processing model
    description="You write movie scripts.",
    output_schema=MovieScript,
    output_model=OpenAIChat(id="gpt-5-mini"),  # Only used to parse the output
    members=[...],
)
```

You can also provide a custom `output_model_prompt` to your Output Model to customize the model's instructions.

<Tip>
  Gemini models often reject requests to use tools and produce structured output
  at the same time. Using an Output Model is an effective workaround for this.
</Tip>

## Developer Resources

* View the [Team schema](/reference/teams/team)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/structured_input_output)


# Teams
Source: https://docs.agno.com/concepts/teams/introduction

Build autonomous multi-agent systems with Agno Teams.

A Team is a collection of Agents (or other sub-teams) that work together to accomplish tasks.

A `Team` has a list of `members` that can be instances of either `Agent` or `Team`.

```python
from agno.team import Team
from agno.agent import Agent

team = Team(members=[
    Agent(name="Agent 1", role="You answer questions in English"),
    Agent(name="Agent 2", role="You answer questions in Chinese"),
    Team(name="Team 1", role="You answer questions in French"),
])
```

The team will transfer tasks to the members depending on the `mode` of the team.

As with agents, teams support the following features:

* **Model:** Set the model that is used by the "team leader" to delegate tasks to the team members.
* **Instructions:** Instruct the team leader on how to solve problems. The names, descriptions and roles of team members are automatically provided to the team leader.
* **Tools:** If the team leader needs to be able to use tools directly, you can add tools to the team.
* **Reasoning:** Enables the team leader to "think" before responding or delegating tasks to team members, and "analyze" the results of team members' responses.
* **Knowledge:** If the team needs to search for information, you can add a knowledge base to the team. This is accessible to the team leader.
* **Storage:** The Team's session history and state is stored in a database. This enables your team to continue conversations from where they left off, enabling multi-turn, long-term conversations.
* **Memory:** Gives Teams the ability to store and recall information from previous interactions, allowing them to learn user preferences and personalize their responses.

<Tip>
  It is recommended to specify the `name` and the `role` fields of each team
  member, for better identification by the team leader.
</Tip>

## Guides

<CardGroup cols={2}>
  <Card title="Running your Team" icon="user-robot" iconType="duotone" href="/concepts/teams/run">
    Learn how to run your teams.
  </Card>

  <Card title="Team Sessions" icon="comments" iconType="duotone" href="/concepts/teams/sessions">
    Learn about team sessions.
  </Card>

  <Card title="Team Storage" icon="database" iconType="duotone" href="/concepts/teams/storage">
    Learn about session storage.
  </Card>

  <Card title="Context Engineering" icon="file-lines" iconType="duotone" href="/concepts/teams/context">
    Learn about context engineering.
  </Card>

  <Card title="Dependencies" icon="brackets-curly" iconType="duotone" href="/concepts/teams/dependencies">
    Learn about dependency injection in your team's context.
  </Card>

  <Card title="Team State" icon="crystal-ball" iconType="duotone" href="/concepts/teams/state">
    Learn about managing team state.
  </Card>

  <Card title="Memory" icon="head-side-brain" iconType="duotone" href="/concepts/teams/memory">
    Learn about adding memory to your teams.
  </Card>

  <Card title="Input & Output" icon="fire" iconType="duotone" href="/concepts/teams/input-output">
    Learn about input and output for teams.
  </Card>

  <Card title="Knowledge" icon="books" iconType="duotone" href="/concepts/teams/knowledge">
    Learn about knowledge in teams.
  </Card>

  <Card title="Team Metrics" icon="chart-line" iconType="duotone" href="/concepts/teams/metrics">
    Learn how to track team metrics.
  </Card>
</CardGroup>

## Developer Resources

* View [Usecases](/examples/use-cases/teams/)
* View [Examples](/examples/concepts/teams/)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/README.md)


# Teams with Knowledge
Source: https://docs.agno.com/concepts/teams/knowledge

Learn how to use teams with knowledge bases.

Teams can use a knowledge base to store and retrieve information, just like agents:

```python
from pathlib import Path

from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb

# Setup paths
cwd = Path(__file__).parent
tmp_dir = cwd.joinpath("tmp")
tmp_dir.mkdir(parents=True, exist_ok=True)

# Initialize knowledge base
agno_docs_knowledge = Knowledge(
    vector_db=LanceDb(
        uri=str(tmp_dir.joinpath("lancedb")),
        table_name="agno_docs",
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

agno_docs_knowledge.add_content(url="https://docs.agno.com/llms-full.txt")

web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
)

team_with_knowledge = Team(
    name="Team with Knowledge",
    members=[web_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=agno_docs_knowledge,
    show_members_responses=True,
    markdown=True,
)

if __name__ == "__main__":
    team_with_knowledge.print_response("Tell me about the Agno framework", stream=True)
```

See more in the [Knowledge](/concepts/knowledge/introduction) section.


# Teams with Memory
Source: https://docs.agno.com/concepts/teams/memory

Learn how to use teams with memory.

The team can also manage user memories, just like agents:

```python
from agno.team import Team
from agno.db.sqlite import SqliteDb

db = SqliteDb(db_file="agno.db")

team_with_memory = Team(
    name="Team with Memory",
    members=[agent1, agent2],
    db=db,
    enable_user_memories=True,
)

team_with_memory.print_response("Hi! My name is John Doe.")
team_with_memory.print_response("What is my name?")
```

See more in the [Memory](/concepts/memory/overview) section.


# Metrics
Source: https://docs.agno.com/concepts/teams/metrics

Understanding team run and session metrics in Agno

When you run a team in Agno, the response you get (**TeamRunOutput**) includes detailed metrics about the run. These metrics help you understand resource usage (like **token usage** and **time**), performance, and other aspects of the model and tool calls across both the team leader and team members.

Metrics are available at multiple levels:

* **Per-message**: Each message (assistant, tool, etc.) has its own metrics.
* **Per-member run**: Each team member run has its own metrics. You can make member runs available on the `TeamRunOutput` by setting `store_member_responses=True`,
* **Team-level**: The `TeamRunOutput` aggregates metrics across all team leader and team member messages.
* **Session-level**: Aggregated metrics across all runs in the session, for both the team leader and all team members.

## Example Usage

Suppose you have a team that performs some tasks and you want to analyze the metrics after running it. Here's how you can access and print the metrics:

```python
from typing import Iterator

from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.pprint import pprint_run_response
from rich.pretty import pprint

# Create team members
web_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Searches the web for information.",
    tools=[DuckDuckGoTools()],
)

# Create the team
team = Team(
    name="Web Research Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[web_searcher],
    markdown=True,
    store_member_responses=True,
)

# Run the team
run_response: TeamRunOutput = team.run(
    "What is going on in the world?"
)
pprint_run_response(run_response, markdown=True)

# Print team leader message metrics
print("---" * 5, "Team Leader Message Metrics", "---" * 5)
if run_response.messages:
    for message in run_response.messages:
        if message.role == "assistant":
            if message.content:
                print(f"Message: {message.content}")
            elif message.tool_calls:
                print(f"Tool calls: {message.tool_calls}")
            print("---" * 5, "Metrics", "---" * 5)
            pprint(message.metrics)
            print("---" * 20)

# Print aggregated team leader metrics
print("---" * 5, "Aggregated Metrics of Team Agent", "---" * 5)
pprint(run_response.metrics)

# Print team leader session metrics
print("---" * 5, "Session Metrics", "---" * 5)
pprint(team.get_session_metrics().to_dict())

# Print team member message metrics
print("---" * 5, "Team Member Message Metrics", "---" * 5)
if run_response.member_responses:
    for member_response in run_response.member_responses:
        if member_response.messages:
            for message in member_response.messages:
                if message.role == "assistant":
                    if message.content:
                        print(f"Member Message: {message.content}")
                    elif message.tool_calls:
                        print(f"Member Tool calls: {message.tool_calls}")
                    print("---" * 5, "Member Metrics", "---" * 5)
                    pprint(message.metrics)
                    print("---" * 20)
```

You'll see the outputs with following information:

* `input_tokens`: The number of tokens sent to the model.
* `output_tokens`: The number of tokens received from the model.
* `total_tokens`: The sum of `input_tokens` and `output_tokens`.
* `audio_input_tokens`: The number of tokens sent to the model for audio input.
* `audio_output_tokens`: The number of tokens received from the model for audio output.
* `audio_total_tokens`: The sum of `audio_input_tokens` and `audio_output_tokens`.
* `cache_read_tokens`: The number of tokens read from the cache.
* `cache_write_tokens`: The number of tokens written to the cache.
* `reasoning_tokens`: The number of tokens used for reasoning.
* `duration`: The duration of the run in seconds.
* `time_to_first_token`: The time taken until the first token was generated.
* `provider_metrics`: Any provider-specific metrics.

## Developer Resources

* View the [TeamRunOutput schema](/reference/teams/team-response)
* View the [Metrics schema](/reference/agents/metrics)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/metrics/01_team_metrics.py)


# Running your Team
Source: https://docs.agno.com/concepts/teams/run

Learn how to run a team and get the response.

The `Team.run()` function runs the team and generates a response, either as a `TeamRunOutput` object or a stream of `TeamRunOutputEvent` objects.

<Note>
  Many of our examples use `team.print_response()` which is a helper utility to
  print the response in the terminal. It uses `team.run()` under the hood.
</Note>

## Running your Team

Here's how to run your team. The response is captured in the `response` and `response_stream` variables.

```python
from agno.team import Team
from agno.models.openai import OpenAIChat

agent_1 = Agent(name="News Agent", role="Get the latest news")

agent_2 = Agent(name="Weather Agent", role="Get the weather for the next 7 days")

team = Team(name="News and Weather Team", members=[agent_1, agent_2])

# Synchronous execution
result = team.run("What is the weather in Tokyo?")

# Asynchronous execution
result = await team.arun("What is the weather in Tokyo?")
```

<Tip>
  You can also run the agent asynchronously using the `Team.arun()` method.
</Tip>

### Print Response

For development purposes, you can also print the response in the terminal using the `Team.print_response()` method.

```python
team.print_response("What is the weather in Tokyo?")

# Or for streaming
team.print_response("What is the weather in Tokyo?", stream=True)
```

<Note>
  The `Team.print_response()` method is a helper method that uses the `Team.run()` method under the hood.
  This is only for convenience during development and not recommended for production use.

  See the [Team class reference](/reference/teams/team) for more details.
</Note>

### Typed inputs and outputs

Teams support the same typesafe input and output patterns as individual agents, allowing you to define structured data schemas for validation and consistent response formats.

For comprehensive information about using Pydantic models for input validation and output schema definition, see the [Input and Output](/concepts/agents/input-output) documentation. All patterns shown there apply to teams as well.

<Tip>
  You can set the `input_schema` on the team to validate the input and `output_schema` to ensure structured outputs. See more details in the [Input and Output](/concepts/teams/input-output) documentation.
</Tip>

### RunOutput

The `Team.run()` function returns a `TeamRunOutput` object when not streaming. Here are some of the core attributes:

* `run_id`: The id of the run.
* `team_id`: The id of the team.
* `team_name`: The name of the team.
* `session_id`: The id of the session.
* `user_id`: The id of the user.
* `content`: The response content.
* `content_type`: The type of content. In the case of structured output, this will be the class name of the pydantic model.
* `reasoning_content`: The reasoning content.
* `messages`: The list of messages sent to the model.
* `metrics`: The metrics of the run. For more details see [Metrics](/concepts/teams/metrics).
* `model`: The model used for the run.
* `member_responses`: The list of member responses. Optional to add when `store_member_responses=True` on the `Team`.

See detailed documentation in the [TeamRunOutput](/reference/teams/team-response) documentation.

## Streaming Responses

To enable streaming, set `stream=True` when calling `run()`. This will return an iterator of `TeamRunOutputEvent` objects instead of a single response.

```python
from agno.team import Team
from agno.models.openai import OpenAIChat

agent_1 = Agent(name="News Agent", role="Get the latest news")

agent_2 = Agent(name="Weather Agent", role="Get the weather for the next 7 days")

team = Team(name="News and Weather Team", members=[agent_1, agent_2])

# Synchronous execution
for chunk in team.run("What is the weather in Tokyo?", stream=True, stream_intermediate_steps=True):
    print(chunk.content, end="", flush=True)

# Asynchronous execution
async for chunk in team.arun("What is the weather in Tokyo?", stream=True, stream_intermediate_steps=True):
    print(chunk.content, end="", flush=True)
```

### Streaming Intermediate Steps

Throughout the execution of a team, multiple events take place, and we provide these events in real-time for enhanced team transparency.

You can enable streaming of intermediate steps by setting `stream_intermediate_steps=True`.

```python
# Stream with intermediate steps
response_stream = team.run(
    "What is the weather in Tokyo?",
    stream=True,
    stream_intermediate_steps=True
)
```

### Handling Events

You can process events as they arrive by iterating over the response stream:

```python
response_stream = team.run("Your prompt", stream=True, stream_intermediate_steps=True)

for event in response_stream:
    if event.event == "TeamRunContent":
        print(f"Content: {event.content}")
    elif event.event == "TeamToolCallStarted":
        print(f"Tool call started: {event.tool}")
    elif event.event == "ToolCallStarted":
        print(f"Member tool call started: {event.tool}")
    elif event.event == "ToolCallCompleted":
        print(f"Member tool call completed: {event.tool}")
    elif event.event == "TeamReasoningStep":
        print(f"Reasoning step: {event.content}")
    ...
```

<Note>
  Team member events are yielded during team execution when a team member is
  being executed. You can disable this by setting `stream_member_events=False`.
</Note>

### Storing Events

You can store all the events that happened during a run on the `RunOutput` object.

```python
from agno.team import Team
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

team = Team(model=OpenAIChat(id="gpt-5-mini"), members=[], store_events=True)

response = team.run("Tell me a 5 second short story about a lion", stream=True, stream_intermediate_steps=True)
pprint_run_response(response)

for event in response.events:
    print(event.event)
```

By default the `TeamRunContentEvent` and `RunContentEvent` events are not stored. You can modify which events are skipped by setting the `events_to_skip` parameter.

For example:

```python
team = Team(model=OpenAIChat(id="gpt-5-mini"), members=[], store_events=True, events_to_skip=[TeamRunEvent.run_started.value])
```

### Event Types

The following events are sent by the `Team.run()` and `Team.arun()` functions depending on team's configuration:

#### Core Events

| Event Type         | Description                                             |
| ------------------ | ------------------------------------------------------- |
| `TeamRunStarted`   | Indicates the start of a run                            |
| `TeamRunContent`   | Contains the model's response text as individual chunks |
| `TeamRunCompleted` | Signals successful completion of the run                |
| `TeamRunError`     | Indicates an error occurred during the run              |
| `TeamRunCancelled` | Signals that the run was cancelled                      |

#### Tool Events

| Event Type              | Description                                                    |
| ----------------------- | -------------------------------------------------------------- |
| `TeamToolCallStarted`   | Indicates the start of a tool call                             |
| `TeamToolCallCompleted` | Signals completion of a tool call, including tool call results |

#### Reasoning Events

| Event Type               | Description                                         |
| ------------------------ | --------------------------------------------------- |
| `TeamReasoningStarted`   | Indicates the start of the team's reasoning process |
| `TeamReasoningStep`      | Contains a single step in the reasoning process     |
| `TeamReasoningCompleted` | Signals completion of the reasoning process         |

#### Memory Events

| Event Type                  | Description                                    |
| --------------------------- | ---------------------------------------------- |
| `TeamMemoryUpdateStarted`   | Indicates that the team is updating its memory |
| `TeamMemoryUpdateCompleted` | Signals completion of a memory update          |

#### Parser Model events

| Event Type                         | Description                                      |
| ---------------------------------- | ------------------------------------------------ |
| `TeamParserModelResponseStarted`   | Indicates the start of the parser model response |
| `TeamParserModelResponseCompleted` | Signals completion of the parser model response  |

#### Output Model events

| Event Type                         | Description                                      |
| ---------------------------------- | ------------------------------------------------ |
| `TeamOutputModelResponseStarted`   | Indicates the start of the output model response |
| `TeamOutputModelResponseCompleted` | Signals completion of the output model response  |

See detailed documentation in the [TeamRunOutput](/reference/teams/team-response) documentation.

### Custom Events

If you are using your own custom tools, it will often be useful to be able to yield custom events. Your custom events will be yielded together with the rest of the expected Agno events.

We recommend creating your custom event class extending the built-in `CustomEvent` class:

```python
from dataclasses import dataclass
from agno.run.team import CustomEvent

@dataclass
class CustomerProfileEvent(CustomEvent):
    """CustomEvent for customer profile."""

    customer_name: Optional[str] = None
    customer_email: Optional[str] = None
    customer_phone: Optional[str] = None
```

You can then yield your custom event from your tool. The event will be handled internally as an Agno event, and you will be able to access it in the same way you would access any other Agno event.

```python
from agno.tools import tool

@tool()
async def get_customer_profile():
    """Example custom tool that simply yields a custom event."""

    yield CustomerProfileEvent(
        customer_name="John Doe",
        customer_email="john.doe@example.com",
        customer_phone="1234567890",
    )
```

See the [full example](/examples/concepts/teams/events/custom_events) for more details.

## Interactive CLI

You can also interact with the team via a CLI.

```python
team.cli_app(input="What is the weather in Tokyo?", stream=True)
```

See the [Team class reference](/reference/teams/team) for more details.

## Agno Telemetry

Agno logs which model an team used so we can prioritize updates to the most popular providers. You can disable this by setting `AGNO_TELEMETRY=false` in your environment or by setting `telemetry=False` on the team.

```bash
export AGNO_TELEMETRY=false
```

or:

```python
team = Team(model=OpenAIChat(id="gpt-5-mini"), members=[], telemetry=False)
```

See the [Team class reference](/reference/teams/team) for more details.

## Developer Resources

* View the [Team reference](/reference/teams/team)
* View the [TeamRunOutput schema](/reference/teams/team-response)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/README.md)


# Cancelling a Run
Source: https://docs.agno.com/concepts/teams/run-cancel

Learn how to cancel a team run.

You can cancel a run by using the `cancel_run` function on the Team.

Below is a basic example that starts an team run in a thread and cancels it from another thread, simulating how it can be done via an API. This is supported via [AgentOS](/agent-os/introduction) as well.

```python
import threading
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent
from agno.run.base import RunStatus
from agno.run.team import TeamRunEvent
from agno.team import Team


def long_running_task(team: Team, run_id_container: dict):
    """
    Simulate a long-running team task that can be cancelled.
    """
    try:
        # Start the team run - this simulates a long task
        final_response = None
        content_pieces = []

        for chunk in team.run(
            "Write a very long story about a dragon who learns to code. "
            "Make it at least 2000 words with detailed descriptions and dialogue. "
            "Take your time and be very thorough.",
            stream=True,
        ):
            if "run_id" not in run_id_container and chunk.run_id:
                print(f"üöÄ Team run started: {chunk.run_id}")
                run_id_container["run_id"] = chunk.run_id

            if chunk.event in [TeamRunEvent.run_content, RunEvent.run_content]:
                print(chunk.content, end="", flush=True)
                content_pieces.append(chunk.content)
            elif chunk.event == RunEvent.run_cancelled:
                print(f"\nüö´ Member run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif chunk.event == TeamRunEvent.run_cancelled:
                print(f"\nüö´ Team run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif hasattr(chunk, "status") and chunk.status == RunStatus.completed:
                final_response = chunk

        # If we get here, the run completed successfully
        if final_response:
            run_id_container["result"] = {
                "status": final_response.status.value
                if final_response.status
                else "completed",
                "run_id": final_response.run_id,
                "cancelled": final_response.status == RunStatus.cancelled,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }
        else:
            run_id_container["result"] = {
                "status": "unknown",
                "run_id": run_id_container.get("run_id"),
                "cancelled": False,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }

    except Exception as e:
        print(f"\n‚ùå Exception in run: {str(e)}")
        run_id_container["result"] = {
            "status": "error",
            "error": str(e),
            "run_id": run_id_container.get("run_id"),
            "cancelled": True,
            "content": "Error occurred",
        }


def cancel_after_delay(team: Team, run_id_container: dict, delay_seconds: int = 3):
    """
    Cancel the team run after a specified delay.
    """
    print(f"‚è∞ Will cancel team run in {delay_seconds} seconds...")
    time.sleep(delay_seconds)

    run_id = run_id_container.get("run_id")
    if run_id:
        print(f"üö´ Cancelling team run: {run_id}")
        success = team.cancel_run(run_id)
        if success:
            print(f"‚úÖ Team run {run_id} marked for cancellation")
        else:
            print(
                f"‚ùå Failed to cancel team run {run_id} (may not exist or already completed)"
            )
    else:
        print("‚ö†Ô∏è  No run_id found to cancel")


def main():
    """Main function demonstrating team run cancellation."""

    # Create team members
    storyteller_agent = Agent(
        name="StorytellerAgent",
        model=OpenAIChat(id="gpt-5-mini"),
        description="An agent that writes creative stories",
    )

    editor_agent = Agent(
        name="EditorAgent",
        model=OpenAIChat(id="gpt-5-mini"),
        description="An agent that reviews and improves stories",
    )

    # Initialize the team with agents
    team = Team(
        name="Storytelling Team",
        members=[storyteller_agent, editor_agent],
        model=OpenAIChat(id="gpt-5-mini"),  # Team leader model
        description="A team that collaborates to write detailed stories",
    )

    print("üöÄ Starting team run cancellation example...")
    print("=" * 50)

    # Container to share run_id between threads
    run_id_container = {}

    # Start the team run in a separate thread
    team_thread = threading.Thread(
        target=lambda: long_running_task(team, run_id_container), name="TeamRunThread"
    )

    # Start the cancellation thread
    cancel_thread = threading.Thread(
        target=cancel_after_delay,
        args=(team, run_id_container, 8),  # Cancel after 8 seconds
        name="CancelThread",
    )

    # Start both threads
    print("üèÉ Starting team run thread...")
    team_thread.start()

    print("üèÉ Starting cancellation thread...")
    cancel_thread.start()

    # Wait for both threads to complete
    print("‚åõ Waiting for threads to complete...")
    team_thread.join()
    cancel_thread.join()

    # Print the results
    print("\n" + "=" * 50)
    print("üìä RESULTS:")
    print("=" * 50)

    result = run_id_container.get("result")
    if result:
        print(f"Status: {result['status']}")
        print(f"Run ID: {result['run_id']}")
        print(f"Was Cancelled: {result['cancelled']}")

        if result.get("error"):
            print(f"Error: {result['error']}")
        else:
            print(f"Content Preview: {result['content']}")

        if result["cancelled"]:
            print("\n‚úÖ SUCCESS: Team run was successfully cancelled!")
        else:
            print("\n‚ö†Ô∏è  WARNING: Team run completed before cancellation")
    else:
        print("‚ùå No result obtained - check if cancellation happened during streaming")

    print("\nüèÅ Team cancellation example completed!")


if __name__ == "__main__":
    # Run the main example
    main()
```

For a more complete example, see [Cancel a run](https://github.com/agno-agi/agno/tree/main/cookbook/teams/basic/team_cancel_a_run.py).


# Team Sessions
Source: https://docs.agno.com/concepts/teams/sessions

Learn about Team sessions.

When we call `Team.run()`, it creates a stateless, singular Team run.

But what if we want to continue this conversation i.e. have a multi-turn conversation? That's where "Sessions" come in. A session is collection of consecutive runs.

In practice, a session in the context of a Team is a multi-turn conversation between a user and the Team. Using a `session_id`, we can connect the conversation history and state across multiple runs.

See more details in the [Agent Sessions](/concepts/agents/sessions) documentation.

## Multi-user, multi-session Teams

Each user that is interacting with a Team gets a unique set of sessions and you can have multiple users interacting with the same Team at the same time.

Set a `user_id` to connect a user to their sessions with the Team.

In the example below, we set a `session_id` to demo how to have multi-turn conversations with multiple users at the same time.

<Steps>
  <Step title="Multi-user, multi-session example">
    ```python
    from agno.team import Team
    from agno.models.openai import OpenAIChat
    from agno.db.sqlite import SqliteDb

    db = SqliteDb(db_file="tmp/data.db")

    team = Team(
        model=OpenAIChat(id="gpt-5-mini"),
        members=[
            Agent(name="Agent 1", role="You answer questions in English"),
            Agent(name="Agent 2", role="You answer questions in Chinese"),
            Agent(name="Agent 3", role="You answer questions in French"),
        ],
        db=db,
        respond_directly=True,
    )

    user_1_id = "user_101"
    user_2_id = "user_102"

    user_1_session_id = "session_101"
    user_2_session_id = "session_102"

    # Start the session with user 1 (This means "how are you?" in French)
    team.print_response(
        "comment √ßa va?",
        user_id=user_1_id,
        session_id=user_1_session_id,
    )
    # Continue the session with user 1 (This means "tell me a joke" in French)
    team.print_response("Raconte-moi une blague.", user_id=user_1_id, session_id=user_1_session_id)

    # Start the session with user 2
    team.print_response("Tell me about quantum physics.", user_id=user_2_id, session_id=user_2_session_id)
    # Continue the session with user 2
    agent.print_response("What is the speed of light?", user_id=user_2_id, session_id=user_2_session_id)

    # Ask the agent to give a summary of the conversation, this will use the history from the previous messages (but only for user 1)
    agent.print_response(
        "Give me a summary of our conversation.",
        user_id=user_2_id,
        session_id=user_2_session_id,
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install agno openai
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python multi_user_multi_session.py
    ```
  </Step>
</Steps>

## Session Summaries

The Team can store a condensed representations of the session, useful when chat histories gets too long. This is called a "Session Summary" in Agno.

To enable session summaries, set `enable_session_summaries=True` on the `Team`.

<Steps>
  <Step title="Session summary example">
    ```python session_summary.py
        from agno.team import Team
        from agno.models.google.gemini import Gemini
        from agno.db.sqlite import SqliteDb

        db = SqliteDb(db_file="tmp/data.db")

        user_id = "jon_hamm@example.com"
        session_id = "1001"

        team = Team(
            model=Gemini(id="gemini-2.0-flash-001"),
            members=[
                Agent(name="Agent 1", role="You answer questions in English"),
                Agent(name="Agent 2", role="You answer questions in Chinese"),
            ],
            db=db,
            enable_session_summaries=True,
        )

        team.print_response(
            "What can you tell me about quantum computing?",
            stream=True,
            user_id=user_id,
            session_id=session_id,
        )

        team.print_response(
            "I would also like to know about LLMs?",
            stream=True,
            user_id=user_id,
            session_id=session_id
        )

        session_summary = team.get_session_summary(session_id=session_id)
        print(f"Session summary: {session_summary.summary}")
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install google-genai agno
    ```

    Export your key

    ```shell
    export GOOGLE_API_KEY=xxx
    ```

    Run the example

    ```shell
    python session_summary.py
    ```
  </Step>
</Steps>

### Customize Session Summaries

You can adjust the session summaries by providing a custom `session_summary_prompt` to the `Team`.

The `SessionSummaryManager` class is responsible for handling the model used to create and update session summaries.
You can adjust it to personalize how summaries are created and updated:

```python
from agno.team import Team
from agno.session import SessionSummaryManager
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

# Setup your database
db = SqliteDb(db_file="agno.db")

# Setup your Session Summary Manager, to adjust how summaries are created
session_summary_manager = SessionSummaryManager(
    # Select the model used for session summary creation and updates. If not specified, the agent's model is used by default.
    model=OpenAIChat(id="gpt-5-mini"),
    # You can also overwrite the prompt used for session summary creation
    session_summary_prompt="Create a very succinct summary of the following conversation:",
)

# Now provide the adjusted Memory Manager to your Agent
team = Team(
  members=[],
  db=db,
  session_summary_manager=session_summary_manager,
  enable_session_summaries=True,
)
```

## Session history

Teams with storage enabled automatically have access to the message and run history of the session.

You can access these messages using:

* `agent.get_messages_for_session()` -> Gets access to all the messages for the session, for the current agent.
* `agent.get_chat_history()` -> Gets access to all the unique messages for the session.

We can give the Agent access to the chat history in the following ways:

* We can set `add_history_to_context=True` and `num_history_runs=5` to add the messages from the last 5 runs automatically to every message sent to the agent.
* We can set `read_chat_history=True` to provide a `get_chat_history()` tool to your agent allowing it to read any message in the entire chat history.
* **We recommend setting all 3: `add_history_to_context=True`, `num_history_runs=3` and `read_chat_history=True` for the best experience.**
* We can also set `read_tool_call_history=True` to provide a `get_tool_call_history()` tool to your agent allowing it to read tool calls in reverse chronological order.

Take a look at this example:

<Steps>
  <Step title="Session history example">
    ```python session_history.py
    from agno.agent import Agent
    from agno.models.google.gemini import Gemini
    from agno.db.sqlite import SqliteDb

    agent = Agent(
        model=Gemini(id="gemini-2.0-flash-exp"),
        db=SqliteDb(db_file="tmp/data.db"),
        add_history_to_context=True,
        num_history_runs=3,
        read_chat_history=True,
        description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
    )

    agent.print_response("Share a 2 sentence horror story", stream=True)

    agent.print_response("What was my first message?", stream=True)
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install google-genai agno
    ```

    Export your key

    ```shell
    export GOOGLE_API_KEY=xxx
    ```

    Run the example

    ```shell
    python session_history.py
    ```
  </Step>
</Steps>

### Search the session history

In some scenarios, you might want to fetch messages from across multiple sessions to provide context or continuity in conversations.

To enable fetching messages from the last N sessions, you need to use the following flags:

* `search_session_history`: Set this to `True` to allow searching through previous sessions.
* `num_history_sessions`: Specify the number of past sessions to include in the search. In the example below, it is set to `2` to include only the last 2 sessions.

It's advisable to keep this number low (2 or 3), as a larger number might fill up the context length of the model, potentially leading to performance issues.

Here's an example of searching through the last 2 sessions:

```python
# Remove the tmp db file before running the script
import os

from agno.team import Team
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb

os.remove("tmp/data.db")

db = SqliteDb(db_file="tmp/data.db")

team = Team(
    members=[
      Agent(name="Agent 1", role="You answer questions in English"),
      Agent(name="Agent 2", role="You answer questions in Chinese"),
    ],
    model=OpenAIChat(id="gpt-5-mini"),
    user_id="user_1",
    db=db,
    search_session_history=True,  # allow searching previous sessions
    num_history_sessions=2,  # only include the last 2 sessions in the search to avoid context length issues
)

session_1_id = "session_1_id"
session_2_id = "session_2_id"
session_3_id = "session_3_id"
session_4_id = "session_4_id"
session_5_id = "session_5_id"

team.print_response("What is the capital of South Africa?", session_id=session_1_id)
team.print_response("What is the capital of China?", session_id=session_2_id)
team.print_response("What is the capital of France?", session_id=session_3_id)
team.print_response("What is the capital of Japan?", session_id=session_4_id)
team.print_response(
    "What did I discuss in my previous conversations?", session_id=session_5_id
)  # It should only include information from the last 2 sessions
```

## Developer Resources

* View the [Team schema](/reference/teams/team)
* View the [Session schema](/reference/teams/session)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/teams/session/)


# Shared State
Source: https://docs.agno.com/concepts/teams/state

Learn about the shared state of Agent Teams.

Team Session State enables sophisticated state management across teams of agents. Teams often need to coordinate on shared information.

<Check>
  Shared state propagates through nested team structures as well
</Check>

## How to use Shared State

You can set the `session_state` parameter on `Team` to share state between the team leader and team members.
This state is available to all team members and is synchronized between them.

For example:

```python
team = Team(
    members=[agent1, agent2, agent3],
    session_state={"shopping_list": []},
)
```

Members can access the shared state using the `session_state` attribute in tools.

For example:

```python
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list and return confirmation.

    Args:
        item (str): The item to add to the shopping list.
    """
    # Add the item if it's not already in the list
    if item.lower() not in [
        i.lower() for i in session_state["shopping_list"]
    ]:
        session_state["shopping_list"].append(item)
        return f"Added '{item}' to the shopping list"
    else:
        return f"'{item}' is already in the shopping list"
```

<Note>
  The `session_state` variable is automatically passed to the tool as an argument.  Any updates to it is automatically reflected in the shared state.
</Note>

### Example

Here's a simple example of a team managing a shared shopping list:

```python team_session_state.py
from agno.models.openai import OpenAIChat
from agno.agent import Agent
from agno.team import Team


# Define tools that work with shared team state
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list."""
    if item.lower() not in [
        i.lower() for i in session_state["shopping_list"]
    ]:
        session_state["shopping_list"].append(item)
        return f"Added '{item}' to the shopping list"
    else:
        return f"'{item}' is already in the shopping list"


def remove_item(session_state, item: str) -> str:
    """Remove an item from the shopping list."""
    for i, list_item in enumerate(session_state["shopping_list"]):
        if list_item.lower() == item.lower():
            session_state["shopping_list"].pop(i)
            return f"Removed '{list_item}' from the shopping list"
    
    return f"'{item}' was not found in the shopping list"


# Create an agent that manages the shopping list
shopping_agent = Agent(
    name="Shopping List Agent",
    role="Manage the shopping list",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[add_item, remove_item],
)


# Define team-level tools
def list_items(session_state) -> str:
    """List all items in the shopping list."""
    # Access shared state (not private state)
    shopping_list = session_state["shopping_list"]
    
    if not shopping_list:
        return "The shopping list is empty."
    
    items_text = "\n".join([f"- {item}" for item in shopping_list])
    return f"Current shopping list:\n{items_text}"


def add_chore(session_state, chore: str) -> str:
    """Add a completed chore to the team's private log."""
    # Access team's private state
    if "chores" not in session_state:
        session_state["chores"] = []
    
    session_state["chores"].append(chore)
    return f"Logged chore: {chore}"


# Create a team with both shared and private state
shopping_team = Team(
    name="Shopping Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[shopping_agent],
    session_state={"shopping_list": [], "chores": []},
    tools=[list_items, add_chore],
    instructions=[
        "You manage a shopping list.",
        "Forward add/remove requests to the Shopping List Agent.",
        "Use list_items to show the current list.",
        "Log completed tasks using add_chore.",
    ],
)

# Example usage
shopping_team.print_response("Add milk, eggs, and bread", stream=True)
print(f"Shared state: {shopping_team.get_session_state()}")

shopping_team.print_response("What's on my list?", stream=True)

shopping_team.print_response("I got the eggs", stream=True)
print(f"Shared state: {shopping_team.get_session_state()}")
```

<Tip>
  Notice how shared tools use `session_state`, which allows state to propagate and persist across the entire team ‚Äî even for subteams within the team. This ensures consistent shared state for all members.
</Tip>

See a full example [here](/examples/concepts/teams/state/team_with_nested_shared_state).

## Agentic Session State

Agno provides a way to allow the team and team members to automatically update the shared session state.

Simply set the `enable_agentic_state` parameter to `True`.

```python agentic_session_state.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team.team import Team

db = SqliteDb(db_file="tmp/agents.db")
shopping_agent = Agent(
    name="Shopping List Agent",
    role="Manage the shopping list",
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    add_session_state_to_context=True,  # Required so the agent is aware of the session state
    enable_agentic_state=True,
)

team = Team(
    members=[shopping_agent],
    session_state={"shopping_list": []},
    db=db,
    add_session_state_to_context=True,  # Required so the team is aware of the session state
    enable_agentic_state=True,
    description="You are a team that manages a shopping list and chores",
    show_members_responses=True,
)


team.print_response("Add milk, eggs, and bread to the shopping list")

team.print_response("I picked up the eggs, now what's on my list?")

print(f"Session state: {team.get_session_state()}")
```

<Tip>
  Don't forget to set `add_session_state_to_context=True` to make the session state available to the team's context.
</Tip>

## Using state in instructions

You can reference variables from the session state in your instructions.

<Tip>
  Don't use the f-string syntax in the instructions. Directly use the `{key}` syntax, Agno substitutes the values for you.
</Tip>

```python state_in_instructions.py
from agno.team.team import Team

team = Team(
    members=[],
    # Initialize the session state with a variable
    session_state={"user_name": "John"},
    instructions="Users name is {user_name}",
    markdown=True,
)

team.print_response("What is my name?", stream=True)
```

## Changing state on run

When you pass `session_id` to the team on `team.run()`, it will switch to the session with the given `session_id` and load any state that was set on that session.

This is useful when you want to continue a session for a specific user.

```python changing_state_on_run.py
from agno.team.team import Team
from agno.models.openai import OpenAIChat
from agno.db.in_memory import InMemoryDb

team = Team(
    db=InMemoryDb(),
    model=OpenAIChat(id="gpt-5-mini"),
    members=[],
    instructions="Users name is {user_name} and age is {age}",
)

# Sets the session state for the session with the id "user_1_session_1"
team.print_response("What is my name?", session_id="user_1_session_1", user_id="user_1", session_state={"user_name": "John", "age": 30})

# Will load the session state from the session with the id "user_1_session_1"
team.print_response("How old am I?", session_id="user_1_session_1", user_id="user_1")

# Sets the session state for the session with the id "user_2_session_1"
team.print_response("What is my name?", session_id="user_2_session_1", user_id="user_2", session_state={"user_name": "Jane", "age": 25})

# Will load the session state from the session with the id "user_2_session_1"
team.print_response("How old am I?", session_id="user_2_session_1", user_id="user_2")
```

## Team Member Interactions

Agent Teams can share interactions between members, allowing agents to learn from each other's outputs:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team

from agno.db.sqlite import SqliteDb
from agno.tools.duckduckgo import DuckDuckGoTools

db = SqliteDb(db_file="tmp/agents.db")

web_research_agent = Agent(
    name="Web Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are a web research agent that can answer questions from the web.",
)

report_agent = Agent(
    name="Report Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a report agent that can write a report from the web research.",
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    members=[web_research_agent, report_agent],
    share_member_interactions=True,
    instructions=[
        "You are a team of agents that can research the web and write a report.",
        "First, research the web for information about the topic.",
        "Then, use your report agent to write a report from the web research.",
    ],
    show_members_responses=True,
    debug_mode=True,
)

team.print_response("How are LEDs made?")
```


# Storage
Source: https://docs.agno.com/concepts/teams/storage

Use Storage to persist Team sessions and state to a database or file.

**Why do we need Session Storage?**

Teams are ephemeral and stateless. When you run a Team, no state is persisted automatically.

In production environments, we serve (or trigger) Teams via an API and need to continue the same session across multiple requests.

Storage persists the session history and state in a database and allows us to pick up where we left off.

Here is a simple example showing how to configure storage for a Team:

```python
from agno.team import Team
from agno.db.postgres import PostgresDb

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

team = Team(members=[], db=db)
team.print_response("What is the capital of France?")
team.print_response("What was my question?")

```

See [Agent Session Storage](/concepts/agents/storage) for more details on how sessions are stored in general.

## Session table schema

If you have a `db` configured for your team, the sessions will be stored in the sessions table in your database.

The schema for the sessions table is as follows:

| Field           | Type   | Description                                      |
| --------------- | ------ | ------------------------------------------------ |
| `session_id`    | `str`  | The unique identifier for the session.           |
| `session_type`  | `str`  | The type of the session.                         |
| `agent_id`      | `str`  | The agent ID of the session.                     |
| `team_id`       | `str`  | The team ID of the session.                      |
| `workflow_id`   | `str`  | The workflow ID of the session.                  |
| `user_id`       | `str`  | The user ID of the session.                      |
| `session_data`  | `dict` | The data of the session.                         |
| `agent_data`    | `dict` | The data of the agent.                           |
| `team_data`     | `dict` | The data of the team.                            |
| `workflow_data` | `dict` | The data of the workflow.                        |
| `metadata`      | `dict` | The metadata of the session.                     |
| `runs`          | `list` | The runs of the session.                         |
| `summary`       | `dict` | The summary of the session.                      |
| `created_at`    | `int`  | The timestamp when the session was created.      |
| `updated_at`    | `int`  | The timestamp when the session was last updated. |

This data is best displayed on the [sessions page of the AgentOS UI](https://os.agno.com/sessions).

## Developer Resources

* View the [Team schema](/reference/teams/team)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/)


# Agno Telemetry
Source: https://docs.agno.com/concepts/telemetry

Understanding what Agno logs

Agno automatically logs anonymised data about agents, teams and workflows, as well as AgentOS configurations.
This helps us improve the Agno platform and provide better support.

<Note>
  No sensitive data is sent to the Agno servers. Telemetry is only used to improve the Agno platform.
</Note>

Agno logs the following:

* Agent runs
* Team runs
* Workflow runs
* AgentOS Launches

Below is an example of the payload sent to the Agno servers for an agent run:

```json
{
    "session_id": "123",
    "run_id": "123",
    "sdk_version": "1.0.0",
    "type": "agent",
    "data": {
        "agent_id": "123",
        "db_type": "PostgresDb",
        "model_provider": "openai",
        "model_name": "OpenAIResponses",
        "model_id": "gpt-5-mini",
        "parser_model": {
            "model_provider": "openai",
            "model_name": "OpenAIResponses",
            "model_id": "gpt-5-mini",
        },
        "output_model": {
            "model_provider": "openai",
            "model_name": "OpenAIResponses",
            "model_id": "gpt-5-mini",
        },
        "has_tools": true,
        "has_memory": false,
        "has_reasoning": true,
        "has_knowledge": true,
        "has_input_schema": false,
        "has_output_schema": false,
        "has_team": true,
    },
}
```

## Disabling Telemetry

You can disable this by setting `AGNO_TELEMETRY=false` in your environment or by setting `telemetry=False` on the agent, team, workflow or AgentOS.

```bash
export AGNO_TELEMETRY=false
```

or:

```python
agent = Agent(model=OpenAIChat(id="gpt-5-mini"), telemetry=False)
```

See the [Agent class reference](/reference/agents/agent) for more details.


# Async Tools
Source: https://docs.agno.com/concepts/tools/async-tools

Learn how to use async tools in Agno.

Agno Agents can execute multiple tools concurrently, allowing you to process function calls that the model makes efficiently. This is especially valuable when the functions involve time-consuming operations. It improves responsiveness and reduces overall execution time.

<Check>
  When you call `arun` or `aprint_response`, your tools will execute concurrently. If you provide synchronous functions as tools, they will execute concurrently on separate threads.
</Check>

## Example

Here is an example:

```python async_tools.py
import asyncio
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.log import logger

async def atask1(delay: int):
    """Simulate a task that takes a random amount of time to complete
    Args:
        delay (int): The amount of time to delay the task
    """
    logger.info("Task 1 has started")
    for _ in range(delay):
        await asyncio.sleep(1)
        logger.info("Task 1 has slept for 1s")
    logger.info("Task 1 has completed")
    return f"Task 1 completed in {delay:.2f}s"


async def atask2(delay: int):
    """Simulate a task that takes a random amount of time to complete
    Args:
        delay (int): The amount of time to delay the task
    """
    logger.info("Task 2 has started")
    for _ in range(delay):
        await asyncio.sleep(1)
        logger.info("Task 2 has slept for 1s")
    logger.info("Task 2 has completed")
    return f"Task 2 completed in {delay:.2f}s"


async def atask3(delay: int):
    """Simulate a task that takes a random amount of time to complete
    Args:
        delay (int): The amount of time to delay the task
    """
    logger.info("Task 3 has started")
    for _ in range(delay):
        await asyncio.sleep(1)
        logger.info("Task 3 has slept for 1s")
    logger.info("Task 3 has completed")
    return f"Task 3 completed in {delay:.2f}s"


async_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[atask2, atask1, atask3],
    markdown=True,
)

asyncio.run(
    async_agent.aprint_response("Please run all tasks with a delay of 3s", stream=True)
)
```

Run the Agent:

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python async_tools.py
```

How to use:

1. Provide your Agent with a list of tools, preferably asynchronous for optimal performance. However, synchronous functions can also be used since they will execute concurrently on separate threads.
2. Run the Agent using either the `arun` or `aprint_response` method, enabling concurrent execution of tool calls.

<Note>
  Concurrent execution of tools requires a model that supports parallel function
  calling. For example, OpenAI models have a `parallel_tool_calls` parameter
  (enabled by default) that allows multiple tool calls to be requested and
  executed simultaneously.
</Note>

In this example, `gpt-5-mini` makes three simultaneous tool calls to `atask1`, `atask2` and `atask3`. Normally these tool calls would execute sequentially, but using the `aprint_response` function, they run concurrently, improving execution time.

<img height="200" src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=4ec6216f4c1dafa6c7a675bd345c6ad2" style={{ borderRadius: "8px" }} data-og-width="344" data-og-height="463" data-path="images/async-tools.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2ef332604d86c02722791a3beffa7589 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=948e641806ce6a2224074a78a5dd9521 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=9bbc9234b871fdec04c5229f69637c4a 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7a8dcfeb62df06475d15981339375437 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7078423de7061f62251c3f6209dbb38e 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/async-tools.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=512ee4e5ccf4e4bfa33edac026b3a472 2500w" />


# Updating Tools
Source: https://docs.agno.com/concepts/tools/attaching-tools

Learn how to add/update tools on Agents and Teams after they have been created.

Tools can be added to Agents and Teams post-creation. This gives you the flexibility to add tools to an existing Agent or Team instance after initialization, which is useful for dynamic tool management or when you need to conditionally add tools based on runtime requirements.
The whole collection of tools available to an Agent or Team can also be updated by using the `set_tools` call. Note that this will remove any other tools already assigned to your Agent or Team and override it with the list of tools provided to `set_tools`.

## Agent Example

Create your own tool, for example `get_weather`. Then call `add_tool` to attach it to your Agent.

```python add_agent_tool_post_initialization.py
import random

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool


@tool(stop_after_tool_call=True)
def get_weather(city: str) -> str:
    """Get the weather for a city."""
    # In a real implementation, this would call a weather API
    weather_conditions = ["sunny", "cloudy", "rainy", "snowy", "windy"]
    random_weather = random.choice(weather_conditions)

    return f"The weather in {city} is {random_weather}."


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
)

agent.print_response("What can you do?", stream=True)

agent.add_tool(get_weather)

agent.print_response("What is the weather in San Francisco?", stream=True)
```

# Team Example

Create a list of tools, and assign them to your Team with `set_tools`

```python add_team_tool_post_initialization.py
import random

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools import tool
from agno.tools.calculator import CalculatorTools


agent1 = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
)

agent2 = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
)

team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[agent1, agent2],
    tools=[CalculatorTools()],
    markdown=True,
    show_members_responses=True,
)


@tool
def get_stock_price(stock_symbol: str) -> str:
    """Get the current stock price of a stock."""
    return f"The current stock price of {stock_symbol} is {random.randint(100, 1000)}."

@tool
def get_stock_availability(stock_symbol: str) -> str:
    """Get the current availability of a stock."""
    return f"The current stock available of {stock_symbol} is {random.randint(100, 1000)}."


team.set_tools([get_stock_price, get_stock_availability])

team.print_response("What is the current stock price of NVDA?", stream=True)
team.print_response("How much stock NVDA stock is available?", stream=True)

```

<Tip>
  The `add_tool` method allows you to dynamically extend an Agent's or a Team's capabilities. This is particularly useful when you want to add tools based on user input or other runtime conditions.
  The `set_tool` method allows you to override an Agent's or a Team's capabilities. Note that this will remove any existing tools previously assigned to your Agent or Team.
</Tip>

## Related Documentation

* [Tool Decorator](/concepts/tools/custom-tools) - Learn how to create custom tools
* [Available Toolkits](/concepts/tools/toolkits) - Explore pre-built toolkits
* [Selecting Tools](/concepts/tools/selecting-tools) - Learn how to filter tools in toolkits


# Tool Result Caching
Source: https://docs.agno.com/concepts/tools/caching

Learn how to cache tool results in Agno.

Tool result caching is designed to avoid unnecessary recomputation by storing the results of function calls on disk.
This is useful during development and testing to speed up the development process, avoid rate limiting, and reduce costs.

<Check>
  This is supported for all Agno Toolkits
</Check>

## On Toolkit

Pass `cache_results=True` to the Toolkit constructor to enable caching for that Toolkit.

```python cache_tool_calls.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(cache_results=True), YFinanceTools(cache_results=True)],
)

asyncio.run(
    agent.aprint_response(
        "What is the current stock price of AAPL and latest news on 'Apple'?",
        markdown=True,
    )
)
```

## On @tool

Pass `cache_results=True` to the `@tool` decorator to enable caching for that tool.

```python cache_tool_calls.py
from agno.tools import tool

@tool(cache_results=True)
def get_stock_price(ticker: str) -> str:
    """Get the current stock price of a given ticker"""

    # ... Long running operation

    return f"The current stock price of {ticker} is 100"
```


# Creating your own tools
Source: https://docs.agno.com/concepts/tools/custom-tools

Learn how to write your own tools and how to use the `@tool` decorator to modify the behavior of a tool.

In most production cases, you will need to write your own tools. Which is why we're focused on provide the best tool-use experience in Agno.

The rule is simple:

* Any Python function can be used as a tool by an Agent.
* Use the `@tool` decorator to modify what happens before and after this tool is called.

## Python Functions as Tools

For example, here's how to use a `get_top_hackernews_stories` function as a tool:

```python hn_agent.py
import json
import httpx

from agno.agent import Agent

def get_top_hackernews_stories(num_stories: int = 10) -> str:
    """
    Use this function to get top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to return. Defaults to 10.

    Returns:
        str: JSON string of top stories.
    """

    # Fetch top story IDs
    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')
    story_ids = response.json()

    # Fetch story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        stories.append(story)
    return json.dumps(stories)

agent = Agent(tools=[get_top_hackernews_stories], markdown=True)
agent.print_response("Summarize the top 5 stories on hackernews?", stream=True)
```

## Magic of the @tool decorator

To modify the behavior of a tool, use the `@tool` decorator. Some notable features:

* `requires_confirmation=True`: Requires user confirmation before execution.
* `requires_user_input=True`: Requires user input before execution. Use `user_input_fields` to specify which fields require user input.
* `external_execution=True`: The tool will be executed outside of the agent's control.
* `show_result=True`: Show the output of the tool call in the Agent's response, `True` by default. Without this flag, the result of the tool call is sent to the model for further processing.
* `stop_after_tool_call=True`: Stop the agent run after the tool call.
* `tool_hooks`: Run custom logic before and after this tool call.
* `cache_results=True`: Cache the tool result to avoid repeating the same call. Use `cache_dir` and `cache_ttl` to configure the cache.

Here's an example that uses many possible parameters on the `@tool` decorator.

```python advanced_tool.py
import httpx
from agno.agent import Agent
from agno.tools import tool
from typing import Any, Callable, Dict

def logger_hook(function_name: str, function_call: Callable, arguments: Dict[str, Any]):
    """Hook function that wraps the tool execution"""
    print(f"About to call {function_name} with arguments: {arguments}")
    result = function_call(**arguments)
    print(f"Function call completed with result: {result}")
    return result

@tool(
    name="fetch_hackernews_stories",                # Custom name for the tool (otherwise the function name is used)
    description="Get top stories from Hacker News",  # Custom description (otherwise the function docstring is used)
    stop_after_tool_call=True,                      # Return the result immediately after the tool call and stop the agent
    tool_hooks=[logger_hook],                       # Hook to run before and after execution
    requires_confirmation=True,                     # Requires user confirmation before execution
    cache_results=True,                             # Enable caching of results
    cache_dir="/tmp/agno_cache",                    # Custom cache directory
    cache_ttl=3600                                  # Cache TTL in seconds (1 hour)
)
def get_top_hackernews_stories(num_stories: int = 5) -> str:
    """
    Fetch the top stories from Hacker News.

    Args:
        num_stories: Number of stories to fetch (default: 5)

    Returns:
        str: The top stories in text format
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Get story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json")
        story = story_response.json()
        stories.append(f"{story.get('title')} - {story.get('url', 'No URL')}")

    return "\n".join(stories)

agent = Agent(tools=[get_top_hackernews_stories])
agent.print_response("Show me the top news from Hacker News")
```

### @tool Parameters Reference

| Parameter               | Type             | Description                                                       |
| ----------------------- | ---------------- | ----------------------------------------------------------------- |
| `name`                  | `str`            | Override for the function name                                    |
| `description`           | `str`            | Override for the function description                             |
| `stop_after_tool_call`  | `bool`           | If True, the agent will stop after the function call              |
| `tool_hooks`            | `list[Callable]` | List of hooks that wrap the function execution                    |
| `pre_hook`              | `Callable`       | Hook to run before the function is executed                       |
| `post_hook`             | `Callable`       | Hook to run after the function is executed                        |
| `requires_confirmation` | `bool`           | If True, requires user confirmation before execution              |
| `requires_user_input`   | `bool`           | If True, requires user input before execution                     |
| `user_input_fields`     | `list[str]`      | List of fields that require user input                            |
| `external_execution`    | `bool`           | If True, the tool will be executed outside of the agent's control |
| `cache_results`         | `bool`           | If True, enable caching of function results                       |
| `cache_dir`             | `str`            | Directory to store cache files                                    |
| `cache_ttl`             | `int`            | Time-to-live for cached results in seconds (default: 3600)        |

## Writing your own Toolkit

Many advanced use-cases will require writing custom Toolkits. Here's the general flow:

1. Create a class inheriting the `agno.tools.Toolkit` class.
2. Add your functions to the class.
3. **Important:** Include all the functions in the `tools` argument to the `Toolkit` constructor.

Now your Toolkit is ready to use with an Agent. For example:

```python shell_toolkit.py
from typing import List

from agno.agent import Agent
from agno.tools import Toolkit
from agno.utils.log import logger

class ShellTools(Toolkit):
    def __init__(self, **kwargs):
        super().__init__(name="shell_tools", tools=[self.run_shell_command], **kwargs)

    def run_shell_command(self, args: List[str], tail: int = 100) -> str:
        """
        Runs a shell command and returns the output or error.

        Args:
            args (List[str]): The command to run as a list of strings.
            tail (int): The number of lines to return from the output.
        Returns:
            str: The output of the command.
        """
        import subprocess

        logger.info(f"Running shell command: {args}")
        try:
            logger.info(f"Running shell command: {args}")
            result = subprocess.run(args, capture_output=True, text=True)
            logger.debug(f"Result: {result}")
            logger.debug(f"Return code: {result.returncode}")
            if result.returncode != 0:
                return f"Error: {result.stderr}"
            # return only the last n lines of the output
            return "\n".join(result.stdout.split("\n")[-tail:])
        except Exception as e:
            logger.warning(f"Failed to run shell command: {e}")
            return f"Error: {e}"

agent = Agent(tools=[ShellTools()], markdown=True)
agent.print_response("List all the files in my home directory.")

```


# Exceptions & Retries
Source: https://docs.agno.com/concepts/tools/exceptions



If after a tool call we need to "retry" the model with a different set of instructions or stop the agent, we can raise one of the following exceptions:

* `RetryAgentRun`: Use this exception when you want to retry the agent run with a different set of instructions.
* `StopAgentRun`: Use this exception when you want to stop the agent run.
* `AgentRunException`: A generic exception that can be used to retry the tool call.

This example shows how to use the `RetryAgentRun` exception to retry the agent with additional instructions.

```python retry_in_tool_call.py
from agno.agent import Agent
from agno.exceptions import RetryAgentRun
from agno.models.openai import OpenAIChat
from agno.utils.log import logger


def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list."""
    session_state["shopping_list"].append(item)
    len_shopping_list = len(session_state["shopping_list"])
    if len_shopping_list < 3:
        raise RetryAgentRun(
            f"Shopping list is: {session_state['shopping_list']}. Minimum 3 items in the shopping list. "
            + f"Add {3 - len_shopping_list} more items.",
        )

    logger.info(f"The shopping list is now: {session_state.get('shopping_list')}")
    return f"The shopping list is now: {session_state.get('shopping_list')}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with empty shopping list
    session_state={"shopping_list": []},
    tools=[add_item],
    markdown=True,
)
agent.print_response("Add milk", stream=True)
print(f"Final session state: {agent.get_session_state()}")
```

<Tip>
  Make sure to set `AGNO_DEBUG=True` to see the debug logs.
</Tip>


# Hooks
Source: https://docs.agno.com/concepts/tools/hooks

Learn how to use tool hooks to modify the behavior of a tool.

## Tool Hooks

You can use tool hooks to perform validation, logging, or any other logic before or after a tool is called.

A tool hook is a function that takes a function name, function call, and arguments. Optionally, you can access the `Agent` or `Team` object as well.  Inside the tool hook, you have to call the function call and return the result.

<Note>
  It is important to use exact parameter names when defining a tool hook. `agent`, `team`, `function_name`, `function_call`, and `arguments` are available parameters.
</Note>

For example:

```python
def logger_hook(
    function_name: str, function_call: Callable, arguments: Dict[str, Any]
):
    """Log the duration of the function call"""
    start_time = time.time()

    # Call the function
    result = function_call(**arguments)
    
    end_time = time.time()
    duration = end_time - start_time
    
    logger.info(f"Function {function_name} took {duration:.2f} seconds to execute")

    # Return the result
    return result
```

or

```python
def confirmation_hook(
    function_name: str, function_call: Callable, arguments: Dict[str, Any]
):
    """Confirm the function call"""
    if function_name != "get_top_hackernews_stories":
        raise ValueError("This tool is not allowed to be called")
    return function_call(**arguments)
```

You can assign tool hooks on agents and teams.  The tool hooks will be applied to all tool calls made by the agent or team.

For example:

```python
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    tool_hooks=[logger_hook],
)
```

You can also get access to the `Agent` or `Team` object in the tool hook.

```python

def grab_customer_profile_hook(
    session_state: dict, function_name: str, function_call: Callable, arguments: Dict[str, Any]
):
    cust_id = arguments.get("customer")
    if cust_id not in session_state["customer_profiles"]:
        raise ValueError(f"Customer profile for {cust_id} not found")
    customer_profile = session_state["customer_profiles"][cust_id]

    # Replace the customer with the customer_profile for the function call
    arguments["customer"] = json.dumps(customer_profile)
    # Call the function with the updated arguments
    result = function_call(**arguments)

    return result
```

### Multiple Tool Hooks

You can also assign multiple tool hooks at once. They will be applied in the order they are assigned.

```python
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    tool_hooks=[logger_hook, confirmation_hook],  # The logger_hook will run on the outer layer, and the confirmation_hook will run on the inner layer
)
```

You can also assign tool hooks to specific custom tools.

```python
@tool(tool_hooks=[logger_hook, confirmation_hook])
def get_top_hackernews_stories(num_stories: int) -> Iterator[str]:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    final_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        final_stories.append(story)

    return json.dumps(final_stories)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories],
)
```

## Pre and Post Hooks

Pre and post hooks let's you modify what happens before and after a tool is called. It is an alternative to tool hooks.

Set the `pre_hook` in the `@tool` decorator to run a function before the tool call.

Set the `post_hook` in the `@tool` decorator to run a function after the tool call.

Here's a demo example of using a `pre_hook`, `post_hook` along with Agent Context.

```python pre_and_post_hooks.py
import json
from typing import Iterator

import httpx
from agno.agent import Agent
from agno.tools import FunctionCall, tool


def pre_hook(fc: FunctionCall):
    print(f"Pre-hook: {fc.function.name}")
    print(f"Arguments: {fc.arguments}")
    print(f"Result: {fc.result}")


def post_hook(fc: FunctionCall):
    print(f"Post-hook: {fc.function.name}")
    print(f"Arguments: {fc.arguments}")
    print(f"Result: {fc.result}")


@tool(pre_hook=pre_hook, post_hook=post_hook)
def get_top_hackernews_stories(agent: Agent) -> Iterator[str]:
    num_stories = agent.context.get("num_stories", 5) if agent.context else 5

    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        yield json.dumps(story)


agent = Agent(
    dependencies={
        "num_stories": 2,
    },
    tools=[get_top_hackernews_stories],
    markdown=True,
)
agent.print_response("What are the top hackernews stories?", stream=True)
```

## Example: Human in the loop using tool hooks

This example shows how to:

* Add hooks to tools for user confirmation
* Handle user input during tool execution
* Gracefully cancel operations based on user choice

<Steps>
  <Step title="Create the example">
    ```python hitl.py
    """ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

    This example shows how to implement human-in-the-loop functionality in your Agno tools.
    It shows how to:
    - Add tool hooks to tools for user confirmation
    - Handle user input during tool execution
    - Gracefully cancel operations based on user choice

    Some practical applications:
    - Confirming sensitive operations before execution
    - Reviewing API calls before they're made
    - Validating data transformations
    - Approving automated actions in critical systems

    Run `pip install openai httpx rich agno` to install dependencies.
    """

    import json
    from typing import Any, Callable, Dict, Iterator

    import httpx
    from agno.agent import Agent
    from agno.exceptions import StopAgentRun
    from agno.models.openai import OpenAIChat
    from agno.tools import FunctionCall, tool
    from rich.console import Console
    from rich.pretty import pprint
    from rich.prompt import Prompt

    # This is the console instance used by the print_response method
    # We can use this to stop and restart the live display and ask for user confirmation
    console = Console()


    def confirmation_hook(
        function_name: str, function_call: Callable, arguments: Dict[str, Any]
    ):
        # Get the live display instance from the console
        live = console._live

        # Stop the live display temporarily so we can ask for user confirmation
        live.stop()  # type: ignore

        # Ask for confirmation
        console.print(f"\nAbout to run [bold blue]{fc.function.name}[/]")
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        # Restart the live display
        live.start()  # type: ignore

        # If the user does not want to continue, raise a StopExecution exception
        if message != "y":
            raise StopAgentRun(
                "Tool call cancelled by user",
                agent_message="Stopping execution as permission was not granted.",
            )
        
        # Call the function
        result = function_call(**arguments)

        # Optionally transform the result

        return result


    @tool(tool_hooks=[confirmation_hook])
    def get_top_hackernews_stories(num_stories: int) -> Iterator[str]:
        """Fetch top stories from Hacker News.

        Args:
            num_stories (int): Number of stories to retrieve

        Returns:
            str: JSON string containing story details
        """
        # Fetch top story IDs
        response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
        story_ids = response.json()

        # Yield story details
        final_stories = []
        for story_id in story_ids[:num_stories]:
            story_response = httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
            )
            story = story_response.json()
            if "text" in story:
                story.pop("text", None)
            final_stories.append(story)

        return json.dumps(final_stories)


    # Initialize the agent with a tech-savvy personality and clear instructions
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[get_top_hackernews_stories],
        markdown=True,
    )

    agent.print_response(
        "Fetch the top 2 hackernews stories?", stream=True, console=console
    )
    ```
  </Step>

  <Step title="Run the example">
    Install libraries

    ```shell
    pip install openai agno
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```

    Run the example

    ```shell
    python hitl.py
    ```
  </Step>
</Steps>


# What are Tools?
Source: https://docs.agno.com/concepts/tools/introduction

Tools are functions your Agno Agents can use to get things done.

Tools are what make Agents capable of real-world action. While using LLMs directly you can only generate text, Agents equipped with tools can

They are used to enable Agents to interact with external systems, and perform actions like searching the web, running SQL, sending an email or calling APIs.

Agno comes with 120+ pre-built toolkits, which you can use to give your Agents all kind of abilities. You can also write your own tools, to give your Agents even more capabilities. The general syntax is:

```python
import random

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool

# This is our tool, marked by the @tool decorator
@tool(stop_after_tool_call=True)
def get_weather(city: str) -> str:
    """Get the weather for the given city."""

    # In a real implementation, this would call a weather API
    weather_conditions = ["sunny", "cloudy", "rainy", "snowy", "windy"]
    random_weather = random.choice(weather_conditions)

    return f"The weather in {city} is {random_weather}."

# To equipt our Agent with our tool, we simply pass it with the tools parameter
agent = Agent(
    model=OpenAIChat(id="gpt-5-nano"),
    tools=[get_weather],
    markdown=True,
)

# Our Agent will now be able to use our tool, when it deems it relevant
agent.print_response("What is the weather in San Francisco?", stream=True)
```

<Tip>
  In the example above, the `get_weather` function is a tool. When called, the tool result is shown in the output.

  Then, the Agent will stop after the tool call (without waiting for the model to respond) because we set `stop_after_tool_call=True`.
</Tip>

### Using the Toolkit Class

The `Toolkit` class provides a way to manage multiple tools with additional control over their execution.

You can specify which tools should stop the agent after execution and which should have their results shown.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Importing our GoogleSearchTools ToolKit, containing multiple web search tools
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        GoogleSearchTools(),
    ],
)

agent.print_response("What's the latest about OpenAIs GPT-5?", markdown=True)
```

In this example, the `GoogleSearchTools` toolkit is added to the agent. This ToolKit comes pre-configured with the `google_search` function.

## Tool Built-in Parameters

Agno automatically provides special parameters to your tools that give access to the agent's state. These parameters are injected automatically - you don't pass them when calling the tool.

### Session State Parameter

The built-in parameter `session_state` allows tools to access and modify persistent data across conversations.

This is useful in cases where a tool result is relevant for the next steps of the conversation.

Add `session_state` as a parameter in your tool function to access the agent's persistent state:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat


def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list."""
    session_state["shopping_list"].append(item)  # type: ignore
    return f"The shopping list is now {session_state['shopping_list']}"  # type: ignore


# Create an Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    # Initialize the session state with a counter starting at 0 (this is the default session state for all users)
    session_state={"shopping_list": []},
    db=SqliteDb(db_file="tmp/agents.db"),
    tools=[add_item],
    # You can use variables from the session state in the instructions
    instructions="Current state (shopping list) is: {shopping_list}",
    markdown=True,
)

# Example usage
agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Final session state: {agent.get_session_state()}")
```

See more in [Agent State](/concepts/agents/state).

### Media Parameters

The built-in parameter `images`, `videos`, `audio`, and `files` allows tools to access and modify the input media to an agent.

<Note>
  Using the `send_media_to_model` parameter, you can control whether the media is sent to the model or not and using `store_media` parameter, you can control whether the
  media is stored in the `RunOutput` or not.
</Note>

See the [image input example](/examples/concepts/agent/multimodal/image_input_for_tool) and [file input example](/examples/concepts/agent/multimodal/file_input_for_tool) for an advanced example using media.

## Tool Results

Tools can return different types of results depending on their complexity and what they need to communicate back to the agent.

### Simple Return Types

Most tools can return simple Python types directly like `str`, `int`, `float`, `dict`, and `list`:

```python
@tool
def get_weather(city: str) -> str:
    """Get the weather for a city."""
    return f"The weather in {city} is sunny and 75¬∞F"

@tool
def calculate_sum(a: int, b: int) -> int:
    """Calculate the sum of two numbers."""
    return a + b

@tool
def get_user_info(user_id: str) -> dict:
    """Get user information."""
    return {
        "user_id": user_id,
        "name": "John Doe",
        "email": "john@example.com",
        "status": "active"
    }

@tool
def search_products(query: str) -> list:
    """Search for products."""
    return [
        {"id": 1, "name": "Product A", "price": 29.99},
        {"id": 2, "name": "Product B", "price": 39.99}
    ]
```

### `ToolResult` for Media Content

When your tool needs to return media artifacts (images, videos, audio), you **must** use `ToolResult`:

<Snippet file="tool-result-reference.mdx" />

```python
from agno.tools.function import ToolResult
from agno.media import Image

@tool
def generate_image(prompt: str) -> ToolResult:
    """Generate an image from a prompt."""

    # Create your image (example)
    image_artifact = Image(
        id="img_123",
        url="https://example.com/generated-image.jpg",
        original_prompt=prompt
    )

    return ToolResult(
        content=f"Generated image for: {prompt}",
        images=[image]
    )
```

This would **make generated media available** to the LLM model.

## Useful Links

<CardGroup cols={2}>
  <Card title="Available Toolkits" icon="box-open" href="/concepts/tools/toolkits">
    See the full list of available toolkits
  </Card>

  <Card title="MCP Tools" icon="robot" href="/concepts/tools/mcp">
    Learn how to use MCP tools with Agno
  </Card>

  <Card title="Reasoning Tools" icon="brain-circuit" href="/concepts/tools/reasoning_tools">
    Learn how to use reasoning tools with Agno
  </Card>

  <Card title="Creating your own tools" icon="code" href="/concepts/tools/custom-tools">
    Learn how to create your own tools
  </Card>
</CardGroup>


# Model Context Protocol (MCP)
Source: https://docs.agno.com/concepts/tools/mcp/mcp

Learn how to use MCP with Agno to enable your agents to interact with external systems through a standardized interface.

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io) enables Agents to interact with external systems through a standardized interface.
You can connect your Agents to any MCP server, using Agno's MCP integration.

This simple example shows how to connect an Agent to the Agno MCP server:

```python agno_agent.py lines
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.mcp import MCPTools

# Create the Agent
agno_agent = Agent(
    name="Agno Agent",
    model=Claude(id="claude-sonnet-4-0"),
    # Add the Agno MCP server to the Agent
    tools=[MCPTools(transport="streamable-http", url="https://docs.agno.com/mcp")],
)
```

## Usage

<Steps>
  <Step title="Find the MCP server you want to use">
    You can use any working MCP server. To see some examples, you can check [this GitHub repository](https://github.com/modelcontextprotocol/servers), by the maintainers of the MCP themselves.
  </Step>

  <Step title="Initialize the MCP integration">
    Initialize the `MCPTools` class and connect to the MCP server. The recommended way to define the MCP server is to use the `command` or `url` parameters. With `command`, you can pass the command used to run the MCP server you want. With `url`, you can pass the URL of the running MCP server you want to use.

    For example, to connect to the Agno documentation MCP server, you can do the following:

    ```python
    from agno.tools.mcp import MCPTools

    # Initialize and connect to the MCP server
    mcp_tools = MCPTools(transport="streamable-http", url="https://docs.agno.com/mcp"))
    await mcp_tools.connect()
    ```
  </Step>

  <Step title="Provide the MCPTools to the Agent">
    When initializing the Agent, pass the `MCPTools` instance in the `tools` parameter. Remember to close the connection when you're done.

    The agent will now be ready to use the MCP server:

    ```python
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.mcp import MCPTools

    # Initialize and connect to the MCP server
    mcp_tools = MCPTools(url="https://docs.agno.com/mcp")
    await mcp_tools.connect()

    try:
        # Setup and run the agent
        agent = Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[mcp_tools])
        await agent.aprint_response("Tell me more about MCP support in Agno", stream=True)
    finally:
        # Always close the connection when done
        await mcp_tools.close()
    ```
  </Step>
</Steps>

### Example: Filesystem Agent

Here's a filesystem agent that uses the [Filesystem MCP server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) to explore and analyze files:

```python filesystem_agent.py
import asyncio
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools


async def run_agent(message: str) -> None:
    """Run the filesystem agent with the given message."""

    file_path = "<path to the directory you want to explore>"

    # Initialize and connect to the MCP server to access the filesystem
    mcp_tools = MCPTools(command=f"npx -y @modelcontextprotocol/server-filesystem {file_path}")
    await mcp_tools.connect()

    try:
        agent = Agent(
            model=OpenAIChat(id="gpt-5-mini"),
            tools=[mcp_tools],
            instructions=dedent("""\
                You are a filesystem assistant. Help users explore files and directories.

                - Navigate the filesystem to answer questions
                - Use the list_allowed_directories tool to find directories that you can access
                - Provide clear context about files you examine
                - Use headings to organize your responses
                - Be concise and focus on relevant information\
            """),
            markdown=True,
        )

        # Run the agent
        await agent.aprint_response(message, stream=True)
    finally:
        # Always close the connection when done
        await mcp_tools.close()


# Example usage
if __name__ == "__main__":
    # Basic example - exploring project license
    asyncio.run(run_agent("What is the license for this project?"))
```

## Connecting your MCP server

### Using `connect()` and `close()`

You should use the `connect()` and `close()` methods to connect and disconnect from the MCP server.

This is the recommended way to setup your MCP server.

```python
mcp_tools = MCPTools(command="uvx mcp-server-git")
await mcp_tools.connect()
```

After you're done, you should close the connection to the MCP server.

```python
await mcp_tools.close()
```

### Using Async Context Manager

If you prefer, you can also use `MCPTools` or `MultiMCPTools` as async context managers for automatic resource cleanup:

```python
async with MCPTools(command="uvx mcp-server-git") as mcp_tools:
    agent = Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[mcp_tools])
    await agent.aprint_response("What is the license for this project?", stream=True)
```

This pattern automatically handles connection and cleanup, but the explicit `.connect()` and `.close()` methods provide more control over connection lifecycle.

## Transports

Transports in the Model Context Protocol (MCP) define how messages are sent and received. The Agno integration supports the three existing types:

* [stdio](https://modelcontextprotocol.io/docs/concepts/transports#standard-input%2Foutput-stdio) -> See the [stdio transport documentation](/concepts/tools/mcp/transports/stdio)
* [Streamable HTTP](https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http) -> See the [streamable HTTP transport documentation](/concepts/tools/mcp/transports/streamable_http)
* [SSE](https://modelcontextprotocol.io/docs/concepts/transports#server-sent-events-sse) -> See the [SSE transport documentation](/concepts/tools/mcp/transports/sse)

<Note>
  The stdio (standard input/output) transport is the default one in Agno's `MCPTools` and `MultiMCPTools`.
</Note>

## Best Practices

1. **Resource Cleanup**: Always close MCP connections when done to prevent resource leaks:

```python
mcp_tools = MCPTools(command="uvx mcp-server-git")
await mcp_tools.connect()

try:
    # Your agent code here
    pass
finally:
    await mcp_tools.close()
```

2. **Error Handling**: Always include proper error handling for MCP server connections and operations.

3. **Clear Instructions**: Provide clear and specific instructions to your agent:

```python
instructions = """
You are a filesystem assistant. Help users explore files and directories.
- Navigate the filesystem to answer questions
- Use the list_allowed_directories tool to find accessible directories
- Provide clear context about files you examine
- Be concise and focus on relevant information
"""
```

## Developer Resources

* See how to use MCP with AgentOS [here](/agent-os/mcp/mcp).
* Find examples of Agents that use MCP [here](/examples/concepts/tools/mcp/airbnb).
* Find a collection of MCP servers [here](https://github.com/modelcontextprotocol/servers).


# Multiple MCP Servers
Source: https://docs.agno.com/concepts/tools/mcp/multiple-servers

Understanding how to connect to multiple MCP servers with Agno

Agno's MCP integration also supports handling connections to multiple servers, specifying server parameters and using your own MCP servers

There are two approaches to this:

1. Using multiple `MCPTools` instances
2. Using a single `MultiMCPTools` instance

## Using multiple `MCPTools` instances

```python multiple_mcp_servers.py
import asyncio
import os

from agno.agent import Agent
from agno.tools.mcp import MCPTools


async def run_agent(message: str) -> None:
    """Run the Airbnb and Google Maps agent with the given message."""

    env = {
        **os.environ,
        "GOOGLE_MAPS_API_KEY": os.getenv("GOOGLE_MAPS_API_KEY"),
    }

    # Initialize and connect to multiple MCP servers
    airbnb_tools = MCPTools(command="npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt")
    google_maps_tools = MCPTools(command="npx -y @modelcontextprotocol/server-google-maps", env=env)
    await airbnb_tools.connect()
    await google_maps_tools.connect()

    try:
        agent = Agent(
            tools=[airbnb_tools, google_maps_tools],
            markdown=True,
        )

        await agent.aprint_response(message, stream=True)
    finally:
        await airbnb_tools.close()
        await google_maps_tools.close()


# Example usage
if __name__ == "__main__":
    # Pull request example
    asyncio.run(
        run_agent(
            "What listings are available in Cape Town for 2 people for 3 nights from 1 to 4 August 2025?"
        )
    )
```

## Using a single `MultiMCPTools` instance

```python multiple_mcp_servers.py
import asyncio
import os

from agno.agent import Agent
from agno.tools.mcp import MultiMCPTools


async def run_agent(message: str) -> None:
    """Run the Airbnb and Google Maps agent with the given message."""

    env = {
        **os.environ,
        "GOOGLE_MAPS_API_KEY": os.getenv("GOOGLE_MAPS_API_KEY"),
    }

    # Initialize and connect to multiple MCP servers
    mcp_tools = MultiMCPTools(
        commands=[
            "npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt",
            "npx -y @modelcontextprotocol/server-google-maps",
        ],
        env=env,
    )
    await mcp_tools.connect()

    try:
        agent = Agent(
            tools=[mcp_tools],
            markdown=True,
        )

        await agent.aprint_response(message, stream=True)
    finally:
        # Always close the connection when done
        await mcp_tools.close()


# Example usage
if __name__ == "__main__":
    # Pull request example
    asyncio.run(
        run_agent(
            "What listings are available in Cape Town for 2 people for 3 nights from 1 to 4 August 2025?"
        )
    )
```

### Allowing partial failures with `MultiMCPTools`

If you are connecting to multiple MCP servers using the `MultiMCPTools` class, an error will be raised by default if connection to any MCP server fails.

If you want to avoid raising in that case, you can set the `allow_partial_failures` parameter to `True`.

This is useful if you are connecting to MCP servers that are not always available, and don't want to exit your program if one of the servers is not available.

```python
import asyncio
from os import getenv

from agno.agent import Agent
from agno.tools.mcp import MultiMCPTools


async def run_agent(message: str) -> None:
    # Initialize the MCP tools
    mcp_tools = MultiMCPTools(
        [
            "npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt",
            "npx -y @modelcontextprotocol/server-brave-search",
        ],
        env={
            "BRAVE_API_KEY": getenv("BRAVE_API_KEY"),
        },
        timeout_seconds=30,
        # Set the allow_partial_failure to True to allow for partial failure connecting to the MCP servers
        allow_partial_failure=True,
    )

    # Connect to the MCP servers
    await mcp_tools.connect()

    # Use the MCP tools with an Agent
    agent = Agent(
        tools=[mcp_tools],
        markdown=True,
    )
    await agent.aprint_response(message)

    # Close the MCP connection
    await mcp_tools.close()


# Example usage
if __name__ == "__main__":
    asyncio.run(run_agent("What listings are available in Barcelona tonight?"))
    asyncio.run(run_agent("What's the fastest way to get to Barcelona from London?"))
```


# Understanding Server Parameters
Source: https://docs.agno.com/concepts/tools/mcp/server-params

Understanding how to configure the server parameters for the MCPTools and MultiMCPTools classes

The recommended way to configure `MCPTools` is to use the `command` or `url` parameters.

Alternatively, you can use the `server_params` parameter with `MCPTools` to configure the connection to the MCP server in more detail.

When using the **stdio** transport, the `server_params` parameter should be an instance of `StdioServerParameters`. It contains the following keys:

* `command`: The command to run the MCP server.
  * Use `npx` for mcp servers that can be installed via npm (or `node` if running on Windows).
  * Use `uvx` for mcp servers that can be installed via uvx.
* `args`: The arguments to pass to the MCP server.
* `env`: Optional environment variables to pass to the MCP server. Remember to include all current environment variables in the `env` dictionary. If `env` is not provided, the current environment variables will be used.
  e.g.

```python
{
    **os.environ,
    "GOOGLE_MAPS_API_KEY": os.getenv("GOOGLE_MAPS_API_KEY"),
}
```

When using the **SSE** transport, the `server_params` parameter should be an instance of `SSEClientParams`. It contains the following fields:

* `url`: The URL of the MCP server.
* `headers`: Headers to pass to the MCP server (optional).
* `timeout`: Timeout for the connection to the MCP server (optional).
* `sse_read_timeout`: Timeout for the SSE connection itself (optional).

When using the **Streamable HTTP** transport, the `server_params` parameter should be an instance of `StreamableHTTPClientParams`. It contains the following fields:

* `url`: The URL of the MCP server.
* `headers`: Headers to pass to the MCP server (optional).
* `timeout`: Timeout for the connection to the MCP server (optional).
* `sse_read_timeout`: how long (in seconds) the client will wait for a new event before disconnecting. All other HTTP operations are controlled by `timeout` (optional).
* `terminate_on_close`: Whether to terminate the connection when the client is closed (optional).


# SSE Transport
Source: https://docs.agno.com/concepts/tools/mcp/transports/sse



Agno's MCP integration supports the [SSE transport](https://modelcontextprotocol.io/docs/concepts/transports#server-sent-events-sse). This transport enables server-to-client streaming, and can prove more useful than [stdio](https://modelcontextprotocol.io/docs/concepts/transports#standard-input%2Foutput-stdio) when working with restricted networks.

<Note>
  This transport is not recommended anymore by the MCP protocol. Use the [Streamable HTTP transport](/concepts/tools/mcp/transports/streamable_http) instead.
</Note>

To use it, initialize the `MCPTools` passing the URL of the MCP server and setting the transport to `sse`:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools

server_url = "http://localhost:8000/sse"

# Initialize and connect to the SSE MCP server
mcp_tools = MCPTools(url=server_url, transport="sse")
await mcp_tools.connect()

try:
    agent = Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[mcp_tools])
    await agent.aprint_response("What is the license for this project?", stream=True)
finally:
    # Always close the connection when done
    await mcp_tools.close()
```

You can also use the `server_params` argument to define the MCP connection. This way you can specify the headers to send to the MCP server with every request, and the timeout values:

```python
from agno.tools.mcp import MCPTools, SSEClientParams

server_params = SSEClientParams(
    url=...,
    headers=...,
    timeout=...,
    sse_read_timeout=...,
)

# Initialize and connect using server parameters
mcp_tools = MCPTools(server_params=server_params, transport="sse")
await mcp_tools.connect()

try:
    # Use mcp_tools with your agent
    pass
finally:
    await mcp_tools.close()
```

## Complete example

Let's set up a simple local server and connect to it using the SSE transport:

<Steps>
  <Step title="Setup the server">
    ```python sse_server.py
    from mcp.server.fastmcp import FastMCP

    mcp = FastMCP("calendar_assistant")


    @mcp.tool()
    def get_events(day: str) -> str:
        return f"There are no events scheduled for {day}."


    @mcp.tool()
    def get_birthdays_this_week() -> str:
        return "It is your mom's birthday tomorrow"


    if __name__ == "__main__":
        mcp.run(transport="sse")
    ```
  </Step>

  <Step title="Setup the client">
    ```python sse_client.py
    import asyncio

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.mcp import MCPTools, MultiMCPTools

    # This is the URL of the MCP server we want to use.
    server_url = "http://localhost:8000/sse"


    async def run_agent(message: str) -> None:
        # Initialize and connect to the SSE MCP server
        mcp_tools = MCPTools(transport="sse", url=server_url)
        await mcp_tools.connect()

        try:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp_tools],
                markdown=True,
            )
            await agent.aprint_response(message=message, stream=True, markdown=True)
        finally:
            await mcp_tools.close()


    # Using MultiMCPTools, we can connect to multiple MCP servers at once, even if they use different transports.
    # In this example we connect to both our example server (SSE transport), and a different server (stdio transport).
    async def run_agent_with_multimcp(message: str) -> None:
        # Initialize and connect to multiple MCP servers with different transports
        mcp_tools = MultiMCPTools(
            commands=["npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt"],
            urls=[server_url],
            urls_transports=["sse"],
        )
        await mcp_tools.connect()

        try:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp_tools],
                markdown=True,
            )
            await agent.aprint_response(message=message, stream=True, markdown=True)
        finally:
            await mcp_tools.close()


    if __name__ == "__main__":
        asyncio.run(run_agent("Do I have any birthdays this week?"))
        asyncio.run(
            run_agent_with_multimcp(
                "Can you check when is my mom's birthday, and if there are any AirBnb listings in SF for two people for that day?"
            )
        )
    ```
  </Step>

  <Step title="Run the server">
    ```bash
    python sse_server.py
    ```
  </Step>

  <Step title="Run the client">
    ```bash
    python sse_client.py
    ```
  </Step>
</Steps>


# Stdio Transport
Source: https://docs.agno.com/concepts/tools/mcp/transports/stdio



The stdio (standard input/output) transport is the default one in Agno's integration. It works best for local integrations.

To use it, simply initialize the `MCPTools` class with the `command` argument.
The command you want to pass is the one used to run the MCP server the agent will have access to.

For example `uvx mcp-server-git`, which runs a [git MCP server](https://github.com/modelcontextprotocol/servers/tree/main/src/git):

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools

# Initialize and connect to the MCP server
mcp_tools = MCPTools(command="uvx mcp-server-git")
await mcp_tools.connect()

try:
    agent = Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[mcp_tools])
    await agent.aprint_response("What is the license for this project?", stream=True)
finally:
    # Always close the connection when done
    await mcp_tools.close()
```

You can also use multiple MCP servers at once, with the `MultiMCPTools` class. For example:

```python
import asyncio
import os

from agno.agent import Agent
from agno.tools.mcp import MultiMCPTools


async def run_agent(message: str) -> None:
    """Run the Airbnb and Google Maps agent with the given message."""

    env = {
        **os.environ,
        "GOOGLE_MAPS_API_KEY": os.getenv("GOOGLE_MAPS_API_KEY"),
    }

    # Initialize and connect to multiple MCP servers
    mcp_tools = MultiMCPTools(
        commands=[
            "npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt",
            "npx -y @modelcontextprotocol/server-google-maps",
        ],
        env=env,
    )
    await mcp_tools.connect()

    try:
        agent = Agent(
            tools=[mcp_tools],
            markdown=True,
        )

        await agent.aprint_response(message, stream=True)
    finally:
        # Always close the connection when done
        await mcp_tools.close()


# Example usage
if __name__ == "__main__":
    # Pull request example
    asyncio.run(
        run_agent(
            "What listings are available in Cape Town for 2 people for 3 nights from 1 to 4 August 2025?"
        )
    )
```


# Streamable HTTP Transport
Source: https://docs.agno.com/concepts/tools/mcp/transports/streamable_http



The new [Streamable HTTP transport](https://modelcontextprotocol.io/specification/draft/basic/transports#streamable-http) replaces the HTTP+SSE transport from protocol version `2024-11-05`.

This transport enables the MCP server to handle multiple client connections, and can also use SSE for server-to-client streaming.

To use it, initialize the `MCPTools` passing the URL of the MCP server and setting the transport to `streamable-http`:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools

# Initialize and connect to the Streamable HTTP MCP server
mcp_tools = MCPTools(url="https://docs.agno.com/mcp", transport="streamable-http")
await mcp_tools.connect()

try:
    agent = Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[mcp_tools])
    await agent.aprint_response("What can you tell me about MCP support in Agno?", stream=True)
finally:
    # Always close the connection when done
    await mcp_tools.close()
```

You can also use the `server_params` argument to define the MCP connection. This way you can specify the headers to send to the MCP server with every request, and the timeout values:

```python
from agno.tools.mcp import MCPTools, StreamableHTTPClientParams

server_params = StreamableHTTPClientParams(
    url=...,
    headers=...,
    timeout=...,
    sse_read_timeout=...,
    terminate_on_close=...,
)

# Initialize and connect using server parameters
mcp_tools = MCPTools(server_params=server_params, transport="streamable-http")
await mcp_tools.connect()

try:
    # Use mcp_tools with your agent
    pass
finally:
    await mcp_tools.close()
```

## Complete example

Let's set up a simple local server and connect to it using the Streamable HTTP transport:

<Steps>
  <Step title="Setup the server">
    ```python streamable_http_server.py
    from mcp.server.fastmcp import FastMCP

    mcp = FastMCP("calendar_assistant")


    @mcp.tool()
    def get_events(day: str) -> str:
        return f"There are no events scheduled for {day}."


    @mcp.tool()
    def get_birthdays_this_week() -> str:
        return "It is your mom's birthday tomorrow"


    if __name__ == "__main__":
        mcp.run(transport="streamable-http")
    ```
  </Step>

  <Step title="Setup the client">
    ```python streamable_http_client.py
    import asyncio

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.mcp import MCPTools, MultiMCPTools

    # This is the URL of the MCP server we want to use.
    server_url = "http://localhost:8000/mcp"


    async def run_agent(message: str) -> None:
        # Initialize and connect to the Streamable HTTP MCP server
        mcp_tools = MCPTools(transport="streamable-http", url=server_url)
        await mcp_tools.connect()

        try:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp_tools],
                markdown=True,
            )
            await agent.aprint_response(message=message, stream=True, markdown=True)
        finally:
            await mcp_tools.close()


    # Using MultiMCPTools, we can connect to multiple MCP servers at once, even if they use different transports.
    # In this example we connect to both our example server (Streamable HTTP transport), and a different server (stdio transport).
    async def run_agent_with_multimcp(message: str) -> None:
        # Initialize and connect to multiple MCP servers with different transports
        mcp_tools = MultiMCPTools(
            commands=["npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt"],
            urls=[server_url],
            urls_transports=["streamable-http"],
        )
        await mcp_tools.connect()

        try:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp_tools],
                markdown=True,
            )
            await agent.aprint_response(message=message, stream=True, markdown=True)
        finally:
            await mcp_tools.close()


    if __name__ == "__main__":
        asyncio.run(run_agent("Do I have any birthdays this week?"))
        asyncio.run(
            run_agent_with_multimcp(
                "Can you check when is my mom's birthday, and if there are any AirBnb listings in SF for two people for that day?"
            )
        )
    ```
  </Step>

  <Step title="Run the server">
    ```bash
    python streamable_http_server.py
    ```
  </Step>

  <Step title="Run the client">
    ```bash
    python streamable_http_client.py
    ```
  </Step>
</Steps>


# Knowledge Tools
Source: https://docs.agno.com/concepts/tools/reasoning_tools/knowledge-tools



The `KnowledgeTools` toolkit enables Agents to search, retrieve, and analyze information from knowledge bases. This toolkit integrates with `Knowledge` and provides a structured workflow for finding and evaluating relevant information before responding to users.

The toolkit implements a "Think ‚Üí Search ‚Üí Analyze" cycle that allows an Agent to:

1. Think through the problem and plan search queries
2. Search the knowledge base for relevant information
3. Analyze the results to determine if they are sufficient or if additional searches are needed

This approach significantly improves an Agent's ability to provide accurate information by giving it tools to find, evaluate, and synthesize knowledge.

The toolkit includes the following tools:

* `think`: A scratchpad for planning, brainstorming keywords, and refining approaches. These thoughts remain internal to the Agent and are not shown to users.
* `search`: Executes queries against the knowledge base to retrieve relevant documents.
* `analyze`: Evaluates whether the returned documents are correct and sufficient, determining if further searches are needed.

## Example

Here's an example of how to use the `KnowledgeTools` toolkit:

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.tools.knowledge import KnowledgeTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge base containing information from a URL
agno_docs = Knowledge(
    # Use LanceDB as the vector database and store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
agno_docs.add_content(
    url="https://docs.agno.com/llms-full.txt"
)

knowledge_tools = KnowledgeTools(
    knowledge=agno_docs,
    think=True,
    search=True,
    analyze=True,
    add_few_shot=True,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[knowledge_tools],
    markdown=True,
)

if __name__ == "__main__":
    agent.print_response("How do I build multi-agent teams with Agno?", stream=True)
```

The toolkit comes with default instructions and few-shot examples to help the Agent use the tools effectively. Here is how you can configure them:

```python
from agno.tools.knowledge import KnowledgeTools

knowledge_tools = KnowledgeTools(
    knowledge=my_knowledge_base,
    think=True,                # Enable the think tool
    search=True,               # Enable the search tool
    analyze=True,              # Enable the analyze tool
    add_instructions=True,     # Add default instructions
    add_few_shot=True,         # Add few-shot examples
    few_shot_examples=None,    # Optional custom few-shot examples
)
```


# Memory Tools
Source: https://docs.agno.com/concepts/tools/reasoning_tools/memory-tools



The `MemoryTools` toolkit enables Agents to manage user memories through create, update, and delete operations. This toolkit integrates with a provided database where memories are stored.

The toolkit implements a "Think ‚Üí Operate ‚Üí Analyze" cycle that allows an Agent to:

1. Think through memory management requirements and plan operations
2. Execute memory operations (add, update, delete) on the database
3. Analyze the results to ensure operations completed successfully and meet requirements

This approach gives Agents the ability to persistently store, retrieve, and manage user information, preferences, and context across conversations.

The toolkit includes the following tools:

* `think`: A scratchpad for planning memory operations, brainstorming content, and refining approaches. These thoughts remain internal to the Agent and are not shown to users.
* `get_memories`: Gets a list of memories for the current user from the database.
* `add_memory`: Creates new memories in the database with specified content and optional topics.
* `update_memory`: Modifies existing memories by memory ID, allowing updates to content and topics.
* `delete_memory`: Removes memories from the database by memory ID.
* `analyze`: Evaluates whether memory operations completed successfully and produced the expected results.

## Example

Here's an example of how to use the `MemoryTools` toolkit:

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.memory import MemoryTools

# Create a database connection
db = SqliteDb(
    db_file="tmp/memory.db"
)

memory_tools = MemoryTools(
    db=db,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[memory_tools],
    markdown=True,
)

agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends. "
    "I like to travel to new places and experience different cultures. "
    "I am planning to travel to Africa in December. ",
    user_id="john_doe@example.com",
    stream=True
)

# This won't use the session history, but instead will use the memory tools to get the memories
agent.print_response("What have you remembered about me?", stream=True, user_id="john_doe@example.com")
```

Here is how you can configure the toolkit:

```python
from agno.tools.memory import MemoryTools

memory_tools = MemoryTools(
    db=my_database,
    enable_think=True,            # Enable the think tool (true by default)
    enable_get_memories=True,     # Enable the get_memories tool (true by default)
    enable_add_memory=True,       # Enable the add_memory tool (true by default)
    enable_update_memory=True,    # Enable the update_memory tool (true by default)
    enable_delete_memory=True,    # Enable the delete_memory tool (true by default)
    enable_analyze=True,          # Enable the analyze tool (true by default)
    add_instructions=True,        # Add default instructions
    instructions=None,            # Optional custom instructions
    add_few_shot=True,           # Add few-shot examples
    few_shot_examples=None,      # Optional custom few-shot examples
)
```


# Reasoning Tools
Source: https://docs.agno.com/concepts/tools/reasoning_tools/reasoning-tools



The `ReasoningTools` toolkit allows an Agent to use reasoning like any other tool, at any point during execution. Unlike traditional approaches that reason once at the start to create a fixed plan, this enables the Agent to reflect after each step, adjust its thinking, and update its actions on the fly.

We've found that this approach significantly improves an Agent's ability to solve complex problems it would otherwise fail to handle. By giving the Agent space to "think" about its actions, it can examine its own responses more deeply, question its assumptions, and approach the problem from different angles.

The toolkit includes the following tools:

* `think`: This tool is used as a scratchpad by the Agent to reason about the question and work through it step by step. It helps break down complex problems into smaller, manageable chunks and track the reasoning process.
* `analyze`: This tool is used to analyze the results from a reasoning step and determine the next actions.

## Example

Here's an example of how to use the `ReasoningTools` toolkit:

```python
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.reasoning import ReasoningTools
from agno.tools.yfinance import YFinanceTools

thinking_agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    tools=[
        ReasoningTools(add_instructions=True),
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        ),
    ],
    instructions="Use tables where possible",
    markdown=True,
)

thinking_agent.print_response("Write a report comparing NVDA to TSLA", stream=True)
```

The toolkit comes with default instructions and few-shot examples to help the Agent use the tool effectively. Here is how you can enable them:

```python
reasoning_agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    tools=[
        ReasoningTools(
            think=True,
            analyze=True,
            add_instructions=True,
            add_few_shot=True,
        ),
    ],
)
```

`ReasoningTools` can be used with any model provider that supports function calling. Here is an example with of a reasoning Agent using `OpenAIChat`:

```python
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ReasoningTools(add_instructions=True)],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†

        Your approach to problems:
        1. First, break down complex questions into component parts
        2. Clearly state your assumptions
        3. Develop a structured reasoning path
        4. Consider multiple perspectives
        5. Evaluate evidence and counter-arguments
        6. Draw well-justified conclusions

        When solving problems:
        - Use explicit step-by-step reasoning
        - Identify key variables and constraints
        - Explore alternative scenarios
        - Highlight areas of uncertainty
        - Explain your thought process clearly
        - Consider both short and long-term implications
        - Evaluate trade-offs explicitly

        For quantitative problems:
        - Show your calculations
        - Explain the significance of numbers
        - Consider confidence intervals when appropriate
        - Identify source data reliability

        For qualitative reasoning:
        - Assess how different factors interact
        - Consider psychological and social dynamics
        - Evaluate practical constraints
        - Address value considerations
        \
    """),
    add_datetime_to_context=True,
    stream_intermediate_steps=True,
    markdown=True,
)
```

This Agent can be used to ask questions that elicit thoughtful analysis, such as:

```python
reasoning_agent.print_response(
    "A startup has $500,000 in funding and needs to decide between spending it on marketing or "
    "product development. They want to maximize growth and user acquisition within 12 months. "
    "What factors should they consider and how should they analyze this decision?",
    stream=True
)
```

or,

```python
reasoning_agent.print_response(
    "Solve this logic puzzle: A man has to take a fox, a chicken, and a sack of grain across a river. "
    "The boat is only big enough for the man and one item. If left unattended together, the fox will "
    "eat the chicken, and the chicken will eat the grain. How can the man get everything across safely?",
    stream=True,
)
```


# Workflow Tools
Source: https://docs.agno.com/concepts/tools/reasoning_tools/workflow-tools



The `WorkflowTools` toolkit enables Agents to execute, analyze, and reason about workflow operations. This toolkit integrates with `Workflow` and provides a structured approach for running workflows and evaluating their results.

The toolkit implements a "Think ‚Üí Run ‚Üí Analyze" cycle that allows an Agent to:

1. Think through the problem and plan workflow inputs and execution strategy
2. Execute the workflow with appropriate inputs and parameters
3. Analyze the results to determine if they are sufficient or if additional workflow runs are needed

This approach significantly improves an Agent's ability to successfully execute complex workflows by giving it tools to plan, execute, and evaluate workflow operations.

The toolkit includes the following tools:

* `think`: A scratchpad for planning workflow execution, brainstorming inputs, and refining approaches. These thoughts remain internal to the Agent and are not shown to users.
* `run_workflow`: Executes the workflow with specified inputs and additional parameters.
* `analyze`: Evaluates whether the workflow execution results are correct and sufficient, determining if further workflow runs are needed.

<Tip>
  Reasoning is not enabled by default on this toolkit. You can enable it by setting `enable_think=True` and `enable_analyze=True`.
</Tip>

## Example

Here's an example of how to use the `WorkflowTools` toolkit:

```python
import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.tools.workflow import WorkflowTools
from agno.workflow.types import StepInput, StepOutput
from agno.workflow.workflow import Workflow

FEW_SHOT_EXAMPLES = dedent("""\
    You can refer to the examples below as guidance for how to use each tool.
    ### Examples
    #### Example: Blog Post Workflow
    User: Please create a blog post on the topic: AI Trends in 2024
    Run: input_data="AI trends in 2024", additional_data={"topic": "AI, AI agents, AI workflows", "style": "The blog post should be written in a style that is easy to understand and follow."}
    Final Answer: I've created a blog post on the topic: AI trends in 2024 through the workflow. The blog post shows...
    
    You HAVE TO USE additional_data to pass the topic and style to the workflow.
""")


# Define agents
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)

writer_agent = Agent(
    name="Writer Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    instructions="Write a blog post on the topic",
)


def prepare_input_for_web_search(step_input: StepInput) -> StepOutput:
    title = step_input.input
    topic = step_input.additional_data.get("topic")
    return StepOutput(
        content=dedent(f"""\
	I'm writing a blog post with the title: {title}
	<topic>
	{topic}
	</topic>
	Search the web for atleast 10 articles\
	""")
    )


def prepare_input_for_writer(step_input: StepInput) -> StepOutput:
    title = step_input.additional_data.get("title")
    topic = step_input.additional_data.get("topic")
    style = step_input.additional_data.get("style")

    research_team_output = step_input.previous_step_content

    return StepOutput(
        content=dedent(f"""\
	I'm writing a blog post with the title: {title}
	<required_style>
	{style}
	</required_style>
	<topic>
	{topic}
	</topic>
	Here is information from the web:
	<research_results>
	{research_team_output}
	<research_results>\
	""")
    )


# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)


content_creation_workflow = Workflow(
    name="Blog Post Workflow",
    description="Automated blog post creation from Hackernews and the web",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflow.db",
    ),
    steps=[
        prepare_input_for_web_search,
        research_team,
        prepare_input_for_writer,
        writer_agent,
    ],
)

workflow_tools = WorkflowTools(
    workflow=content_creation_workflow,
    add_few_shot=True,
    few_shot_examples=FEW_SHOT_EXAMPLES,
    async_mode=True,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[workflow_tools],
    markdown=True,
)

asyncio.run(agent.aprint_response(
    "Create a blog post with the following title: Quantum Computing in 2025",
    instructions="When you run the workflow using the `run_workflow` tool, remember to pass `additional_data` as a dictionary of key-value pairs.",
    stream=True,
    debug_mode=True,
))
```

Here is how you can configure the toolkit:

```python
from agno.tools.workflow import WorkflowTools

workflow_tools = WorkflowTools(
    workflow=my_workflow,
    enable_think=True,            # Enable the think tool
    enable_run_workflow=True,     # Enable the run_workflow tool (true by default)
    enable_analyze=True,          # Enable the analyze tool
    add_instructions=True,        # Add default instructions
    instructions=None,            # Optional custom instructions
    add_few_shot=True,           # Add few-shot examples
    few_shot_examples=None,      # Optional custom few-shot examples
    async_mode=False,            # Set to True for async workflow execution
)
```

## Async Support

The `WorkflowTools` toolkit supports both synchronous and asynchronous workflow execution:

```python
# For async workflow execution
workflow_tools = WorkflowTools(
    workflow=my_async_workflow,
    async_mode=True,  # This will use async versions of the tools
    enable_run_workflow=True,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[workflow_tools],
)

await agent.arun(...)
```


# Including and excluding tools
Source: https://docs.agno.com/concepts/tools/selecting-tools

Learn how to include and exclude tools from a Toolkit.

You can specify which tools to include or exclude from a `Toolkit` by using the `include_tools` and `exclude_tools` parameters. This can be very useful to limit the number of tools that are available to an Agent.

For example, here's how to include only the `get_latest_emails` tool in the `GmailTools` toolkit:

```python
agent = Agent(
    tools=[GmailTools(include_tools=["get_latest_emails"])],
)
```

Similarly, here's how to exclude the `create_draft_email` tool from the `GmailTools` toolkit:

```python
agent = Agent(
    tools=[GmailTools(exclude_tools=["create_draft_email"])],
)
```

## Example

Here's an example of how to use the `include_tools` and `exclude_tools` parameters to limit the number of tools that are available to an Agent:

```python include_exclude_tools.py

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        CalculatorTools(
            exclude_tools=["exponentiate", "factorial", "is_prime", "square_root"],
        ),
        DuckDuckGoTools(include_tools=["duckduckgo_search"]),
    ],
    markdown=True,
)

agent.print_response(
    "Search the web for a difficult sum that can be done with normal arithmetic and solve it.",
)
```


# Tool Call Limit
Source: https://docs.agno.com/concepts/tools/tool-call-limit

Learn to limit the number of tool calls an agent can make.

Limiting the number of tool calls an Agent can make is useful to prevent loops and have better control over costs and performance.

Doing this is very simple with Agno. You just need to pass the `tool_call_limit` parameter when initializing your Agent or Team.

## Example

```python
from agno.agent import Agent
from agno.models.openai.chat import OpenAIChat
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools(company_news=True, cache_results=True)],
    tool_call_limit=1, # The Agent will not perform more than one tool call.
)

# The first tool call will be performed. The second one will fail gracefully.
agent.print_response(
    "Find me the current price of TSLA, then after that find me the latest news about Tesla.",
    stream=True,
)

```

## To consider

* If the Agent tries to run a number of tool calls that exceeds the limit **all at once**, the limit will remain effective. Only as many tool calls as allowed will be performed.
* The limit is enforced **across a full run**, and not per individual requests triggered by the Agent.


# CSV
Source: https://docs.agno.com/concepts/tools/toolkits/database/csv



**CsvTools** enable an Agent to read and write CSV files.

## Example

The following agent will download the IMDB csv file and allow the user to query it using a CLI app.

```python cookbook/tools/csv_tools.py
import httpx
from pathlib import Path
from agno.agent import Agent
from agno.tools.csv_toolkit import CsvTools

url = "https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv"
response = httpx.get(url)

imdb_csv = Path(__file__).parent.joinpath("wip").joinpath("imdb.csv")
imdb_csv.parent.mkdir(parents=True, exist_ok=True)
imdb_csv.write_bytes(response.content)

agent = Agent(
    tools=[CsvTools(csvs=[imdb_csv])],
    markdown=True,
    instructions=[
        "First always get the list of files",
        "Then check the columns in the file",
        "Then run the query to answer the question",
        "Always wrap column names with double quotes if they contain spaces or special characters",
        "Remember to escape the quotes in the JSON string (use \")",
        "Use single quotes for string values"
    ],
)

agent.cli_app(stream=False)
```

## Toolkit Params

| Parameter               | Type                     | Default | Description                                                            |
| ----------------------- | ------------------------ | ------- | ---------------------------------------------------------------------- |
| `csvs`                  | `List[Union[str, Path]]` | `None`  | A list of CSV files or paths to be processed or read.                  |
| `row_limit`             | `int`                    | `None`  | The maximum number of rows to process from each CSV file.              |
| `duckdb_connection`     | `Any`                    | `None`  | Specifies a connection instance for DuckDB database operations.        |
| `duckdb_kwargs`         | `Dict[str, Any]`         | `None`  | A dictionary of keyword arguments for configuring DuckDB operations.   |
| `enable_read_csv_file`  | `bool`                   | `True`  | Enables the functionality to read data from specified CSV files.       |
| `enable_list_csv_files` | `bool`                   | `True`  | Enables the functionality to list all available CSV files.             |
| `enable_get_columns`    | `bool`                   | `True`  | Enables the functionality to read the column names from CSV files.     |
| `enable_query_csv_file` | `bool`                   | `True`  | Enables the functionality to execute queries on data within CSV files. |
| `all`                   | `bool`                   | `False` | Enables all functionality when set to True.                            |

## Toolkit Functions

| Function         | Description                                      |
| ---------------- | ------------------------------------------------ |
| `list_csv_files` | Lists all available CSV files.                   |
| `read_csv_file`  | This function reads the contents of a csv file   |
| `get_columns`    | This function returns the columns of a csv file  |
| `query_csv_file` | This function queries the contents of a csv file |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/csv.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/csv_tools.py)


# DuckDb
Source: https://docs.agno.com/concepts/tools/toolkits/database/duckdb



**DuckDbTools** enable an Agent to run SQL and analyze data using DuckDb.

## Prerequisites

The following example requires DuckDB library. To install DuckDB, run the following command:

```shell
pip install duckdb
```

For more installation options, please refer to [DuckDB documentation](https://duckdb.org/docs/installation).

## Example

The following agent will analyze the movies file using SQL and return the result.

```python cookbook/tools/duckdb_tools.py
from agno.agent import Agent
from agno.tools.duckdb import DuckDbTools

agent = Agent(
    tools=[DuckDbTools()],
    system_message="Use this file for Movies data: https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
)

agent.print_response("What is the average rating of movies?", markdown=True, stream=False)
```

## Toolkit Params

| Parameter       | Type                 | Default | Description                                                   |
| --------------- | -------------------- | ------- | ------------------------------------------------------------- |
| `db_path`       | `str`                | `None`  | Specifies the path to the database file.                      |
| `connection`    | `DuckDBPyConnection` | `None`  | Provides an existing DuckDB connection object.                |
| `init_commands` | `List`               | `None`  | A list of initial SQL commands to run on database connection. |
| `read_only`     | `bool`               | `False` | Configures the database connection to be read-only.           |
| `config`        | `dict`               | `None`  | Configuration options for the database connection.            |

## Toolkit Functions

| Function                   | Description                                                                                                                                                                                                                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `show_tables`              | Function to show tables in the database                                                                                                                                                                                                        |
| `describe_table`           | Function to describe a table                                                                                                                                                                                                                   |
| `inspect_query`            | Function to inspect a query and return the query plan. Always inspect your query before running them.                                                                                                                                          |
| `run_query`                | Function that runs a query and returns the result.                                                                                                                                                                                             |
| `summarize_table`          | Function to compute a number of aggregates over a table. The function launches a query that computes a number of aggregates over all columns, including min, max, avg, std and approx\_unique.                                                 |
| `get_table_name_from_path` | Get the table name from a path                                                                                                                                                                                                                 |
| `create_table_from_path`   | Creates a table from a path                                                                                                                                                                                                                    |
| `export_table_to_path`     | Save a table in a desired format (default: parquet). If the path is provided, the table will be saved under that path. Eg: If path is /tmp, the table will be saved as /tmp/table.parquet. Otherwise it will be saved in the current directory |
| `load_local_path_to_table` | Load a local file into duckdb                                                                                                                                                                                                                  |
| `load_local_csv_to_table`  | Load a local CSV file into duckdb                                                                                                                                                                                                              |
| `load_s3_path_to_table`    | Load a file from S3 into duckdb                                                                                                                                                                                                                |
| `load_s3_csv_to_table`     | Load a CSV file from S3 into duckdb                                                                                                                                                                                                            |
| `create_fts_index`         | Create a full text search index on a table                                                                                                                                                                                                     |
| `full_text_search`         | Full text Search in a table column for a specific text/keyword                                                                                                                                                                                 |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/duckdb.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/duckdb_tools.py)


# Google BigQuery
Source: https://docs.agno.com/concepts/tools/toolkits/database/google_bigquery

GoogleBigQueryTools enables agents to interact with Google BigQuery for large-scale data analysis and SQL queries.

## Example

The following agent can query and analyze BigQuery datasets:

```python
from agno.agent import Agent
from agno.tools.google_bigquery import GoogleBigQueryTools

agent = Agent(
    instructions=[
        "You are a data analyst assistant that helps with BigQuery operations",
        "Execute SQL queries to analyze large datasets",
        "Provide insights and summaries of query results",
        "Help with data exploration and table analysis",
    ],
    tools=[GoogleBigQueryTools(dataset="your_dataset_name")],
)

agent.print_response("List all tables in the dataset and describe the sales table", stream=True)
```

## Toolkit Params

| Parameter               | Type            | Default | Description                                           |
| ----------------------- | --------------- | ------- | ----------------------------------------------------- |
| `dataset`               | `str`           | `None`  | BigQuery dataset name (required).                     |
| `project`               | `Optional[str]` | `None`  | Google Cloud project ID. Uses GOOGLE\_CLOUD\_PROJECT. |
| `location`              | `Optional[str]` | `None`  | BigQuery location. Uses GOOGLE\_CLOUD\_LOCATION.      |
| `credentials`           | `Optional[Any]` | `None`  | Google Cloud credentials object.                      |
| `enable_list_tables`    | `bool`          | `True`  | Enable table listing functionality.                   |
| `enable_describe_table` | `bool`          | `True`  | Enable table description functionality.               |
| `enable_run_sql_query`  | `bool`          | `True`  | Enable SQL query execution functionality.             |

## Toolkit Functions

| Function         | Description                                             |
| ---------------- | ------------------------------------------------------- |
| `list_tables`    | List all tables in the specified BigQuery dataset.      |
| `describe_table` | Get detailed schema information about a specific table. |
| `run_sql_query`  | Execute SQL queries on BigQuery datasets.               |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/google_bigquery.py)
* [BigQuery Documentation](https://cloud.google.com/bigquery/docs)
* [BigQuery SQL Reference](https://cloud.google.com/bigquery/docs/reference/standard-sql/)


# Neo4j
Source: https://docs.agno.com/concepts/tools/toolkits/database/neo4j



**Neo4jTools** enables agents to interact with Neo4j graph databases for querying and managing graph data.

## Prerequisites

The following example requires the `neo4j` library.

```shell
pip install -U neo4j
```

You will also need a Neo4j database. The following example uses a Neo4j database running in a Docker container.

```shell
docker run -d -p 7474:7474 -p 7687:7687 --name neo4j -e NEO4J_AUTH=neo4j/password neo4j
```

Make sure to set the `NEO4J_URI` environment variable to the URI of the Neo4j database.

```shell
    export NEO4J_URI=bolt://localhost:7687
    export NEO4J_USERNAME=neo4j
    export NEO4J_PASSWORD=your-password
    export OPENAI_API_KEY=xxx
```

Install libraries

```shell
pip install -U neo4j openai agno
```

Run the agent

```shell
python cookbook/tools/neo4j_tools.py
```

## Example

The following agent can interact with Neo4j graph databases:

```python
from agno.agent import Agent
from agno.tools.neo4j import Neo4jTools

agent = Agent(
    instructions=[
        "You are a graph database assistant that helps with Neo4j operations",
        "Execute Cypher queries to analyze graph data and relationships",
        "Provide insights about graph structure and patterns",
        "Help with graph data modeling and optimization",
    ],
    tools=[Neo4jTools()],
)

agent.print_response("Show me the schema of the graph database", stream=True)
```

## Toolkit Params

| Parameter                   | Type            | Default | Description                                       |
| --------------------------- | --------------- | ------- | ------------------------------------------------- |
| `uri`                       | `Optional[str]` | `None`  | Neo4j connection URI. Uses NEO4J\_URI if not set. |
| `user`                      | `Optional[str]` | `None`  | Neo4j username. Uses NEO4J\_USERNAME if not set.  |
| `password`                  | `Optional[str]` | `None`  | Neo4j password. Uses NEO4J\_PASSWORD if not set.  |
| `database`                  | `Optional[str]` | `None`  | Specific database name to connect to.             |
| `enable_list_labels`        | `bool`          | `True`  | Enable listing node labels.                       |
| `enable_list_relationships` | `bool`          | `True`  | Enable listing relationship types.                |
| `enable_get_schema`         | `bool`          | `True`  | Enable schema information retrieval.              |
| `enable_run_cypher`         | `bool`          | `True`  | Enable Cypher query execution.                    |

## Toolkit Functions

| Function             | Description                                           |
| -------------------- | ----------------------------------------------------- |
| `list_labels`        | List all node labels in the graph database.           |
| `list_relationships` | List all relationship types in the graph database.    |
| `get_schema`         | Get comprehensive schema information about the graph. |
| `run_cypher`         | Execute Cypher queries on the graph database.         |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/neo4j.py)
* [Neo4j Documentation](https://neo4j.com/docs/)
* [Cypher Query Language](https://neo4j.com/docs/cypher-manual/current/)


# Pandas
Source: https://docs.agno.com/concepts/tools/toolkits/database/pandas



**PandasTools** enable an Agent to perform data manipulation tasks using the Pandas library.

```python cookbook/tools/pandas_tool.py
from agno.agent import Agent
from agno.tools.pandas import PandasTools

# Create an agent with PandasTools
agent = Agent(tools=[PandasTools()])

# Example: Create a dataframe with sample data and get the first 5 rows
agent.print_response("""
Please perform these tasks:
1. Create a pandas dataframe named 'sales_data' using DataFrame() with this sample data:
   {'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],
    'product': ['Widget A', 'Widget B', 'Widget A', 'Widget C', 'Widget B'],
    'quantity': [10, 15, 8, 12, 20],
    'price': [9.99, 15.99, 9.99, 12.99, 15.99]}
2. Show me the first 5 rows of the sales_data dataframe
""")
```

## Toolkit Params

| Parameter                        | Type   | Default | Description                                        |
| -------------------------------- | ------ | ------- | -------------------------------------------------- |
| `enable_create_pandas_dataframe` | `bool` | `True`  | Enables functionality to create pandas DataFrames. |
| `enable_run_dataframe_operation` | `bool` | `True`  | Enables functionality to run DataFrame operations. |
| `all`                            | `bool` | `False` | Enables all functionality when set to True.        |

## Toolkit Functions

| Function                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| ------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `create_pandas_dataframe` | Creates a Pandas DataFrame named `dataframe_name` by using the specified function `create_using_function` with parameters `function_parameters`. Parameters include 'dataframe\_name' for the name of the DataFrame, 'create\_using\_function' for the function to create it (e.g., 'read\_csv'), and 'function\_parameters' for the arguments required by the function. Returns the name of the created DataFrame if successful, otherwise returns an error message. |
| `run_dataframe_operation` | Runs a specified operation `operation` on a DataFrame `dataframe_name` with the parameters `operation_parameters`. Parameters include 'dataframe\_name' for the DataFrame to operate on, 'operation' for the operation to perform (e.g., 'head', 'tail'), and 'operation\_parameters' for the arguments required by the operation. Returns the result of the operation if successful, otherwise returns an error message.                                             |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/pandas.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/pandas_tools.py)


# Postgres
Source: https://docs.agno.com/concepts/tools/toolkits/database/postgres



**PostgresTools** enable an Agent to interact with a PostgreSQL database.

## Prerequisites

The following example requires the `psycopg2` library.

```shell
pip install -U psycopg2
```

You will also need a database. The following example uses a Postgres database running in a Docker container.

```shell
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

## Example

The following agent will list all tables in the database.

```python cookbook/tools/postgres.py
from agno.agent import Agent
from agno.tools.postgres import PostgresTools

# Initialize PostgresTools with connection details
postgres_tools = PostgresTools(
    host="localhost",
    port=5532,
    db_name="ai",
    user="ai",
    password="ai"
)

# Create an agent with the PostgresTools
agent = Agent(tools=[postgres_tools])

# Example: Ask the agent to run a SQL query
agent.print_response("""
Please run a SQL query to get all users from the users table
who signed up in the last 30 days
""")
```

## Toolkit Params

| Name           | Type                              | Default  | Description                                    |
| -------------- | --------------------------------- | -------- | ---------------------------------------------- |
| `connection`   | `Optional[PgConnection[DictRow]]` | `None`   | Optional existing psycopg connection object.   |
| `db_name`      | `Optional[str]`                   | `None`   | Optional name of the database to connect to.   |
| `user`         | `Optional[str]`                   | `None`   | Optional username for database authentication. |
| `password`     | `Optional[str]`                   | `None`   | Optional password for database authentication. |
| `host`         | `Optional[str]`                   | `None`   | Optional host for the database connection.     |
| `port`         | `Optional[int]`                   | `None`   | Optional port for the database connection.     |
| `table_schema` | `str`                             | `public` | Schema name to search for tables.              |

## Toolkit Functions

| Function               | Description                                                                                                                                                                                                                                                                            |
| ---------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `show_tables`          | Retrieves and displays a list of tables in the database. Returns the list of tables.                                                                                                                                                                                                   |
| `describe_table`       | Describes the structure of a specified table by returning its columns, data types, and nullability. Parameters include `table` (str) to specify the table name. Returns the table description.                                                                                         |
| `summarize_table`      | Summarizes a table by computing aggregates such as min, max, average, standard deviation, and non-null counts for numeric columns, or unique values and average length for text columns. Parameters include `table` (str) to specify the table name. Returns the summary of the table. |
| `inspect_query`        | Inspects an SQL query by returning the query plan using EXPLAIN. Parameters include `query` (str) to specify the SQL query. Returns the query plan.                                                                                                                                    |
| `export_table_to_path` | Exports a specified table in CSV format to a given path. Parameters include `table` (str) to specify the table name and `path` (str) to specify where to save the file. Returns the result of the export operation.                                                                    |
| `run_query`            | Executes a read-only SQL query and returns the result. Parameters include `query` (str) to specify the SQL query. Returns the result of the query execution.                                                                                                                           |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/postgres.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/postgres_tools.py)


# SQL
Source: https://docs.agno.com/concepts/tools/toolkits/database/sql



**SQLTools** enable an Agent to run SQL queries and interact with databases.

## Prerequisites

The following example requires the `sqlalchemy` library and a database URL.

```shell
pip install -U sqlalchemy
```

You will also need to install the appropriate Python adapter for the specific database you intend to use.

### PostgreSQL

For PostgreSQL, you can install the `psycopg2-binary` adapter:

```shell
pip install -U psycopg2-binary
```

### MySQL

For MySQL, you can install the `mysqlclient` adapter:

```shell
pip install -U mysqlclient
```

The `mysqlclient` adapter may have additional system-level dependencies. Please consult the [official installation guide](https://github.com/PyMySQL/mysqlclient/blob/main/README.md#install) for more details.

You will also need a database. The following example uses a Postgres database running in a Docker container.

```shell
 docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

## Example

The following agent will run a SQL query to list all tables in the database and describe the contents of one of the tables.

```python cookbook/tools/sql_tools.py
from agno.agent import Agent
from agno.tools.sql import SQLTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(tools=[SQLTools(db_url=db_url)])
agent.print_response("List the tables in the database. Tell me about contents of one of the tables", markdown=True)
```

## Toolkit Params

| Parameter               | Type             | Default | Description                                                                 |
| ----------------------- | ---------------- | ------- | --------------------------------------------------------------------------- |
| `db_url`                | `str`            | `None`  | The URL for connecting to the database.                                     |
| `db_engine`             | `Engine`         | `None`  | The database engine used for connections and operations.                    |
| `user`                  | `str`            | `None`  | The username for database authentication.                                   |
| `password`              | `str`            | `None`  | The password for database authentication.                                   |
| `host`                  | `str`            | `None`  | The hostname or IP address of the database server.                          |
| `port`                  | `int`            | `None`  | The port number on which the database server is listening.                  |
| `schema`                | `str`            | `None`  | The specific schema within the database to use.                             |
| `dialect`               | `str`            | `None`  | The SQL dialect used by the database.                                       |
| `tables`                | `Dict[str, Any]` | `None`  | A dictionary mapping table names to their respective metadata or structure. |
| `enable_list_tables`    | `bool`           | `True`  | Enables the functionality to list all tables in the database.               |
| `enable_describe_table` | `bool`           | `True`  | Enables the functionality to describe the schema of a specific table.       |
| `enable_run_sql_query`  | `bool`           | `True`  | Enables the functionality to execute SQL queries directly.                  |
| `all`                   | `bool`           | `False` | Enables all functionality when set to True.                                 |

## Toolkit Functions

| Function         | Description                               |
| ---------------- | ----------------------------------------- |
| `list_tables`    | Lists all tables in the database.         |
| `describe_table` | Describes the schema of a specific table. |
| `run_sql_query`  | Executes SQL queries directly.            |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/sql.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/sql_tools.py)


# Zep
Source: https://docs.agno.com/concepts/tools/toolkits/database/zep



**ZepTools** enable an Agent to interact with a Zep memory system, providing capabilities to store, retrieve, and search memory data associated with user sessions.

## Prerequisites

The ZepTools require the `zep-cloud` Python package and a Zep API key.

```shell
pip install zep-cloud
```

```shell
export ZEP_API_KEY=your_api_key
```

## Example

The following example demonstrates how to create an agent with access to Zep memory:

```python cookbook/tools/zep_tools.py
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.zep import ZepTools

# Initialize the ZepTools
zep_tools = ZepTools(user_id="agno", session_id="agno-session", add_instructions=True)

# Initialize the Agent
agent = Agent(
    model=OpenAIChat(),
    tools=[zep_tools],
    dependencies={"memory": zep_tools.get_zep_memory(memory_type="context")},
    add_dependencies_to_context=True,
)

# Interact with the Agent so that it can learn about the user
agent.print_response("My name is John Billings")
agent.print_response("I live in NYC")
agent.print_response("I'm going to a concert tomorrow")

# Allow the memories to sync with Zep database
time.sleep(10)

# Refresh the context
agent.context["memory"] = zep_tools.get_zep_memory(memory_type="context")

# Ask the Agent about the user
agent.print_response("What do you know about me?")
```

## Toolkit Params

| Parameter                   | Type   | Default | Description                                                 |
| --------------------------- | ------ | ------- | ----------------------------------------------------------- |
| `session_id`                | `str`  | `None`  | Optional session ID. Auto-generated if not provided.        |
| `user_id`                   | `str`  | `None`  | Optional user ID. Auto-generated if not provided.           |
| `api_key`                   | `str`  | `None`  | Zep API key. If not provided, uses ZEP\_API\_KEY env var.   |
| `ignore_assistant_messages` | `bool` | `False` | Whether to ignore assistant messages when adding to memory. |
| `enable_add_zep_message`    | `bool` | `True`  | Add a message to the current Zep session memory.            |
| `enable_get_zep_memory`     | `bool` | `True`  | Retrieve memory for the current Zep session.                |
| `enable_search_zep_memory`  | `bool` | `True`  | Search the Zep memory store for relevant information.       |
| `instructions`              | `str`  | `None`  | Custom instructions for using the Zep tools.                |
| `add_instructions`          | `bool` | `False` | Whether to add default instructions.                        |

## Toolkit Functions

| Function            | Description                                                                                                                                                                                                                                |
| ------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `add_zep_message`   | Adds a message to the current Zep session memory. Takes `role` (str) for the message sender and `content` (str) for the message text. Returns a confirmation or error message.                                                             |
| `get_zep_memory`    | Retrieves memory for the current Zep session. Takes optional `memory_type` (str) parameter with options "context" (default), "summary", or "messages". Returns the requested memory content or an error.                                   |
| `search_zep_memory` | Searches the Zep memory store for relevant information. Takes `query` (str) to find relevant facts and optional `search_scope` (str) parameter with options "messages" (default) or "summary". Returns search results or an error message. |

## Async Toolkit

The `ZepAsyncTools` class extends the `ZepTools` class and provides asynchronous versions of the toolkit functions.

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/zep.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/zep_tools.py)
* View [Async Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/zep_async_tools.py)


# File Generation
Source: https://docs.agno.com/concepts/tools/toolkits/file-generation/file-generation



**FileGenerationTools** enable an Agent or Team to generate files in multiple formats.

<Tip>
  Supported file types:

  * JSON
  * CSV
  * PDF
  * TXT
</Tip>

## Prerequisites

1. **Install the libraries:**
   ```bash
   pip install reportlab openai
   ```

2. **Set your credentials:**
   For OpenAI API:
   ```bash
   export OPENAI_API_KEY="your-openai-api-key"
   ```

## Example

The following agent will generate files in different formats based on user requests.

```python cookbook/tools/file_generation_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.file_generation import FileGenerationTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    db=SqliteDb(db_file="tmp/test.db"),
    tools=[FileGenerationTools(output_directory="tmp")],  
    description="You are a helpful assistant that can generate files in various formats.",
    instructions=[
        "When asked to create files, use the appropriate file generation tools.",
        "Always provide meaningful content and appropriate filenames.",
        "Explain what you've created and how it can be used.",
    ],
    markdown=True,
)

response =agent.run(
        "Create a PDF report about renewable energy trends in 2024. Include sections on solar, wind, and hydroelectric power."
    )
print(response.content)
    if response.files:
        for file in response.files:
            print(f"Generated file: {file.filename} ({file.size} bytes)")
            if file.url:
                print(f"File location: {file.url}")
    print()
```

<Note>
  You can use the `output_directory` parameter to specify a custom output directory for the generated files.
  If not specified, the files will be available in the `RunOutput` object.
</Note>

## Toolkit Params

| Parameter                | Type   | Default | Description                                      |
| ------------------------ | ------ | ------- | ------------------------------------------------ |
| `enable_json_generation` | `bool` | `True`  | Enables JSON file generation                     |
| `enable_csv_generation`  | `bool` | `True`  | Enables CSV file generation                      |
| `enable_pdf_generation`  | `bool` | `True`  | Enables PDF file generation (requires reportlab) |
| `enable_txt_generation`  | `bool` | `True`  | Enables text file generation                     |
| `output_directory`       | `str`  | `None`  | Custom output directory path                     |
| `all`                    | `bool` | `False` | Enables all file generation types when True      |

## Toolkit Functions

| Name                 | Description                                                  |
| -------------------- | ------------------------------------------------------------ |
| `generate_json_file` | Generates a JSON file from data (dict, list, or JSON string) |
| `generate_csv_file`  | Generates a CSV file from tabular data                       |
| `generate_pdf_file`  | Generates a PDF document from text content                   |
| `generate_text_file` | Generates a plain text file from string content              |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/file_generation.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/file_generation_tools.py)


# Calculator
Source: https://docs.agno.com/concepts/tools/toolkits/local/calculator



**Calculator** enables an Agent to perform mathematical calculations.

## Example

The following agent will calculate the result of `10*5` and then raise it to the power of `2`:

```python cookbook/tools/calculator_tools.py
from agno.agent import Agent
from agno.tools.calculator import CalculatorTools

agent = Agent(
    tools=[
        CalculatorTools()
    ],
        markdown=True,
)

agent.print_response("What is 10*5 then to the power of 2, do it step by step")
```

## Toolkit Functions

| Function       | Description                                                                              |
| -------------- | ---------------------------------------------------------------------------------------- |
| `add`          | Adds two numbers and returns the result.                                                 |
| `subtract`     | Subtracts the second number from the first and returns the result.                       |
| `multiply`     | Multiplies two numbers and returns the result.                                           |
| `divide`       | Divides the first number by the second and returns the result. Handles division by zero. |
| `exponentiate` | Raises the first number to the power of the second number and returns the result.        |
| `factorial`    | Calculates the factorial of a number and returns the result. Handles negative numbers.   |
| `is_prime`     | Checks if a number is prime and returns the result.                                      |
| `square_root`  | Calculates the square root of a number and returns the result. Handles negative numbers. |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/calculator.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/calculator_tools.py)


# Docker
Source: https://docs.agno.com/concepts/tools/toolkits/local/docker



**DockerTools** enable an Agent to interact with Docker containers, images, volumes, and networks.

## Prerequisites

The Docker tools require the `docker` Python package. You'll also need Docker installed and running on your system.

```shell
pip install docker
```

## Example

The following example creates an agent that can manage Docker resources:

```python cookbook/tools/docker_tools.py
import sys
from agno.agent import Agent

try:
    from agno.tools.docker import DockerTools

    docker_tools = DockerTools(
        enable_container_management=True,
        enable_image_management=True,
        enable_volume_management=True,
        enable_network_management=True,
    )

    # Create an agent with Docker tools
    docker_agent = Agent(
        name="Docker Agent",
        instructions=[
            "You are a Docker management assistant that can perform various Docker operations.",
            "You can manage containers, images, volumes, and networks.",
        ],
        tools=[docker_tools],
                markdown=True,
    )

    # Example: List all running Docker containers
    docker_agent.print_response("List all running Docker containers", stream=True)

    # Example: Pull and run an NGINX container
    docker_agent.print_response("Pull the latest nginx image", stream=True)
    docker_agent.print_response("Run an nginx container named 'web-server' on port 8080", stream=True)

except ValueError as e:
    print(f"\n‚ùå Docker Tool Error: {e}")
    print("\nüîç Troubleshooting steps:")

    if sys.platform == "darwin":  # macOS
        print("1. Ensure Docker Desktop is running")
        print("2. Check Docker Desktop settings")
        print("3. Try running 'docker ps' in terminal to verify access")

    elif sys.platform == "linux":
        print("1. Check if Docker service is running:")
        print("   systemctl status docker")
        print("2. Make sure your user has permissions to access Docker:")
        print("   sudo usermod -aG docker $USER")

    elif sys.platform == "win32":
        print("1. Ensure Docker Desktop is running")
        print("2. Check Docker Desktop settings")
```

## Toolkit Params

| Parameter                     | Type   | Default | Description                                                      |
| ----------------------------- | ------ | ------- | ---------------------------------------------------------------- |
| `enable_container_management` | `bool` | `True`  | Enables container management functions (list, start, stop, etc.) |
| `enable_image_management`     | `bool` | `True`  | Enables image management functions (pull, build, etc.)           |
| `enable_volume_management`    | `bool` | `False` | Enables volume management functions                              |
| `enable_network_management`   | `bool` | `False` | Enables network management functions                             |

## Toolkit Functions

### Container Management

| Function             | Description                                     |
| -------------------- | ----------------------------------------------- |
| `list_containers`    | Lists all containers or only running containers |
| `start_container`    | Starts a stopped container                      |
| `stop_container`     | Stops a running container                       |
| `remove_container`   | Removes a container                             |
| `get_container_logs` | Retrieves logs from a container                 |
| `inspect_container`  | Gets detailed information about a container     |
| `run_container`      | Creates and starts a new container              |
| `exec_in_container`  | Executes a command inside a running container   |

### Image Management

| Function        | Description                              |
| --------------- | ---------------------------------------- |
| `list_images`   | Lists all images on the system           |
| `pull_image`    | Pulls an image from a registry           |
| `remove_image`  | Removes an image                         |
| `build_image`   | Builds an image from a Dockerfile        |
| `tag_image`     | Tags an image                            |
| `inspect_image` | Gets detailed information about an image |

### Volume Management

| Function         | Description                              |
| ---------------- | ---------------------------------------- |
| `list_volumes`   | Lists all volumes                        |
| `create_volume`  | Creates a new volume                     |
| `remove_volume`  | Removes a volume                         |
| `inspect_volume` | Gets detailed information about a volume |

### Network Management

| Function                            | Description                               |
| ----------------------------------- | ----------------------------------------- |
| `list_networks`                     | Lists all networks                        |
| `create_network`                    | Creates a new network                     |
| `remove_network`                    | Removes a network                         |
| `inspect_network`                   | Gets detailed information about a network |
| `connect_container_to_network`      | Connects a container to a network         |
| `disconnect_container_from_network` | Disconnects a container from a network    |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/docker.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/docker_tools.py)


# File
Source: https://docs.agno.com/concepts/tools/toolkits/local/file



**FileTools** enable an Agent to read and write files on the local file system.

## Example

The following agent will generate an answer and save it in a file.

```python cookbook/tools/file_tools.py
from agno.agent import Agent
from agno.tools.file import FileTools

agent = Agent(tools=[FileTools()])
agent.print_response("What is the most advanced LLM currently? Save the answer to a file.", markdown=True)
```

## Toolkit Params

| Parameter             | Type   | Default | Description                                           |
| --------------------- | ------ | ------- | ----------------------------------------------------- |
| `base_dir`            | `Path` | `None`  | Specifies the base directory path for file operations |
| `enable_save_file`    | `bool` | `True`  | Enables functionality to save files                   |
| `enable_read_file`    | `bool` | `True`  | Enables functionality to read files                   |
| `enable_list_files`   | `bool` | `True`  | Enables functionality to list files in directories    |
| `enable_search_files` | `bool` | `True`  | Enables functionality to search for files             |
| `all`                 | `bool` | `False` | Enables all functionality when set to True            |

## Toolkit Functions

| Name         | Description                                                                              |
| ------------ | ---------------------------------------------------------------------------------------- |
| `save_file`  | Saves the contents to a file called `file_name` and returns the file name if successful. |
| `read_file`  | Reads the contents of the file `file_name` and returns the contents if successful.       |
| `list_files` | Returns a list of files in the base directory                                            |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/file.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/file_tools.py)


# Local File System
Source: https://docs.agno.com/concepts/tools/toolkits/local/local_file_system

LocalFileSystemTools enables agents to write files to the local file system with automatic directory management.

## Example

The following agent can write content to local files:

```python
from agno.agent import Agent
from agno.tools.local_file_system import LocalFileSystemTools

agent = Agent(
    instructions=[
        "You are a file management assistant that helps save content to local files",
        "Create files with appropriate names and extensions",
        "Organize files in the specified directory structure",
        "Provide clear feedback about file operations",
    ],
    tools=[LocalFileSystemTools(target_directory="./output")],
)

agent.print_response("Save this meeting summary to a file: 'Discussed Q4 goals and budget allocation'", stream=True)
```

## Toolkit Params

| Parameter           | Type            | Default | Description                                                  |
| ------------------- | --------------- | ------- | ------------------------------------------------------------ |
| `target_directory`  | `Optional[str]` | `None`  | Default directory to write files to. Uses current directory. |
| `default_extension` | `str`           | `"txt"` | Default file extension to use if none specified.             |
| `enable_write_file` | `bool`          | `True`  | Enable file writing functionality.                           |

## Toolkit Functions

| Function     | Description                                              |
| ------------ | -------------------------------------------------------- |
| `write_file` | Write content to a local file with customizable options. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/local_file_system.py)
* [Python pathlib Documentation](https://docs.python.org/3/library/pathlib.html)
* [File I/O Best Practices](https://docs.python.org/3/tutorial/inputoutput.html)


# Python
Source: https://docs.agno.com/concepts/tools/toolkits/local/python



**PythonTools** enable an Agent to write and run python code.

## Example

The following agent will write a python script that creates the fibonacci series, save it to a file, run it and return the result.

```python cookbook/tools/python_tools.py
from agno.agent import Agent
from agno.tools.python import PythonTools

agent = Agent(tools=[PythonTools()])
agent.print_response("Write a python script for fibonacci series and display the result till the 10th number")
```

## Toolkit Params

| Parameter      | Type   | Default | Description                                                                                            |
| -------------- | ------ | ------- | ------------------------------------------------------------------------------------------------------ |
| `base_dir`     | `Path` | `None`  | Specifies the base directory for operations. Default is None, indicating the current working directory |
| `safe_globals` | `dict` | `None`  | Dictionary of global variables that are considered safe to use during execution                        |
| `safe_locals`  | `dict` | `None`  | Dictionary of local variables that are considered safe to use during execution                         |

## Toolkit Functions

| Function                          | Description                                                                                                                                                                                                                                                            |
| --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `save_to_file_and_run`            | This function saves Python code to a file called `file_name` and then runs it. If successful, returns the value of `variable_to_return` if provided otherwise returns a success message. If failed, returns an error message. Make sure the file\_name ends with `.py` |
| `run_python_file_return_variable` | This function runs code in a Python file. If successful, returns the value of `variable_to_return` if provided otherwise returns a success message. If failed, returns an error message.                                                                               |
| `read_file`                       | Reads the contents of the file `file_name` and returns the contents if successful.                                                                                                                                                                                     |
| `list_files`                      | Returns a list of files in the base directory                                                                                                                                                                                                                          |
| `run_python_code`                 | This function runs Python code in the current environment. If successful, returns the value of `variable_to_return` if provided otherwise returns a success message. If failed, returns an error message.                                                              |
| `pip_install_package`             | This function installs a package using pip in the current environment. If successful, returns a success message. If failed, returns an error message.                                                                                                                  |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/python.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/python_tools.py)


# Shell
Source: https://docs.agno.com/concepts/tools/toolkits/local/shell



**ShellTools** enable an Agent to interact with the shell to run commands.

## Example

The following agent will run a shell command and show contents of the current directory.

<Note>
  Mention your OS to the agent to make sure it runs the correct command.
</Note>

```python cookbook/tools/shell_tools.py
from agno.agent import Agent
from agno.tools.shell import ShellTools

agent = Agent(tools=[ShellTools()])
agent.print_response("Show me the contents of the current directory", markdown=True)
```

## Toolkit Params

| Parameter                  | Type   | Default | Description                                 |                                            |
| -------------------------- | ------ | ------- | ------------------------------------------- | ------------------------------------------ |
| `base_dir`                 | \`Path | str\`   | `None`                                      | Base directory for shell command execution |
| `enable_run_shell_command` | `bool` | `True`  | Enables functionality to run shell commands |                                            |
| `all`                      | `bool` | `False` | Enables all functionality when set to True  |                                            |

## Toolkit Functions

| Function            | Description                                           |
| ------------------- | ----------------------------------------------------- |
| `run_shell_command` | Runs a shell command and returns the output or error. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/shell.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/shell_tools.py)


# Sleep
Source: https://docs.agno.com/concepts/tools/toolkits/local/sleep



## Example

The following agent will use the `sleep` tool to pause execution for a given number of seconds.

```python cookbook/tools/sleep_tools.py
from agno.agent import Agent
from agno.tools.sleep import SleepTools

# Create an Agent with the Sleep tool
agent = Agent(tools=[SleepTools()], name="Sleep Agent")

# Example 1: Sleep for 2 seconds
agent.print_response("Sleep for 2 seconds")

# Example 2: Sleep for a longer duration
agent.print_response("Sleep for 5 seconds")
```

## Toolkit Params

| Parameter      | Type   | Default | Description                                |
| -------------- | ------ | ------- | ------------------------------------------ |
| `enable_sleep` | `bool` | `True`  | Enables sleep functionality                |
| `all`          | `bool` | `False` | Enables all functionality when set to True |

## Toolkit Functions

| Function | Description                                        |
| -------- | -------------------------------------------------- |
| `sleep`  | Pauses execution for a specified number of seconds |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/sleep.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/sleep_tools.py)


# Azure OpenAI
Source: https://docs.agno.com/concepts/tools/toolkits/models/azure_openai

AzureOpenAITools provides access to Azure OpenAI services including DALL-E image generation.

## Prerequisites

The following examples require the `requests` library:

```shell
pip install -U requests
```

Set the following environment variables:

```shell
export AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
export AZURE_OPENAI_API_VERSION="2023-12-01-preview"
export AZURE_OPENAI_IMAGE_DEPLOYMENT="your-dalle-deployment-name"
```

## Example

The following agent can generate images using Azure OpenAI's DALL-E:

```python
from agno.agent import Agent
from agno.tools.models.azure_openai import AzureOpenAITools

agent = Agent(
    instructions=[
        "You are an AI image generation assistant using Azure OpenAI",
        "Generate high-quality images based on user descriptions",
        "Provide detailed descriptions of the generated images",
    ],
    tools=[AzureOpenAITools()],
)

agent.print_response("Generate an image of a sunset over mountains", stream=True)
```

## Toolkit Params

| Parameter               | Type            | Default                | Description                                                     |
| ----------------------- | --------------- | ---------------------- | --------------------------------------------------------------- |
| `api_key`               | `Optional[str]` | `None`                 | Azure OpenAI API key. Uses AZURE\_OPENAI\_API\_KEY if not set.  |
| `azure_endpoint`        | `Optional[str]` | `None`                 | Azure OpenAI endpoint. Uses AZURE\_OPENAI\_ENDPOINT if not set. |
| `api_version`           | `Optional[str]` | `"2023-12-01-preview"` | Azure OpenAI API version.                                       |
| `image_deployment`      | `Optional[str]` | `None`                 | DALL-E deployment name. Uses AZURE\_OPENAI\_IMAGE\_DEPLOYMENT.  |
| `image_model`           | `str`           | `"dall-e-3"`           | DALL-E model to use (dall-e-2, dall-e-3).                       |
| `image_quality`         | `Literal`       | `"standard"`           | Image quality: "standard" or "hd" (hd only for dall-e-3).       |
| `enable_generate_image` | `bool`          | `True`                 | Enable the generate image functionality                         |
| `all`                   | `bool`          | `False`                | Enable all functionality when set to True                       |

## Toolkit Functions

| Function         | Description                                       |
| ---------------- | ------------------------------------------------- |
| `generate_image` | Generate images using Azure OpenAI DALL-E models. |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models/azure_openai.py)
* [Azure OpenAI Documentation](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/)


# Gemini
Source: https://docs.agno.com/concepts/tools/toolkits/models/gemini



`GeminiTools` are a set of tools that allow an Agent to interact with Google AI API services for generating images and videos.

## Prerequisites

Before using `GeminiTools`, make sure to have the `google-genai` library installed and the credentials configured.

1. **Install the library:**
   ```bash
   pip install google-genai agno
   ```

2. **Set your credentials:**
   * For Gemini API:
     ```bash
     export GOOGLE_API_KEY="your-google-genai-api-key"
     ```
   * For Vertex AI:
     ```bash
     export GOOGLE_CLOUD_PROJECT="your-google-cloud-project-id"
     export GOOGLE_CLOUD_LOCATION="your-google-cloud-location"
     export GOOGLE_GENAI_USE_VERTEXAI=true
     ```

## Initialization

Import `GeminiTools` and add it to your Agent's tool list.

```python
from agno.agent import Agent
from agno.tools.models.gemini import GeminiTools

agent = Agent(
    tools=[GeminiTools()],
    )
```

## Usage Examples

GeminiTools can be used for a variety of tasks. Here are some examples:

### Image Generation

```python image_generation_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.gemini import GeminiTools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GeminiTools()],
    )

response = agent.run("Create an artistic portrait of a cyberpunk samurai in a rainy city")
if response.images:
    save_base64_data(response.images[0].content, "tmp/cyberpunk_samurai.png")
```

### Video Generation

<Note>
  Video generation requires Vertex AI.
</Note>

```python video_generation_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.gemini import GeminiTools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GeminiTools(vertexai=True)],
        debug_mode=True,
)

agent.print_response(
    "Generate a 5-second video of a kitten playing a piano",
)
response = agent.run("Generate a 5-second video of a kitten playing a piano")
if response.videos:
    for video in response.videos:
        save_base64_data(video.content, f"tmp/kitten_piano_{video.id}.mp4")
```

## Toolkit Params

| Parameter                | Type            | Default                     | Description                                                                                     |
| ------------------------ | --------------- | --------------------------- | ----------------------------------------------------------------------------------------------- |
| `api_key`                | `Optional[str]` | `None`                      | Google API key for authentication. If not provided, uses GOOGLE\_API\_KEY environment variable. |
| `vertexai`               | `bool`          | `False`                     | Whether to use Vertex AI instead of standard Gemini API. Required for video generation.         |
| `project_id`             | `Optional[str]` | `None`                      | Google Cloud project ID. Required when using Vertex AI.                                         |
| `location`               | `Optional[str]` | `None`                      | Google Cloud location/region. Required when using Vertex AI.                                    |
| `image_generation_model` | `str`           | `"imagen-3.0-generate-002"` | Model to use for image generation.                                                              |
| `video_generation_model` | `str`           | `"veo-2.0-generate-001"`    | Model to use for video generation.                                                              |
| `enable_generate_image`  | `bool`          | `True`                      | Enable the image generation function.                                                           |
| `enable_generate_video`  | `bool`          | `True`                      | Enable the video generation function.                                                           |
| `all`                    | `bool`          | `False`                     | Enable all available functions. When True, all enable flags are ignored.                        |

## Toolkit Functions

| Function         | Description                              |
| ---------------- | ---------------------------------------- |
| `generate_image` | Generate an image based on a text prompt |
| `generate_video` | Generate a video based on a text prompt  |

## Developer Resources

* View [Toolkit](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models/gemini.py)
* View [Image Generation Guide](https://ai.google.dev/gemini-api/docs/image-generation)
* View [Video Generation Guide](https://ai.google.dev/gemini-api/docs/video)


# Groq
Source: https://docs.agno.com/concepts/tools/toolkits/models/groq



`GroqTools` allows an Agent to interact with the Groq API for performing fast audio transcription, translation, and text-to-speech (TTS).

## Prerequisites

Before using `GroqTools`, ensure you have the `groq` library installed and your Groq API key configured.

1. **Install the library:**
   ```bash
   pip install -U groq
   ```

2. **Set your API key:** Obtain your API key from the [Groq Console](https://console.groq.com/keys) and set it as an environment variable.

   <CodeGroup>
     ```bash Mac
     export GROQ_API_KEY="your-groq-api-key"
     ```

     ```bash Windows
     setx GROQ_API_KEY "your-groq-api-key"
     ```
   </CodeGroup>

## Initialization

Import `GroqTools` and add it to your Agent's tool list.

```python
from agno.agent import Agent
from agno.tools.models.groq import GroqTools

agent = Agent(
    instructions=[
        "You are a helpful assistant that can transcribe audio, translate text and generate speech."
    ],
    tools=[GroqTools()],
    )
```

## Usage Examples

### 1. Transcribing Audio

This example demonstrates how to transcribe an audio file hosted at a URL.

```python transcription_agent.py
import os
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.groq import GroqTools

audio_url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

agent = Agent(
    name="Groq Transcription Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GroqTools()],
    )

agent.print_response(f"Please transcribe the audio file located at '{audio_url}'")
```

### 2. Translating Audio and Generating Speech

This example shows how to translate an audio file (e.g., French) to English and then generate a new audio file from the translated text.

```python translation_agent.py
from pathlib import Path
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.groq import GroqTools
from agno.utils.media import save_base64_data

local_audio_path = "tmp/sample-fr.mp3"
output_path = Path("tmp/sample-en.mp3")
output_path.parent.mkdir(parents=True, exist_ok=True)

agent = Agent(
    name="Groq Translation Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GroqTools()],
    )

instruction = (
    f"Translate the audio file at '{local_audio_path}' to English. "
    f"Then, generate a new audio file using the translated English text."
)
response = agent.run(instruction)
if response and response.audio:
    save_base64_data(response.audio[0].base64_audio, output_path)
```

You can customize the underlying Groq models used for transcription, translation, and TTS during initialization:

```python
groq_tools = GroqTools(
    transcription_model="whisper-large-v3",
    translation_model="whisper-large-v3",
    tts_model="playai-tts",
    tts_voice="Chip-PlayAI"
)
```

## Toolkit Params

| Parameter                 | Type            | Default              | Description                                                                                 |
| ------------------------- | --------------- | -------------------- | ------------------------------------------------------------------------------------------- |
| `api_key`                 | `Optional[str]` | `None`               | Groq API key for authentication. If not provided, uses GROQ\_API\_KEY environment variable. |
| `transcription_model`     | `str`           | `"whisper-large-v3"` | Model to use for audio transcription.                                                       |
| `translation_model`       | `str`           | `"whisper-large-v3"` | Model to use for audio translation to English.                                              |
| `tts_model`               | `str`           | `"playai-tts"`       | Model to use for text-to-speech generation.                                                 |
| `tts_voice`               | `str`           | `"Chip-PlayAI"`      | Voice to use for text-to-speech generation.                                                 |
| `enable_transcribe_audio` | `bool`          | `True`               | Enable the audio transcription function.                                                    |
| `enable_translate_audio`  | `bool`          | `True`               | Enable the audio translation function.                                                      |
| `enable_generate_speech`  | `bool`          | `True`               | Enable the text-to-speech generation function.                                              |
| `all`                     | `bool`          | `False`              | Enable all available functions. When True, all enable flags are ignored.                    |

## Toolkit Functions

The `GroqTools` toolkit provides the following functions:

| Function           | Description                                                                  |
| ------------------ | ---------------------------------------------------------------------------- |
| `transcribe_audio` | Transcribes audio from a local file path or a public URL using Groq Whisper. |
| `translate_audio`  | Translates audio from a local file path or public URL to English using Groq. |
| `generate_speech`  | Generates speech from text using Groq TTS.                                   |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models/groq.py)
* View [Transcription Example](https://github.com/agno-agi/agno/tree/main/cookbook/models/groq/transcription_agent.py)
* View [Translation Example](https://github.com/agno-agi/agno/tree/main/cookbook/models/groq/translation_agent.py)


# Morph
Source: https://docs.agno.com/concepts/tools/toolkits/models/morph

MorphTools provides advanced code editing capabilities using Morph's Fast Apply API for intelligent code modifications.

## Example

The following agent can perform intelligent code editing using Morph:

```python
from agno.agent import Agent
from agno.tools.models.morph import MorphTools

agent = Agent(
    instructions=[
        "You are a code editing assistant using Morph's advanced AI capabilities",
        "Help users modify, improve, and refactor their code intelligently",
        "Apply code changes efficiently while maintaining code quality",
        "Provide explanations for the modifications made",
    ],
    tools=[MorphTools()],
)

agent.print_response("Refactor this Python function to be more efficient and add type hints", stream=True)
```

## Toolkit Params

| Parameter          | Type            | Default                         | Description                                     |
| ------------------ | --------------- | ------------------------------- | ----------------------------------------------- |
| `api_key`          | `Optional[str]` | `None`                          | Morph API key. Uses MORPH\_API\_KEY if not set. |
| `base_url`         | `str`           | `"https://api.morphllm.com/v1"` | Morph API base URL.                             |
| `model`            | `str`           | `"morph-v3-large"`              | Morph model to use for code editing.            |
| `instructions`     | `Optional[str]` | `None`                          | Custom instructions for code editing behavior.  |
| `add_instructions` | `bool`          | `True`                          | Whether to add instructions to the agent.       |

## Toolkit Functions

| Function    | Description                                                        |
| ----------- | ------------------------------------------------------------------ |
| `edit_file` | Apply intelligent code modifications using Morph's Fast Apply API. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models/morph.py)
* [Morph API Documentation](https://docs.morphllm.com/)
* [Fast Apply API Reference](https://api.morphllm.com/docs)


# Nebius
Source: https://docs.agno.com/concepts/tools/toolkits/models/nebius

NebiusTools provides access to Nebius AI Studio's text-to-image generation capabilities with advanced AI models.

## Example

The following agent can generate images using Nebius AI Studio:

```python
from agno.agent import Agent
from agno.tools.models.nebius import NebiusTools

agent = Agent(
    instructions=[
        "You are an AI image generation assistant using Nebius AI Studio",
        "Create high-quality images based on user descriptions",
        "Provide detailed information about the generated images",
        "Help users refine their prompts for better results",
    ],
    tools=[NebiusTools()],
)

agent.print_response("Generate an image of a futuristic city with flying cars at sunset", stream=True)
```

## Toolkit Params

| Parameter               | Type            | Default                              | Description                                       |
| ----------------------- | --------------- | ------------------------------------ | ------------------------------------------------- |
| `api_key`               | `Optional[str]` | `None`                               | Nebius API key. Uses NEBIUS\_API\_KEY if not set. |
| `base_url`              | `str`           | `"https://api.studio.nebius.com/v1"` | Nebius API base URL.                              |
| `image_model`           | `str`           | `"black-forest-labs/flux-schnell"`   | Default image generation model.                   |
| `image_quality`         | `Optional[str]` | `"standard"`                         | Image quality setting.                            |
| `image_size`            | `Optional[str]` | `"1024x1024"`                        | Default image dimensions.                         |
| `image_style`           | `Optional[str]` | `None`                               | Image style preference.                           |
| `enable_generate_image` | `bool`          | `True`                               | Enable image generation functionality.            |

## Toolkit Functions

| Function         | Description                                                    |
| ---------------- | -------------------------------------------------------------- |
| `generate_image` | Generate images from text descriptions using Nebius AI models. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models/nebius.py)
* [Nebius AI Studio Documentation](https://docs.nebius.com/)
* [Nebius API Reference](https://api.studio.nebius.com/docs)


# OpenAI
Source: https://docs.agno.com/concepts/tools/toolkits/models/openai



OpenAITools allow an Agent to interact with OpenAI models for performing audio transcription, image generation, and text-to-speech.

## Prerequisites

Before using `OpenAITools`, ensure you have the `openai` library installed and your OpenAI API key configured.

1. **Install the library:**
   ```bash
   pip install -U openai
   ```

2. **Set your API key:** Obtain your API key from [OpenAI](https://platform.openai.com/account/api-keys) and set it as an environment variable.

   <CodeGroup>
     ```bash Mac
     export OPENAI_API_KEY=xxx
     ```

     ```bash Windows
     setx OPENAI_API_KEY xxx
     ```
   </CodeGroup>

## Initialization

Import `OpenAITools` and add it to your Agent's tool list.

```python
from agno.agent import Agent
from agno.tools.openai import OpenAITools

agent = Agent(
    name="OpenAI Agent",
    tools=[OpenAITools()],
        markdown=True,
)
```

## Usage Examples

### 1. Transcribing Audio

This example demonstrates an agent that transcribes an audio file.

```python transcription_agent.py
from pathlib import Path
from agno.agent import Agent
from agno.tools.openai import OpenAITools
from agno.utils.media import download_file

audio_url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

local_audio_path = Path("tmp/sample_conversation.wav")
download_file(audio_url, local_audio_path)

agent = Agent(
    name="OpenAI Transcription Agent",
    tools=[OpenAITools(transcription_model="whisper-1")],
        markdown=True,
)

agent.print_response(f"Transcribe the audio file located at '{local_audio_path}'")
```

### 2. Generating Images

This example demonstrates an agent that generates an image based on a text prompt.

```python image_generation_agent.py
from agno.agent import Agent
from agno.tools.openai import OpenAITools
from agno.utils.media import save_base64_data

agent = Agent(
    name="OpenAI Image Generation Agent",
    tools=[OpenAITools(image_model="dall-e-3")],
        markdown=True,
)

response = agent.run("Generate a photorealistic image of a cozy coffee shop interior")

if response.images:
    save_base64_data(response.images[0].content, "tmp/coffee_shop.png")
```

### 3. Generating Speech

This example demonstrates an agent that generates speech from text.

```python speech_synthesis_agent.py
from agno.agent import Agent
from agno.tools.openai import OpenAITools
from agno.utils.media import save_base64_data

agent = Agent(
    name="OpenAI Speech Agent",
    tools=[OpenAITools(
        text_to_speech_model="tts-1",
        text_to_speech_voice="alloy",
        text_to_speech_format="mp3"
    )],
    markdown=True,
)

response = agent.run("Generate audio for the text: 'Hello, this is a synthesized voice example.'")
if response and response.audio:
    save_base64_data(response.audio[0].base64_audio, "tmp/hello.mp3")
```

<Note> View more examples [here](/examples/concepts/tools/models/openai). </Note>

## Customization

You can customize the underlying OpenAI models used for transcription, image generation, and TTS:

```python
OpenAITools(
    transcription_model="whisper-1",
    image_model="dall-e-3",
    text_to_speech_model="tts-1-hd",
    text_to_speech_voice="nova",
    text_to_speech_format="wav"
)
```

## Toolkit Params

| Parameter                  | Type   | Default     | Description                                                               |
| -------------------------- | ------ | ----------- | ------------------------------------------------------------------------- |
| `api_key`                  | `str`  | `None`      | OpenAI API key. Uses OPENAI\_API\_KEY env var if not provided             |
| `enable_transcription`     | `bool` | `True`      | Enable audio transcription functionality                                  |
| `enable_image_generation`  | `bool` | `True`      | Enable image generation functionality                                     |
| `enable_speech_generation` | `bool` | `True`      | Enable speech generation functionality                                    |
| `all`                      | `bool` | `False`     | Enable all tools when set to True                                         |
| `transcription_model`      | `str`  | `whisper-1` | Model to use for audio transcription                                      |
| `text_to_speech_voice`     | `str`  | `alloy`     | Voice to use for text-to-speech (alloy, echo, fable, onyx, nova, shimmer) |
| `text_to_speech_model`     | `str`  | `tts-1`     | Model to use for text-to-speech (tts-1, tts-1-hd)                         |
| `text_to_speech_format`    | `str`  | `mp3`       | Audio format for TTS output (mp3, opus, aac, flac, wav, pcm)              |
| `image_model`              | `str`  | `dall-e-3`  | Model to use for image generation                                         |
| `image_quality`            | `str`  | `None`      | Quality setting for image generation                                      |
| `image_size`               | `str`  | `None`      | Size setting for image generation                                         |
| `image_style`              | `str`  | `None`      | Style setting for image generation (vivid, natural)                       |

## Toolkit Functions

The `OpenAITools` toolkit provides the following functions:

| Function           | Description                                              |
| ------------------ | -------------------------------------------------------- |
| `transcribe_audio` | Transcribes audio from a local file path or a public URL |
| `generate_image`   | Generates images based on a text prompt                  |
| `generate_speech`  | Synthesizes speech from text                             |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/openai.py)
* View [OpenAI Transcription Guide](https://platform.openai.com/docs/guides/speech-to-text)
* View [OpenAI Image Generation Guide](https://platform.openai.com/docs/guides/image-generation?image-generation-model=gpt-image-1)
* View [OpenAI Text-to-Speech Guide](https://platform.openai.com/docs/guides/text-to-speech)


# Airflow
Source: https://docs.agno.com/concepts/tools/toolkits/others/airflow



## Example

The following agent will use Airflow to save and read a DAG file.

```python cookbook/tools/airflow_tools.py
from agno.agent import Agent
from agno.tools.airflow import AirflowTools

agent = Agent(
    tools=[AirflowTools(dags_dir="dags", save_dag=True, read_dag=True)], markdown=True
)

dag_content = """
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}
# Using 'schedule' instead of deprecated 'schedule_interval'
with DAG(
    'example_dag',
    default_args=default_args,
    description='A simple example DAG',
    schedule='@daily',  # Changed from schedule_interval
    catchup=False
) as dag:
    def print_hello():
        print("Hello from Airflow!")
        return "Hello task completed"
    task = PythonOperator(
        task_id='hello_task',
        python_callable=print_hello,
        dag=dag,
    )
"""

agent.run(f"Save this DAG file as 'example_dag.py': {dag_content}")

agent.print_response("Read the contents of 'example_dag.py'")
```

## Toolkit Params

| Parameter              | Type            | Default | Description                                     |
| ---------------------- | --------------- | ------- | ----------------------------------------------- |
| `dags_dir`             | `Path` or `str` | `None`  | Directory for DAG files                         |
| `enable_save_dag_file` | `bool`          | `True`  | Enables functionality to save Airflow DAG files |
| `enable_read_dag_file` | `bool`          | `True`  | Enables functionality to read Airflow DAG files |
| `all`                  | `bool`          | `False` | Enables all functionality when set to True      |

## Toolkit Functions

| Function        | Description                                        |
| --------------- | -------------------------------------------------- |
| `save_dag_file` | Saves python code for an Airflow DAG to a file     |
| `read_dag_file` | Reads an Airflow DAG file and returns the contents |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/airflow.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/airflow_tools.py)


# Apify
Source: https://docs.agno.com/concepts/tools/toolkits/others/apify



This guide demonstrates how to integrate and use [Apify](https://apify.com/actors) Actors within the Agno framework to enhance your AI agents with web scraping, crawling, data extraction, and web automation capabilities.

## What is Apify?

[Apify](https://apify.com/) is a platform that provides:

* Data collection services for AI Agents, specializing in extracting data from social media, search engines, online maps, e-commerce sites, travel portals, or general websites
* A marketplace of ready-to-use Actors (specialized tools) for various data tasks
* Infrastructure to run and monetize our own AI Agents

## Prerequisites

1. Sign up for an [Apify account](https://console.apify.com/sign-up)
2. Obtain your Apify API token (can be obtained from [Apify](https://docs.apify.com/platform/integrations/api))
3. Install the required packages:

```bash
pip install agno apify-client
```

## Basic Usage

The Agno framework makes it easy to integrate Apify Actors into your agents. Here's a simple example:

```python
from agno.agent import Agent
from agno.tools.apify import ApifyTools

# Create an agent with ApifyTools
agent = Agent(
    tools=[
        ApifyTools(
            actors=["apify/rag-web-browser"],  # Specify which Apify Actors to use, use multiple ones if needed
            apify_api_token="your_apify_api_key"  # Or set the APIFY_API_TOKEN environment variable 
        )
    ],
        markdown=True
)

# Use the agent to get website content
agent.print_response("What information can you find on https://docs.agno.com/introduction ?", markdown=True)
```

## Available Apify Tools

You can easily integrate any Apify Actor as a tool. Here are some examples:

### 1. RAG Web Browser

The [RAG Web Browser](https://apify.com/apify/rag-web-browser) Actor is specifically designed for AI and LLM applications. It searches the web for a query or processes a URL, then cleans and formats the content for your agent. This tool is enabled by default.

```python
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(
    tools=[
        ApifyTools(actors=["apify/rag-web-browser"])
    ],
        markdown=True
)

# Search for information and process the results
agent.print_response("What are the latest developments in large language models?", markdown=True)
```

### 2. Website Content Crawler

This tool uses Apify's [Website Content Crawler](https://apify.com/apify/website-content-crawler) Actor to extract text content from websites, making it perfect for RAG applications.

```python
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(
    tools=[
        ApifyTools(actors=["apify/website-content-crawler"])
    ],
    markdown=True
)

# Ask the agent to process web content
agent.print_response("Summarize the content from https://docs.agno.com/introduction", markdown=True)
```

### 3. Google Places Crawler

The [Google Places Crawler](https://apify.com/compass/crawler-google-places) extracts data about businesses from Google Maps and Google Places.

```python
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(
    tools=[
        ApifyTools(actors=["compass/crawler-google-places"])
    ]
)

# Find business information in a specific location
agent.print_response("What are the top-rated restaurants in San Francisco?", markdown=True)
agent.print_response("Find coffee shops in Prague", markdown=True)
```

## Example Scenarios

### RAG Web Browser + Google Places Crawler

This example combines web search with local business data to provide comprehensive information about a topic:

```python
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(
    tools=[
        ApifyTools(actors=[
            "apify/rag-web-browser",
            "compass/crawler-google-places"
        ])
    ]
)

# Get general information and local businesses
agent.print_response(
    """
    I'm traveling to Tokyo next month.
    1. Research the best time to visit and major attractions
    2. Find one good rated sushi restaurants near Shinjuku
    Compile a comprehensive travel guide with this information.
    """,
    markdown=True
)
```

## Toolkit Params

| Parameter         | Type                 | Default | Description                                                         |
| ----------------- | -------------------- | ------- | ------------------------------------------------------------------- |
| `apify_api_token` | `str`                | `None`  | Apify API token (or set via APIFY\_API\_TOKEN environment variable) |
| `actors`          | `str` or `List[str]` | `None`  | Single Actor ID or list of Actor IDs to register                    |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/apify.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/apify_tools.py)

## Resources

* [Apify Actor Documentation](https://docs.apify.com/Actors)
* [Apify Store - Browse available Actors](https://apify.com/store)
* [How to build and monetize an AI agent on Apify](https://blog.apify.com/how-to-build-an-ai-agent/)


# AWS Lambda
Source: https://docs.agno.com/concepts/tools/toolkits/others/aws_lambda



## Prerequisites

The following example requires the `boto3` library.

```shell
pip install openai boto3
```

## Example

The following agent will use AWS Lambda to list all Lambda functions in our AWS account and invoke a specific Lambda function.

```python cookbook/tools/aws_lambda_tools.py

from agno.agent import Agent
from agno.tools.aws_lambda import AWSLambdaTools


# Create an Agent with the AWSLambdaTool
agent = Agent(
    tools=[AWSLambdaTools(region_name="us-east-1")],
    name="AWS Lambda Agent",
    )

# Example 1: List all Lambda functions
agent.print_response("List all Lambda functions in our AWS account", markdown=True)

# Example 2: Invoke a specific Lambda function
agent.print_response("Invoke the 'hello-world' Lambda function with an empty payload", markdown=True)
```

## Toolkit Params

| Parameter                | Type   | Default       | Description                                         |
| ------------------------ | ------ | ------------- | --------------------------------------------------- |
| `region_name`            | `str`  | `"us-east-1"` | AWS region name where Lambda functions are located. |
| `enable_list_functions`  | `bool` | `True`        | Enable the list\_functions functionality.           |
| `enable_invoke_function` | `bool` | `True`        | Enable the invoke\_function functionality.          |
| `all`                    | `bool` | `False`       | Enable all functionality.                           |

## Toolkit Functions

| Function          | Description                                                                                                           |
| ----------------- | --------------------------------------------------------------------------------------------------------------------- |
| `list_functions`  | Lists all Lambda functions available in the AWS account.                                                              |
| `invoke_function` | Invokes a specific Lambda function with an optional payload. Takes `function_name` and optional `payload` parameters. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/aws_lambda.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/aws_lambda_tools.py)


# AWS SES
Source: https://docs.agno.com/concepts/tools/toolkits/others/aws_ses



**AWSSESTool** enables an Agent to send emails using Amazon Simple Email Service (SES).

## Prerequisites

The following example requires the `boto3` library and valid AWS credentials. You can install `boto3` via pip:

```shell
pip install boto3
```

You must also configure your AWS credentials so that the SDK can authenticate to SES. The easiest way is via the AWS CLI:

```shell
aws configure
# OR set environment variables manually
export AWS_ACCESS_KEY_ID=****
export AWS_SECRET_ACCESS_KEY=****
export AWS_DEFAULT_REGION=us-east-1
```

<Note>
  Make sure to add the domain or email address you want to send FROM (and, if
  still in sandbox mode, the TO address) to the verified emails in the [SES
  Console](https://console.aws.amazon.com/ses/home).
</Note>

## Example

The following agent researches the latest AI news and then emails a summary via AWS SES:

```python aws_ses_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.aws_ses import AWSSESTool
from agno.tools.duckduckgo import DuckDuckGoTools

# Configure email settings
sender_email = "verified-sender@example.com"  # Your verified SES email
sender_name = "Sender Name"
region_name = "us-east-1"

agent = Agent(
    name="Research Newsletter Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        AWSSESTool(
            sender_email=sender_email,
            sender_name=sender_name,
            region_name=region_name
        ),
        DuckDuckGoTools(),
    ],
    markdown=True,
        instructions=[
        "When given a prompt:",
        "1. Extract the recipient's complete email address (e.g. user@domain.com)",
        "2. Research the latest AI developments using DuckDuckGo",
        "3. Compose a concise, engaging email summarising 3 ‚Äì 4 key developments",
        "4. Send the email using AWS SES via the send_email tool",
    ],
)

agent.print_response(
    "Research recent AI developments in healthcare and email the summary to johndoe@example.com"
)
```

## Toolkit Params

| Parameter           | Type   | Default       | Description                              |
| ------------------- | ------ | ------------- | ---------------------------------------- |
| `sender_email`      | `str`  | `None`        | Verified SES sender address.             |
| `sender_name`       | `str`  | `None`        | Display name that appears to recipients. |
| `region_name`       | `str`  | `"us-east-1"` | AWS region where SES is provisioned.     |
| `enable_send_email` | `bool` | `True`        | Enable the send\_email functionality.    |
| `all`               | `bool` | `False`       | Enable all functionality.                |

## Toolkit Functions

| Function     | Description                                                                          |
| ------------ | ------------------------------------------------------------------------------------ |
| `send_email` | Send a plain-text email. Accepts the arguments: `subject`, `body`, `receiver_email`. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/aws_ses.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/aws_ses_tools.py)
* [Amazon SES Documentation](https://docs.aws.amazon.com/ses/latest/dg/)


# Bitbucket
Source: https://docs.agno.com/concepts/tools/toolkits/others/bitbucket

BitbucketTools enables agents to interact with Bitbucket repositories for managing code, pull requests, and issues.

## Example

The following agent can manage Bitbucket repositories:

```python
from agno.agent import Agent
from agno.tools.bitbucket import BitbucketTools

agent = Agent(
    instructions=[
        "You are a Bitbucket repository management assistant",
        "Help users manage their Bitbucket repositories, pull requests, and issues",
        "Provide clear information about repository operations",
        "Handle errors gracefully and suggest solutions",
    ],
    tools=[BitbucketTools(
        workspace="your-workspace",
        repo_slug="your-repository"
    )],
)

agent.print_response("List all pull requests for this repository", stream=True)
```

## Toolkit Params

| Parameter     | Type            | Default               | Description                                                  |
| ------------- | --------------- | --------------------- | ------------------------------------------------------------ |
| `server_url`  | `str`           | `"api.bitbucket.org"` | Bitbucket server URL (for Bitbucket Server instances).       |
| `username`    | `Optional[str]` | `None`                | Bitbucket username. Uses BITBUCKET\_USERNAME if not set.     |
| `password`    | `Optional[str]` | `None`                | Bitbucket app password. Uses BITBUCKET\_PASSWORD if not set. |
| `token`       | `Optional[str]` | `None`                | Access token. Uses BITBUCKET\_TOKEN if not set.              |
| `workspace`   | `Optional[str]` | `None`                | Bitbucket workspace name (required).                         |
| `repo_slug`   | `Optional[str]` | `None`                | Repository slug name (required).                             |
| `api_version` | `str`           | `"2.0"`               | Bitbucket API version to use.                                |

## Toolkit Functions

| Function                   | Description                                             |
| -------------------------- | ------------------------------------------------------- |
| `get_issue`                | Get details of a specific issue by ID.                  |
| `get_issues`               | List all issues in the repository.                      |
| `create_issue`             | Create a new issue in the repository.                   |
| `update_issue`             | Update an existing issue.                               |
| `get_pull_request`         | Get details of a specific pull request.                 |
| `get_pull_requests`        | List all pull requests in the repository.               |
| `create_pull_request`      | Create a new pull request.                              |
| `update_pull_request`      | Update an existing pull request.                        |
| `get_pull_request_diff`    | Get the diff/changes of a pull request.                 |
| `get_pull_request_commits` | Get commits associated with a pull request.             |
| `get_repository_info`      | Get detailed information about the repository.          |
| `get_branches`             | List all branches in the repository.                    |
| `get_commits`              | List commits in the repository.                         |
| `get_file_content`         | Get the content of a specific file from the repository. |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/bitbucket.py)
* [Bitbucket API Documentation](https://developer.atlassian.com/bitbucket/api/2/reference/)


# Brandfetch
Source: https://docs.agno.com/concepts/tools/toolkits/others/brandfetch

BrandfetchTools provides access to brand data and logo information through the Brandfetch API.

## Example

The following agent can search for brand information and retrieve brand data:

```python
from agno.agent import Agent
from agno.tools.brandfetch import BrandfetchTools

agent = Agent(
    instructions=[
        "You are a brand research assistant that helps find brand information",
        "Use Brandfetch to retrieve logos, colors, and other brand assets",
        "Provide comprehensive brand information when requested",
    ],
    tools=[BrandfetchTools()],
)

agent.print_response("Find brand information for Apple Inc.", stream=True)
```

## Toolkit Params

| Parameter                     | Type              | Default                          | Description                                                   |
| ----------------------------- | ----------------- | -------------------------------- | ------------------------------------------------------------- |
| `api_key`                     | `Optional[str]`   | `None`                           | Brandfetch API key. Uses BRANDFETCH\_API\_KEY if not set.     |
| `client_id`                   | `Optional[str]`   | `None`                           | Brandfetch Client ID for search. Uses BRANDFETCH\_CLIENT\_ID. |
| `base_url`                    | `str`             | `"https://api.brandfetch.io/v2"` | Brandfetch API base URL.                                      |
| `timeout`                     | `Optional[float]` | `20.0`                           | Request timeout in seconds.                                   |
| `enable_search_by_identifier` | `bool`            | `True`                           | Enable searching brands by domain/identifier.                 |
| `enable_search_by_brand`      | `bool`            | `False`                          | Enable searching brands by name.                              |
| `async_tools`                 | `bool`            | `False`                          | Enable async versions of tools.                               |

## Toolkit Functions

| Function                | Description                                               |
| ----------------------- | --------------------------------------------------------- |
| `search_by_identifier`  | Search for brand data using domain or company identifier. |
| `search_by_brand`       | Search for brands by name (requires client\_id).          |
| `asearch_by_identifier` | Async version of search by identifier.                    |
| `asearch_by_brand`      | Async version of search by brand name.                    |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/brandfetch.py)
* [Brandfetch API Documentation](https://docs.brandfetch.com/)


# Cal.com
Source: https://docs.agno.com/concepts/tools/toolkits/others/calcom



## Prerequisites

The following example requires the `pytz` and `requests` libraries.

```shell
pip install requests pytz
```

```shell
export CALCOM_API_KEY="your_api_key"
export CALCOM_EVENT_TYPE_ID="your_event_type_id"
```

## Example

The following agent will use Cal.com to list all events in your Cal.com account for tomorrow.

```python cookbook/tools/calcom_tools.py

agent = Agent(
    name="Calendar Assistant",
    instructions=[
        f"You're scheduing assistant. Today is {datetime.now()}.",
        "You can help users by:",
        "- Finding available time slots",
        "- Creating new bookings",
        "- Managing existing bookings (view, reschedule, cancel) ",
        "- Getting booking details",
        "- IMPORTANT: In case of rescheduling or cancelling booking, call the get_upcoming_bookings function to get the booking uid. check available slots before making a booking for given time",
        "Always confirm important details before making bookings or changes.",
    ],
    model=OpenAIChat(id="gpt-4"),
    tools=[CalComTools(user_timezone="America/New_York")],
        markdown=True,
)

agent.print_response("What are my bookings for tomorrow?")
```

## Toolkit Params

| Parameter                      | Type   | Default | Description                                |
| ------------------------------ | ------ | ------- | ------------------------------------------ |
| `api_key`                      | `str`  | `None`  | Cal.com API key                            |
| `event_type_id`                | `int`  | `None`  | Event type ID for scheduling               |
| `user_timezone`                | `str`  | `None`  | User's timezone (e.g. "America/New\_York") |
| `enable_get_available_slots`   | `bool` | `True`  | Enable getting available time slots        |
| `enable_create_booking`        | `bool` | `True`  | Enable creating new bookings               |
| `enable_get_upcoming_bookings` | `bool` | `True`  | Enable getting upcoming bookings           |
| `enable_reschedule_booking`    | `bool` | `True`  | Enable rescheduling bookings               |
| `enable_cancel_booking`        | `bool` | `True`  | Enable canceling bookings                  |

## Toolkit Functions

| Function                | Description                                      |
| ----------------------- | ------------------------------------------------ |
| `get_available_slots`   | Gets available time slots for a given date range |
| `create_booking`        | Creates a new booking with provided details      |
| `get_upcoming_bookings` | Gets list of upcoming bookings                   |
| `get_booking_details`   | Gets details for a specific booking              |
| `reschedule_booking`    | Reschedules an existing booking                  |
| `cancel_booking`        | Cancels an existing booking                      |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/calcom.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/calcom_tools.py)


# Cartesia
Source: https://docs.agno.com/concepts/tools/toolkits/others/cartesia

Tools for interacting with Cartesia Voice AI services including text-to-speech and voice localization

**CartesiaTools** enable an Agent to perform text-to-speech, list available voices, and localize voices using [Cartesia](https://docs.cartesia.ai/).

## Prerequisites

The following example requires the `cartesia` library and an API key.

```bash
pip install cartesia
```

```bash
export CARTESIA_API_KEY="your_api_key_here"
```

## Example

```python
from agno.agent import Agent
from agno.tools.cartesia import CartesiaTools
from agno.utils.audio import write_audio_to_file

# Initialize Agent with Cartesia tools
agent = Agent(
    name="Cartesia TTS Agent",
    description="An agent that uses Cartesia for text-to-speech.",
    tools=[CartesiaTools()],
)

response = agent.run(
    """Generate a simple greeting using Text-to-Speech:

    Say "Welcome to Cartesia, the advanced  speech synthesis platform. This speech is generated by an agent."
    """
)

# Save the generated audio
if response.audio:
    write_audio_to_file(audio=response.audio[0].content, filename="tmp/greeting.mp3")

```

## Advanced Example: Translation and Voice Localization

This example demonstrates how to translate text, analyze emotion, localize a new voice, and generate a voice note using CartesiaTools.

```python
from textwrap import dedent
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.cartesia import CartesiaTools
from agno.utils.audio import write_audio_to_file

agent_instructions = dedent(
    """Follow these steps SEQUENTIALLY to translate text and generate a localized voice note:
    1. Identify the text to translate and the target language from the user request.
    2. Translate the text accurately to the target language.
    3. Analyze the emotion conveyed by the translated text.
    4. Call `list_voices` to retrieve available voices.
    5. Select a base voice matching the language and emotion.
    6. Call `localize_voice` to create a new localized voice.
    7. Call `text_to_speech` to generate the final audio.
    """
)

agent = Agent(
    name="Emotion-Aware Translator Agent",
    description="Translates text, analyzes emotion, selects a suitable voice, creates a localized voice, and generates a voice note (audio file) using Cartesia TTS tools.",
    instructions=agent_instructions,
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[CartesiaTools(enable_localize_voice=True)],  
    )

agent.print_response(
    "Translate 'Hello! How are you? Tell me more about the weather in Paris?' to French and create a voice note."
)
response = agent.run_response

if response.audio:
    write_audio_to_file(
        response.audio[0].base64_audio,
        filename="french_weather.mp3",
    )
```

## Toolkit Params

| Parameter               | Type   | Default                                | Description                                                                                         |
| ----------------------- | ------ | -------------------------------------- | --------------------------------------------------------------------------------------------------- |
| `api_key`               | `str`  | `None`                                 | The Cartesia API key for authentication. If not provided, uses the `CARTESIA_API_KEY` env variable. |
| `model_id`              | `str`  | `sonic-2`                              | The model ID to use for text-to-speech.                                                             |
| `default_voice_id`      | `str`  | `78ab82d5-25be-4f7d-82b3-7ad64e5b85b2` | The default voice ID to use for text-to-speech and localization.                                    |
| `enable_text_to_speech` | `bool` | `True`                                 | Enable text-to-speech functionality.                                                                |
| `enable_list_voices`    | `bool` | `True`                                 | Enable listing available voices functionality.                                                      |
| `enable_localize_voice` | `bool` | `False`                                | Enable voice localization functionality.                                                            |

## Toolkit Functions

| Function         | Description                          |
| ---------------- | ------------------------------------ |
| `list_voices`    | List available voices from Cartesia. |
| `text_to_speech` | Converts text to speech.             |
| `localize_voice` | Create a new localized voice.        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/cartesia.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/cartesia_tools.py)


# ClickUp
Source: https://docs.agno.com/concepts/tools/toolkits/others/clickup

ClickUpTools enables agents to interact with ClickUp workspaces for project management and task organization.

## Example

The following agent can manage ClickUp tasks and projects:

```python
from agno.agent import Agent
from agno.tools.clickup import ClickUpTools

agent = Agent(
    instructions=[
        "You are a ClickUp project management assistant",
        "Help users manage their tasks, projects, and workspaces",
        "Create, update, and organize tasks efficiently",
        "Provide clear status updates on task operations",
    ],
    tools=[ClickUpTools()],
)

agent.print_response("Create a new task called 'Review documentation' in the todo list", stream=True)
```

## Toolkit Params

| Parameter         | Type            | Default | Description                                                 |
| ----------------- | --------------- | ------- | ----------------------------------------------------------- |
| `api_key`         | `Optional[str]` | `None`  | ClickUp API key. Uses CLICKUP\_API\_KEY if not set.         |
| `master_space_id` | `Optional[str]` | `None`  | Default space ID to use. Uses MASTER\_SPACE\_ID if not set. |

## Toolkit Functions

| Function      | Description                                                  |
| ------------- | ------------------------------------------------------------ |
| `list_tasks`  | List tasks with optional filtering by status, assignee, etc. |
| `create_task` | Create a new task in a specified list.                       |
| `get_task`    | Get detailed information about a specific task.              |
| `update_task` | Update an existing task's properties.                        |
| `delete_task` | Delete a task from ClickUp.                                  |
| `list_spaces` | List all spaces accessible to the user.                      |
| `list_lists`  | List all lists within a space or folder.                     |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/clickup.py)
* [ClickUp API Documentation](https://clickup.com/api/)


# Composio
Source: https://docs.agno.com/concepts/tools/toolkits/others/composio



[**ComposioTools**](https://docs.composio.dev/framework/phidata) enable an Agent to work with tools like Gmail, Salesforce, Github, etc.

## Prerequisites

The following example requires the `composio-agno` library.

```shell
pip install composio-agno
composio add github # Login into Github
```

## Example

The following agent will use Github Tool from Composio Toolkit to star a repo.

```python cookbook/tools/composio_tools.py
from agno.agent import Agent
from composio_agno import Action, ComposioToolSet


toolset = ComposioToolSet()
composio_tools = toolset.get_tools(
  actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)

agent = Agent(tools=composio_tools)
agent.print_response("Can you star agno-agi/agno repo?")
```

## Toolkit Params

The following parameters are used when calling the GitHub star repository action:

| Parameter | Type  | Default | Description                          |
| --------- | ----- | ------- | ------------------------------------ |
| `owner`   | `str` | -       | The owner of the repository to star. |
| `repo`    | `str` | -       | The name of the repository to star.  |

## Toolkit Functions

Composio Toolkit provides 1000+ functions to connect to different software tools.
Open this [link](https://composio.dev/tools) to view the complete list of functions.


# Confluence
Source: https://docs.agno.com/concepts/tools/toolkits/others/confluence



**ConfluenceTools** enable an Agent to retrieve, create, and update pages in Confluence. They also allow you to explore spaces and page details.

## Prerequisites

The following example requires the `atlassian-python-api` library and Confluence credentials. You can obtain an API token by going [here](https://id.atlassian.com/manage-profile/security).

```shell
pip install atlassian-python-api
```

```shell
export CONFLUENCE_URL="https://your-confluence-instance"
export CONFLUENCE_USERNAME="your-username"
export CONFLUENCE_PASSWORD="your-password"
# or
export CONFLUENCE_API_KEY="your-api-key"
```

## Example

The following agent will retrieve the number of spaces and their names.

```python
from agno.agent import Agent
from agno.tools.confluence import ConfluenceTools

agent = Agent(
    name="Confluence agent",
    tools=[ConfluenceTools()],
        markdown=True,
)

agent.print_response("How many spaces are there and what are their names?")
```

## Toolkit Params

| Parameter    | Type            | Default | Description                                                                                                    |
| ------------ | --------------- | ------- | -------------------------------------------------------------------------------------------------------------- |
| `username`   | `Optional[str]` | `None`  | Confluence username. If not provided, uses CONFLUENCE\_USERNAME environment variable.                          |
| `password`   | `Optional[str]` | `None`  | Confluence password. If not provided, uses CONFLUENCE\_PASSWORD environment variable.                          |
| `url`        | `Optional[str]` | `None`  | Confluence instance URL. If not provided, uses CONFLUENCE\_URL environment variable.                           |
| `api_key`    | `Optional[str]` | `None`  | Confluence API key (alternative to password). If not provided, uses CONFLUENCE\_API\_KEY environment variable. |
| `verify_ssl` | `bool`          | `True`  | Whether to verify SSL certificates when making requests.                                                       |

## Toolkit Functions

| Function                  | Description                                                     |
| ------------------------- | --------------------------------------------------------------- |
| `get_page_content`        | Gets the content of a specific page.                            |
| `get_all_space_detail`    | Gets details about all Confluence spaces.                       |
| `get_space_key`           | Gets the Confluence key for the specified space.                |
| `get_all_page_from_space` | Gets details of all pages from the specified space.             |
| `create_page`             | Creates a new Confluence page with the provided title and body. |
| `update_page`             | Updates an existing Confluence page.                            |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/confluence.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/confluence.py)


# Custom API
Source: https://docs.agno.com/concepts/tools/toolkits/others/custom_api



**CustomApiTools** enable an Agent to make HTTP requests to any external API with customizable authentication and parameters.

## Prerequisites

The following example requires the `requests` library.

```shell
pip install requests
```

## Example

The following agent will use CustomApiTools to make API calls to the Dog CEO API.

```python cookbook/tools/custom_api_tools.py
from agno.agent import Agent
from agno.tools.api import CustomApiTools

agent = Agent(
    tools=[CustomApiTools(base_url="https://dog.ceo/api")],
    markdown=True,
)

agent.print_response(
    'Make API calls to the following two different endpoints: /breeds/image/random and /breeds/list/all to get a random dog image and list of dog breeds respectively. Use GET method for both calls.'
)
```

## Toolkit Params

| Parameter             | Type             | Default | Description                                 |
| --------------------- | ---------------- | ------- | ------------------------------------------- |
| `base_url`            | `str`            | `None`  | Base URL for API calls                      |
| `username`            | `str`            | `None`  | Username for basic authentication           |
| `password`            | `str`            | `None`  | Password for basic authentication           |
| `api_key`             | `str`            | `None`  | API key for bearer token authentication     |
| `headers`             | `Dict[str, str]` | `None`  | Default headers to include in requests      |
| `verify_ssl`          | `bool`           | `True`  | Whether to verify SSL certificates          |
| `timeout`             | `int`            | `30`    | Request timeout in seconds                  |
| `enable_make_request` | `bool`           | `True`  | Enables functionality to make HTTP requests |
| `all`                 | `bool`           | `False` | Enables all functionality when set to True  |

## Toolkit Functions

| Function       | Description                                                                                                                                |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| `make_request` | Makes an HTTP request to the API. Takes method (GET, POST, etc.), endpoint, and optional params, data, headers, and json\_data parameters. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/api.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/custom_api_tools.py)

```
```


# Dalle
Source: https://docs.agno.com/concepts/tools/toolkits/others/dalle



## Prerequisites

You need to install the `openai` library.

```bash
pip install openai
```

Set the `OPENAI_API_KEY` environment variable.

```bash
export OPENAI_API_KEY=****
```

## Example

The following agent will use DALL-E to generate an image based on a text prompt.

```python cookbook/tools/dalle_tools.py
from agno.agent import Agent
from agno.tools.dalle import DalleTools

# Create an Agent with the DALL-E tool
agent = Agent(tools=[DalleTools()], name="DALL-E Image Generator")

# Example 1: Generate a basic image with default settings
agent.print_response("Generate an image of a futuristic city with flying cars and tall skyscrapers", markdown=True)

# Example 2: Generate an image with custom settings
custom_dalle = Dalle(model="dall-e-3", size="1792x1024", quality="hd", style="natural")

agent_custom = Agent(
    tools=[custom_dalle],
    name="Custom DALL-E Generator",
    )

agent_custom.print_response("Create a panoramic nature scene showing a peaceful mountain lake at sunset", markdown=True)
```

## Toolkit Params

| Parameter             | Type   | Default       | Description                                                       |
| --------------------- | ------ | ------------- | ----------------------------------------------------------------- |
| `model`               | `str`  | `"dall-e-3"`  | The DALL-E model to use                                           |
| `enable_create_image` | `bool` | `True`        | Enable the create image functionality                             |
| `n`                   | `int`  | `1`           | Number of images to generate                                      |
| `size`                | `str`  | `"1024x1024"` | Image size (256x256, 512x512, 1024x1024, 1792x1024, or 1024x1792) |
| `quality`             | `str`  | `"standard"`  | Image quality (standard or hd)                                    |
| `style`               | `str`  | `"vivid"`     | Image style (vivid or natural)                                    |
| `api_key`             | `str`  | `None`        | The OpenAI API key for authentication                             |
| `all`                 | `bool` | `False`       | Enable all functionality when set to True                         |

## Toolkit Functions

| Function         | Description                               |
| ---------------- | ----------------------------------------- |
| `generate_image` | Generates an image based on a text prompt |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/dalle.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/dalle_tools.py)


# Daytona
Source: https://docs.agno.com/concepts/tools/toolkits/others/daytona

Enable your Agents to run code in a remote, secure sandbox.

**Daytona** offers secure and elastic infrastructure for runnning your AI-generated code. At Agno, we integrate with it to enable your Agents and Teams to run code in your Daytona sandboxes.

## Prerequisites

The Daytona tools require the `daytona_sdk` Python package:

```shell
pip install daytona_sdk
```

You will also need a Daytona API key. You can get it from your [Daytona account](https://app.daytona.io/account):

```shell
export DAYTONA_API_KEY=your_api_key
```

## Example

The following example demonstrates how to create an agent that can run Python code in a Daytona sandbox:

```python cookbook/tools/daytona_tools.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.daytona import DaytonaTools

daytona_tools = DaytonaTools()

# Setup an Agent focused on coding tasks, with access to the Daytona tools
agent = Agent(
    name="Coding Agent with Daytona tools",
    id="coding-agent",
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[daytona_tools],
    markdown=True,
        instructions=[
        "You are an expert at writing and validating Python code. You have access to a remote, secure Daytona sandbox.",
        "Your primary purpose is to:",
        "1. Write clear, efficient Python code based on user requests",
        "2. Execute and verify the code in the Daytona sandbox",
        "3. Share the complete code with the user, as this is the main use case",
        "4. Provide thorough explanations of how the code works",
        "You can use the run_python_code tool to run Python code in the Daytona sandbox.",
        "Guidelines:",
        "- ALWAYS share the complete code with the user, properly formatted in code blocks",
        "- Verify code functionality by executing it in the sandbox before sharing",
        "- Iterate and debug code as needed to ensure it works correctly",
        "- Use pandas, matplotlib, and other Python libraries for data analysis when appropriate",
        "- Create proper visualizations when requested and add them as image artifacts to show inline",
        "- Handle file uploads and downloads properly",
        "- Explain your approach and the code's functionality in detail",
        "- Format responses with both code and explanations for maximum clarity",
        "- Handle errors gracefully and explain any issues encountered",
    ],
)

# Example: Generate Fibonacci numbers
agent.print_response(
    "Write Python code to generate the first 10 Fibonacci numbers and calculate their sum and average"
)
```

## Toolkit Params

| Parameter             | Type             | Default               | Description                                                      |
| --------------------- | ---------------- | --------------------- | ---------------------------------------------------------------- |
| `api_key`             | `str`            | `None`                | Daytona API key. If not provided, uses DAYTONA\_API\_KEY env var |
| `api_url`             | `str`            | `None`                | Daytona API URL. If not provided, uses DAYTONA\_API\_URL env var |
| `sandbox_id`          | `str`            | `None`                | Existing sandbox ID to connect to                                |
| `sandbox_language`    | `CodeLanguage`   | `CodeLanguage.PYTHON` | The programming language to run on the sandbox                   |
| `sandbox_target`      | `str`            | `None`                | The target configuration for sandbox creation                    |
| `sandbox_os`          | `str`            | `None`                | The operating system to run on the sandbox                       |
| `auto_stop_interval`  | `int`            | `60`                  | Stop sandbox after this many minutes of inactivity               |
| `sandbox_os_user`     | `str`            | `None`                | The user to run the sandbox as                                   |
| `sandbox_env_vars`    | `Dict[str, str]` | `None`                | Environment variables to set in the sandbox                      |
| `sandbox_labels`      | `Dict[str, str]` | `None`                | Labels to set on the sandbox                                     |
| `sandbox_public`      | `bool`           | `None`                | Whether the sandbox should be public                             |
| `organization_id`     | `str`            | `None`                | The organization ID to use for the sandbox                       |
| `timeout`             | `int`            | `300`                 | Timeout in seconds for communication with the sandbox            |
| `auto_create_sandbox` | `bool`           | `True`                | Whether to automatically create a sandbox if none exists         |
| `verify_ssl`          | `bool`           | `False`               | Whether to verify SSL certificates                               |
| `persistent`          | `bool`           | `True`                | Whether the sandbox should persist between requests              |
| `instructions`        | `str`            | `None`                | Custom instructions for using the Daytona tools                  |
| `add_instructions`    | `bool`           | `False`               | Whether to add default instructions                              |

### Code Execution Tools

| Function          | Description                                           |
| ----------------- | ----------------------------------------------------- |
| `run_python_code` | Run Python code in the contextual Daytona sandbox     |
| `run_code`        | Run non-Python code in the contextual Daytona sandbox |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/daytona.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/daytona_tools.py)
* View [Daytona Documentation](https://www.daytona.io/docs/)


# Desi Vocal
Source: https://docs.agno.com/concepts/tools/toolkits/others/desi_vocal

DesiVocalTools provides text-to-speech capabilities using Indian voices through the Desi Vocal API.

## Example

The following agent can convert text to speech using Indian voices:

```python
from agno.agent import Agent
from agno.tools.desi_vocal import DesiVocalTools

agent = Agent(
    instructions=[
        "You are a text-to-speech assistant that converts text to natural Indian voices",
        "Help users generate audio from text using various Indian accents and languages",
        "Provide information about available voices and their characteristics",
        "Create high-quality audio content for users",
    ],
    tools=[DesiVocalTools()],
)

agent.print_response("Convert this text to speech: 'Namaste, welcome to our service'", stream=True)
```

## Toolkit Params

| Parameter               | Type            | Default                                  | Description                                                |
| ----------------------- | --------------- | ---------------------------------------- | ---------------------------------------------------------- |
| `api_key`               | `Optional[str]` | `None`                                   | Desi Vocal API key. Uses DESI\_VOCAL\_API\_KEY if not set. |
| `voice_id`              | `Optional[str]` | `"f27d74e5-ea71-4697-be3e-f04bbd80c1a8"` | Default voice ID to use for text-to-speech.                |
| `enable_get_voices`     | `bool`          | `True`                                   | Enable voice listing functionality.                        |
| `enable_text_to_speech` | `bool`          | `True`                                   | Enable text-to-speech conversion functionality.            |

## Toolkit Functions

| Function         | Description                                                   |
| ---------------- | ------------------------------------------------------------- |
| `get_voices`     | Retrieve list of available voices with their IDs and details. |
| `text_to_speech` | Convert text to speech using specified or default voice.      |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/desi_vocal.py)
* [Desi Vocal API Documentation](https://desivocal.com/docs)
* [Indian TTS Best Practices](https://desivocal.com/best-practices)


# E2B
Source: https://docs.agno.com/concepts/tools/toolkits/others/e2b

Enable your Agents to run code in a remote, secure sandbox.

**E2BTools** enable an Agent to execute code in a secure sandboxed environment with support for Python, file operations, and web server capabilities.

## Prerequisites

The E2B tools require the `e2b_code_interpreter` Python package and an E2B API key.

```shell
pip install e2b_code_interpreter
```

```shell
export E2B_API_KEY=your_api_key
```

## Example

The following example demonstrates how to create an agent that can run Python code in a secure sandbox:

```python cookbook/tools/e2b_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.e2b import E2BTools

e2b_tools = E2BTools(
    timeout=600,  # 10 minutes timeout (in seconds)
)

agent = Agent(
    name="Code Execution Sandbox",
    id="e2b-sandbox",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[e2b_tools],
    markdown=True,
        instructions=[
        "You are an expert at writing and validating Python code using a secure E2B sandbox environment.",
        "Your primary purpose is to:",
        "1. Write clear, efficient Python code based on user requests",
        "2. Execute and verify the code in the E2B sandbox",
        "3. Share the complete code with the user, as this is the main use case",
        "4. Provide thorough explanations of how the code works",
        "",
        "You can use these tools:",
        "1. Run Python code (run_python_code)",
        "2. Upload files to the sandbox (upload_file)",
        "3. Download files from the sandbox (download_file_from_sandbox)",
        "4. Generate and add visualizations as image artifacts (download_png_result)",
        "5. List files in the sandbox (list_files)",
        "6. Read and write file content (read_file_content, write_file_content)",
        "7. Start web servers and get public URLs (run_server, get_public_url)",
        "8. Manage the sandbox lifecycle (set_sandbox_timeout, get_sandbox_status, shutdown_sandbox)",
    ],
)

# Example: Generate Fibonacci numbers
agent.print_response(
    "Write Python code to generate the first 10 Fibonacci numbers and calculate their sum and average"
)

```

## Toolkit Params

| Parameter         | Type   | Default | Description                                               |
| ----------------- | ------ | ------- | --------------------------------------------------------- |
| `api_key`         | `str`  | `None`  | E2B API key. If not provided, uses E2B\_API\_KEY env var. |
| `timeout`         | `int`  | `300`   | Timeout in seconds for the sandbox (default: 5 minutes)   |
| `sandbox_options` | `dict` | `None`  | Additional options to pass to the Sandbox constructor     |

## Toolkit Functions

### Code Execution

| Function          | Description                                    |
| ----------------- | ---------------------------------------------- |
| `run_python_code` | Run Python code in the E2B sandbox environment |

### File Operations

| Function                     | Description                                             |
| ---------------------------- | ------------------------------------------------------- |
| `upload_file`                | Upload a file to the sandbox                            |
| `download_png_result`        | Add a PNG image result as an Image object to the agent  |
| `download_chart_data`        | Extract chart data from an interactive chart in results |
| `download_file_from_sandbox` | Download a file from the sandbox to the local system    |

### Filesystem Operations

| Function             | Description                                            |
| -------------------- | ------------------------------------------------------ |
| `list_files`         | List files and directories in a path in the sandbox    |
| `read_file_content`  | Read the content of a file from the sandbox            |
| `write_file_content` | Write text content to a file in the sandbox            |
| `watch_directory`    | Watch a directory for changes for a specified duration |

### Command Execution

| Function                  | Description                                    |
| ------------------------- | ---------------------------------------------- |
| `run_command`             | Run a shell command in the sandbox environment |
| `stream_command`          | Run a shell command and stream its output      |
| `run_background_command`  | Run a shell command in the background          |
| `kill_background_command` | Kill a background command                      |

### Internet Access

| Function         | Description                                             |
| ---------------- | ------------------------------------------------------- |
| `get_public_url` | Get a public URL for a service running in the sandbox   |
| `run_server`     | Start a server in the sandbox and return its public URL |

### Sandbox Management

| Function                 | Description                           |
| ------------------------ | ------------------------------------- |
| `set_sandbox_timeout`    | Update the timeout for the sandbox    |
| `get_sandbox_status`     | Get the current status of the sandbox |
| `shutdown_sandbox`       | Shutdown the sandbox immediately      |
| `list_running_sandboxes` | List all running sandboxes            |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/e2b.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/e2b_tools.py)


# Eleven Labs
Source: https://docs.agno.com/concepts/tools/toolkits/others/eleven_labs



**ElevenLabsTools** enable an Agent to perform audio generation tasks using [ElevenLabs](https://elevenlabs.io/docs/product/introduction)

## Prerequisites

You need to install the `elevenlabs` library and an API key which can be obtained from [Eleven Labs](https://elevenlabs.io/)

```bash
pip install elevenlabs
```

Set the `ELEVEN_LABS_API_KEY` environment variable.

```bash
export ELEVEN_LABS_API_KEY=****
```

## Example

The following agent will use Eleven Labs to generate audio based on a user prompt.

```python cookbook/tools/eleven_labs_tools.py
from agno.agent import Agent
from agno.tools.eleven_labs import ElevenLabsTools

# Create an Agent with the ElevenLabs tool
agent = Agent(tools=[
    ElevenLabsTools(
        voice_id="JBFqnCBsd6RMkjVDRZzb", model_id="eleven_multilingual_v2", target_directory="audio_generations"
    )
], name="ElevenLabs Agent")

agent.print_response("Generate a audio summary of the big bang theory", markdown=True)
```

## Toolkit Params

| Parameter                      | Type            | Default                  | Description                                                                                                                                                                    |
| ------------------------------ | --------------- | ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `api_key`                      | `str`           | `None`                   | The Eleven Labs API key for authentication                                                                                                                                     |
| `voice_id`                     | `str`           | `JBFqnCBsd6RMkjVDRZzb`   | The voice ID to use for the audio generation                                                                                                                                   |
| `target_directory`             | `Optional[str]` | `None`                   | The directory to save the audio file                                                                                                                                           |
| `model_id`                     | `str`           | `eleven_multilingual_v2` | The model's id to use for the audio generation                                                                                                                                 |
| `output_format`                | `str`           | `mp3_44100_64`           | The output format to use for the audio generation (check out [the docs](https://elevenlabs.io/docs/api-reference/text-to-speech#parameter-output-format) for more information) |
| `enable_text_to_speech`        | `bool`          | `True`                   | Enable the text\_to\_speech functionality.                                                                                                                                     |
| `enable_generate_sound_effect` | `bool`          | `True`                   | Enable the generate\_sound\_effect functionality.                                                                                                                              |
| `enable_get_voices`            | `bool`          | `True`                   | Enable the get\_voices functionality.                                                                                                                                          |
| `all`                          | `bool`          | `False`                  | Enable all functionality.                                                                                                                                                      |

## Toolkit Functions

| Function                | Description                                     |
| ----------------------- | ----------------------------------------------- |
| `text_to_speech`        | Convert text to speech                          |
| `generate_sound_effect` | Generate sound effect audio from a text prompt. |
| `get_voices`            | Get the list of voices available                |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/eleven_labs.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/elevenlabs_tools.py)


# EVM (Ethereum Virtual Machine)
Source: https://docs.agno.com/concepts/tools/toolkits/others/evm

EvmTools enables agents to interact with Ethereum and EVM-compatible blockchains for transactions and smart contract operations.

## Example

The following agent can interact with Ethereum blockchain:

```python
from agno.agent import Agent
from agno.tools.evm import EvmTools

agent = Agent(
    instructions=[
        "You are a blockchain assistant that helps with Ethereum transactions",
        "Help users send transactions and interact with smart contracts",
        "Always verify transaction details before executing",
        "Provide clear information about gas costs and transaction status",
    ],
    tools=[EvmTools()],
)

agent.print_response("Check my account balance and send 0.01 ETH to 0x742d35Cc6634C0532925a3b8D4034DfA8e5D5C4B", stream=True)
```

## Toolkit Params

| Parameter                 | Type            | Default | Description                                                   |
| ------------------------- | --------------- | ------- | ------------------------------------------------------------- |
| `private_key`             | `Optional[str]` | `None`  | Private key for signing transactions. Uses EVM\_PRIVATE\_KEY. |
| `rpc_url`                 | `Optional[str]` | `None`  | RPC URL for blockchain connection. Uses EVM\_RPC\_URL.        |
| `enable_send_transaction` | `bool`          | `True`  | Enable transaction sending functionality.                     |

## Toolkit Functions

| Function           | Description                                                  |
| ------------------ | ------------------------------------------------------------ |
| `send_transaction` | Send ETH or interact with smart contracts on the blockchain. |
| `get_balance`      | Get ETH balance for an address.                              |
| `get_transaction`  | Get transaction details by hash.                             |
| `estimate_gas`     | Estimate gas cost for a transaction.                         |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/evm.py)
* [Web3.py Documentation](https://web3py.readthedocs.io/)
* [Ethereum Documentation](https://ethereum.org/developers/)


# Fal
Source: https://docs.agno.com/concepts/tools/toolkits/others/fal



**FalTools** enable an Agent to perform media generation tasks.

## Prerequisites

The following example requires the `fal_client` library and an API key which can be obtained from [Fal](https://fal.ai/).

```shell
pip install -U fal_client
```

```shell
export FAL_KEY=***
```

## Example

The following agent will use FAL to generate any video requested by the user.

```python cookbook/tools/fal_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

fal_agent = Agent(
    name="Fal Video Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[FalTools("fal-ai/hunyuan-video")],
    description="You are an AI agent that can generate videos using the Fal API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    )

fal_agent.print_response("Generate video of balloon in the ocean")
```

## Toolkit Params

| Parameter               | Type   | Default | Description                                |
| ----------------------- | ------ | ------- | ------------------------------------------ |
| `api_key`               | `str`  | `None`  | API key for authentication purposes.       |
| `model`                 | `str`  | `None`  | The model to use for the media generation. |
| `enable_generate_media` | `bool` | `True`  | Enable the generate\_media functionality.  |
| `enable_image_to_image` | `bool` | `True`  | Enable the image\_to\_image functionality. |
| `all`                   | `bool` | `False` | Enable all functionality.                  |

## Toolkit Functions

| Function         | Description                                                    |
| ---------------- | -------------------------------------------------------------- |
| `generate_media` | Generate either images or videos depending on the user prompt. |
| `image_to_image` | Transform an input image based on a text prompt.               |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/fal.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/fal_tools.py)


# Financial Datasets API
Source: https://docs.agno.com/concepts/tools/toolkits/others/financial_datasets



**FinancialDatasetsTools** provide a comprehensive API for retrieving and analyzing diverse financial datasets, including stock prices, financial statements, company information, SEC filings, and cryptocurrency data from multiple providers.

## Prerequisites

The toolkit requires a Financial Datasets API key that can be obtained by creating an account at [financialdatasets.ai](https://financialdatasets.ai).

```bash
pip install agno
```

Set your API key as an environment variable:

```bash
export FINANCIAL_DATASETS_API_KEY=your_api_key_here
```

## Example

Basic usage of the Financial Datasets toolkit:

```python
from agno.agent import Agent
from agno.tools.financial_datasets import FinancialDatasetsTools

agent = Agent(
    name="Financial Data Agent",
    tools=[FinancialDatasetsTools()],
    description="You are a financial data specialist that helps analyze financial information for stocks and cryptocurrencies.",
    instructions=[
        "When given a financial query:",
        "1. Use appropriate Financial Datasets methods based on the query type",
        "2. Format financial data clearly and highlight key metrics",
        "3. For financial statements, compare important metrics with previous periods when relevant",
        "4. Calculate growth rates and trends when appropriate",
        "5. Handle errors gracefully and provide meaningful feedback",
    ],
    markdown=True,
    )

# Get the most recent income statement for Apple
agent.print_response("Get the most recent income statement for AAPL and highlight key metrics")
```

For more examples, see the [Financial Datasets Examples](/examples/concepts/tools/others/financial_datasets).

## Toolkit Params

\| Parameter | Type            | Default | Description                                                                             |
\| --------- | --------------- | ------- | --------------------------------------------------------------------------------------- | --- |
\| `api_key` | `Optional[str]` | `None`  | Optional API key. If not provided, uses FINANCIAL\_DATASETS\_API\_KEY environment variable |     |

## Toolkit Functions

| Function                      | Description                                                                                                     |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------- |
| `get_income_statements`       | Get income statements for a company with options for annual, quarterly, or trailing twelve months (ttm) periods |
| `get_balance_sheets`          | Get balance sheets for a company with period options                                                            |
| `get_cash_flow_statements`    | Get cash flow statements for a company                                                                          |
| `get_company_info`            | Get company information including business description, sector, and industry                                    |
| `get_crypto_prices`           | Get cryptocurrency prices with configurable time intervals                                                      |
| `get_earnings`                | Get earnings reports with EPS estimates, actuals, and revenue data                                              |
| `get_financial_metrics`       | Get key financial metrics and ratios for a company                                                              |
| `get_insider_trades`          | Get data on insider buying and selling activity                                                                 |
| `get_institutional_ownership` | Get information about institutional investors and their positions                                               |
| `get_news`                    | Get market news, optionally filtered by company                                                                 |
| `get_stock_prices`            | Get historical stock prices with configurable time intervals                                                    |
| `search_tickers`              | Search for stock tickers based on a query string                                                                |
| `get_sec_filings`             | Get SEC filings with optional filtering by form type (10-K, 10-Q, etc.)                                         |
| `get_segmented_financials`    | Get segmented financial data by product category and geographic region                                          |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Rate Limits and Usage

The Financial Datasets API may have usage limits based on your subscription tier. Please refer to their documentation for specific rate limit information.

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/financial_datasets.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/financial_datasets_tools.py)


# Giphy
Source: https://docs.agno.com/concepts/tools/toolkits/others/giphy



**GiphyTools** enables an Agent to search for GIFs on GIPHY.

## Prerequisites

```shell
export GIPHY_API_KEY=***
```

## Example

The following agent will search GIPHY for a GIF appropriate for a birthday message.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.giphy import GiphyTools


gif_agent = Agent(
    name="Gif Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GiphyTools()],
    description="You are an AI agent that can generate gifs using Giphy.",
)

gif_agent.print_response("I want a gif to send to a friend for their birthday.")
```

## Toolkit Params

| Parameter            | Type   | Default | Description                                       |
| -------------------- | ------ | ------- | ------------------------------------------------- |
| `api_key`            | `str`  | `None`  | If you want to manually supply the GIPHY API key. |
| `limit`              | `int`  | `1`     | The number of GIFs to return in a search.         |
| `enable_search_gifs` | `bool` | `True`  | Enable the search\_gifs functionality.            |
| `all`                | `bool` | `False` | Enable all functionality.                         |

## Toolkit Functions

| Function      | Description                                         |
| ------------- | --------------------------------------------------- |
| `search_gifs` | Searches GIPHY for a GIF based on the query string. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/giphy.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/giphy_tools.py)


# Github
Source: https://docs.agno.com/concepts/tools/toolkits/others/github



**GithubTools** enables an Agent to access Github repositories and perform tasks such as listing open pull requests, issues and more.

## Prerequisites

The following examples requires the `PyGithub` library and a Github access token which can be obtained from [here](https://github.com/settings/tokens).

```shell
pip install -U PyGithub
```

```shell
export GITHUB_ACCESS_TOKEN=***
```

## Example

The following agent will search Google for the latest news about "Mistral AI":

```python cookbook/tools/github_tools.py
from agno.agent import Agent
from agno.tools.github import GithubTools

agent = Agent(
    instructions=[
        "Use your tools to answer questions about the repo: agno-agi/agno",
        "Do not create any issues or pull requests unless explicitly asked to do so",
    ],
    tools=[GithubTools()],
    )

agent.print_response("List open pull requests", markdown=True)
```

## Toolkit Params

| Parameter      | Type            | Default | Description                                                                                                   |
| -------------- | --------------- | ------- | ------------------------------------------------------------------------------------------------------------- |
| `access_token` | `Optional[str]` | `None`  | GitHub access token for authentication. If not provided, will use GITHUB\_ACCESS\_TOKEN environment variable. |
| `base_url`     | `Optional[str]` | `None`  | Optional base URL for GitHub Enterprise installations.                                                        |

## Toolkit Functions

| Function                   | Description                                          |
| -------------------------- | ---------------------------------------------------- |
| `search_repositories`      | Searches Github repositories based on a query.       |
| `list_repositories`        | Lists repositories for a given user or organization. |
| `get_repository`           | Gets details about a specific repository.            |
| `list_pull_requests`       | Lists pull requests for a repository.                |
| `get_pull_request`         | Gets details about a specific pull request.          |
| `get_pull_request_changes` | Gets the file changes in a pull request.             |
| `create_issue`             | Creates a new issue in a repository.                 |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/github.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/github_tools.py)


# Google Maps
Source: https://docs.agno.com/concepts/tools/toolkits/others/google_maps

Tools for interacting with Google Maps services including place search, directions, geocoding, and more

**GoogleMapTools** enable an Agent to interact with various Google Maps services for location-based operations including place search, directions, geocoding, and more.

## Prerequisites

The following example requires the `googlemaps` library and an API key which can be obtained from the [Google Cloud Console](https://console.cloud.google.com/projectselector2/google/maps-apis/credentials).

```shell
pip install googlemaps
```

```shell
export GOOGLE_MAPS_API_KEY=your_api_key_here
```

You'll need to enable the following APIs in your Google Cloud Console:

* Places API
* Directions API
* Geocoding API
* Address Validation API
* Distance Matrix API
* Elevation API
* Time Zone API

## Example

Basic usage of the Google Maps toolkit:

```python
from agno.agent import Agent
from agno.tools.google_maps import GoogleMapTools

agent = Agent(tools=[GoogleMapTools()])
agent.print_response("Find coffee shops in San Francisco")
```

For more examples, see the [Google Maps Tools Examples](/examples/concepts/tools/others/google_maps).

## Toolkit Params

| Parameter | Type            | Default | Description                                                                         |
| --------- | --------------- | ------- | ----------------------------------------------------------------------------------- |
| `key`     | `Optional[str]` | `None`  | Optional API key. If not provided, uses GOOGLE\_MAPS\_API\_KEY environment variable |

## Toolkit Functions

| Function              | Description                                                                                                                                                                                               |
| --------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search_places`       | Search for places using Google Maps Places API. Parameters: `query` (str) for the search query. Returns stringified JSON with place details including name, address, phone, website, rating, and hours.   |
| `get_directions`      | Get directions between locations. Parameters: `origin` (str), `destination` (str), optional `mode` (str) for travel mode, optional `avoid` (List\[str]) for features to avoid. Returns route information. |
| `validate_address`    | Validate an address. Parameters: `address` (str), optional `region_code` (str), optional `locality` (str). Returns address validation results.                                                            |
| `geocode_address`     | Convert address to coordinates. Parameters: `address` (str), optional `region` (str). Returns location information with coordinates.                                                                      |
| `reverse_geocode`     | Convert coordinates to address. Parameters: `lat` (float), `lng` (float), optional `result_type` and `location_type` (List\[str]). Returns address information.                                           |
| `get_distance_matrix` | Calculate distances between locations. Parameters: `origins` (List\[str]), `destinations` (List\[str]), optional `mode` (str) and `avoid` (List\[str]). Returns distance and duration matrix.             |
| `get_elevation`       | Get elevation for a location. Parameters: `lat` (float), `lng` (float). Returns elevation data.                                                                                                           |
| `get_timezone`        | Get timezone for a location. Parameters: `lat` (float), `lng` (float), optional `timestamp` (datetime). Returns timezone information.                                                                     |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Rate Limits

Google Maps APIs have usage limits and quotas that vary by service and billing plan. Please refer to the [Google Maps Platform pricing](https://cloud.google.com/maps-platform/pricing) for details.

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/google_maps.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/google_maps_tools.py)


# Google Sheets
Source: https://docs.agno.com/concepts/tools/toolkits/others/google_sheets



**GoogleSheetsTools** enable an Agent to interact with Google Sheets API for reading, creating, updating, and duplicating spreadsheets.

## Prerequisites

You need to install the required Google API client libraries:

```bash
pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
```

Set up the following environment variables:

```bash
export GOOGLE_CLIENT_ID=your_client_id_here
export GOOGLE_CLIENT_SECRET=your_client_secret_here
export GOOGLE_PROJECT_ID=your_project_id_here
export GOOGLE_REDIRECT_URI=your_redirect_uri_here
```

## How to Get Credentials

1. Go to Google Cloud Console ([https://console.cloud.google.com](https://console.cloud.google.com))

2. Create a new project or select an existing one

3. Enable the Google Sheets API:
   * Go to "APIs & Services" > "Enable APIs and Services"
   * Search for "Google Sheets API"
   * Click "Enable"

4. Create OAuth 2.0 credentials:
   * Go to "APIs & Services" > "Credentials"
   * Click "Create Credentials" > "OAuth client ID"
   * Go through the OAuth consent screen setup
   * Give it a name and click "Create"
   * You'll receive:
     * Client ID (GOOGLE\_CLIENT\_ID)
     * Client Secret (GOOGLE\_CLIENT\_SECRET)
   * The Project ID (GOOGLE\_PROJECT\_ID) is visible in the project dropdown at the top of the page

## Example

The following agent will use Google Sheets to read and update spreadsheet data.

```python cookbook/tools/googlesheets_tools.py
from agno.agent import Agent
from agno.tools.googlesheets import GoogleSheetsTools

SAMPLE_SPREADSHEET_ID = "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms"
SAMPLE_RANGE_NAME = "Class Data!A2:E"

google_sheets_tools = GoogleSheetsTools(
    spreadsheet_id=SAMPLE_SPREADSHEET_ID,
    spreadsheet_range=SAMPLE_RANGE_NAME,
)

agent = Agent(
    tools=[google_sheets_tools],
    instructions=[
        "You help users interact with Google Sheets using tools that use the Google Sheets API",
        "Before asking for spreadsheet details, first attempt the operation as the user may have already configured the ID and range in the constructor",
    ],
)
agent.print_response("Please tell me about the contents of the spreadsheet")

```

## Toolkit Params

| Parameter                       | Type                    | Default | Description                                                |
| ------------------------------- | ----------------------- | ------- | ---------------------------------------------------------- |
| `scopes`                        | `Optional[List[str]]`   | `None`  | Custom OAuth scopes. If None, uses write scope by default. |
| `spreadsheet_id`                | `Optional[str]`         | `None`  | ID of the target spreadsheet.                              |
| `spreadsheet_range`             | `Optional[str]`         | `None`  | Range within the spreadsheet.                              |
| `creds`                         | `Optional[Credentials]` | `None`  | Pre-existing credentials.                                  |
| `creds_path`                    | `Optional[str]`         | `None`  | Path to credentials file.                                  |
| `token_path`                    | `Optional[str]`         | `None`  | Path to token file.                                        |
| `oauth_port`                    | `int`                   | `0`     | Port to use for OAuth authentication.                      |
| `enable_read_sheet`             | `bool`                  | `True`  | Enable reading from a sheet.                               |
| `enable_create_sheet`           | `bool`                  | `False` | Enable creating a sheet.                                   |
| `enable_update_sheet`           | `bool`                  | `False` | Enable updating a sheet.                                   |
| `enable_create_duplicate_sheet` | `bool`                  | `False` | Enable creating a duplicate sheet.                         |
| `all`                           | `bool`                  | `False` | Enable all tools.                                          |

## Toolkit Functions

| Function                 | Description                                                                                                                                                                                                                                                                                 |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `read_sheet`             | Read values from a Google Sheet. Parameters include `spreadsheet_id` (Optional\[str]) for fallback spreadsheet ID and `spreadsheet_range` (Optional\[str]) for fallback range. Returns JSON of list of rows.                                                                                |
| `create_sheet`           | Create a new Google Sheet. Parameters include `title` (str) for the title of the Google Sheet. Returns the ID of the created Google Sheet.                                                                                                                                                  |
| `update_sheet`           | Update data in a Google Sheet. Parameters include `data` (List\[List\[Any]]) for the data to update, `spreadsheet_id` (Optional\[str]) for the ID of the Google Sheet, and `range_name` (Optional\[str]) for the range to update. Returns success or failure message.                       |
| `create_duplicate_sheet` | Create a duplicate of an existing Google Sheet. Parameters include `source_id` (str) for the ID of the source spreadsheet, `new_title` (Optional\[str]) for new title, and `copy_permissions` (bool, default=True) for whether to copy permissions. Returns link to duplicated spreadsheet. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/googlesheets.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/googlesheets_tools.py)


# Google Calendar
Source: https://docs.agno.com/concepts/tools/toolkits/others/googlecalendar



Enable an Agent to work with Google Calendar to view and schedule meetings.

## Prerequisites

### Install dependencies

```shell
pip install tzlocal
```

### Setup Google Project and OAuth

Reference: [https://developers.google.com/calendar/api/quickstart/python](https://developers.google.com/calendar/api/quickstart/python)

1. Enable Google Calender API

   * Go to [Google Cloud Console](https://console.cloud.google.com/apis/enableflow?apiid=calendar-json.googleapis.com).
   * Select Project and Enable.

2. Go To API & Service -> OAuth Consent Screen

3. Select User Type

   * If you are a Google Workspace user, select Internal.
   * Otherwise, select External.

4. Fill in the app details (App name, logo, support email, etc).

5. Select Scope

   * Click on Add or Remove Scope.
   * Search for Google Calender API (Make sure you've enabled Google calender API otherwise scopes wont be visible).
   * Select scopes accordingly
     * From the dropdown check on `/auth/calendar` scope
   * Save and continue.

6. Adding Test User

   * Click Add Users and enter the email addresses of the users you want to allow during testing.
   * NOTE : Only these users can access the app's OAuth functionality when the app is in "Testing" mode.
     Any other users will receive access denied errors.
   * To make the app available to all users, you'll need to move the app's status to "In Production".
     Before doing so, ensure the app is fully verified by Google if it uses sensitive or restricted scopes.
   * Click on Go back to Dashboard.

7. Generate OAuth 2.0 Client ID

   * Go to Credentials.
   * Click on Create Credentials -> OAuth Client ID
   * Select Application Type as Desktop app.
   * Download JSON.

8. Using Google Calender Tool
   * Pass the path of downloaded credentials as credentials\_path to Google Calender tool.
   * Optional: Set the `token_path` parameter to specify where the tool should create the `token.json` file.
   * The `token.json` file is used to store the user's access and refresh tokens and is automatically created during the authorization flow if it doesn't already exist.
   * If `token_path` is not explicitly provided, the file will be created in the default location which is your current working directory.
   * If you choose to specify `token_path`, please ensure that the directory you provide has write access, as the application needs to create or update this file during the authentication process.

## Example

The following agent will use GoogleCalendarTools to find today's events.

```python cookbook/tools/googlecalendar_tools.py
from agno.agent import Agent
from agno.tools.googlecalendar import GoogleCalendarTools
import datetime
import os
from tzlocal import get_localzone_name

agent = Agent(
    tools=[GoogleCalendarTools(credentials_path="<PATH_TO_YOUR_CREDENTIALS_FILE>")],
        instructions=[
        f"""
        You are scheduling assistant . Today is {datetime.datetime.now()} and the users timezone is {get_localzone_name()}.
        You should help users to perform these actions in their Google calendar:
            - get their scheduled events from a certain date and time
            - create events based on provided details
        """
    ],
    add_datetime_to_context=True,
)

agent.print_response("Give me the list of todays events", markdown=True)
```

## Toolkit Params

| Parameter          | Type        | Default      | Description                                                                   |
| ------------------ | ----------- | ------------ | ----------------------------------------------------------------------------- |
| `scopes`           | `List[str]` | `None`       | List of OAuth scopes for Google Calendar API access                           |
| `credentials_path` | `str`       | `None`       | Path of the file credentials.json file which contains OAuth 2.0 Client ID     |
| `token_path`       | `str`       | `token.json` | Path of the file token.json which stores the user's access and refresh tokens |
| `access_token`     | `str`       | `None`       | Direct access token for authentication (alternative to OAuth flow)            |
| `calendar_id`      | `str`       | `primary`    | The calendar ID to use for operations                                         |
| `oauth_port`       | `int`       | `8080`       | Port number for OAuth callback server                                         |
| `allow_update`     | `bool`      | `False`      | Whether to allow write operations (create/update/delete events)               |

## Toolkit Functions

| Function       | Description                                        |
| -------------- | -------------------------------------------------- |
| `list_events`  | List events from the user's primary calendar.      |
| `create_event` | Create a new event in the user's primary calendar. |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/googlecalendar.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/googlecalendar_tools.py)


# Jira
Source: https://docs.agno.com/concepts/tools/toolkits/others/jira



**JiraTools** enable an Agent to perform Jira tasks.

## Prerequisites

The following example requires the `jira` library and auth credentials.

```shell
pip install -U jira
```

```shell
export JIRA_SERVER_URL="YOUR_JIRA_SERVER_URL"
export JIRA_USERNAME="YOUR_USERNAME"
export JIRA_TOKEN="YOUR_API_TOKEN"
```

## Example

The following agent will use Jira API to search for issues in a project.

```python cookbook/tools/jira_tools.py
from agno.agent import Agent
from agno.tools.jira import JiraTools

agent = Agent(tools=[JiraTools()])
agent.print_response("Find all issues in project PROJ", markdown=True)
```

## Toolkit Params

| Parameter              | Type   | Default | Description                                                                                                                   |
| ---------------------- | ------ | ------- | ----------------------------------------------------------------------------------------------------------------------------- |
| `server_url`           | `str`  | `""`    | The URL of the JIRA server, retrieved from the environment variable `JIRA_SERVER_URL`. Default is an empty string if not set. |
| `username`             | `str`  | `None`  | The JIRA username for authentication, retrieved from the environment variable `JIRA_USERNAME`. Default is None if not set.    |
| `password`             | `str`  | `None`  | The JIRA password for authentication, retrieved from the environment variable `JIRA_PASSWORD`. Default is None if not set.    |
| `token`                | `str`  | `None`  | The JIRA API token for authentication, retrieved from the environment variable `JIRA_TOKEN`. Default is None if not set.      |
| `enable_get_issue`     | `bool` | `True`  | Enable the get\_issue functionality.                                                                                          |
| `enable_create_issue`  | `bool` | `True`  | Enable the create\_issue functionality.                                                                                       |
| `enable_search_issues` | `bool` | `True`  | Enable the search\_issues functionality.                                                                                      |
| `enable_add_comment`   | `bool` | `True`  | Enable the add\_comment functionality.                                                                                        |
| `all`                  | `bool` | `False` | Enable all functionality.                                                                                                     |

## Toolkit Functions

| Function        | Description                                                                                                                                                                                                                                                                                                                                |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `get_issue`     | Retrieves issue details from JIRA. Parameters include:<br />- `issue_key`: the key of the issue to retrieve<br />Returns a JSON string containing issue details or an error message.                                                                                                                                                       |
| `create_issue`  | Creates a new issue in JIRA. Parameters include:<br />- `project_key`: the project in which to create the issue<br />- `summary`: the issue summary<br />- `description`: the issue description<br />- `issuetype`: the type of issue (default is "Task")<br />Returns a JSON string with the new issue's key and URL or an error message. |
| `search_issues` | Searches for issues using a JQL query in JIRA. Parameters include:<br />- `jql_str`: the JQL query string<br />- `max_results`: the maximum number of results to return (default is 50)<br />Returns a JSON string containing a list of dictionaries with issue details or an error message.                                               |
| `add_comment`   | Adds a comment to an issue in JIRA. Parameters include:<br />- `issue_key`: the key of the issue<br />- `comment`: the comment text<br />Returns a JSON string indicating success or an error message.                                                                                                                                     |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/jira.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/jira_tools.py)


# Knowledge Tools
Source: https://docs.agno.com/concepts/tools/toolkits/others/knowledge

KnowledgeTools provide intelligent search and analysis capabilities over knowledge bases with reasoning integration.

## Example

The following agent can search and analyze knowledge bases:

```python
from agno.agent import Agent
from agno.tools.knowledge import KnowledgeTools
from agno.knowledge import Knowledge

# Initialize knowledge base
knowledge = Knowledge()
knowledge.load_documents("./docs/")

agent = Agent(
    instructions=[
        "You are a knowledge assistant that helps find and analyze information",
        "Search through the knowledge base to answer questions",
        "Provide detailed analysis and reasoning about the information found",
        "Always cite your sources and explain your reasoning",
    ],
    tools=[KnowledgeTools(knowledge=knowledge)],
)

agent.print_response("What are the best practices for API design?", stream=True)
```

## Toolkit Params

| Parameter           | Type            | Default | Description                                   |
| ------------------- | --------------- | ------- | --------------------------------------------- |
| `knowledge`         | `Knowledge`     | `None`  | Knowledge base instance (required).           |
| `enable_think`      | `bool`          | `True`  | Enable reasoning capabilities.                |
| `enable_search`     | `bool`          | `True`  | Enable knowledge search functionality.        |
| `enable_analyze`    | `bool`          | `True`  | Enable knowledge analysis capabilities.       |
| `instructions`      | `Optional[str]` | `None`  | Custom instructions for knowledge operations. |
| `add_instructions`  | `bool`          | `True`  | Whether to add instructions to the agent.     |
| `add_few_shot`      | `bool`          | `False` | Whether to include few-shot examples.         |
| `few_shot_examples` | `Optional[str]` | `None`  | Custom few-shot examples.                     |

## Toolkit Functions

| Function  | Description                                                |
| --------- | ---------------------------------------------------------- |
| `think`   | Apply reasoning to knowledge-based problems and questions. |
| `search`  | Search the knowledge base for relevant information.        |
| `analyze` | Perform detailed analysis of knowledge base content.       |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/knowledge.py)
* [Agno Knowledge Framework](https://docs.agno.com/knowledge)
* [Vector Database Integration](https://docs.agno.com/vector-db)


# Linear
Source: https://docs.agno.com/concepts/tools/toolkits/others/linear



**LinearTool** enable an Agent to perform [Linear](https://linear.app/) tasks.

## Prerequisites

The following examples require Linear API key, which can be obtained from [here](https://linear.app/settings/account/security).

```shell
export LINEAR_API_KEY="LINEAR_API_KEY"
```

## Example

The following agent will use Linear API to search for issues in a project for a specific user.

```python cookbook/tools/linear_tools.py
from agno.agent import Agent
from agno.tools.linear import LinearTools

agent = Agent(
    name="Linear Tool Agent",
    tools=[LinearTools()],
        markdown=True,
)

agent.print_response("Show all the issues assigned to user id: 12021")
```

## Toolkit Params

| Parameter | Type  | Default | Description         |
| --------- | ----- | ------- | ------------------- |
| `api_key` | `str` | `None`  | Add Linear API key. |

## Toolkit Functions

| Function                   | Description                                                      |
| -------------------------- | ---------------------------------------------------------------- |
| `get_user_details`         | Fetch authenticated user details.                                |
| `get_issue_details`        | Retrieve details of a specific issue by issue ID.                |
| `create_issue`             | Create a new issue within a specific project and team.           |
| `update_issue`             | Update the title or state of a specific issue by issue ID.       |
| `get_user_assigned_issues` | Retrieve issues assigned to a specific user by user ID.          |
| `get_workflow_issues`      | Retrieve issues within a specific workflow state by workflow ID. |
| `get_high_priority_issues` | Retrieve issues with a high priority (priority `<=` 2).          |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/linear.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/linear_tools.py)


# Lumalabs
Source: https://docs.agno.com/concepts/tools/toolkits/others/lumalabs



**LumaLabTools** enables an Agent to generate media using the [Lumalabs platform](https://lumalabs.ai/dream-machine).

## Prerequisites

```shell
export LUMAAI_API_KEY=***
```

The following example requires the `lumaai` library. To install the Lumalabs client, run the following command:

```shell
pip install -U lumaai
```

## Example

The following agent will use Lumalabs to generate any video requested by the user.

```python cookbook/tools/lumalabs_tool.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.lumalab import LumaLabTools

luma_agent = Agent(
    name="Luma Video Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[LumaLabTools()],  # Using the LumaLab tool we created
    markdown=True,
    debug_mode=True,
        instructions=[
        "You are an agent designed to generate videos using the Luma AI API.",
        "You can generate videos in two ways:",
        "1. Text-to-Video Generation:",
        "2. Image-to-Video Generation:",
        "Choose the appropriate function based on whether the user provides image URLs or just a text prompt.",
        "The video will be displayed in the UI automatically below your response, so you don't need to show the video URL in your response.",
    ],
    system_message=(
        "Use generate_video for text-to-video requests and image_to_video for image-based "
        "generation. Don't modify default parameters unless specifically requested. "
        "Always provide clear feedback about the video generation status."
    ),
)

luma_agent.run("Generate a video of a car in a sky")
```

## Toolkit Params

| Parameter               | Type   | Default | Description                                          |
| ----------------------- | ------ | ------- | ---------------------------------------------------- |
| `api_key`               | `str`  | `None`  | If you want to manually supply the Lumalabs API key. |
| `enable_generate_video` | `bool` | `True`  | Enable the generate\_video functionality.            |
| `enable_image_to_video` | `bool` | `True`  | Enable the image\_to\_video functionality.           |
| `all`                   | `bool` | `False` | Enable all functionality.                            |

## Toolkit Functions

| Function         | Description                                                           |
| ---------------- | --------------------------------------------------------------------- |
| `generate_video` | Generate a video from a prompt.                                       |
| `image_to_video` | Generate a video from a prompt, a starting image and an ending image. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/lumalabs.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/lumalabs_tools.py)


# Mem0
Source: https://docs.agno.com/concepts/tools/toolkits/others/mem0

Mem0Tools provides intelligent memory management capabilities for agents using the Mem0 memory platform.

## Example

The following agent can store and retrieve memories using Mem0:

```python
from agno.agent import Agent
from agno.tools.mem0 import Mem0Tools

agent = Agent(
    instructions=[
        "You are a memory-enhanced assistant that can remember information across conversations",
        "Store important information about users and their preferences",
        "Retrieve relevant memories to provide personalized responses",
        "Manage memory effectively to improve user experience",
    ],
    tools=[Mem0Tools(user_id="user_123")],
)

agent.print_response("Remember that I prefer vegetarian meals and I'm allergic to nuts", stream=True)
```

## Toolkit Params

| Parameter                    | Type             | Default | Description                                     |
| ---------------------------- | ---------------- | ------- | ----------------------------------------------- |
| `config`                     | `Optional[Dict]` | `None`  | Mem0 configuration dictionary.                  |
| `api_key`                    | `Optional[str]`  | `None`  | Mem0 API key. Uses MEM0\_API\_KEY if not set.   |
| `user_id`                    | `Optional[str]`  | `None`  | User ID for memory operations.                  |
| `org_id`                     | `Optional[str]`  | `None`  | Organization ID. Uses MEM0\_ORG\_ID if not set. |
| `project_id`                 | `Optional[str]`  | `None`  | Project ID. Uses MEM0\_PROJECT\_ID if not set.  |
| `infer`                      | `bool`           | `True`  | Enable automatic memory inference.              |
| `enable_add_memory`          | `bool`           | `True`  | Enable memory addition functionality.           |
| `enable_search_memory`       | `bool`           | `True`  | Enable memory search functionality.             |
| `enable_get_all_memories`    | `bool`           | `True`  | Enable retrieving all memories functionality.   |
| `enable_delete_all_memories` | `bool`           | `True`  | Enable memory deletion functionality.           |

## Toolkit Functions

| Function              | Description                                   |
| --------------------- | --------------------------------------------- |
| `add_memory`          | Store new memories or information.            |
| `search_memory`       | Search through stored memories using queries. |
| `get_all_memories`    | Retrieve all stored memories for the user.    |
| `delete_all_memories` | Delete all stored memories for the user.      |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/mem0.py)
* [Mem0 Documentation](https://docs.mem0.ai/)
* [Mem0 Platform](https://mem0.ai/)


# Memori
Source: https://docs.agno.com/concepts/tools/toolkits/others/memori

MemoriTools provides persistent memory capabilities for agents with conversation history, user preferences, and long-term context.

## Example

The following agent can maintain persistent memory across conversations:

```python
from agno.agent import Agent
from agno.tools.memori import MemoriTools

agent = Agent(
    instructions=[
        "You are a memory-enhanced assistant with persistent conversation history",
        "Remember important information about users and their preferences",
        "Use stored memories to provide personalized and contextual responses",
        "Maintain conversation continuity across sessions",
    ],
    tools=[MemoriTools(
        database_url="sqlite:///memori.db",
        user_id="user_123"
    )],
)

agent.print_response("Remember that I prefer vegetarian recipes and I'm learning to cook Italian cuisine", stream=True)
```

## Toolkit Params

| Parameter                         | Type            | Default | Description                                            |
| --------------------------------- | --------------- | ------- | ------------------------------------------------------ |
| `database_url`                    | `str`           | `None`  | Database connection string (SQLite, PostgreSQL, etc.). |
| `user_id`                         | `Optional[str]` | `None`  | User identifier for memory isolation.                  |
| `session_id`                      | `Optional[str]` | `None`  | Session identifier for conversation tracking.          |
| `enable_store_memory`             | `bool`          | `True`  | Enable memory storage functionality.                   |
| `enable_retrieve_memory`          | `bool`          | `True`  | Enable memory retrieval functionality.                 |
| `enable_search_memory`            | `bool`          | `True`  | Enable memory search functionality.                    |
| `enable_delete_memory`            | `bool`          | `True`  | Enable memory deletion functionality.                  |
| `enable_get_conversation_history` | `bool`          | `True`  | Enable conversation history retrieval.                 |

## Toolkit Functions

| Function                   | Description                                   |
| -------------------------- | --------------------------------------------- |
| `store_memory`             | Store new memories or information.            |
| `retrieve_memory`          | Retrieve specific memories by ID or criteria. |
| `search_memory`            | Search through stored memories using queries. |
| `delete_memory`            | Delete specific memories or memory sets.      |
| `get_conversation_history` | Retrieve conversation history for context.    |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/memori.py)
* [Memori SDK Documentation](https://docs.memori.ai/)
* [Memory Management Best Practices](https://memori.ai/best-practices)


# MLX Transcribe
Source: https://docs.agno.com/concepts/tools/toolkits/others/mlx_transcribe



**MLX Transcribe** is a tool for transcribing audio files using MLX Whisper.

## Prerequisites

1. **Install ffmpeg**

   * macOS: `brew install ffmpeg`
   * Ubuntu: `sudo apt-get install ffmpeg`
   * Windows: Download from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)

2. **Install mlx-whisper library**

   ```shell
   pip install mlx-whisper
   ```

3. **Prepare audio files**

   * Create a 'storage/audio' directory
   * Place your audio files in this directory
   * Supported formats: mp3, mp4, wav, etc.

4. **Download sample audio** (optional)
   * Visit the [audio-samples](https://audio-samples.github.io/) (as an example) and save the audio file to the `storage/audio` directory.

## Example

The following agent will use MLX Transcribe to transcribe audio files.

```python cookbook/tools/mlx_transcribe_tools.py

from pathlib import Path
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mlx_transcribe import MLXTranscribeTools

# Get audio files from storage/audio directory
agno_root_dir = Path(__file__).parent.parent.parent.resolve()
audio_storage_dir = agno_root_dir.joinpath("storage/audio")
if not audio_storage_dir.exists():
    audio_storage_dir.mkdir(exist_ok=True, parents=True)

agent = Agent(
    name="Transcription Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[MLXTranscribeTools(base_dir=audio_storage_dir)],
    instructions=[
        "To transcribe an audio file, use the `transcribe` tool with the name of the audio file as the argument.",
        "You can find all available audio files using the `read_files` tool.",
    ],
    markdown=True,
)

agent.print_response("Summarize the reid hoffman ted talk, split into sections", stream=True)
```

## Toolkit Params

| Parameter                         | Type                           | Default                                  | Description                                  |
| --------------------------------- | ------------------------------ | ---------------------------------------- | -------------------------------------------- |
| `base_dir`                        | `Path`                         | `Path.cwd()`                             | Base directory for audio files               |
| `enable_read_files_in_base_dir`   | `bool`                         | `True`                                   | Whether to register the read\_files function |
| `path_or_hf_repo`                 | `str`                          | `"mlx-community/whisper-large-v3-turbo"` | Path or HuggingFace repo for the model       |
| `verbose`                         | `bool`                         | `None`                                   | Enable verbose output                        |
| `temperature`                     | `float` or `Tuple[float, ...]` | `None`                                   | Temperature for sampling                     |
| `compression_ratio_threshold`     | `float`                        | `None`                                   | Compression ratio threshold                  |
| `logprob_threshold`               | `float`                        | `None`                                   | Log probability threshold                    |
| `no_speech_threshold`             | `float`                        | `None`                                   | No speech threshold                          |
| `condition_on_previous_text`      | `bool`                         | `None`                                   | Whether to condition on previous text        |
| `initial_prompt`                  | `str`                          | `None`                                   | Initial prompt for transcription             |
| `word_timestamps`                 | `bool`                         | `None`                                   | Enable word-level timestamps                 |
| `prepend_punctuations`            | `str`                          | `None`                                   | Punctuations to prepend                      |
| `append_punctuations`             | `str`                          | `None`                                   | Punctuations to append                       |
| `clip_timestamps`                 | `str` or `List[float]`         | `None`                                   | Clip timestamps                              |
| `hallucination_silence_threshold` | `float`                        | `None`                                   | Hallucination silence threshold              |
| `decode_options`                  | `dict`                         | `None`                                   | Additional decoding options                  |

## Toolkit Functions

| Function     | Description                                 |
| ------------ | ------------------------------------------- |
| `transcribe` | Transcribes an audio file using MLX Whisper |
| `read_files` | Lists all audio files in the base directory |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/mlx_transcribe.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/mlx_transcribe_tools.py)


# ModelsLabs
Source: https://docs.agno.com/concepts/tools/toolkits/others/models_labs



## Prerequisites

You need to install the `requests` library.

```bash
pip install requests
```

Set the `MODELS_LAB_API_KEY` environment variable.

```bash
export MODELS_LAB_API_KEY=****
```

## Example

The following agent will use ModelsLabs to generate a video based on a text prompt.

```python cookbook/tools/models_labs_tools.py
from agno.agent import Agent
from agno.tools.models_labs import ModelsLabsTools

# Create an Agent with the ModelsLabs tool
agent = Agent(tools=[ModelsLabsTools()], name="ModelsLabs Agent")

agent.print_response("Generate a video of a beautiful sunset over the ocean", markdown=True)
```

## Toolkit Params

| Parameter             | Type   | Default | Description                                                                |
| --------------------- | ------ | ------- | -------------------------------------------------------------------------- |
| `api_key`             | `str`  | `None`  | The ModelsLab API key for authentication                                   |
| `wait_for_completion` | `bool` | `False` | Whether to wait for the video to be ready                                  |
| `add_to_eta`          | `int`  | `15`    | Time to add to the ETA to account for the time it takes to fetch the video |
| `max_wait_time`       | `int`  | `60`    | Maximum time to wait for the video to be ready                             |
| `file_type`           | `str`  | `"mp4"` | The type of file to generate                                               |

## Toolkit Functions

| Function         | Description                                     |
| ---------------- | ----------------------------------------------- |
| `generate_media` | Generates a video or gif based on a text prompt |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models_labs.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/models_labs_tools.py)


# MoviePy Video Tools
Source: https://docs.agno.com/concepts/tools/toolkits/others/moviepy

Agno MoviePyVideoTools enable an Agent to process videos, extract audio, generate SRT caption files, and embed rich, word-highlighted captions.

## Prerequisites

To use `MoviePyVideoTools`, you need to install `moviepy` and its dependency `ffmpeg`:

```shell
pip install moviepy ffmpeg
```

**Important for Captioning Workflow:**
The `create_srt` and `embed_captions` tools require a transcription of the video's audio. `MoviePyVideoTools` itself does not perform speech-to-text. You'll typically use another tool, such as `OpenAITools` with its `transcribe_audio` function, to generate the transcription (often in SRT format) which is then used by these tools.

## Example

The following example demonstrates a complete workflow where an agent uses `MoviePyVideoTools` in conjunction with `OpenAITools` to:

1. Extract audio from a video file
2. Transcribe the audio using OpenAI's speech-to-text
3. Generate an SRT caption file from the transcription
4. Embed the captions into the video with word-level highlighting

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.moviepy_video import MoviePyVideoTools
from agno.tools.openai import OpenAITools

video_tools = MoviePyVideoTools(
    process_video=True, generate_captions=True, embed_captions=True
)

openai_tools = OpenAITools()

video_caption_agent = Agent(
    name="Video Caption Generator Agent",
    model=OpenAIChat(
        id="gpt-5-mini",
    ),
    tools=[video_tools, openai_tools],
    description="You are an AI agent that can generate and embed captions for videos.",
    instructions=[
        "When a user provides a video, process it to generate captions.",
        "Use the video processing tools in this sequence:",
        "1. Extract audio from the video using extract_audio",
        "2. Transcribe the audio using transcribe_audio",
        "3. Generate SRT captions using create_srt",
        "4. Embed captions into the video using embed_captions",
    ],
    markdown=True,
)


video_caption_agent.print_response(
    "Generate captions for {video with location} and embed them in the video"
)
```

## Toolkit Functions

These are the functions exposed by `MoviePyVideoTools`:

| Function                | Description                                                                                            |
| ----------------------- | ------------------------------------------------------------------------------------------------------ |
| `enable_extract_audio`  | Extracts the audio track from a video file and saves it to a specified output path.                    |
| `enable_create_srt`     | Saves a given transcription (expected in SRT format) to a `.srt` file at the specified output path.    |
| `enable_embed_captions` | Embeds captions from an SRT file into a video, creating a new video file with word-level highlighting. |

## Toolkit Params

These parameters are passed to the `MoviePyVideoTools` constructor:

| Parameter           | Type   | Default | Description                        |
| ------------------- | ------ | ------- | ---------------------------------- |
| `process_video`     | `bool` | `True`  | Enables the `extract_audio` tool.  |
| `generate_captions` | `bool` | `True`  | Enables the `create_srt` tool.     |
| `embed_captions`    | `bool` | `True`  | Enables the `embed_captions` tool. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/moviepy_video.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/moviepy_video_tools.py)


# OpenBB
Source: https://docs.agno.com/concepts/tools/toolkits/others/openbb



**OpenBBTools** enable an Agent to provide information about stocks and companies.

```python cookbook/tools/openbb_tools.py
from agno.agent import Agent
from agno.tools.openbb import OpenBBTools


agent = Agent(tools=[OpenBBTools()], debug_mode=True)

# Example usage showing stock analysis
agent.print_response(
    "Get me the current stock price and key information for Apple (AAPL)"
)

# Example showing market analysis
agent.print_response(
    "What are the top gainers in the market today?"
)

# Example showing economic indicators
agent.print_response(
    "Show me the latest GDP growth rate and inflation numbers for the US"
)
```

## Toolkit Params

| Parameter                      | Type   | Default      | Description                                                                                                              |
| ------------------------------ | ------ | ------------ | ------------------------------------------------------------------------------------------------------------------------ |
| `obb`                          | `Any`  | `None`       | OpenBB app instance. If not provided, uses default.                                                                      |
| `openbb_pat`                   | `str`  | `None`       | Personal Access Token for OpenBB API authentication.                                                                     |
| `provider`                     | `str`  | `"yfinance"` | Data provider for financial information. Options: "benzinga", "fmp", "intrinio", "polygon", "tiingo", "tmx", "yfinance". |
| `enable_get_stock_price`       | `bool` | `True`       | Enable the stock price retrieval function.                                                                               |
| `enable_search_company_symbol` | `bool` | `False`      | Enable the company symbol search function.                                                                               |
| `enable_get_company_news`      | `bool` | `False`      | Enable the company news retrieval function.                                                                              |
| `enable_get_company_profile`   | `bool` | `False`      | Enable the company profile retrieval function.                                                                           |
| `enable_get_price_targets`     | `bool` | `False`      | Enable the price targets retrieval function.                                                                             |
| `all`                          | `bool` | `False`      | Enable all available functions. When True, all enable flags are ignored.                                                 |

## Toolkit Functions

| Function                | Description                                                                       |
| ----------------------- | --------------------------------------------------------------------------------- |
| `get_stock_price`       | This function gets the current stock price for a stock symbol or list of symbols. |
| `search_company_symbol` | This function searches for the stock symbol of a company.                         |
| `get_price_targets`     | This function gets the price targets for a stock symbol or list of symbols.       |
| `get_company_news`      | This function gets the latest news for a stock symbol or list of symbols.         |
| `get_company_profile`   | This function gets the company profile for a stock symbol or list of symbols.     |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/openbb.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/openbb_tools.py)


# OpenCV
Source: https://docs.agno.com/concepts/tools/toolkits/others/opencv

OpenCVTools enables agents to capture images and videos from webcam using OpenCV computer vision library.

## Example

The following agent can capture images and videos from your webcam:

```python
from agno.agent import Agent
from agno.tools.opencv import OpenCVTools

agent = Agent(
    instructions=[
        "You are a computer vision assistant that can capture images and videos",
        "Use the webcam to take photos or record videos as requested",
        "Provide clear feedback about capture operations",
        "Help with basic computer vision tasks",
    ],
    tools=[OpenCVTools()],
)

agent.print_response("Take a photo using the webcam", stream=True)
```

## Toolkit Params

| Parameter              | Type   | Default | Description                                           |
| ---------------------- | ------ | ------- | ----------------------------------------------------- |
| `show_preview`         | `bool` | `False` | Whether to show camera preview window during capture. |
| `enable_capture_image` | `bool` | `True`  | Enable image capture functionality.                   |
| `enable_capture_video` | `bool` | `True`  | Enable video capture functionality.                   |

## Toolkit Functions

| Function        | Description                                              |
| --------------- | -------------------------------------------------------- |
| `capture_image` | Capture a single image from the webcam.                  |
| `capture_video` | Record a video from the webcam for a specified duration. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/opencv.py)
* [OpenCV Documentation](https://docs.opencv.org/)


# OpenWeather
Source: https://docs.agno.com/concepts/tools/toolkits/others/openweather



**OpenWeatherTools** enable an Agent to access weather data from the OpenWeatherMap API.

## Prerequisites

The following example requires the `requests` library and an API key which can be obtained from [OpenWeatherMap](https://openweathermap.org/api). Once you sign up the mentioned api key will be activated in a few hours so please be patient.

```shell
export OPENWEATHER_API_KEY=***
```

## Example

The following agent will use OpenWeatherMap to get current weather information for Tokyo.

```python cookbook/tools/openweather_tools.py
from agno.agent import Agent
from agno.tools.openweather import OpenWeatherTools

# Create an agent with OpenWeatherTools
agent = Agent(
    tools=[
        OpenWeatherTools(
            units="imperial",  # Options: 'standard', 'metric', 'imperial'
        )
    ],
    markdown=True,
)

# Get current weather for a location
agent.print_response("What's the current weather in Tokyo?", markdown=True)
```

## Toolkit Params

| Parameter                | Type   | Default  | Description                                                                  |
| ------------------------ | ------ | -------- | ---------------------------------------------------------------------------- |
| `api_key`                | `str`  | `None`   | OpenWeatherMap API key. If not provided, uses OPENWEATHER\_API\_KEY env var. |
| `units`                  | `str`  | `metric` | Units of measurement. Options: 'standard', 'metric', 'imperial'.             |
| `enable_current_weather` | `bool` | `True`   | Enable current weather function.                                             |
| `enable_forecast`        | `bool` | `True`   | Enable forecast function.                                                    |
| `enable_air_pollution`   | `bool` | `True`   | Enable air pollution function.                                               |
| `enable_geocoding`       | `bool` | `True`   | Enable geocoding function.                                                   |

## Toolkit Functions

| Function              | Description                                                                                          |
| --------------------- | ---------------------------------------------------------------------------------------------------- |
| `get_current_weather` | Gets current weather data for a location. Takes a location name (e.g., "London").                    |
| `get_forecast`        | Gets weather forecast for a location. Takes a location name and optional number of days (default 5). |
| `get_air_pollution`   | Gets current air pollution data for a location. Takes a location name.                               |
| `geocode_location`    | Converts a location name to geographic coordinates. Takes a location name and optional result limit. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/openweather.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/openweather_tools.py)


# Reasoning
Source: https://docs.agno.com/concepts/tools/toolkits/others/reasoning

ReasoningTools provides step-by-step reasoning capabilities for agents to think through complex problems systematically.

## Example

The following agent can use structured reasoning to solve complex problems:

```python
from agno.agent import Agent
from agno.tools.reasoning import ReasoningTools

agent = Agent(
    instructions=[
        "You are a logical reasoning assistant that breaks down complex problems",
        "Use step-by-step thinking to analyze situations thoroughly",
        "Apply structured reasoning to reach well-founded conclusions",
        "Show your reasoning process clearly to help users understand your logic",
    ],
    tools=[ReasoningTools()],
)

agent.print_response("Analyze the pros and cons of remote work for software developers", stream=True)
```

## Toolkit Params

| Parameter           | Type            | Default | Description                                 |
| ------------------- | --------------- | ------- | ------------------------------------------- |
| `enable_think`      | `bool`          | `True`  | Enable the think reasoning function.        |
| `enable_analyze`    | `bool`          | `True`  | Enable the analyze reasoning function.      |
| `instructions`      | `Optional[str]` | `None`  | Custom instructions for reasoning behavior. |
| `add_instructions`  | `bool`          | `False` | Whether to add instructions to the agent.   |
| `add_few_shot`      | `bool`          | `False` | Whether to include few-shot examples.       |
| `few_shot_examples` | `Optional[str]` | `None`  | Custom few-shot examples for reasoning.     |

## Toolkit Functions

| Function  | Description                                                  |
| --------- | ------------------------------------------------------------ |
| `think`   | Perform step-by-step reasoning about a problem or situation. |
| `analyze` | Conduct detailed analysis with structured reasoning steps.   |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/reasoning.py)
* [Agno Reasoning Framework](https://docs.agno.com/reasoning)


# Replicate
Source: https://docs.agno.com/concepts/tools/toolkits/others/replicate



**ReplicateTools** enables an Agent to generate media using the [Replicate platform](https://replicate.com/).

## Prerequisites

```shell
export REPLICATE_API_TOKEN=***
```

The following example requires the `replicate` library. To install the Replicate client, run the following command:

```shell
pip install -U replicate
```

## Example

The following agent will use Replicate to generate images or videos requested by the user.

```python cookbook/tools/replicate_tool.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.replicate import ReplicateTools

"""Create an agent specialized for Replicate AI content generation"""

image_agent = Agent(
    name="Image Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ReplicateTools(model="luma/photon-flash")],
    description="You are an AI agent that can generate images using the Replicate API.",
    instructions=[
        "When the user asks you to create an image, use the `generate_media` tool to create the image.",
        "Return the URL as raw to the user.",
        "Don't convert image URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    )

image_agent.print_response("Generate an image of a horse in the dessert.")
```

## Toolkit Params

| Parameter               | Type   | Default            | Description                                                          |
| ----------------------- | ------ | ------------------ | -------------------------------------------------------------------- |
| `api_key`               | `str`  | `None`             | If you want to manually supply the Replicate API key.                |
| `model`                 | `str`  | `minimax/video-01` | The replicate model to use. Find out more on the Replicate platform. |
| `enable_generate_media` | `bool` | `True`             | Enable the generate\_media functionality.                            |
| `all`                   | `bool` | `False`            | Enable all functionality.                                            |

## Toolkit Functions

| Function         | Description                                                                         |
| ---------------- | ----------------------------------------------------------------------------------- |
| `generate_media` | Generate either an image or a video from a prompt. The output depends on the model. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/replicate.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/replicate_tools.py)


# Resend
Source: https://docs.agno.com/concepts/tools/toolkits/others/resend



**ResendTools** enable an Agent to send emails using Resend

## Prerequisites

The following example requires the `resend` library and an API key from [Resend](https://resend.com/).

```shell
pip install -U resend
```

```shell
export RESEND_API_KEY=***
```

## Example

The following agent will send an email using Resend

```python cookbook/tools/resend_tools.py
from agno.agent import Agent
from agno.tools.resend import ResendTools

from_email = "<enter_from_email>"
to_email = "<enter_to_email>"

agent = Agent(tools=[ResendTools(from_email=from_email)])
agent.print_response(f"Send an email to {to_email} greeting them with hello world")
```

## Toolkit Params

| Parameter           | Type   | Default | Description                                                   |
| ------------------- | ------ | ------- | ------------------------------------------------------------- |
| `api_key`           | `str`  | -       | API key for authentication purposes.                          |
| `from_email`        | `str`  | -       | The email address used as the sender in email communications. |
| `enable_send_email` | `bool` | `True`  | Enable the send\_email functionality.                         |
| `all`               | `bool` | `False` | Enable all functionality.                                     |

## Toolkit Functions

| Function     | Description                         |
| ------------ | ----------------------------------- |
| `send_email` | Send an email using the Resend API. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/resend.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/resend_tools.py)


# Todoist
Source: https://docs.agno.com/concepts/tools/toolkits/others/todoist



**TodoistTools** enables an Agent to interact with [Todoist](https://www.todoist.com/).

## Prerequisites

The following example requires the `todoist-api-python` library. and a Todoist API token which can be obtained from the [Todoist Developer Portal](https://app.todoist.com/app/settings/integrations/developer).

```shell
pip install todoist-api-python
```

```shell
export TODOIST_API_TOKEN=***
```

## Example

The following agent will create a new task in Todoist.

```python cookbook/tools/todoist.py
"""
Example showing how to use the Todoist Tools with Agno

Requirements:
- Sign up/login to Todoist and get a Todoist API Token (get from https://app.todoist.com/app/settings/integrations/developer)
- pip install todoist-api-python

Usage:
- Set the following environment variables:
    export TODOIST_API_TOKEN="your_api_token"

- Or provide them when creating the TodoistTools instance
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.todoist import TodoistTools

todoist_agent = Agent(
    name="Todoist Agent",
    role="Manage your todoist tasks",
    instructions=[
        "When given a task, create a todoist task for it.",
        "When given a list of tasks, create a todoist task for each one.",
        "When given a task to update, update the todoist task.",
        "When given a task to delete, delete the todoist task.",
        "When given a task to get, get the todoist task.",
    ],
    id="todoist-agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[TodoistTools()],
    markdown=True,
    debug_mode=True,
    )

# Example 1: Create a task
print("\n=== Create a task ===")
todoist_agent.print_response("Create a todoist task to buy groceries tomorrow at 10am")


# Example 2: Delete a task
print("\n=== Delete a task ===")
todoist_agent.print_response(
    "Delete the todoist task to buy groceries tomorrow at 10am"
)


# Example 3: Get all tasks
print("\n=== Get all tasks ===")
todoist_agent.print_response("Get all the todoist tasks")
```

## Toolkit Params

| Parameter   | Type  | Default | Description                                             |
| ----------- | ----- | ------- | ------------------------------------------------------- |
| `api_token` | `str` | `None`  | If you want to manually supply the TODOIST\_API\_TOKEN. |

## Toolkit Functions

| Function           | Description                                                                                     |
| ------------------ | ----------------------------------------------------------------------------------------------- |
| `create_task`      | Creates a new task in Todoist with optional project assignment, due date, priority, and labels. |
| `get_task`         | Fetches a specific task.                                                                        |
| `update_task`      | Updates an existing task with new properties such as content, due date, priority, etc.          |
| `close_task`       | Marks a task as completed.                                                                      |
| `delete_task`      | Deletes a specific task from Todoist.                                                           |
| `get_active_tasks` | Retrieves all active (non-completed) tasks.                                                     |
| `get_projects`     | Retrieves all projects in Todoist.                                                              |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/todoist.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/todoist_tool.py)


# Trello
Source: https://docs.agno.com/concepts/tools/toolkits/others/trello

Agno TrelloTools helps to integrate Trello functionalities into your agents, enabling management of boards, lists, and cards.

## Prerequisites

The following examples require the `trello` library and Trello API credentials which can be obtained by following Trello's developer documentation.

```shell
pip install -U trello
```

Set the following environment variables:

```shell
export TRELLO_API_KEY="YOUR_API_KEY"
export TRELLO_API_SECRET="YOUR_API_SECRET"
export TRELLO_TOKEN="YOUR_TOKEN"
```

## Example

The following agent will create a board called `ai-agent` and inside it create list called `todo` and `doing` and inside each of them create card called `create agent`.

```python
from agno.agent import Agent
from agno.tools.trello import TrelloTools

agent = Agent(
    instructions=[
        "You are a Trello management assistant that helps organize and manage Trello boards, lists, and cards",
        "Help users with tasks like:",
        "- Creating and organizing boards, lists, and cards",
        "- Moving cards between lists",
        "- Retrieving board and list information",
        "- Managing card details and descriptions",
        "Always confirm successful operations and provide relevant board/list/card IDs and URLs",
        "When errors occur, provide clear explanations and suggest solutions",
    ],
    tools=[TrelloTools()],
    )

agent.print_response(
    "Create a board called ai-agent and inside it create list called 'todo' and 'doing' and inside each of them create card called 'create agent'",
    stream=True,
)

```

## Toolkit Functions

| Function          | Description                                                   |
| ----------------- | ------------------------------------------------------------- |
| `create_card`     | Creates a new card in a specified board and list.             |
| `get_board_lists` | Retrieves all lists on a specified Trello board.              |
| `move_card`       | Moves a card to a different list.                             |
| `get_cards`       | Retrieves all cards from a specified list.                    |
| `create_board`    | Creates a new Trello board.                                   |
| `create_list`     | Creates a new list on a specified board.                      |
| `list_boards`     | Lists all Trello boards accessible by the authenticated user. |

## Toolkit Params

| Parameter    | Type            | Default | Description                                                                        |
| ------------ | --------------- | ------- | ---------------------------------------------------------------------------------- |
| `api_key`    | `Optional[str]` | `None`  | Trello API key. If not provided, uses TRELLO\_API\_KEY environment variable.       |
| `api_secret` | `Optional[str]` | `None`  | Trello API secret. If not provided, uses TRELLO\_API\_SECRET environment variable. |
| `token`      | `Optional[str]` | `None`  | Trello token. If not provided, uses TRELLO\_TOKEN environment variable.            |

### Board Filter Options for `list_boards`

The `list_boards` function accepts a `board_filter` argument with the following options:

* `all` (default)
* `open`
* `closed`
* `organization`
* `public`
* `starred`

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/trello.py)
* View [Cookbook Example](https://github.com/agno-agi/agno/tree/main/cookbook/tools/trello_tools.py)


# User Control Flow
Source: https://docs.agno.com/concepts/tools/toolkits/others/user_control_flow

UserControlFlowTools enable agents to pause execution and request input from users during conversations.

## Example

The following agent can request user input during conversations:

```python
from agno.agent import Agent
from agno.tools.user_control_flow import UserControlFlowTools

agent = Agent(
    instructions=[
        "You are an interactive assistant that can ask users for input when needed",
        "Use user input requests to gather specific information or clarify requirements",
        "Always explain why you need the user input and how it will be used",
        "Provide clear prompts and instructions for user responses",
    ],
    tools=[UserControlFlowTools()],
)

agent.print_response("Help me create a personalized workout plan", stream=True)
```

## Toolkit Params

| Parameter               | Type            | Default | Description                                        |
| ----------------------- | --------------- | ------- | -------------------------------------------------- |
| `instructions`          | `Optional[str]` | `None`  | Custom instructions for user interaction behavior. |
| `add_instructions`      | `bool`          | `True`  | Whether to add instructions to the agent.          |
| `enable_get_user_input` | `bool`          | `True`  | Enable user input request functionality.           |

## Toolkit Functions

| Function         | Description                                            |
| ---------------- | ------------------------------------------------------ |
| `get_user_input` | Pause agent execution and request input from the user. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/user_control_flow.py)
* [Agno Interactive Agents](https://docs.agno.com/interactive-agents)
* [User Input Patterns](https://docs.agno.com/user-input)


# Visualization
Source: https://docs.agno.com/concepts/tools/toolkits/others/visualization

VisualizationTools enables agents to create various types of charts and plots using matplotlib.

## Example

The following agent can create various types of data visualizations:

```python
from agno.agent import Agent
from agno.tools.visualization import VisualizationTools

agent = Agent(
    instructions=[
        "You are a data visualization assistant that creates charts and plots",
        "Generate clear, informative visualizations based on user data",
        "Save charts to files and provide insights about the data",
        "Choose appropriate chart types for different data patterns",
    ],
    tools=[VisualizationTools(output_dir="my_charts")],
)

agent.print_response("Create a bar chart showing sales by quarter: Q1=100, Q2=150, Q3=120, Q4=180", stream=True)
```

## Toolkit Params

| Parameter                    | Type   | Default    | Description                         |
| ---------------------------- | ------ | ---------- | ----------------------------------- |
| `output_dir`                 | `str`  | `"charts"` | Directory to save generated charts. |
| `enable_create_bar_chart`    | `bool` | `True`     | Enable bar chart creation.          |
| `enable_create_line_chart`   | `bool` | `True`     | Enable line chart creation.         |
| `enable_create_pie_chart`    | `bool` | `True`     | Enable pie chart creation.          |
| `enable_create_scatter_plot` | `bool` | `True`     | Enable scatter plot creation.       |
| `enable_create_histogram`    | `bool` | `True`     | Enable histogram creation.          |

## Toolkit Functions

| Function              | Description                                                 |
| --------------------- | ----------------------------------------------------------- |
| `create_bar_chart`    | Create bar charts for categorical data comparison.          |
| `create_line_chart`   | Create line charts for time series and trend visualization. |
| `create_pie_chart`    | Create pie charts for proportional data representation.     |
| `create_scatter_plot` | Create scatter plots for correlation analysis.              |
| `create_histogram`    | Create histograms for data distribution visualization.      |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/visualization.py)
* [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)


# Web Browser Tools
Source: https://docs.agno.com/concepts/tools/toolkits/others/web-browser

WebBrowser Tools enable an Agent to open a URL in a web browser.

## Example

```python cookbook/tools/webbrowser_tools.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.webbrowser import WebBrowserTools

agent = Agent(
    model=Gemini("gemini-2.0-flash"),
    tools=[WebBrowserTools(), DuckDuckGoTools()],
    instructions=[
        "Find related websites and pages using DuckDuckGo"
        "Use web browser to open the site"
    ],
        markdown=True,
)
agent.print_response("Find an article explaining MCP and open it in the web browser.")
```

## Toolkit Params

| Parameter          | Type   | Default | Description                                   |
| ------------------ | ------ | ------- | --------------------------------------------- |
| `enable_open_page` | `bool` | `True`  | Enables functionality to open URLs in browser |
| `all`              | `bool` | `False` | Enables all functionality when set to True    |

## Toolkit Functions

| Function    | Description                  |
| ----------- | ---------------------------- |
| `open_page` | Opens a URL in a web browser |


# Web Tools
Source: https://docs.agno.com/concepts/tools/toolkits/others/webtools

WebTools provides utilities for working with web URLs including URL expansion and web-related operations.

## Example

The following agent can work with web URLs and expand shortened links:

```python
from agno.agent import Agent
from agno.tools.webtools import WebTools

agent = Agent(
    instructions=[
        "You are a web utility assistant that helps with URL operations",
        "Expand shortened URLs to show their final destinations",
        "Help users understand where links lead before visiting them",
        "Provide clear information about URL expansions and redirects",
    ],
    tools=[WebTools()],
)

agent.print_response("Expand this shortened URL: https://bit.ly/3example", stream=True)
```

## Toolkit Params

| Parameter           | Type   | Default | Description                                  |
| ------------------- | ------ | ------- | -------------------------------------------- |
| `retries`           | `int`  | `3`     | Number of retry attempts for URL operations. |
| `enable_expand_url` | `bool` | `True`  | Enable URL expansion functionality.          |

## Toolkit Functions

| Function     | Description                                       |
| ------------ | ------------------------------------------------- |
| `expand_url` | Expand shortened URLs to their final destination. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/webtools.py)
* [HTTPX Documentation](https://www.python-httpx.org/)
* [URL Standards](https://tools.ietf.org/html/rfc3986)


# Yfinance
Source: https://docs.agno.com/concepts/tools/toolkits/others/yfinance



**YFinanceTools** enable an Agent to access stock data, financial information and more from Yahoo Finance.

## Prerequisites

The following example requires the `yfinance` library.

```shell
pip install -U yfinance
```

## Example

The following agent will provide information about the stock price and analyst recommendations for NVDA (Nvidia Corporation).

```python cookbook/tools/yfinance_tools.py
from agno.agent import Agent
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    tools=[YFinanceTools()],
    description="You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
    instructions=["Format your response using markdown and use tables to display data where possible."],
)
agent.print_response("Share the NVDA stock price and analyst recommendations", markdown=True)
```

## Toolkit Params

The YFinanceTools toolkit does not require any configuration parameters. All functions are enabled by default and do not have individual enable/disable flags. Simply instantiate the toolkit without any parameters.

## Toolkit Functions

| Function                      | Description                                                      |
| ----------------------------- | ---------------------------------------------------------------- |
| `get_current_stock_price`     | This function retrieves the current stock price of a company.    |
| `get_company_info`            | This function retrieves detailed information about a company.    |
| `get_historical_stock_prices` | This function retrieves historical stock prices for a company.   |
| `get_stock_fundamentals`      | This function retrieves fundamental data about a stock.          |
| `get_income_statements`       | This function retrieves income statements of a company.          |
| `get_key_financial_ratios`    | This function retrieves key financial ratios for a company.      |
| `get_analyst_recommendations` | This function retrieves analyst recommendations for a stock.     |
| `get_company_news`            | This function retrieves the latest news related to a company.    |
| `get_technical_indicators`    | This function retrieves technical indicators for stock analysis. |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/yfinance.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/yfinance_tools.py)


# Youtube
Source: https://docs.agno.com/concepts/tools/toolkits/others/youtube



**YouTubeTools** enable an Agent to access captions and metadata of YouTube videos, when provided with a video URL.

## Prerequisites

The following example requires the `youtube_transcript_api` library.

```shell
pip install -U youtube_transcript_api
```

## Example

The following agent will provide a summary of a YouTube video.

```python cookbook/tools/youtube_tools.py
from agno.agent import Agent
from agno.tools.youtube import YouTubeTools

agent = Agent(
    tools=[YouTubeTools()],
        description="You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.",
)

agent.print_response("Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t", markdown=True)
```

## Toolkit Params

| Param                         | Type        | Default | Description                                                                        |
| ----------------------------- | ----------- | ------- | ---------------------------------------------------------------------------------- |
| `get_video_captions`          | `bool`      | `True`  | Enables the functionality to retrieve video captions.                              |
| `get_video_data`              | `bool`      | `True`  | Enables the functionality to retrieve video metadata and other related data.       |
| `languages`                   | `List[str]` | -       | Specifies the list of languages for which data should be retrieved, if applicable. |
| `enable_get_video_captions`   | `bool`      | `True`  | Enable the get\_video\_captions functionality.                                     |
| `enable_get_video_data`       | `bool`      | `True`  | Enable the get\_video\_data functionality.                                         |
| `enable_get_video_timestamps` | `bool`      | `True`  | Enable the get\_video\_timestamps functionality.                                   |
| `all`                         | `bool`      | `False` | Enable all functionality.                                                          |

## Toolkit Functions

| Function                       | Description                                                |
| ------------------------------ | ---------------------------------------------------------- |
| `get_youtube_video_captions`   | This function retrieves the captions of a YouTube video.   |
| `get_youtube_video_data`       | This function retrieves the metadata of a YouTube video.   |
| `get_youtube_video_timestamps` | This function retrieves the timestamps of a YouTube video. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/youtube.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/youtube_tools.py)


# Zendesk
Source: https://docs.agno.com/concepts/tools/toolkits/others/zendesk



**ZendeskTools** enable an Agent to access Zendesk API to search for articles.

## Prerequisites

The following example requires the `requests` library and auth credentials.

```shell
pip install -U requests
```

```shell
export ZENDESK_USERNAME=***
export ZENDESK_PW=***
export ZENDESK_COMPANY_NAME=***
```

## Example

The following agent will run seach Zendesk for "How do I login?" and print the response.

```python cookbook/tools/zendesk_tools.py
from agno.agent import Agent
from agno.tools.zendesk import ZendeskTools

agent = Agent(tools=[ZendeskTools()])
agent.print_response("How do I login?", markdown=True)
```

## Toolkit Params

| Parameter               | Type   | Default | Description                                                             |
| ----------------------- | ------ | ------- | ----------------------------------------------------------------------- |
| `username`              | `str`  | -       | The username used for authentication or identification purposes.        |
| `password`              | `str`  | -       | The password associated with the username for authentication purposes.  |
| `company_name`          | `str`  | -       | The name of the company related to the user or the data being accessed. |
| `enable_search_zendesk` | `bool` | `True`  | Enable the search Zendesk functionality.                                |
| `all`                   | `bool` | `False` | Enable all functionality.                                               |

## Toolkit Functions

| Function         | Description                                                                                    |
| ---------------- | ---------------------------------------------------------------------------------------------- |
| `search_zendesk` | This function searches for articles in Zendesk Help Center that match the given search string. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/zendesk.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/zendesk_tools.py)


# Arxiv
Source: https://docs.agno.com/concepts/tools/toolkits/search/arxiv



**ArxivTools** enable an Agent to search for publications on Arxiv.

## Prerequisites

The following example requires the `arxiv` and `pypdf` libraries.

```shell
pip install -U arxiv pypdf
```

## Example

The following agent will run seach arXiv for "language models" and print the response.

```python cookbook/tools/arxiv_tools.py
from agno.agent import Agent
from agno.tools.arxiv import ArxivTools

agent = Agent(tools=[ArxivTools()])
agent.print_response("Search arxiv for 'language models'", markdown=True)
```

## Toolkit Params

| Parameter                  | Type   | Default | Description                                                        |
| -------------------------- | ------ | ------- | ------------------------------------------------------------------ |
| `enable_search_arxiv`      | `bool` | `True`  | Enables the functionality to search the arXiv database.            |
| `enable_read_arxiv_papers` | `bool` | `True`  | Allows reading of arXiv papers directly.                           |
| `download_dir`             | `Path` | -       | Specifies the directory path where downloaded files will be saved. |

## Toolkit Functions

| Function                                 | Description                                                                                        |
| ---------------------------------------- | -------------------------------------------------------------------------------------------------- |
| `search_arxiv_and_update_knowledge_base` | This function searches arXiv for a topic, adds the results to the knowledge base and returns them. |
| `search_arxiv`                           | Searches arXiv for a query.                                                                        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/arxiv.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/arxiv_tools.py)


# BaiduSearch
Source: https://docs.agno.com/concepts/tools/toolkits/search/baidusearch



**BaiduSearch** enables an Agent to search the web for information using the Baidu search engine.

## Prerequisites

The following example requires the `baidusearch` library. To install BaiduSearch, run the following command:

```shell
pip install -U baidusearch
```

## Example

```python cookbook/tools/baidusearch_tools.py
from agno.agent import Agent
from agno.tools.baidusearch import BaiduSearchTools

agent = Agent(
    tools=[BaiduSearchTools()],
    description="You are a search agent that helps users find the most relevant information using Baidu.",
    instructions=[
        "Given a topic by the user, respond with the 3 most relevant search results about that topic.",
        "Search for 5 results and select the top 3 unique items.",
        "Search in both English and Chinese.",
    ],
    )

agent.print_response("What are the latest advancements in AI?", markdown=True)
```

## Toolkit Params

| Parameter             | Type   | Default | Description                                                                                          |
| --------------------- | ------ | ------- | ---------------------------------------------------------------------------------------------------- |
| `fixed_max_results`   | `int`  | -       | Sets a fixed number of maximum results to return. No default is provided, must be specified if used. |
| `fixed_language`      | `str`  | -       | Set the fixed language for the results.                                                              |
| `headers`             | `Any`  | -       | Headers to be used in the search request.                                                            |
| `proxy`               | `str`  | -       | Specifies a single proxy address as a string to be used for the HTTP requests.                       |
| `timeout`             | `int`  | `10`    | Sets the timeout for HTTP requests, in seconds.                                                      |
| `enable_baidu_search` | `bool` | `True`  | Enable the baidu\_search functionality.                                                              |
| `all`                 | `bool` | `False` | Enable all functionality.                                                                            |

## Toolkit Functions

| Function       | Description                                    |
| -------------- | ---------------------------------------------- |
| `baidu_search` | Use this function to search Baidu for a query. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/baidusearch.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/baidusearch_tools.py)


# Brave Search
Source: https://docs.agno.com/concepts/tools/toolkits/search/bravesearch



**BraveSearch** enables an Agent to search the web for information using the Brave search engine.

## Prerequisites

The following examples requires the `brave-search` library.

```shell
pip install -U brave-search
```

```shell
export BRAVE_API_KEY=***
```

## Example

```python cookbook/tools/bravesearch_tools.py
from agno.agent import Agent
from agno.tools.bravesearch import BraveSearchTools

agent = Agent(
    tools=[BraveSearchTools()],
    description="You are a news agent that helps users find the latest news.",
    instructions=[
        "Given a topic by the user, respond with 4 latest news items about that topic."
    ],
    )
agent.print_response("AI Agents", markdown=True)

```

## Toolkit Params

| Parameter             | Type            | Default | Description                                                                    |
| --------------------- | --------------- | ------- | ------------------------------------------------------------------------------ |
| `api_key`             | `Optional[str]` | `None`  | Brave API key. If not provided, will use BRAVE\_API\_KEY environment variable. |
| `fixed_max_results`   | `Optional[int]` | `None`  | A fixed number of maximum results.                                             |
| `fixed_language`      | `Optional[str]` | `None`  | A fixed language for the search results.                                       |
| `enable_brave_search` | `bool`          | `True`  | Enable or disable the brave\_search function.                                  |
| `all`                 | `bool`          | `False` | Enable all available functions in the toolkit.                                 |

## Toolkit Functions

| Function       | Description                                                                                                                                                                                                                                                                                                                                                                       |
| -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `brave_search` | Searches Brave for a specified query. Parameters include `query` (str) for the search term, `max_results` (int, default=5) for the maximum number of results, `country` (str, default="US") for the country code for search results, and `search_lang` (str, default="en") for the language of the search results. Returns a JSON formatted string containing the search results. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/bravesearch.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/bravesearch_tools.py)


# DuckDuckGo
Source: https://docs.agno.com/concepts/tools/toolkits/search/duckduckgo



**DuckDuckGo** enables an Agent to search the web for information.

## Prerequisites

The following example requires the `ddgs` library. To install DuckDuckGo, run the following command:

```shell
pip install -U ddgs
```

## Example

```python cookbook/tools/duckduckgo.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(tools=[DuckDuckGoTools()])
agent.print_response("Whats happening in France?", markdown=True)
```

## Toolkit Params

| Parameter           | Type            | Default | Description                                           |
| ------------------- | --------------- | ------- | ----------------------------------------------------- |
| `enable_search`     | `bool`          | `True`  | Enable DuckDuckGo search function.                    |
| `enable_news`       | `bool`          | `True`  | Enable DuckDuckGo news function.                      |
| `all`               | `bool`          | `False` | Enable all available functions in the toolkit.        |
| `modifier`          | `Optional[str]` | `None`  | A modifier to be used in the search request.          |
| `fixed_max_results` | `Optional[int]` | `None`  | A fixed number of maximum results.                    |
| `proxy`             | `Optional[str]` | `None`  | Proxy to be used in the search request.               |
| `timeout`           | `Optional[int]` | `10`    | The maximum number of seconds to wait for a response. |
| `verify_ssl`        | `bool`          | `True`  | Whether to verify SSL certificates.                   |

## Toolkit Functions

| Function            | Description                                                                                                                                                                             |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `duckduckgo_search` | Search DuckDuckGo for a query. Parameters include `query` (str) for the search query and `max_results` (int, default=5) for maximum results. Returns JSON formatted search results.     |
| `duckduckgo_news`   | Get the latest news from DuckDuckGo. Parameters include `query` (str) for the search query and `max_results` (int, default=5) for maximum results. Returns JSON formatted news results. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/duckduckgo.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/duckduckgo_tools.py)


# Exa
Source: https://docs.agno.com/concepts/tools/toolkits/search/exa



**ExaTools** enable an Agent to search the web using Exa, retrieve content from URLs, find similar content, and get AI-powered answers.

## Prerequisites

The following examples require the `exa-py` library and an API key which can be obtained from [Exa](https://exa.ai).

```shell
pip install -U exa-py
```

```shell
export EXA_API_KEY=***
```

## Example

The following agent will search Exa for AAPL news and print the response.

```python cookbook/tools/exa_tools.py
from agno.agent import Agent
from agno.tools.exa import ExaTools

agent = Agent(
    tools=[ExaTools(
        include_domains=["cnbc.com", "reuters.com", "bloomberg.com"],
        category="news",
        show_results=True,
        text_length_limit=1000,
    )],
    )
agent.print_response("Search for AAPL news", markdown=True)
```

## Toolkit Functions

| Function       | Description                                                      |
| -------------- | ---------------------------------------------------------------- |
| `search_exa`   | Searches Exa for a query with optional category filtering        |
| `get_contents` | Retrieves detailed content from specific URLs                    |
| `find_similar` | Finds similar content to a given URL                             |
| `exa_answer`   | Gets an AI-powered answer to a question using Exa search results |

## Toolkit Params

| Parameter              | Type                  | Default    | Description                                        |
| ---------------------- | --------------------- | ---------- | -------------------------------------------------- |
| `enable_search`        | `bool`                | `True`     | Enable search functionality                        |
| `enable_get_contents`  | `bool`                | `True`     | Enable content retrieval                           |
| `enable_find_similar`  | `bool`                | `True`     | Enable finding similar content                     |
| `enable_answer`        | `bool`                | `True`     | Enable AI-powered answers                          |
| `enable_research`      | `bool`                | `True`     | Enable research functionality                      |
| `all`                  | `bool`                | `False`    | Enable all functionality                           |
| `text`                 | `bool`                | `True`     | Include text content in results                    |
| `text_length_limit`    | `int`                 | `1000`     | Maximum length of text content per result          |
| `highlights`           | `bool`                | `True`     | Include highlighted snippets                       |
| `summary`              | `bool`                | `False`    | Include result summaries                           |
| `num_results`          | `Optional[int]`       | `None`     | Default number of results                          |
| `livecrawl`            | `str`                 | `"always"` | Livecrawl behavior                                 |
| `start_crawl_date`     | `Optional[str]`       | `None`     | Include results crawled after date (YYYY-MM-DD)    |
| `end_crawl_date`       | `Optional[str]`       | `None`     | Include results crawled before date (YYYY-MM-DD)   |
| `start_published_date` | `Optional[str]`       | `None`     | Include results published after date (YYYY-MM-DD)  |
| `end_published_date`   | `Optional[str]`       | `None`     | Include results published before date (YYYY-MM-DD) |
| `use_autoprompt`       | `Optional[bool]`      | `None`     | Enable autoprompt features                         |
| `type`                 | `Optional[str]`       | `None`     | Content type filter (e.g., article, blog, video)   |
| `category`             | `Optional[str]`       | `None`     | Category filter (e.g., news, research paper)       |
| `include_domains`      | `Optional[List[str]]` | `None`     | Restrict results to these domains                  |
| `exclude_domains`      | `Optional[List[str]]` | `None`     | Exclude results from these domains                 |
| `show_results`         | `bool`                | `False`    | Log search results for debugging                   |
| `model`                | `Optional[str]`       | `None`     | Search model to use ('exa' or 'exa-pro')           |

### Categories

Available categories for filtering:

* company
* research paper
* news
* pdf
* github
* tweet
* personal site
* linkedin profile
* financial report

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/exa.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/exa_tools.py)


# Google Search
Source: https://docs.agno.com/concepts/tools/toolkits/search/googlesearch



**GoogleSearch** enables an Agent to perform web crawling and scraping tasks.

## Prerequisites

The following examples requires the `googlesearch` and `pycountry` libraries.

```shell
pip install -U googlesearch-python pycountry
```

## Example

The following agent will search Google for the latest news about "Mistral AI":

```python cookbook/tools/googlesearch_tools.py
from agno.agent import Agent
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    tools=[GoogleSearchTools()],
    description="You are a news agent that helps users find the latest news.",
    instructions=[
        "Given a topic by the user, respond with 4 latest news items about that topic.",
        "Search for 10 news items and select the top 4 unique items.",
        "Search in English and in French.",
    ],
        debug_mode=True,
)

agent.print_response("Mistral AI", markdown=True)
```

## Toolkit Params

| Parameter              | Type   | Default | Description                                        |
| ---------------------- | ------ | ------- | -------------------------------------------------- |
| `fixed_max_results`    | `int`  | `None`  | Optional fixed maximum number of results to return |
| `fixed_language`       | `str`  | `None`  | Optional fixed language for the requests           |
| `headers`              | `Any`  | `None`  | Optional headers to include in the requests        |
| `proxy`                | `str`  | `None`  | Optional proxy to be used for the requests         |
| `timeout`              | `int`  | `10`    | Timeout for the requests in seconds                |
| `enable_google_search` | `bool` | `True`  | Enables Google search functionality                |
| `all`                  | `bool` | `False` | Enables all functionality when set to True         |

## Toolkit Functions

| Function        | Description                                                                                                                                                                                                                                                                            |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `google_search` | Searches Google for a specified query. Parameters include `query` for the search term, `max_results` for the maximum number of results (default is 5), and `language` for the language of the search results (default is "en"). Returns the search results as a JSON formatted string. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/googlesearch.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/googlesearch_tools.py)


# Hacker News
Source: https://docs.agno.com/concepts/tools/toolkits/search/hackernews



**HackerNews** enables an Agent to search Hacker News website.

## Example

The following agent will write an engaging summary of the users with the top 2 stories on hackernews along with the stories.

```python cookbook/tools/hackernews.py
from agno.agent import Agent
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    name="Hackernews Team",
    tools=[HackerNewsTools()],
        markdown=True,
)

agent.print_response(
    "Write an engaging summary of the "
    "users with the top 2 stories on hackernews. "
    "Please mention the stories as well.",
)
```

## Toolkit Params

| Parameter                 | Type   | Default | Description                    |
| ------------------------- | ------ | ------- | ------------------------------ |
| `enable_get_top_stories`  | `bool` | `True`  | Enables fetching top stories.  |
| `enable_get_user_details` | `bool` | `True`  | Enables fetching user details. |
| `all`                     | `bool` | `False` | Enables all functionality.     |

## Toolkit Functions

| Function                     | Description                                                                                                                                                                      |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `get_top_hackernews_stories` | Retrieves the top stories from Hacker News. Parameters include `num_stories` to specify the number of stories to return (default is 10). Returns the top stories in JSON format. |
| `get_user_details`           | Retrieves the details of a Hacker News user by their username. Parameters include `username` to specify the user. Returns the user details in JSON format.                       |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/hackernews.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/hackernews_tools.py)


# Linkup
Source: https://docs.agno.com/concepts/tools/toolkits/search/linkup

LinkupTools provides advanced web search capabilities with deep search options and structured results.

## Example

The following agent can perform advanced web searches using Linkup:

```python
from agno.agent import Agent
from agno.tools.linkup import LinkupTools

agent = Agent(
    instructions=[
        "You are a web search assistant that provides comprehensive search results",
        "Use Linkup to find detailed and relevant information from the web",
        "Provide structured search results with source attribution",
        "Help users find accurate and up-to-date information",
    ],
    tools=[LinkupTools()],
)

agent.print_response("Search for the latest developments in quantum computing", stream=True)
```

## Toolkit Params

| Parameter                       | Type            | Default           | Description                                        |
| ------------------------------- | --------------- | ----------------- | -------------------------------------------------- |
| `api_key`                       | `Optional[str]` | `None`            | Linkup API key. Uses LINKUP\_API\_KEY if not set.  |
| `depth`                         | `Literal`       | `"standard"`      | Search depth: "standard" or "deep".                |
| `output_type`                   | `Literal`       | `"searchResults"` | Output format: "searchResults" or "sourcedAnswer". |
| `enable_web_search_with_linkup` | `bool`          | `True`            | Enable web search functionality.                   |

## Toolkit Functions

| Function                 | Description                                                       |
| ------------------------ | ----------------------------------------------------------------- |
| `web_search_with_linkup` | Perform advanced web searches with configurable depth and format. |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/linkup.py)
* [Linkup SDK Documentation](https://docs.linkup.com/)
* [Linkup API Reference](https://api.linkup.com/docs)


# Pubmed
Source: https://docs.agno.com/concepts/tools/toolkits/search/pubmed



**PubmedTools** enable an Agent to search for Pubmed for articles.

## Example

The following agent will search Pubmed for articles related to "ulcerative colitis".

```python cookbook/tools/pubmed.py
from agno.agent import Agent
from agno.tools.pubmed import PubmedTools

agent = Agent(tools=[PubmedTools()])
agent.print_response("Tell me about ulcerative colitis.")
```

## Toolkit Params

| Parameter              | Type   | Default                    | Description                                                            |
| ---------------------- | ------ | -------------------------- | ---------------------------------------------------------------------- |
| `email`                | `str`  | `"your_email@example.com"` | Specifies the email address to use.                                    |
| `max_results`          | `int`  | `None`                     | Optional parameter to specify the maximum number of results to return. |
| `enable_search_pubmed` | `bool` | `True`                     | Enable the search\_pubmed functionality.                               |
| `all`                  | `bool` | `False`                    | Enable all functionality.                                              |

## Toolkit Functions

| Function        | Description                                                                                                                                                                                                                                                                                 |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search_pubmed` | Searches PubMed for articles based on a specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results to return (default is 10). Returns a JSON string containing the search results, including publication date, title, and summary. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/pubmed.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/pubmed_tools.py)


# Searxng
Source: https://docs.agno.com/concepts/tools/toolkits/search/searxng



## Example

**Searxng** enables an Agent to search the web for a query, scrape a website, or crawl a website.

```python cookbook/tools/searxng_tools.py
from agno.agent import Agent
from agno.tools.searxng import SearxngTools

# Initialize Searxng with your Searxng instance URL
searxng = SearxngTools(
    host="http://localhost:53153",
    engines=[],
    fixed_max_results=5,
    news=True,
    science=True
)

# Create an agent with Searxng
agent = Agent(tools=[searxng])

# Example: Ask the agent to search using Searxng
agent.print_response("""
Please search for information about artificial intelligence
and summarize the key points from the top results
""")
```

## Toolkit Params

| Parameter           | Type        | Default | Description                                                        |
| ------------------- | ----------- | ------- | ------------------------------------------------------------------ |
| `host`              | `str`       | -       | The host for the connection.                                       |
| `engines`           | `List[str]` | `[]`    | A list of search engines to use.                                   |
| `fixed_max_results` | `int`       | `None`  | Optional parameter to specify the fixed maximum number of results. |

## Toolkit Functions

| Function         | Description                                                                                                                                                                                                                         |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search`         | Performs a general web search using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the search results.                             |
| `image_search`   | Performs an image search using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the image search results.                            |
| `it_search`      | Performs a search for IT-related information using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the IT-related search results.   |
| `map_search`     | Performs a search for maps using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the map search results.                            |
| `music_search`   | Performs a search for music-related information using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the music search results.     |
| `news_search`    | Performs a search for news using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the news search results.                           |
| `science_search` | Performs a search for science-related information using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the science search results. |
| `video_search`   | Performs a search for videos using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the video search results.                        |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/searxng.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/searxng_tools.py)


# Serpapi
Source: https://docs.agno.com/concepts/tools/toolkits/search/serpapi



**SerpApiTools** enable an Agent to search Google and YouTube for a query.

## Prerequisites

The following example requires the `google-search-results` library and an API key from [SerpApi](https://serpapi.com/).

```shell
pip install -U google-search-results
```

```shell
export SERP_API_KEY=***
```

## Example

The following agent will search Google for the query: "Whats happening in the USA" and share results.

```python cookbook/tools/serpapi_tools.py
from agno.agent import Agent
from agno.tools.serpapi import SerpApiTools

agent = Agent(tools=[SerpApiTools()])
agent.print_response("Whats happening in the USA?", markdown=True)
```

## Toolkit Params

| Parameter               | Type            | Default | Description                                                                     |
| ----------------------- | --------------- | ------- | ------------------------------------------------------------------------------- |
| `api_key`               | `Optional[str]` | `None`  | SerpApi API key. If not provided, will use SERP\_API\_KEY environment variable. |
| `enable_search_google`  | `bool`          | `True`  | Enable Google search functionality.                                             |
| `enable_search_youtube` | `bool`          | `False` | Enable YouTube search functionality.                                            |
| `all`                   | `bool`          | `False` | Enable all available functions in the toolkit.                                  |

## Toolkit Functions

| Function         | Description                                                                                                                                                                                                                                                                              |
| ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search_google`  | Search Google using the Serpapi API. Parameters include `query` (str) for the search query and `num_results` (int, default=10) for the number of results. Returns JSON formatted search results with organic results, recipes, shopping results, knowledge graph, and related questions. |
| `search_youtube` | Search YouTube using the Serpapi API. Parameters include `query` (str) for the search query. Returns JSON formatted search results with video results, movie results, and channel results.                                                                                               |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/serpapi.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/serpapi_tools.py)


# SerperApi
Source: https://docs.agno.com/concepts/tools/toolkits/search/serper



**SerperApiTools** enable an Agent to search Google for a query.

## Prerequisites

The following example requires an API key from [SerperApi](https://serper.dev/).

```shell
export SERPER_API_KEY=***
```

## Example

The following agent will search Google for the query: "Whats happening in the USA" and share results.

```python cookbook/tools/serper_tools.py
from agno.agent import Agent
from agno.tools.serper import SerperTools

agent = Agent(tools=[SerperTools(location="us")])
agent.print_response("Whats happening in the USA?", markdown=True)
```

## Toolkit Params

| Parameter               | Type   | Default | Description                               |
| ----------------------- | ------ | ------- | ----------------------------------------- |
| `api_key`               | `str`  | -       | API key for authentication purposes.      |
| `location`              | `str`  | `"us"`  | Location to search from.                  |
| `enable_search`         | `bool` | `True`  | Enable the search functionality.          |
| `enable_search_news`    | `bool` | `True`  | Enable the search\_news functionality.    |
| `enable_search_scholar` | `bool` | `True`  | Enable the search\_scholar functionality. |
| `enable_scrape_webpage` | `bool` | `True`  | Enable the scrape\_webpage functionality. |
| `all`                   | `bool` | `False` | Enable all functionality.                 |

## Toolkit Functions

| Function         | Description                                        |
| ---------------- | -------------------------------------------------- |
| `search_google`  | This function searches Google for a query.         |
| `search_news`    | This function searches Google News for a query.    |
| `search_scholar` | This function searches Google Scholar for a query. |
| `scrape_webpage` | This function scrapes a webpage for a query.       |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/serper.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/serper_tools.py)


# Tavily
Source: https://docs.agno.com/concepts/tools/toolkits/search/tavily



**TavilyTools** enable an Agent to search the web using the Tavily API.

## Prerequisites

The following examples requires the `tavily-python` library and an API key from [Tavily](https://tavily.com/).

```shell
pip install -U tavily-python
```

```shell
export TAVILY_API_KEY=***
```

## Example

The following agent will run a search on Tavily for "language models" and print the response.

```python cookbook/tools/tavily_tools.py
from agno.agent import Agent
from agno.tools.tavily import TavilyTools

agent = Agent(tools=[TavilyTools()])
agent.print_response("Search tavily for 'language models'", markdown=True)
```

## Toolkit Params

| Parameter               | Type                           | Default      | Description                                                                               |
| ----------------------- | ------------------------------ | ------------ | ----------------------------------------------------------------------------------------- |
| `api_key`               | `Optional[str]`                | `None`       | Tavily API key. If not provided, will use TAVILY\_API\_KEY environment variable.          |
| `enable_search`         | `bool`                         | `True`       | Enable search functionality.                                                              |
| `enable_search_context` | `bool`                         | `False`      | Enable search context functionality using Tavily's context API.                           |
| `all`                   | `bool`                         | `False`      | Enable all available functions in the toolkit.                                            |
| `max_tokens`            | `int`                          | `6000`       | Maximum number of tokens to use in search results.                                        |
| `include_answer`        | `bool`                         | `True`       | Whether to include an AI-generated answer summary in the response.                        |
| `search_depth`          | `Literal['basic', 'advanced']` | `'advanced'` | Depth of search - 'basic' for faster results or 'advanced' for more comprehensive search. |
| `format`                | `Literal['json', 'markdown']`  | `'markdown'` | Output format - 'json' for raw data or 'markdown' for formatted text.                     |

## Toolkit Functions

| Function                  | Description                                                                                                                                                                                                                                                                    |
| ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `web_search_using_tavily` | Search the web for a given query using Tavily API. Parameters include `query` (str) for the search query and `max_results` (int, default=5) for maximum number of results. Returns JSON string of results with titles, URLs, content and relevance scores in specified format. |
| `web_search_with_tavily`  | Alternative search function that uses Tavily's search context API. Parameters include `query` (str) for the search query. Returns contextualized search results. Only available when `enable_search_context` is True.                                                          |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/tavily.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/tavily_tools.py)


# Valyu
Source: https://docs.agno.com/concepts/tools/toolkits/search/valyu

ValyuTools provides academic and web search capabilities with advanced filtering and relevance scoring.

## Example

The following agent can perform academic and web searches:

```python
from agno.agent import Agent
from agno.tools.valyu import ValyuTools

agent = Agent(
    instructions=[
        "You are a research assistant that helps find academic papers and web content",
        "Use Valyu to search for high-quality, relevant information",
        "Provide detailed analysis of search results with relevance scores",
        "Focus on credible sources and academic publications",
    ],
    tools=[ValyuTools()],
)

agent.print_response("Find recent research papers about machine learning in healthcare", stream=True)
```

## Toolkit Params

| Parameter                | Type                  | Default | Description                                     |
| ------------------------ | --------------------- | ------- | ----------------------------------------------- |
| `api_key`                | `Optional[str]`       | `None`  | Valyu API key. Uses VALYU\_API\_KEY if not set. |
| `enable_academic_search` | `bool`                | `True`  | Enable academic sources search functionality.   |
| `enable_web_search`      | `bool`                | `True`  | Enable web search functionality.                |
| `enable_paper_search`    | `bool`                | `True`  | Enable search within paper functionality.       |
| `text_length`            | `int`                 | `1000`  | Maximum length of text content per result.      |
| `max_results`            | `int`                 | `10`    | Maximum number of results to return.            |
| `relevance_threshold`    | `float`               | `0.5`   | Minimum relevance score for results.            |
| `content_category`       | `Optional[str]`       | `None`  | Content category for filtering.                 |
| `search_start_date`      | `Optional[str]`       | `None`  | Start date for search filtering (YYYY-MM-DD).   |
| `search_end_date`        | `Optional[str]`       | `None`  | End date for search filtering (YYYY-MM-DD).     |
| `search_domains`         | `Optional[List[str]]` | `None`  | List of domains to search within.               |
| `sources`                | `Optional[List[str]]` | `None`  | List of specific sources to search.             |
| `max_price`              | `float`               | `30.0`  | Maximum price for API calls.                    |

## Toolkit Functions

| Function          | Description                                                   |
| ----------------- | ------------------------------------------------------------- |
| `academic_search` | Search academic sources for research papers and publications. |
| `web_search`      | Search web sources for general information and content.       |
| `paper_search`    | Search within specific papers for detailed information.       |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/valyu.py)
* [Valyu API Documentation](https://valyu.ai/docs)
* [Academic Search Best Practices](https://valyu.ai/academic-search)


# Wikipedia
Source: https://docs.agno.com/concepts/tools/toolkits/search/wikipedia



**WikipediaTools** enable an Agent to search wikipedia a website and add its contents to the knowledge base.

## Prerequisites

The following example requires the `wikipedia` library.

```shell
pip install -U wikipedia
```

## Example

The following agent will run seach wikipedia for "ai" and print the response.

```python cookbook/tools/wikipedia_tools.py
from agno.agent import Agent
from agno.tools.wikipedia import WikipediaTools

agent = Agent(tools=[WikipediaTools()])
agent.print_response("Search wikipedia for 'ai'")
```

## Toolkit Params

| Name        | Type        | Default | Description                                                                                                        |
| ----------- | ----------- | ------- | ------------------------------------------------------------------------------------------------------------------ |
| `knowledge` | `Knowledge` | -       | The knowledge base associated with Wikipedia, containing various data and resources linked to Wikipedia's content. |
| `all`       | `bool`      | `False` | Enable all functionality.                                                                                          |

## Toolkit Functions

| Function Name                                | Description                                                                                            |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| `search_wikipedia_and_update_knowledge_base` | This function searches wikipedia for a topic, adds the results to the knowledge base and returns them. |
| `search_wikipedia`                           | Searches Wikipedia for a query.                                                                        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/wikipedia.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/wikipedia_tools.py)


# Discord
Source: https://docs.agno.com/concepts/tools/toolkits/social/discord



**DiscordTools** enable an agent to send messages, read message history, manage channels, and delete messages in Discord.

## Prerequisites

The following example requires a Discord bot token which can be obtained from [here](https://discord.com/developers/applications).

```shell
export DISCORD_BOT_TOKEN=***
```

## Example

```python cookbook/tools/discord.py
from agno.agent import Agent
from agno.tools.discord import DiscordTools

agent = Agent(
    tools=[DiscordTools()],
        markdown=True,
)

agent.print_response("Send 'Hello World!' to channel 1234567890", markdown=True)
```

## Toolkit Params

| Parameter                   | Type   | Default | Description                                                   |
| --------------------------- | ------ | ------- | ------------------------------------------------------------- |
| `bot_token`                 | `str`  | -       | Discord bot token for authentication.                         |
| `enable_messaging`          | `bool` | `True`  | Whether to enable sending messages to channels.               |
| `enable_history`            | `bool` | `True`  | Whether to enable retrieving message history from channels.   |
| `enable_channel_management` | `bool` | `True`  | Whether to enable fetching channel info and listing channels. |
| `enable_message_management` | `bool` | `True`  | Whether to enable deleting messages from channels.            |

## Toolkit Functions

| Function               | Description                                                                                   |
| ---------------------- | --------------------------------------------------------------------------------------------- |
| `send_message`         | Send a message to a specified channel. Returns a success or error message.                    |
| `get_channel_info`     | Retrieve information about a specified channel. Returns the channel info as a JSON string.    |
| `list_channels`        | List all channels in a specified server (guild). Returns the list of channels as JSON.        |
| `get_channel_messages` | Retrieve message history from a specified channel. Returns messages as a JSON string.         |
| `delete_message`       | Delete a specific message by ID from a specified channel. Returns a success or error message. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/discord.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/discord.py)


# Email
Source: https://docs.agno.com/concepts/tools/toolkits/social/email



**EmailTools** enable an Agent to send an email to a user. The Agent can send an email to a user with a specific subject and body.

## Example

```python cookbook/tools/email_tools.py
from agno.agent import Agent
from agno.tools.email import EmailTools

receiver_email = "<receiver_email>"
sender_email = "<sender_email>"
sender_name = "<sender_name>"
sender_passkey = "<sender_passkey>"

agent = Agent(
    tools=[
        EmailTools(
            receiver_email=receiver_email,
            sender_email=sender_email,
            sender_name=sender_name,
            sender_passkey=sender_passkey,
        )
    ]
)

agent.print_response("send an email to <receiver_email>")
```

## Toolkit Params

| Parameter           | Type            | Default | Description                         |
| ------------------- | --------------- | ------- | ----------------------------------- |
| `receiver_email`    | `Optional[str]` | `None`  | The email address of the receiver.  |
| `sender_name`       | `Optional[str]` | `None`  | The name of the sender.             |
| `sender_email`      | `Optional[str]` | `None`  | The email address of the sender.    |
| `sender_passkey`    | `Optional[str]` | `None`  | The passkey for the sender's email. |
| `enable_email_user` | `bool`          | `True`  | Enable the email\_user function.    |
| `all`               | `bool`          | `False` | Enable all available functions.     |

## Toolkit Functions

| Function     | Description                                                                                                                                                                                                                       |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `email_user` | Emails the user with the given subject and body. Parameters include `subject` (str) for the email subject and `body` (str) for the email content. Currently works with Gmail. Returns "email sent successfully" or error message. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/email.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/email_tools.py)


# Gmail
Source: https://docs.agno.com/concepts/tools/toolkits/social/gmail



**Gmail** enables an Agent to interact with Gmail, allowing it to read, search, send, and manage emails.

## Prerequisites

The Gmail toolkit requires Google API client libraries and proper authentication setup. Install the required dependencies:

```shell
pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
```

You'll also need to set up Google Cloud credentials:

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a project or select an existing one
3. Enable the Gmail API
4. Create OAuth 2.0 credentials
5. Set up environment variables:

```shell
export GOOGLE_CLIENT_ID=your_client_id_here
export GOOGLE_CLIENT_SECRET=your_client_secret_here
export GOOGLE_PROJECT_ID=your_project_id_here
export GOOGLE_REDIRECT_URI=http://localhost  # Default value
```

## Example

```python cookbook/tools/gmail_tools.py
from agno.agent import Agent
from agno.tools.gmail import GmailTools

agent = Agent(tools=[GmailTools()])
agent.print_response("Show me my latest 5 unread emails", markdown=True)
```

## Toolkit Params

| Parameter          | Type          | Default | Description                          |
| ------------------ | ------------- | ------- | ------------------------------------ |
| `creds`            | `Credentials` | `None`  | Pre-fetched OAuth credentials        |
| `credentials_path` | `str`         | `None`  | Path to credentials file             |
| `token_path`       | `str`         | `None`  | Path to token file                   |
| `scopes`           | `List[str]`   | `None`  | Custom OAuth scopes                  |
| `port`             | `int`         | `None`  | Port to use for OAuth authentication |

## Toolkit Functions

| Function                | Description                                        |
| ----------------------- | -------------------------------------------------- |
| `get_latest_emails`     | Get the latest X emails from the user's inbox      |
| `get_emails_from_user`  | Get X number of emails from a specific sender      |
| `get_unread_emails`     | Get the latest X unread emails                     |
| `get_starred_emails`    | Get X number of starred emails                     |
| `get_emails_by_context` | Get X number of emails matching a specific context |
| `get_emails_by_date`    | Get emails within a specific date range            |
| `create_draft_email`    | Create and save an email draft                     |
| `send_email`            | Send an email immediately                          |
| `search_emails`         | Search emails using natural language queries       |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/gmail.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/gmail_tools.py)


# Reddit
Source: https://docs.agno.com/concepts/tools/toolkits/social/reddit

RedditTools enables agents to interact with Reddit for browsing posts, comments, and subreddit information.

## Example

The following agent can browse and analyze Reddit content:

```python
from agno.agent import Agent
from agno.tools.reddit import RedditTools

agent = Agent(
    instructions=[
        "You are a Reddit content analyst that helps explore and understand Reddit data",
        "Browse subreddits, analyze posts, and provide insights about discussions",
        "Respect Reddit's community guidelines and rate limits",
        "Provide clear summaries of Reddit content and trends",
    ],
    tools=[RedditTools()],
)

agent.print_response("Show me the top posts from r/technology today", stream=True)
```

## Toolkit Params

| Parameter         | Type                    | Default              | Description                                                   |
| ----------------- | ----------------------- | -------------------- | ------------------------------------------------------------- |
| `reddit_instance` | `Optional[praw.Reddit]` | `None`               | Existing Reddit instance to use.                              |
| `client_id`       | `Optional[str]`         | `None`               | Reddit client ID. Uses REDDIT\_CLIENT\_ID if not set.         |
| `client_secret`   | `Optional[str]`         | `None`               | Reddit client secret. Uses REDDIT\_CLIENT\_SECRET if not set. |
| `user_agent`      | `Optional[str]`         | `"RedditTools v1.0"` | User agent string for API requests.                           |
| `username`        | `Optional[str]`         | `None`               | Reddit username for authenticated access.                     |
| `password`        | `Optional[str]`         | `None`               | Reddit password for authenticated access.                     |

## Toolkit Functions

| Function              | Description                                              |
| --------------------- | -------------------------------------------------------- |
| `get_subreddit_info`  | Get information about a specific subreddit.              |
| `get_subreddit_posts` | Get posts from a subreddit with various sorting options. |
| `search_subreddits`   | Search for subreddits by name or topic.                  |
| `get_post_details`    | Get detailed information about a specific post.          |
| `get_post_comments`   | Get comments from a specific post.                       |
| `search_posts`        | Search for posts across Reddit or within subreddits.     |
| `get_user_info`       | Get information about a Reddit user.                     |
| `get_user_posts`      | Get posts submitted by a specific user.                  |
| `get_user_comments`   | Get comments made by a specific user.                    |
| `create_post`         | Create a new post (requires authentication).             |
| `create_comment`      | Create a comment on a post (requires authentication).    |
| `vote_on_post`        | Vote on a post (requires authentication).                |
| `vote_on_comment`     | Vote on a comment (requires authentication).             |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/reddit.py)
* [Reddit API Documentation](https://www.reddit.com/dev/api/)
* [PRAW Documentation](https://praw.readthedocs.io/)


# Slack
Source: https://docs.agno.com/concepts/tools/toolkits/social/slack



## Prerequisites

The following example requires the `slack-sdk` library.

```shell
pip install openai slack-sdk
```

Get a Slack token from [here](https://api.slack.com/tutorials/tracks/getting-a-token).

```shell
export SLACK_TOKEN=***
```

## Example

The following agent will use Slack to send a message to a channel, list all channels, and get the message history of a specific channel.

```python cookbook/tools/slack_tools.py
import os

from agno.agent import Agent
from agno.tools.slack import SlackTools

slack_tools = SlackTools()

agent = Agent(tools=[slack_tools])

# Example 1: Send a message to a Slack channel
agent.print_response("Send a message 'Hello from Agno!' to the channel #general", markdown=True)

# Example 2: List all channels in the Slack workspace
agent.print_response("List all channels in our Slack workspace", markdown=True)

# Example 3: Get the message history of a specific channel by channel ID
agent.print_response("Get the last 10 messages from the channel 1231241", markdown=True)

```

## Toolkit Params

| Parameter                    | Type   | Default | Description                                                     |
| ---------------------------- | ------ | ------- | --------------------------------------------------------------- |
| `token`                      | `str`  | `None`  | Slack API token for authentication                              |
| `enable_send_message`        | `bool` | `True`  | Enables functionality to send messages to Slack channels        |
| `enable_send_message_thread` | `bool` | `True`  | Enables functionality to send threaded messages                 |
| `enable_list_channels`       | `bool` | `True`  | Enables functionality to list available Slack channels          |
| `enable_get_channel_history` | `bool` | `True`  | Enables functionality to retrieve message history from channels |
| `all`                        | `bool` | `False` | Enables all functionality when set to True                      |

## Toolkit Functions

| Function              | Description                                         |
| --------------------- | --------------------------------------------------- |
| `send_message`        | Sends a message to a specified Slack channel        |
| `list_channels`       | Lists all available channels in the Slack workspace |
| `get_channel_history` | Retrieves message history from a specified channel  |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/slack.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/slack_tools.py)


# Telegram
Source: https://docs.agno.com/concepts/tools/toolkits/social/telegram



**TelegramTools** enable an Agent to send messages to a Telegram chat using the Telegram Bot API.

## Prerequisites

```shell
pip install -U agno httpx
```

```shell
export TELEGRAM_TOKEN=***
```

## Example

The following agent will send a message to a Telegram chat.

```python cookbook/tools/telegram_tools.py
from agno.agent import Agent
from agno.tools.telegram import TelegramTools

# How to get the token and chat_id:
# 1. Create a new bot with BotFather on Telegram. https://core.telegram.org/bots/features#creating-a-new-bot
# 2. Get the token from BotFather.
# 3. Send a message to the bot.
# 4. Get the chat_id by going to the URL:
#    https://api.telegram.org/bot/<your-bot-token>/getUpdates

telegram_token = "<enter-your-bot-token>"
chat_id = "<enter-your-chat-id>"

agent = Agent(
    name="telegram",
    tools=[TelegramTools(token=telegram_token, chat_id=chat_id)],
)

agent.print_response("Send message to telegram chat a paragraph about the moon")
```

## Toolkit Params

| Parameter             | Type              | Default | Description                                                                               |
| --------------------- | ----------------- | ------- | ----------------------------------------------------------------------------------------- |
| `token`               | `Optional[str]`   | `None`  | Telegram Bot API token. If not provided, will check TELEGRAM\_TOKEN environment variable. |
| `chat_id`             | `Union[str, int]` | -       | The ID of the chat to send messages to.                                                   |
| `enable_send_message` | `bool`            | `True`  | Enable the send\_message functionality.                                                   |
| `all`                 | `bool`            | `False` | Enable all functionality.                                                                 |

## Toolkit Functions

| Function       | Description                                                                                                                                                         |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `send_message` | Sends a message to the specified Telegram chat. Takes a message string as input and returns the API response as text. If an error occurs, returns an error message. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/telegram.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/telegram_tools.py)


# Twilio
Source: https://docs.agno.com/concepts/tools/toolkits/social/twilio



**TwilioTools** enables an Agent to interact with [Twilio](https://www.twilio.com/docs) services, such as sending SMS, retrieving call details, and listing messages.

## Prerequisites

The following examples require the `twilio` library and appropriate Twilio credentials, which can be obtained from [here](https://www.twilio.com/console).

```shell
pip install twilio
```

Set the following environment variables:

```shell
export TWILIO_ACCOUNT_SID=***
export TWILIO_AUTH_TOKEN=***
```

## Example

The following agent will send an SMS message using Twilio:

```python
from agno.agent import Agent
from agno.tools.twilio import TwilioTools

agent = Agent(
    instructions=[
        "Use your tools to send SMS using Twilio.",
    ],
    tools=[TwilioTools(debug=True)],
    )

agent.print_response("Send an SMS to +1234567890", markdown=True)
```

## Toolkit Params

| Name                      | Type            | Default | Description                                       |
| ------------------------- | --------------- | ------- | ------------------------------------------------- |
| `account_sid`             | `Optional[str]` | `None`  | Twilio Account SID for authentication.            |
| `auth_token`              | `Optional[str]` | `None`  | Twilio Auth Token for authentication.             |
| `api_key`                 | `Optional[str]` | `None`  | Twilio API Key for alternative authentication.    |
| `api_secret`              | `Optional[str]` | `None`  | Twilio API Secret for alternative authentication. |
| `region`                  | `Optional[str]` | `None`  | Optional Twilio region (e.g., `au1`).             |
| `edge`                    | `Optional[str]` | `None`  | Optional Twilio edge location (e.g., `sydney`).   |
| `debug`                   | `bool`          | `False` | Enable debug logging for troubleshooting.         |
| `enable_send_sms`         | `bool`          | `True`  | Enable the send\_sms functionality.               |
| `enable_get_call_details` | `bool`          | `True`  | Enable the get\_call\_details functionality.      |
| `enable_list_messages`    | `bool`          | `True`  | Enable the list\_messages functionality.          |
| `all`                     | `bool`          | `False` | Enable all functionality.                         |

## Toolkit Functions

| Function           | Description                                                                                                                                                                 |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `send_sms`         | Sends an SMS to a recipient. Takes recipient phone number, sender number (Twilio), and message body. Returns message SID if successful or error message if failed.          |
| `get_call_details` | Retrieves details of a call using its SID. Takes the call SID and returns a dictionary with call details (e.g., status, duration).                                          |
| `list_messages`    | Lists recent SMS messages. Takes a limit for the number of messages to return (default 20). Returns a list of message details (e.g., SID, sender, recipient, body, status). |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/twilio.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/twilio_tools.py)


# Webex
Source: https://docs.agno.com/concepts/tools/toolkits/social/webex



**WebexTools** enable an Agent to interact with Cisco Webex, allowing it to send messages and list rooms.

## Prerequisites

The following example requires the `webexpythonsdk` library and a Webex access token which can be obtained from [Webex Developer Portal](https://developer.webex.com/docs/bots).

To get started with Webex:

1. **Create a Webex Bot:**
   * Go to the [Developer Portal](https://developer.webex.com/)
   * Navigate to My Webex Apps ‚Üí Create a Bot
   * Fill in the bot details and click Add Bot

2. **Get your access token:**
   * Copy the token shown after bot creation
   * Or regenerate via My Webex Apps ‚Üí Edit Bot
   * Set as WEBEX\_ACCESS\_TOKEN environment variable

3. **Add the bot to Webex:**
   * Launch Webex and add the bot to a space
   * Use the bot's email (e.g. [test@webex.bot](mailto:test@webex.bot))

```shell
pip install webexpythonsdk
```

```shell
export WEBEX_ACCESS_TOKEN=your_access_token_here
```

## Example

The following agent will list all spaces and send a message using Webex:

```python cookbook/tools/webex_tool.py
from agno.agent import Agent
from agno.tools.webex import WebexTools

agent = Agent(tools=[WebexTools()])

# List all spaces in Webex
agent.print_response("List all space on our Webex", markdown=True)

# Send a message to a Space in Webex
agent.print_response(
    "Send a funny ice-breaking message to the webex Welcome space", markdown=True
)
```

## Toolkit Params

| Parameter             | Type   | Default | Description                                                                                             |
| --------------------- | ------ | ------- | ------------------------------------------------------------------------------------------------------- |
| `access_token`        | `str`  | `None`  | Webex access token for authentication. If not provided, uses WEBEX\_ACCESS\_TOKEN environment variable. |
| `enable_send_message` | `bool` | `True`  | Enable sending messages to Webex spaces.                                                                |
| `enable_list_rooms`   | `bool` | `True`  | Enable listing Webex spaces/rooms.                                                                      |
| `all`                 | `bool` | `False` | Enable all functionality.                                                                               |

## Toolkit Functions

| Function       | Description                                                                                                     |
| -------------- | --------------------------------------------------------------------------------------------------------------- |
| `send_message` | Sends a message to a Webex room. Parameters: `room_id` (str) for the target room, `text` (str) for the message. |
| `list_rooms`   | Lists all available Webex rooms/spaces with their details including ID, title, type, and visibility settings.   |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/webex.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/webex_tools.py)


# WhatsApp
Source: https://docs.agno.com/concepts/tools/toolkits/social/whatsapp



**WhatsAppTools** enable an Agent to interact with the WhatsApp Business API, allowing it to send text and template messages.

## Prerequisites

This cookbook demonstrates how to use WhatsApp integration with Agno. Before running this example,
you'''ll need to complete these setup steps:

1. Create Meta Developer Account
   * Go to [Meta Developer Portal](https://developers.facebook.com/) and create a new account
   * Create a new app at [Meta Apps Dashboard](https://developers.facebook.com/apps/)
   * Enable WhatsApp integration for your app [here](https://developers.facebook.com/docs/whatsapp/cloud-api/get-started)

2. Set Up WhatsApp Business API
   You can get your WhatsApp Business Account ID from [Business Settings](https://developers.facebook.com/docs/whatsapp/cloud-api/get-started)

3. Configure Environment
   * Set these environment variables:
     ```shell
     export WHATSAPP_ACCESS_TOKEN=your_access_token          # Access Token
     export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id    # Phone Number ID
     export WHATSAPP_RECIPIENT_WAID=your_recipient_waid      # Recipient WhatsApp ID (e.g. 1234567890)
     export WHATSAPP_VERSION=your_whatsapp_version           # WhatsApp API Version (e.g. v22.0)
     ```

Important Notes:

* For first-time outreach, you must use pre-approved message templates
  [here](https://developers.facebook.com/docs/whatsapp/cloud-api/guides/send-message-templates)
* Test messages can only be sent to numbers that are registered in your test environment

The example below shows how to send a template message using Agno'''s WhatsApp tools.
For more complex use cases, check out the WhatsApp Cloud API documentation:
[here](https://developers.facebook.com/docs/whatsapp/cloud-api/overview)

## Example

The following agent will send a template message using WhatsApp:

```python cookbook/tools/whatsapp_tool.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.whatsapp import WhatsAppTools

agent = Agent(
    name="whatsapp",
    model=Gemini(id="gemini-2.0-flash"),
    tools=[WhatsAppTools()]
)

# Example: Send a template message
# Note: Replace '''hello_world''' with your actual template name
# and +91 1234567890 with the recipient's WhatsApp ID
agent.print_response(
    "Send a template message using the '''hello_world''' template in English to +91 1234567890"
)
```

## Toolkit Params

| Parameter         | Type            | Default   | Description                                                                                                               |
| ----------------- | --------------- | --------- | ------------------------------------------------------------------------------------------------------------------------- |
| `access_token`    | `Optional[str]` | `None`    | WhatsApp Business API access token. If not provided, uses `WHATSAPP_ACCESS_TOKEN` environment variable.                   |
| `phone_number_id` | `Optional[str]` | `None`    | WhatsApp Business Account phone number ID. If not provided, uses `WHATSAPP_PHONE_NUMBER_ID` environment variable.         |
| `version`         | `str`           | `"v22.0"` | API version to use. If not provided, uses `WHATSAPP_VERSION` environment variable or defaults to "v22.0".                 |
| `recipient_waid`  | `Optional[str]` | `None`    | Default recipient WhatsApp ID (e.g., "1234567890"). If not provided, uses `WHATSAPP_RECIPIENT_WAID` environment variable. |
| `async_mode`      | `bool`          | `False`   | Enable asynchronous methods for sending messages.                                                                         |

## Toolkit Functions

| Function                      | Description                                                                                                                                                                                           |
| ----------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `send_text_message_sync`      | Sends a text message to a WhatsApp user (synchronous). Parameters: `text` (str), `recipient` (Optional\[str]), `preview_url` (bool), `recipient_type` (str).                                          |
| `send_template_message_sync`  | Sends a template message to a WhatsApp user (synchronous). Parameters: `recipient` (Optional\[str]), `template_name` (str), `language_code` (str), `components` (Optional\[List\[Dict\[str, Any]]]).  |
| `send_text_message_async`     | Sends a text message to a WhatsApp user (asynchronous). Parameters: `text` (str), `recipient` (Optional\[str]), `preview_url` (bool), `recipient_type` (str).                                         |
| `send_template_message_async` | Sends a template message to a WhatsApp user (asynchronous). Parameters: `recipient` (Optional\[str]), `template_name` (str), `language_code` (str), `components` (Optional\[List\[Dict\[str, Any]]]). |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/whatsapp.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/whatsapp_tools.py)


# X (Twitter)
Source: https://docs.agno.com/concepts/tools/toolkits/social/x



**XTools** allows an Agent to interact with X, providing functionality for posting, messaging, and searching tweets.

## Prerequisites

Install the required library:

```shell
pip install tweepy
```

<Info>Tweepy is a Python library for interacting with the X API.</Info>

## Setup

1. **Create X Developer Account**

   * Visit [developer.x.com](https://developer.x.com) and apply for developer access
   * Create a new project and app in your developer portal

2. **Generate API Credentials**

   * Navigate to your app's "Keys and tokens" section
   * Generate and copy these credentials:
     * API Key & Secret
     * Bearer Token
     * Access Token & Secret

3. **Configure Environment**
   ```shell
   export X_CONSUMER_KEY=your_api_key
   export X_CONSUMER_SECRET=your_api_secret
   export X_ACCESS_TOKEN=your_access_token
   export X_ACCESS_TOKEN_SECRET=your_access_token_secret
   export X_BEARER_TOKEN=your_bearer_token
   ```

## Example

```python cookbook/tools/x_tools.py
from agno.agent import Agent
from agno.tools.x import XTools

# Initialize the X toolkit
x_tools = XTools(
    wait_on_rate_limit=True # Retry when rate limits are reached
)

# Create an agent equipped with X toolkit
agent = Agent(
    instructions=[
        "Use X tools to interact as the authorized user",
        "Generate appropriate content when asked to create posts",
        "Only post content when explicitly instructed",
        "Respect X's usage policies and rate limits",
    ],
    tools=[x_tools],
    )

# Search for posts
agent.print_response("Search for recent posts about AI agents", markdown=True)

# Create and post a tweet
agent.print_response("Create a post about AI ethics", markdown=True)

# Get user timeline
agent.print_response("Get my timeline", markdown=True)

# Reply to a post
agent.print_response(
    "Can you reply to this [post ID] post as a general message as to how great this project is: https://x.com/AgnoAgi",
    markdown=True,
)

# Get information about a user
agent.print_response("Can you retrieve information about this user https://x.com/AgnoAgi ", markdown=True)

# Send a direct message
agent.print_response(
    "Send direct message to the user @AgnoAgi telling them I want to learn more about them and a link to their community.",
    markdown=True,
)

# Get user profile
agent.print_response("Get my X profile", markdown=True)
```

<Note>
  {" "}

  Check out the [Tweet Analysis Agent](/examples/use-cases/agents/tweet-analysis-agent)
  for a more advanced example.{" "}
</Note>

## Toolkit Params

| Parameter              | Type   | Default | Description                                                    |
| ---------------------- | ------ | ------- | -------------------------------------------------------------- |
| `bearer_token`         | `str`  | `None`  | Bearer token for authentication                                |
| `consumer_key`         | `str`  | `None`  | Consumer key for authentication                                |
| `consumer_secret`      | `str`  | `None`  | Consumer secret for authentication                             |
| `access_token`         | `str`  | `None`  | Access token for authentication                                |
| `access_token_secret`  | `str`  | `None`  | Access token secret for authentication                         |
| `include_post_metrics` | `bool` | `False` | Include post metrics (likes, retweets, etc.) in search results |
| `wait_on_rate_limit`   | `bool` | `False` | Retry when rate limits are reached                             |

## Toolkit Functions

| Function            | Description                                 |
| ------------------- | ------------------------------------------- |
| `create_post`       | Creates and posts a new post                |
| `reply_to_post`     | Replies to an existing post                 |
| `send_dm`           | Sends a direct message to a X user          |
| `get_user_info`     | Retrieves information about a X user        |
| `get_home_timeline` | Gets the authenticated user's home timeline |
| `search_posts`      | Searches for tweets                         |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/x.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/x_tools.py)
* View [Tweet Analysis Agent Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/examples/agents/social_media_agent.py)


# Zoom
Source: https://docs.agno.com/concepts/tools/toolkits/social/zoom



**Zoom** enables an Agent to interact with Zoom, allowing it to schedule meetings, manage recordings, and handle various meeting-related operations through the Zoom API. The toolkit uses Zoom's Server-to-Server OAuth authentication for secure API access.

## Prerequisites

The Zoom toolkit requires the following setup:

1. Install required dependencies:

```shell
pip install requests
```

2. Set up Server-to-Server OAuth app in Zoom Marketplace:

   * Go to [Zoom Marketplace](https://marketplace.zoom.us/)
   * Click "Develop" ‚Üí "Build App"
   * Choose "Server-to-Server OAuth" app type
   * Configure the app with required scopes:
     * `/meeting:write:admin`
     * `/meeting:read:admin`
     * `/recording:read:admin`
   * Note your Account ID, Client ID, and Client Secret

3. Set up environment variables:

```shell
export ZOOM_ACCOUNT_ID=your_account_id
export ZOOM_CLIENT_ID=your_client_id
export ZOOM_CLIENT_SECRET=your_client_secret
```

## Example Usage

```python
from agno.agent import Agent
from agno.tools.zoom import ZoomTools

# Initialize Zoom tools with credentials
zoom_tools = ZoomTools(
    account_id="your_account_id",
    client_id="your_client_id",
    client_secret="your_client_secret"
)

# Create an agent with Zoom capabilities
agent = Agent(tools=[zoom_tools])

# Schedule a meeting
response = agent.print_response("""
Schedule a team meeting with the following details:
- Topic: Weekly Team Sync
- Time: Tomorrow at 2 PM UTC
- Duration: 45 minutes
""", markdown=True)
```

## Toolkit Params

| Parameter       | Type            | Default | Description                                                                          |
| --------------- | --------------- | ------- | ------------------------------------------------------------------------------------ |
| `account_id`    | `Optional[str]` | `None`  | Zoom account ID. If not provided, uses ZOOM\_ACCOUNT\_ID environment variable.       |
| `client_id`     | `Optional[str]` | `None`  | Zoom client ID. If not provided, uses ZOOM\_CLIENT\_ID environment variable.         |
| `client_secret` | `Optional[str]` | `None`  | Zoom client secret. If not provided, uses ZOOM\_CLIENT\_SECRET environment variable. |

## Toolkit Functions

| Function                 | Description                                       |
| ------------------------ | ------------------------------------------------- |
| `schedule_meeting`       | Schedule a new Zoom meeting                       |
| `get_upcoming_meetings`  | Get a list of upcoming meetings                   |
| `list_meetings`          | List all meetings based on type                   |
| `get_meeting_recordings` | Get recordings for a specific meeting             |
| `delete_meeting`         | Delete a scheduled meeting                        |
| `get_meeting`            | Get detailed information about a specific meeting |

You can use `include_tools` or `exclude_tools` to modify the list of tools the agent has access to. Learn more about [selecting tools](/concepts/tools/selecting-tools).

## Rate Limits

The Zoom API has rate limits that vary by endpoint and account type:

* Server-to-Server OAuth apps: 100 requests/second
* Meeting endpoints: Specific limits apply based on account type
* Recording endpoints: Lower rate limits, check Zoom documentation

For detailed rate limits, refer to [Zoom API Rate Limits](https://developers.zoom.us/docs/api/#rate-limits).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/zoom.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/zoom_tools.py)


# Toolkit Index
Source: https://docs.agno.com/concepts/tools/toolkits/toolkits



A **Toolkit** is a collection of functions that can be added to an Agent. The functions in a Toolkit are designed to work together, share internal state and provide a better development experience.

The following **Toolkits** are available to use

## Search

<CardGroup cols={3}>
  <Card title="Arxiv" icon="book" iconType="duotone" href="/concepts/tools/toolkits/search/arxiv">
    Tools to read arXiv papers.
  </Card>

  <Card title="BaiduSearch" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/baidusearch">
    Tools to search the web using Baidu.
  </Card>

  <Card title="DuckDuckGo" icon="duck" iconType="duotone" href="/concepts/tools/toolkits/search/duckduckgo">
    Tools to search the web using DuckDuckGo.
  </Card>

  <Card title="Exa" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/exa">
    Tools to search the web using Exa.
  </Card>

  <Card title="Google Search" icon="google" iconType="duotone" href="/concepts/tools/toolkits/search/googlesearch">
    Tools to search Google.
  </Card>

  <Card title="HackerNews" icon="newspaper" iconType="duotone" href="/concepts/tools/toolkits/search/hackernews">
    Tools to read Hacker News articles.
  </Card>

  <Card title="Pubmed" icon="file-medical" iconType="duotone" href="/concepts/tools/toolkits/search/pubmed">
    Tools to search Pubmed.
  </Card>

  <Card title="SearxNG" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/searxng">
    Tools to search the web using SearxNG.
  </Card>

  <Card title="SerperApi" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/serpapi">
    Tools to search Google using SerperApi.
  </Card>

  <Card title="Serpapi" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/serper">
    Tools to search Google, YouTube, and more using Serpapi.
  </Card>

  <Card title="Tavily" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/tavily">
    Tools to search the web using Tavily.
  </Card>

  <Card title="Linkup" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/linkup">
    Tools to search the web using Linkup.
  </Card>

  <Card title="Valyu" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/search/valyu">
    Tools to search academic papers and web content using Valyu.
  </Card>

  <Card title="Wikipedia" icon="book" iconType="duotone" href="/concepts/tools/toolkits/search/wikipedia">
    Tools to search Wikipedia.
  </Card>
</CardGroup>

## Social

<CardGroup cols={3}>
  <Card title="Discord" icon="comment" iconType="duotone" href="/concepts/tools/toolkits/social/discord">
    Tools to interact with Discord.
  </Card>

  <Card title="Email" icon="envelope" iconType="duotone" href="/concepts/tools/toolkits/social/email">
    Tools to send emails.
  </Card>

  <Card title="Gmail" icon="envelope" iconType="duotone" href="/concepts/tools/toolkits/social/gmail">
    Tools to interact with Gmail.
  </Card>

  <Card title="Slack" icon="slack" iconType="duotone" href="/concepts/tools/toolkits/social/slack">
    Tools to interact with Slack.
  </Card>

  <Card title="Telegram" icon="telegram" iconType="brands" href="/concepts/tools/toolkits/social/telegram">
    Tools to interact with Telegram.
  </Card>

  <Card title="Twilio" icon="mobile-screen-button" iconType="duotone" href="/concepts/tools/toolkits/social/twilio">
    Tools to interact with Twilio services.
  </Card>

  <Card title="WhatsApp" icon="whatsapp" iconType="brands" href="/concepts/tools/toolkits/social/whatsapp">
    Tools to interact with WhatsApp.
  </Card>

  <Card title="Webex" icon="message" iconType="duotone" href="/concepts/tools/toolkits/social/webex">
    Tools to interact with Cisco Webex.
  </Card>

  <Card title="X (Twitter)" icon="x-twitter" iconType="brands" href="/concepts/tools/toolkits/social/x">
    Tools to interact with X.
  </Card>

  <Card title="Reddit" icon="reddit" iconType="brands" href="/concepts/tools/toolkits/social/reddit">
    Tools to interact with Reddit.
  </Card>

  <Card title="Zoom" icon="video" iconType="duotone" href="/concepts/tools/toolkits/social/zoom">
    Tools to interact with Zoom.
  </Card>
</CardGroup>

## Web Scraping

<CardGroup cols={3}>
  <Card title="AgentQL" icon="magnifying-glass" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/agentql">
    Browse and scrape websites using AgentQL.
  </Card>

  <Card title="BrowserBase" icon="browser" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/browserbase">
    Tools to interact with BrowserBase.
  </Card>

  <Card title="Crawl4AI" icon="spider" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/crawl4ai">
    Tools to crawl web data.
  </Card>

  <Card title="Jina Reader" icon="robot" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/jina_reader">
    Tools for neural search and AI services using Jina.
  </Card>

  <Card title="Newspaper" icon="newspaper" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/newspaper">
    Tools to read news articles.
  </Card>

  <Card title="Newspaper4k" icon="newspaper" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/newspaper4k">
    Tools to read articles using Newspaper4k.
  </Card>

  <Card title="Website" icon="globe" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/website">
    Tools to scrape websites.
  </Card>

  <Card title="Firecrawl" icon="fire" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/firecrawl">
    Tools to crawl the web using Firecrawl.
  </Card>

  <Card title="Spider" icon="spider" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/spider">
    Tools to crawl websites.
  </Card>

  <Card title="Trafilatura" icon="text" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/trafilatura">
    Tools to extract text content from web pages.
  </Card>

  <Card title="BrightData" icon="screen-users" iconType="duotone" href="/concepts/tools/toolkits/web_scrape/brightdata">
    Tools to scrape websites using BrightData.
  </Card>
</CardGroup>

## Data

<CardGroup cols={3}>
  <Card title="CSV" icon="file-csv" iconType="duotone" href="/concepts/tools/toolkits/database/csv">
    Tools to work with CSV files.
  </Card>

  <Card title="DuckDb" icon="server" iconType="duotone" href="/concepts/tools/toolkits/database/duckdb">
    Tools to run SQL using DuckDb.
  </Card>

  <Card title="Pandas" icon="table" iconType="duotone" href="/concepts/tools/toolkits/database/pandas">
    Tools to manipulate data using Pandas.
  </Card>

  <Card title="Postgres" icon="database" iconType="duotone" href="/concepts/tools/toolkits/database/postgres">
    Tools to interact with PostgreSQL databases.
  </Card>

  <Card title="SQL" icon="database" iconType="duotone" href="/concepts/tools/toolkits/database/sql">
    Tools to run SQL queries.
  </Card>

  <Card title="Google BigQuery" icon="database" iconType="duotone" href="/concepts/tools/toolkits/database/google_bigquery">
    Tools to query large datasets using Google BigQuery.
  </Card>

  <Card title="Neo4j" icon="project-diagram" iconType="duotone" href="/concepts/tools/toolkits/database/neo4j">
    Tools to interact with Neo4j graph databases.
  </Card>

  <Card title="Zep" icon="memory" iconType="duotone" href="/concepts/tools/toolkits/database/zep">
    Tools to interact with Zep.
  </Card>
</CardGroup>

## Local

<CardGroup cols={3}>
  <Card title="Calculator" icon="calculator" iconType="duotone" href="/concepts/tools/toolkits/local/calculator">
    Tools to perform calculations.
  </Card>

  <Card title="Docker" icon="docker" iconType="duotone" href="/concepts/tools/toolkits/local/docker">
    Tools to interact with Docker.
  </Card>

  <Card title="File" icon="file" iconType="duotone" href="/concepts/tools/toolkits/local/file">
    Tools to read and write files.
  </Card>

  <Card title="Python" icon="code" iconType="duotone" href="/concepts/tools/toolkits/local/python">
    Tools to write and run Python code.
  </Card>

  <Card title="Shell" icon="terminal" iconType="duotone" href="/concepts/tools/toolkits/local/shell">
    Tools to run shell commands.
  </Card>

  <Card title="Local File System" icon="file" iconType="duotone" href="/concepts/tools/toolkits/local/local_file_system">
    Tools to write files to the local file system.
  </Card>

  <Card title="Sleep" icon="bed" iconType="duotone" href="/concepts/tools/toolkits/local/sleep">
    Tools to pause execution for a given number of seconds.
  </Card>
</CardGroup>

## Native Model Toolkit

<CardGroup cols={3}>
  <Card title="Azure OpenAI" icon="microsoft" iconType="brands" href="/concepts/tools/toolkits/models/azure_openai">
    Tools to generate images using Azure OpenAI DALL-E.
  </Card>

  <Card title="Groq" icon="groq" iconType="brands" href="/concepts/tools/toolkits/models/groq">
    Tools to interact with Groq.
  </Card>

  <Card title="Morph" icon="code" iconType="duotone" href="/concepts/tools/toolkits/models/morph">
    Tools to modify code using Morph AI.
  </Card>

  <Card title="Nebius" icon="image" iconType="duotone" href="/concepts/tools/toolkits/models/nebius">
    Tools to generate images using Nebius AI Studio.
  </Card>
</CardGroup>

## Additional Toolkits

<CardGroup cols={3}>
  <Card title="Airflow" icon="wind" iconType="duotone" href="/concepts/tools/toolkits/others/airflow">
    Tools to manage Airflow DAGs.
  </Card>

  <Card title="Apify" icon="gear" iconType="duotone" href="/concepts/tools/toolkits/others/apify">
    Tools to use Apify Actors.
  </Card>

  <Card title="AWS Lambda" icon="server" iconType="duotone" href="/concepts/tools/toolkits/others/aws_lambda">
    Tools to run serverless functions using AWS Lambda.
  </Card>

  <Card title="AWS SES" icon="envelope" iconType="duotone" href="/concepts/tools/toolkits/others/aws_ses">
    Tools to send emails using AWS SES
  </Card>

  <Card title="CalCom" icon="calendar" iconType="duotone" href="/concepts/tools/toolkits/others/calcom">
    Tools to interact with the Cal.com API.
  </Card>

  <Card title="Cartesia" icon="waveform" iconType="duotone" href="/concepts/tools/toolkits/others/cartesia">
    Tools for integrating voice AI.
  </Card>

  <Card title="Composio" icon="code-branch" iconType="duotone" href="/concepts/tools/toolkits/others/composio">
    Tools to compose complex workflows.
  </Card>

  <Card title="Confluence" icon="file" iconType="duotone" href="/concepts/tools/toolkits/others/confluence">
    Tools to manage Confluence pages.
  </Card>

  <Card title="Custom API" icon="puzzle-piece" iconType="duotone" href="/concepts/tools/toolkits/others/custom_api">
    Tools to call any custom HTTP API.
  </Card>

  <Card title="Dalle" icon="eye" iconType="duotone" href="/concepts/tools/toolkits/others/dalle">
    Tools to interact with Dalle.
  </Card>

  <Card title="Eleven Labs" icon="headphones" iconType="duotone" href="/concepts/tools/toolkits/others/eleven_labs">
    Tools to generate audio using Eleven Labs.
  </Card>

  <Card title="E2B" icon="server" iconType="duotone" href="/concepts/tools/toolkits/others/e2b">
    Tools to interact with E2B.
  </Card>

  <Card title="Fal" icon="video" iconType="duotone" href="/concepts/tools/toolkits/others/fal">
    Tools to generate media using Fal.
  </Card>

  <Card title="Financial Datasets" icon="dollar-sign" iconType="duotone" href="/concepts/tools/toolkits/others/financial_datasets">
    Tools to access and analyze financial data.
  </Card>

  <Card title="Giphy" icon="image" iconType="duotone" href="/concepts/tools/toolkits/others/giphy">
    Tools to search for GIFs on Giphy.
  </Card>

  <Card title="GitHub" icon="github" iconType="brands" href="/concepts/tools/toolkits/others/github">
    Tools to interact with GitHub.
  </Card>

  <Card title="Google Maps" icon="map" iconType="duotone" href="/concepts/tools/toolkits/others/google_maps">
    Tools to search for places on Google Maps.
  </Card>

  <Card title="Google Calendar" icon="calendar" iconType="duotone" href="/concepts/tools/toolkits/others/googlecalendar">
    Tools to manage Google Calendar events.
  </Card>

  <Card title="Google Sheets" icon="google" iconType="duotone" href="/concepts/tools/toolkits/others/google_sheets">
    Tools to work with Google Sheets.
  </Card>

  <Card title="Jira" icon="jira" iconType="brands" href="/concepts/tools/toolkits/others/jira">
    Tools to interact with Jira.
  </Card>

  <Card title="Linear" icon="list" iconType="duotone" href="/concepts/tools/toolkits/others/linear">
    Tools to interact with Linear.
  </Card>

  <Card title="Lumalabs" icon="lightbulb" iconType="duotone" href="/concepts/tools/toolkits/others/lumalabs">
    Tools to interact with Lumalabs.
  </Card>

  <Card title="MLX Transcribe" icon="headphones" iconType="duotone" href="/concepts/tools/toolkits/others/mlx_transcribe">
    Tools to transcribe audio using MLX.
  </Card>

  <Card title="ModelsLabs" icon="video" iconType="duotone" href="/concepts/tools/toolkits/others/models_labs">
    Tools to generate videos using ModelsLabs.
  </Card>

  <Card title="OpenBB" icon="chart-bar" iconType="duotone" href="/concepts/tools/toolkits/others/openbb">
    Tools to search for stock data using OpenBB.
  </Card>

  <Card title="Openweather" icon="cloud-sun" iconType="duotone" href="/concepts/tools/toolkits/others/openweather">
    Tools to search for weather data using Openweather.
  </Card>

  <Card title="Replicate" icon="robot" iconType="duotone" href="/concepts/tools/toolkits/others/replicate">
    Tools to interact with Replicate.
  </Card>

  <Card title="Resend" icon="paper-plane" iconType="duotone" href="/concepts/tools/toolkits/others/resend">
    Tools to send emails using Resend.
  </Card>

  <Card title="Todoist" icon="list" iconType="duotone" href="/concepts/tools/toolkits/others/todoist">
    Tools to interact with Todoist.
  </Card>

  <Card title="YFinance" icon="dollar-sign" iconType="duotone" href="/concepts/tools/toolkits/others/yfinance">
    Tools to search Yahoo Finance.
  </Card>

  <Card title="YouTube" icon="youtube" iconType="brands" href="/concepts/tools/toolkits/others/youtube">
    Tools to search YouTube.
  </Card>

  <Card title="Bitbucket" icon="bitbucket" iconType="brands" href="/concepts/tools/toolkits/others/bitbucket">
    Tools to interact with Bitbucket repositories.
  </Card>

  <Card title="Brandfetch" icon="trademark" iconType="duotone" href="/concepts/tools/toolkits/others/brandfetch">
    Tools to retrieve brand information and logos.
  </Card>

  <Card title="ClickUp" icon="tasks" iconType="duotone" href="/concepts/tools/toolkits/others/clickup">
    Tools to manage ClickUp tasks and projects.
  </Card>

  <Card title="Desi Vocal" icon="microphone" iconType="duotone" href="/concepts/tools/toolkits/others/desi_vocal">
    Tools for Indian text-to-speech synthesis.
  </Card>

  <Card title="EVM" icon="coins" iconType="duotone" href="/concepts/tools/toolkits/others/evm">
    Tools to interact with Ethereum blockchain.
  </Card>

  <Card title="Knowledge" icon="brain" iconType="duotone" href="/concepts/tools/toolkits/others/knowledge">
    Tools to search and analyze knowledge bases.
  </Card>

  <Card title="Mem0" icon="memory" iconType="duotone" href="/concepts/tools/toolkits/others/mem0">
    Tools for advanced memory management.
  </Card>

  <Card title="Memori" icon="brain" iconType="duotone" href="/concepts/tools/toolkits/others/memori">
    Tools for persistent conversation memory.
  </Card>

  <Card title="OpenCV" icon="camera" iconType="duotone" href="/concepts/tools/toolkits/others/opencv">
    Tools for computer vision and camera operations.
  </Card>

  <Card title="Reasoning" icon="brain" iconType="duotone" href="/concepts/tools/toolkits/others/reasoning">
    Tools for structured logical analysis.
  </Card>

  <Card title="User Control Flow" icon="user-check" iconType="duotone" href="/concepts/tools/toolkits/others/user_control_flow">
    Tools for interactive user input collection.
  </Card>

  <Card title="Visualization" icon="chart-bar" iconType="duotone" href="/concepts/tools/toolkits/others/visualization">
    Tools for data visualization and charting.
  </Card>

  <Card title="WebTools" icon="globe" iconType="duotone" href="/concepts/tools/toolkits/others/webtools">
    Tools for URL expansion and web utilities.
  </Card>

  <Card title="Zendesk" icon="headphones" iconType="duotone" href="/concepts/tools/toolkits/others/zendesk">
    Tools to search Zendesk.
  </Card>
</CardGroup>


# AgentQL
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/agentql



**AgentQLTools** enable an Agent to browse and scrape websites using the AgentQL API.

## Prerequisites

The following example requires the `agentql` library and an API token which can be obtained from [AgentQL](https://agentql.com/).

```shell
pip install -U agentql
```

```shell
export AGENTQL_API_KEY=***
```

## Example

The following agent will open a web browser and scrape all the text from the page.

```python cookbook/tools/agentql_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.agentql import AgentQLTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"), tools=[AgentQLTools()]
)

agent.print_response("https://docs.agno.com/introduction", markdown=True)
```

<Note>
  AgentQL will open up a browser instance (don't close it) and do scraping on
  the site.
</Note>

## Toolkit Params

| Parameter                      | Type   | Default | Description                                       |
| ------------------------------ | ------ | ------- | ------------------------------------------------- |
| `api_key`                      | `str`  | `None`  | API key for AgentQL                               |
| `scrape`                       | `bool` | `True`  | Whether to use the scrape text tool               |
| `agentql_query`                | `str`  | `None`  | Custom AgentQL query                              |
| `enable_scrape_website`        | `bool` | `True`  | Enable the scrape\_website functionality.         |
| `enable_custom_scrape_website` | `bool` | `True`  | Enable the custom\_scrape\_website functionality. |
| `all`                          | `bool` | `False` | Enable all functionality.                         |

## Toolkit Functions

| Function                | Description                                          |
| ----------------------- | ---------------------------------------------------- |
| `scrape_website`        | Used to scrape all text from a web page              |
| `custom_scrape_website` | Uses the custom `agentql_query` to scrape a web page |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/agentql.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/agentql_tools.py)


# BrightData
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/brightdata



**BrightDataTools** provide comprehensive web scraping capabilities including markdown conversion, screenshots, search engine results, and structured data feeds from various platforms like LinkedIn, Amazon, Instagram, and more.

## Prerequisites

The following examples require the `requests` library:

```shell
pip install -U requests
```

You'll also need a BrightData API key. Set the `BRIGHT_DATA_API_KEY` environment variable:

```shell
export BRIGHT_DATA_API_KEY="YOUR_BRIGHTDATA_API_KEY"
```

Optionally, you can configure zone settings:

```shell
export BRIGHT_DATA_WEB_UNLOCKER_ZONE="your_web_unlocker_zone"
export BRIGHT_DATA_SERP_ZONE="your_serp_zone"
```

## Example

Extract structured data from platforms like LinkedIn, Amazon, etc.:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.brightdata import BrightDataTools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        BrightDataTools(
            get_screenshot=True,
        )
    ],
    markdown=True,
    )

# Example 1: Scrape a webpage as Markdown
agent.print_response(
    "Scrape this webpage as markdown: https://docs.agno.com/introduction",
)
```

## Toolkit Params

| Parameter                | Type            | Default           | Description                                                                                                               |
| ------------------------ | --------------- | ----------------- | ------------------------------------------------------------------------------------------------------------------------- |
| `api_key`                | `Optional[str]` | `None`            | BrightData API key. If not provided, uses BRIGHT\_DATA\_API\_KEY environment variable.                                    |
| `enable_scrape_markdown` | `bool`          | `True`            | Enable the scrape\_as\_markdown function.                                                                                 |
| `enable_screenshot`      | `bool`          | `True`            | Enable the get\_screenshot function.                                                                                      |
| `enable_search_engine`   | `bool`          | `True`            | Enable the search\_engine function.                                                                                       |
| `enable_web_data_feed`   | `bool`          | `True`            | Enable the web\_data\_feed function.                                                                                      |
| `all`                    | `bool`          | `False`           | Enable all available functions. When True, all enable flags are ignored.                                                  |
| `serp_zone`              | `str`           | `"serp_api"`      | SERP zone for search operations. Can be overridden with BRIGHT\_DATA\_SERP\_ZONE environment variable.                    |
| `web_unlocker_zone`      | `str`           | `"web_unlocker1"` | Web unlocker zone for scraping operations. Can be overridden with BRIGHT\_DATA\_WEB\_UNLOCKER\_ZONE environment variable. |
| `verbose`                | `bool`          | `False`           | Enable verbose logging.                                                                                                   |
| `timeout`                | `int`           | `600`             | Timeout in seconds for operations.                                                                                        |

## Toolkit Functions

| Function             | Description                                                                                                                                                                                                                           |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `scrape_as_markdown` | Scrapes a webpage and returns content in Markdown format. Parameters: `url` (str) - URL to scrape.                                                                                                                                    |
| `get_screenshot`     | Captures a screenshot of a webpage and adds it as an image artifact. Parameters: `url` (str) - URL to screenshot, `output_path` (str, optional) - Output path (default: "screenshot.png").                                            |
| `search_engine`      | Searches using Google, Bing, or Yandex and returns results in Markdown. Parameters: `query` (str), `engine` (str, default: "google"), `num_results` (int, default: 10), `language` (Optional\[str]), `country_code` (Optional\[str]). |
| `web_data_feed`      | Retrieves structured data from various sources like LinkedIn, Amazon, Instagram, etc. Parameters: `source_type` (str), `url` (str), `num_of_reviews` (Optional\[int]).                                                                |

## Supported Data Sources

### E-commerce

* `amazon_product` - Amazon product details
* `amazon_product_reviews` - Amazon product reviews
* `amazon_product_search` - Amazon product search results
* `walmart_product` - Walmart product details
* `walmart_seller` - Walmart seller information
* `ebay_product` - eBay product details
* `homedepot_products` - Home Depot products
* `zara_products` - Zara products
* `etsy_products` - Etsy products
* `bestbuy_products` - Best Buy products

### Professional Networks

* `linkedin_person_profile` - LinkedIn person profiles
* `linkedin_company_profile` - LinkedIn company profiles
* `linkedin_job_listings` - LinkedIn job listings
* `linkedin_posts` - LinkedIn posts
* `linkedin_people_search` - LinkedIn people search results

### Social Media

* `instagram_profiles` - Instagram profiles
* `instagram_posts` - Instagram posts
* `instagram_reels` - Instagram reels
* `instagram_comments` - Instagram comments
* `facebook_posts` - Facebook posts
* `facebook_marketplace_listings` - Facebook Marketplace listings
* `facebook_company_reviews` - Facebook company reviews
* `facebook_events` - Facebook events
* `tiktok_profiles` - TikTok profiles
* `tiktok_posts` - TikTok posts
* `tiktok_shop` - TikTok shop
* `tiktok_comments` - TikTok comments
* `x_posts` - X (Twitter) posts

### Other Platforms

* `google_maps_reviews` - Google Maps reviews
* `google_shopping` - Google Shopping results
* `google_play_store` - Google Play Store apps
* `apple_app_store` - Apple App Store apps
* `youtube_profiles` - YouTube profiles
* `youtube_videos` - YouTube videos
* `youtube_comments` - YouTube comments
* `reddit_posts` - Reddit posts
* `zillow_properties_listing` - Zillow property listings
* `booking_hotel_listings` - Booking.com hotel listings
* `crunchbase_company` - Crunchbase company data
* `zoominfo_company_profile` - ZoomInfo company profiles
* `reuter_news` - Reuters news
* `github_repository_file` - GitHub repository files
* `yahoo_finance_business` - Yahoo Finance business data

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/brightdata.py)
* View [Cookbook Example](https://github.com/agno-agi/agno/tree/main/cookbook/tools/brightdata_tools.py)


# Browserbase
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/browserbase



**BrowserbaseTools** enable an Agent to automate browser interactions using Browserbase, a headless browser service.

## Prerequisites

The following example requires Browserbase API credentials after you signup [here](https://www.browserbase.com/), and the Playwright library.

```shell
pip install browserbase playwright
export BROWSERBASE_API_KEY=xxx
export BROWSERBASE_PROJECT_ID=xxx
```

## Example

The following agent will use Browserbase to visit `https://quotes.toscrape.com` and extract content. Then navigate to page two of the website and get quotes from there as well.

```python cookbook/tools/browserbase_tools.py
from agno.agent import Agent
from agno.tools.browserbase import BrowserbaseTools

agent = Agent(
    name="Web Automation Assistant",
    tools=[BrowserbaseTools()],
    instructions=[
        "You are a web automation assistant that can help with:",
        "1. Capturing screenshots of websites",
        "2. Extracting content from web pages",
        "3. Monitoring website changes",
        "4. Taking visual snapshots of responsive layouts",
        "5. Automated web testing and verification",
    ],
    markdown=True,
)

agent.print_response("""
    Visit https://quotes.toscrape.com and:
    1. Extract the first 5 quotes and their authors
    2. Navigate to page 2
    3. Extract the first 5 quotes from page 2
""")
```

<Tip>View the [Startup Analyst MCP agent](/examples/concepts/tools/mcp/stagehand)</Tip>

## Toolkit Params

| Parameter                 | Type   | Default | Description                                                                                                                                                                                           |
| ------------------------- | ------ | ------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `api_key`                 | `str`  | `None`  | Browserbase API key. If not provided, uses BROWSERBASE\_API\_KEY env var.                                                                                                                             |
| `project_id`              | `str`  | `None`  | Browserbase project ID. If not provided, uses BROWSERBASE\_PROJECT\_ID env var.                                                                                                                       |
| `base_url`                | `str`  | `None`  | Custom Browserbase API endpoint URL. Only use this if you're using a self-hosted Browserbase instance or need to connect to a different region. If not provided, uses BROWSERBASE\_BASE\_URL env var. |
| `enable_navigate_to`      | `bool` | `True`  | Enable the navigate\_to functionality.                                                                                                                                                                |
| `enable_screenshot`       | `bool` | `True`  | Enable the screenshot functionality.                                                                                                                                                                  |
| `enable_get_page_content` | `bool` | `True`  | Enable the get\_page\_content functionality.                                                                                                                                                          |
| `enable_close_session`    | `bool` | `True`  | Enable the close\_session functionality.                                                                                                                                                              |
| `all`                     | `bool` | `False` | Enable all functionality.                                                                                                                                                                             |

## Toolkit Functions

| Function           | Description                                                                                                                                           |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| `navigate_to`      | Navigates to a URL. Takes a URL and an optional connect\_url parameter.                                                                               |
| `screenshot`       | Takes a screenshot of the current page. Takes a path to save the screenshot, a boolean for full-page capture, and an optional connect\_url parameter. |
| `get_page_content` | Gets the HTML content of the current page. Takes an optional connect\_url parameter.                                                                  |
| `close_session`    | Closes a browser session.                                                                                                                             |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/browserbase.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/browserbase_tools.py)


# Crawl4AI
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/crawl4ai



**Crawl4aiTools** enable an Agent to perform web crawling and scraping tasks using the Crawl4ai library.

## Prerequisites

The following example requires the `crawl4ai` library.

```shell
pip install -U crawl4ai
```

## Example

The following agent will scrape the content from the [https://github.com/agno-agi/agno](https://github.com/agno-agi/agno) webpage:

```python cookbook/tools/crawl4ai_tools.py
from agno.agent import Agent
from agno.tools.crawl4ai import Crawl4aiTools

agent = Agent(tools=[Crawl4aiTools(max_length=None)])
agent.print_response("Tell me about https://github.com/agno-agi/agno.")
```

## Toolkit Params

| Parameter           | Type    | Default              | Description                                                                               |
| ------------------- | ------- | -------------------- | ----------------------------------------------------------------------------------------- |
| `max_length`        | `int`   | `1000`               | Specifies the maximum length of the text from the webpage to be returned.                 |
| `timeout`           | `int`   | `60`                 | Timeout in seconds for web crawling operations.                                           |
| `use_pruning`       | `bool`  | `False`              | Enable content pruning to remove less relevant content.                                   |
| `pruning_threshold` | `float` | `0.48`               | Threshold for content pruning relevance scoring.                                          |
| `bm25_threshold`    | `float` | `1.0`                | BM25 scoring threshold for content relevance.                                             |
| `headless`          | `bool`  | `True`               | Run browser in headless mode.                                                             |
| `wait_until`        | `str`   | `"domcontentloaded"` | Browser wait condition before crawling (e.g., "domcontentloaded", "load", "networkidle"). |
| `enable_crawl`      | `bool`  | `True`               | Enable the web crawling functionality.                                                    |
| `all`               | `bool`  | `False`              | Enable all available functions. When True, all enable flags are ignored.                  |

## Toolkit Functions

| Function      | Description                                                                                                                                                                                                      |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `web_crawler` | Crawls a website using crawl4ai's WebCrawler. Parameters include 'url' for the URL to crawl and an optional 'max\_length' to limit the length of extracted content. The default value for 'max\_length' is 1000. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/crawl4ai.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/crawl4ai_tools.py)


# Firecrawl
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/firecrawl

Use Firecrawl with Agno to scrape and crawl the web.

**FirecrawlTools** enable an Agent to perform web crawling and scraping tasks.

## Prerequisites

The following example requires the `firecrawl-py` library and an API key which can be obtained from [Firecrawl](https://firecrawl.dev).

```shell
pip install -U firecrawl-py
```

```shell
export FIRECRAWL_API_KEY=***
```

## Example

The following agent will scrape the content from [https://finance.yahoo.com/](https://finance.yahoo.com/) and return a summary of the content:

```python cookbook/tools/firecrawl_tools.py
from agno.agent import Agent
from agno.tools.firecrawl import FirecrawlTools

agent = Agent(tools=[FirecrawlTools(enable_scrape=False, enable_crawl=True)], markdown=True)
agent.print_response("Summarize this https://finance.yahoo.com/")
```

## Toolkit Params

| Parameter        | Type             | Default                     | Description                                                                  |
| ---------------- | ---------------- | --------------------------- | ---------------------------------------------------------------------------- |
| `api_key`        | `str`            | `None`                      | API key for authentication. Uses FIRECRAWL\_API\_KEY env var if not provided |
| `enable_scrape`  | `bool`           | `True`                      | Enables website scraping functionality                                       |
| `enable_crawl`   | `bool`           | `False`                     | Enables website crawling functionality                                       |
| `enable_mapping` | `bool`           | `False`                     | Enables website mapping functionality                                        |
| `enable_search`  | `bool`           | `False`                     | Enables web search functionality                                             |
| `all`            | `bool`           | `False`                     | Enables all functionality when set to True                                   |
| `formats`        | `List[str]`      | `None`                      | List of formats to be used for operations                                    |
| `limit`          | `int`            | `10`                        | Maximum number of items to retrieve                                          |
| `poll_interval`  | `int`            | `30`                        | Interval in seconds between polling for results                              |
| `search_params`  | `Dict[str, Any]` | `None`                      | Parameters for search operations                                             |
| `api_url`        | `str`            | `https://api.firecrawl.dev` | API URL to use for the Firecrawl app                                         |

## Toolkit Functions

| Function         | Description                                                                                                                                                                                                                                             |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `scrape_website` | Scrapes a website using Firecrawl. Parameters include `url` to specify the URL to scrape. The function supports optional formats if specified. Returns the results of the scraping in JSON format.                                                      |
| `crawl_website`  | Crawls a website using Firecrawl. Parameters include `url` to specify the URL to crawl, and an optional `limit` to define the maximum number of pages to crawl. The function supports optional formats and returns the crawling results in JSON format. |
| `map_website`    | Maps a website structure using Firecrawl. Parameters include `url` to specify the URL to map. Returns the mapping results in JSON format.                                                                                                               |
| `search`         | Performs a web search using Firecrawl. Parameters include `query` for the search term and optional `limit` for maximum results. Returns search results in JSON format.                                                                                  |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/firecrawl.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/firecrawl_tools.py)


# Jina Reader
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/jina_reader



**JinaReaderTools** enable an Agent to perform web search tasks using Jina.

## Prerequisites

The following example requires the `jina` library.

```shell
pip install -U jina
```

## Example

The following agent will use Jina API to summarize the content of [https://github.com/AgnoAgi](https://github.com/AgnoAgi)

```python cookbook/tools/jinareader.py
from agno.agent import Agent
from agno.tools.jina import JinaReaderTools

agent = Agent(tools=[JinaReaderTools()])
agent.print_response("Summarize: https://github.com/AgnoAgi")
```

## Toolkit Params

| Parameter              | Type            | Default                | Description                                                                                         |
| ---------------------- | --------------- | ---------------------- | --------------------------------------------------------------------------------------------------- |
| `api_key`              | `Optional[str]` | `None`                 | The API key for authentication purposes. If not provided, uses JINA\_API\_KEY environment variable. |
| `base_url`             | `str`           | `"https://r.jina.ai/"` | The base URL of the API.                                                                            |
| `search_url`           | `str`           | `"https://s.jina.ai/"` | The URL used for search queries.                                                                    |
| `max_content_length`   | `int`           | `10000`                | The maximum length of content allowed.                                                              |
| `timeout`              | `Optional[int]` | `None`                 | Timeout in seconds for API requests.                                                                |
| `search_query_content` | `bool`          | `True`                 | Include content in search query results.                                                            |
| `enable_read_url`      | `bool`          | `True`                 | Enable the read\_url functionality.                                                                 |
| `enable_search_query`  | `bool`          | `False`                | Enable the search\_query functionality.                                                             |
| `all`                  | `bool`          | `False`                | Enable all functionality.                                                                           |

## Toolkit Functions

| Function       | Description                                                                                                                                                                                            |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `read_url`     | Reads the content of a specified URL using Jina Reader API. Parameters include `url` for the URL to read. Returns the truncated content or an error message if the request fails.                      |
| `search_query` | Performs a web search using Jina Reader API based on a specified query. Parameters include `query` for the search term. Returns the truncated search results or an error message if the request fails. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/jina_reader.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/jina_reader_tools.py)


# Newspaper
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/newspaper



**NewspaperTools** enable an Agent to read news articles using the Newspaper4k library.

## Prerequisites

The following example requires the `newspaper3k` library.

```shell
pip install -U newspaper3k
```

## Example

The following agent will summarize the wikipedia article on language models.

```python cookbook/tools/newspaper_tools.py
from agno.agent import Agent
from agno.tools.newspaper import NewspaperTools

agent = Agent(tools=[NewspaperTools()])
agent.print_response("Please summarize https://en.wikipedia.org/wiki/Language_model")
```

## Toolkit Params

| Parameter                 | Type   | Default | Description                                                   |
| ------------------------- | ------ | ------- | ------------------------------------------------------------- |
| `enable_get_article_text` | `bool` | `True`  | Enables the functionality to retrieve the text of an article. |

## Toolkit Functions

| Function           | Description                                                                                                                                                                             |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `get_article_text` | Retrieves the text of an article from a specified URL. Parameters include `url` for the URL of the article. Returns the text of the article or an error message if the retrieval fails. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/newspaper.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/newspaper_tools.py)


# Newspaper4k
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/newspaper4k



**Newspaper4k** enables an Agent to read news articles using the Newspaper4k library.

## Prerequisites

The following example requires the `newspaper4k` and `lxml_html_clean` libraries.

```shell
pip install -U newspaper4k lxml_html_clean
```

## Example

The following agent will summarize the article: [https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime](https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime).

```python cookbook/tools/newspaper4k_tools.py
from agno.agent import Agent
from agno.tools.newspaper4k import Newspaper4kTools

agent = Agent(tools=[Newspaper4kTools()], debug_mode=True)
agent.print_response("Please summarize https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime")
```

## Toolkit Params

| Parameter             | Type   | Default | Description                                                                        |
| --------------------- | ------ | ------- | ---------------------------------------------------------------------------------- |
| `enable_read_article` | `bool` | `True`  | Enables the functionality to read the full content of an article.                  |
| `include_summary`     | `bool` | `False` | Specifies whether to include a summary of the article along with the full content. |
| `article_length`      | `int`  | -       | The maximum length of the article or its summary to be processed or returned.      |

## Toolkit Functions

| Function           | Description                                                  |
| ------------------ | ------------------------------------------------------------ |
| `get_article_data` | This function reads the full content and data of an article. |
| `read_article`     | This function reads the full content of an article.          |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/newspaper4k.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/newspaper4k_tools.py)


# Oxylabs
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/oxylabs



**OxylabsTools** provide Agents with access to Oxylabs' powerful web scraping capabilities, including SERP, Amazon product data, and universal web scraping endpoints.

## Prerequisites

The following examples require the `oxylabs-sdk` library:

```shell
pip install -U oxylabs-sdk
```

Set your credentials as environment variables (recommended):

```shell
export OXYLABS_USERNAME=your_oxylabs_username
export OXYLABS_PASSWORD=your_oxylabs_password
```

## Example

```python cookbook/tools/oxylabs_tools.py
from agno.agent import Agent
from agno.tools.oxylabs import OxylabsTools

agent = Agent(
    tools=[OxylabsTools()],
    markdown=True,
    )

agent.print_response("""
Search for 'latest iPhone reviews' and provide a summary of the top 3 results. 
""")
```

## Amazon Product Search

```
from agno.agent import Agent
from agno.tools.oxylabs import OxylabsTools

agent = Agent(
    tools=[OxylabsTools()],
    markdown=True,
    )

agent.print_response(
    "Let's search for an Amazon product with ASIN code 'B07FZ8S74R' ",
 )
```

## Toolkit Params

| Parameter  | Type  | Default | Description                                                                             |
| ---------- | ----- | ------- | --------------------------------------------------------------------------------------- |
| `username` | `str` | `None`  | Oxylabs dashboard username. If not provided, it defaults to `OXYLABS_USERNAME` env var. |
| `password` | `str` | `None`  | Oxylabs dashboard password. If not provided, it defaults to `OXYLABS_PASSWORD` env var. |

## Toolkit Functions

| Function                 | Description                                                                                            |
| ------------------------ | ------------------------------------------------------------------------------------------------------ |
| `search_google`          | Performs a Google SERP search. Accepts all the standard Oxylabs params (e.g. `query`, `geo_location`). |
| `get_amazon_product`     | Retrieves the details of Amazon product(s). Accepts ASIN code or full product URL.                     |
| `search_amazon_products` | Searches for Amazon product(s) using a search term.                                                    |
| `scrape_website`         | Scrapes a webpage URL.                                                                                 |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/oxylabs.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/oxylabs_tools.py)
* View [Oxylabs MCP Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/mcp/oxylabs.py)


# ScrapeGraph
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/scrapegraph

ScrapeGraphTools enable an Agent to extract structured data from webpages, convert content to markdown, and retrieve raw HTML content.

**ScrapeGraphTools** enable an Agent to extract structured data from webpages, convert content to markdown, and retrieve raw HTML content using the ScrapeGraphAI API.

The toolkit provides 5 core capabilities:

1. **smartscraper**: Extract structured data using natural language prompts
2. **markdownify**: Convert web pages to markdown format
3. **searchscraper**: Search the web and extract information
4. **crawl**: Crawl websites with structured data extraction
5. **scrape**: Get raw HTML content from websites *(NEW!)*

The scrape method is particularly useful when you need:

* Complete HTML source code
* Raw content for further processing
* HTML structure analysis
* Content that needs to be parsed differently

All methods support heavy JavaScript rendering when needed.

## Prerequisites

The following examples require the `scrapegraph-py` library.

```shell
pip install -U scrapegraph-py
```

Optionally, if your ScrapeGraph configuration or specific models require an API key, set the `SGAI_API_KEY` environment variable:

```shell
export SGAI_API_KEY="YOUR_SGAI_API_KEY"
```

## Example

The following agent will extract structured data from a website using the smartscraper tool:

```python cookbook/tools/scrapegraph_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.scrapegraph import ScrapeGraphTools

agent_model = OpenAIChat(id="gpt-4.1")
scrapegraph_smartscraper = ScrapeGraphTools(enable_smartscraper=True)

agent = Agent(
    tools=[scrapegraph_smartscraper], model=agent_model, markdown=True, stream=True
)

agent.print_response("""
Use smartscraper to extract the following from https://www.wired.com/category/science/:
- News articles
- Headlines
- Images
- Links
- Author
""")
```

### Raw HTML Scraping

Get complete HTML content from websites for custom processing:

```python cookbook/tools/scrapegraph_tools.py
# Enable scrape method for raw HTML content
scrapegraph_scrape = ScrapeGraphTools(enable_scrape=True, enable_smartscraper=False)

scrape_agent = Agent(
    tools=[scrapegraph_scrape],
    model=agent_model,
    markdown=True,
    stream=True,
)

scrape_agent.print_response(
    "Use the scrape tool to get the complete raw HTML content from https://en.wikipedia.org/wiki/2025_FIFA_Club_World_Cup"
)
```

### All Functions with JavaScript Rendering

Enable all ScrapeGraph functions with heavy JavaScript support:

```python cookbook/tools/scrapegraph_tools.py
# Enable all ScrapeGraph functions
scrapegraph_all = Agent(
    tools=[
        ScrapeGraphTools(all=True, render_heavy_js=True)
    ],  # render_heavy_js=True scrapes all JavaScript
    model=agent_model,
    markdown=True,
    stream=True,
)

scrapegraph_all.print_response("""
Use any appropriate scraping method to extract comprehensive information from https://www.wired.com/category/science/:
- News articles and headlines
- Convert to markdown if needed  
- Search for specific information
""")
```

<Note>View the [Startup Analyst example](/examples/use-cases/agents/startup-analyst-agent) </Note>

## Toolkit Params

| Parameter                | Type            | Default | Description                                                                                        |
| ------------------------ | --------------- | ------- | -------------------------------------------------------------------------------------------------- |
| `api_key`                | `Optional[str]` | `None`  | ScrapeGraph API key. If not provided, uses SGAI\_API\_KEY environment variable.                    |
| `enable_smartscraper`    | `bool`          | `True`  | Enable the smartscraper function for LLM-powered data extraction.                                  |
| `enable_markdownify`     | `bool`          | `False` | Enable the markdownify function for webpage to markdown conversion.                                |
| `enable_crawl`           | `bool`          | `False` | Enable the crawl function for website crawling and data extraction.                                |
| `enable_searchscraper`   | `bool`          | `False` | Enable the searchscraper function for web search and information extraction.                       |
| `enable_agentic_crawler` | `bool`          | `False` | Enable the agentic\_crawler function for automated browser actions and AI extraction.              |
| `enable_scrape`          | `bool`          | `False` | Enable the scrape function for retrieving raw HTML content from websites.                          |
| `render_heavy_js`        | `bool`          | `False` | Enable heavy JavaScript rendering for all scraping functions. Useful for SPAs and dynamic content. |
| `all`                    | `bool`          | `False` | Enable all available functions. When True, all enable flags are ignored.                           |

## Toolkit Functions

| Function          | Description                                                                                                                                                                                                            |
| ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `smartscraper`    | Extract structured data from a webpage using LLM and natural language prompt. Parameters: url (str), prompt (str).                                                                                                     |
| `markdownify`     | Convert a webpage to markdown format. Parameters: url (str).                                                                                                                                                           |
| `crawl`           | Crawl a website and extract structured data. Parameters: url (str), prompt (str), data\_schema (dict), cache\_website (bool), depth (int), max\_pages (int), same\_domain\_only (bool), batch\_size (int).             |
| `searchscraper`   | Search the web and extract information. Parameters: user\_prompt (str).                                                                                                                                                |
| `agentic_crawler` | Perform automated browser actions with optional AI extraction. Parameters: url (str), steps (List\[str]), use\_session (bool), user\_prompt (Optional\[str]), output\_schema (Optional\[dict]), ai\_extraction (bool). |
| `scrape`          | Get raw HTML content from a website. Useful for complete source code retrieval and custom processing. Parameters: website\_url (str), headers (Optional\[dict]).                                                       |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/scrapegraph.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/scrapegraph_tools.py)
* View [Tests](https://github.com/agno-agi/agno/blob/main/libs/agno/tests/unit/tools/test_scrapegraph.py)


# Spider
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/spider



**SpiderTools** is an open source web Scraper & Crawler that returns LLM-ready data. To start using Spider, you need an API key from the [Spider dashboard](https://spider.cloud).

## Prerequisites

The following example requires the `spider-client` library.

```shell
pip install -U spider-client
```

## Example

The following agent will run a search query to get the latest news in USA and scrape the first search result. The agent will return the scraped data in markdown format.

```python cookbook/tools/spider_tools.py
from agno.agent import Agent
from agno.tools.spider import SpiderTools

agent = Agent(tools=[SpiderTools()])
agent.print_response('Can you scrape the first search result from a search on "news in USA"?', markdown=True)
```

## Toolkit Params

| Parameter         | Type             | Default | Description                                             |
| ----------------- | ---------------- | ------- | ------------------------------------------------------- |
| `max_results`     | `Optional[int]`  | `None`  | Default maximum number of results.                      |
| `url`             | `Optional[str]`  | `None`  | Default URL for operations.                             |
| `optional_params` | `Optional[dict]` | `None`  | Additional parameters for operations.                   |
| `enable_search`   | `bool`           | `True`  | Enable web search functionality.                        |
| `enable_scrape`   | `bool`           | `True`  | Enable web scraping functionality.                      |
| `enable_crawl`    | `bool`           | `True`  | Enable web crawling functionality.                      |
| `all`             | `bool`           | `False` | Enable all tools. Overrides individual flags when True. |

## Toolkit Functions

| Function | Description                                                                                                                                                                                        |
| -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search` | Searches the web for the given query. Parameters include `query` (str) for the search query and `max_results` (int, default=5) for maximum results. Returns search results in JSON format.         |
| `scrape` | Scrapes the content of a webpage. Parameters include `url` (str) for the URL of the webpage to scrape. Returns markdown of the webpage.                                                            |
| `crawl`  | Crawls the web starting from a URL. Parameters include `url` (str) for the URL to crawl and `limit` (Optional\[int], default=10) for maximum pages to crawl. Returns crawl results in JSON format. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/spider.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/spider_tools.py)


# Trafilatura
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/trafilatura

TrafilaturaTools provides advanced web scraping and text extraction capabilities with support for crawling and content analysis.

## Example

The following agent can extract and analyze web content:

```python
from agno.agent import Agent
from agno.tools.trafilatura import TrafilaturaTools

agent = Agent(
    instructions=[
        "You are a web content extraction specialist",
        "Extract clean text and structured data from web pages",
        "Provide detailed analysis of web content and metadata",
        "Help with content research and web data collection",
    ],
    tools=[TrafilaturaTools()],
)

agent.print_response("Extract the main content from https://example.com/article", stream=True)
```

## Toolkit Params

| Parameter                 | Type            | Default | Description                                                  |
| ------------------------- | --------------- | ------- | ------------------------------------------------------------ |
| `output_format`           | `str`           | `"txt"` | Default output format (txt, json, xml, markdown, csv, html). |
| `include_comments`        | `bool`          | `False` | Whether to extract comments along with main text.            |
| `include_tables`          | `bool`          | `False` | Whether to include table content.                            |
| `include_images`          | `bool`          | `False` | Whether to include image information (experimental).         |
| `include_formatting`      | `bool`          | `False` | Whether to preserve text formatting.                         |
| `include_links`           | `bool`          | `False` | Whether to preserve links (experimental).                    |
| `with_metadata`           | `bool`          | `False` | Whether to include metadata in extractions.                  |
| `favor_precision`         | `bool`          | `False` | Whether to prefer precision over recall.                     |
| `favor_recall`            | `bool`          | `False` | Whether to prefer recall over precision.                     |
| `target_language`         | `Optional[str]` | `None`  | Target language filter (ISO 639-1 format).                   |
| `deduplicate`             | `bool`          | `True`  | Whether to remove duplicate segments.                        |
| `max_crawl_urls`          | `int`           | `100`   | Maximum number of URLs to crawl per website.                 |
| `max_known_urls`          | `int`           | `1000`  | Maximum number of known URLs during crawling.                |
| `enable_extract_text`     | `bool`          | `True`  | Whether to extract text content.                             |
| `enable_extract_metadata` | `bool`          | `True`  | Whether to extract metadata information.                     |
| `enable_html_to_text`     | `bool`          | `True`  | Whether to convert HTML content to clean text.               |
| `enable_batch_extract`    | `bool`          | `True`  | Whether to extract content from multiple URLs in batch.      |

## Toolkit Functions

| Function           | Description                                              |
| ------------------ | -------------------------------------------------------- |
| `extract_text`     | Extract clean text content from a URL or HTML.           |
| `extract_metadata` | Extract metadata information from web pages.             |
| `html_to_text`     | Convert HTML content to clean text.                      |
| `crawl_website`    | Crawl a website and extract content from multiple pages. |
| `batch_extract`    | Extract content from multiple URLs in batch.             |
| `get_page_info`    | Get comprehensive page information including metadata.   |

## Developer Resources

* View [Tools Source](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/trafilatura.py)
* [Trafilatura Documentation](https://trafilatura.readthedocs.io/)
* [Web Scraping Best Practices](https://trafilatura.readthedocs.io/en/latest/corefunctions.html)


# Website Tools
Source: https://docs.agno.com/concepts/tools/toolkits/web_scrape/website



**WebsiteTools** enable an Agent to parse a website and add its contents to the knowledge base.

## Prerequisites

The following example requires the `beautifulsoup4` library.

```shell
pip install -U beautifulsoup4
```

## Example

The following agent will read the contents of a website and add it to the knowledge base.

```python cookbook/tools/website_tools.py
from agno.agent import Agent
from agno.tools.website import WebsiteTools

agent = Agent(tools=[WebsiteTools()])
agent.print_response("Search web page: 'https://docs.agno.com/introduction'", markdown=True)
```

## Toolkit Params

| Parameter   | Type        | Default | Description                                                                                                            |
| ----------- | ----------- | ------- | ---------------------------------------------------------------------------------------------------------------------- |
| `knowledge` | `Knowledge` | -       | The knowledge base associated with the website, containing various data and resources linked to the website's content. |

## Toolkit Functions

| Function                        | Description                                                                                                                                                                                                          |
| ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `add_website_to_knowledge_base` | This function adds a website's content to the knowledge base. **NOTE:** The website must start with `https://` and should be a valid website. Use this function to get information about products from the internet. |
| `read_url`                      | This function reads a URL and returns the contents.                                                                                                                                                                  |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/website.py)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/website_tools.py)


# Accessing Multiple Previous Steps
Source: https://docs.agno.com/concepts/workflows/advanced/access-previous-steps

How to access multiple previous steps

Advanced workflows often require data from multiple previous steps beyond just the immediate predecessor. The `StepInput` object provides powerful methods to access any previous step's output by name or retrieve all accumulated content.

## Example

```python
def create_comprehensive_report(step_input: StepInput) -> StepOutput:
    """
    Custom function that creates a report using data from multiple previous steps.
    This function has access to ALL previous step outputs and the original workflow message.
    """

    # Access original workflow input
    original_topic = step_input.workflow_message or ""

    # Access specific step outputs by name
    hackernews_data = step_input.get_step_content("research_hackernews") or ""
    web_data = step_input.get_step_content("research_web") or ""

    # Or access ALL previous content
    all_research = step_input.get_all_previous_content()

    # Create a comprehensive report combining all sources
    report = f"""
        # Comprehensive Research Report: {original_topic}

        ## Executive Summary
        Based on research from HackerNews and web sources, here's a comprehensive analysis of {original_topic}.

        ## HackerNews Insights
        {hackernews_data[:500]}...

        ## Web Research Findings  
        {web_data[:500]}...
    """

    return StepOutput(
        step_name="comprehensive_report", 
        content=report.strip(), 
        success=True
    )

# Use in workflow
workflow = Workflow(
    name="Enhanced Research Workflow",
    steps=[
        Step(name="research_hackernews", agent=hackernews_agent),
        Step(name="research_web", agent=web_agent),
        Step(name="comprehensive_report", executor=create_comprehensive_report),  # Accesses both previous steps
        Step(name="final_reasoning", agent=reasoning_agent),
    ],
)
```

**Available Methods**

* `step_input.get_step_content("step_name")` - Get content from specific step by name
* `step_input.get_all_previous_content()` - Get all previous step content combined
* `step_input.workflow_message` - Access the original workflow input message
* `step_input.previous_step_content` - Get content from immediate previous step

<Note>
  In case of `Parallel` step, when you do `step_input.get_step_content("parallel_step_name")`, it will return a dict with each key as `individual_step_name` for all the outputs from the steps defined in parallel.
  Example:

  ```python
  parallel_step_output = step_input.get_step_content("parallel_step_name")
  ```

  `parallel_step_output` will be a dict with each key as `individual_step_name` for all the outputs from the steps defined in parallel.

  ```python
  {
      "individual_step_name_1": "output_from_individual_step_1",
      "individual_step_name_2": "output_from_individual_step_2",
  }
  ```
</Note>

## Developer Resources

* [Access Multiple Previous Steps Output](/examples/concepts/workflows/06_workflows_advanced_concepts/access_multiple_previous_steps_output)


# Additional Data and Metadata
Source: https://docs.agno.com/concepts/workflows/advanced/additional-data

How to pass additional data to workflows

**When to Use**
Pass metadata, configuration, or contextual information to specific steps without cluttering the main workflow message flow.

**Key Benefits**

* **Separation of Concerns**: Keep workflow logic separate from metadata
* **Step-Specific Context**: Access additional information in custom functions
* **Clean Message Flow**: Main message stays focused on content
* **Flexible Configuration**: Pass user info, priorities, settings, and more

**Access Pattern**
Use `step_input.additional_data` for dictionary access to all additional data passed to the workflow.

## Example

```python
from agno.workflow import Step, Workflow, StepInput, StepOutput

def custom_content_planning_function(step_input: StepInput) -> StepOutput:
    """Custom function that uses additional_data for enhanced context"""
    
    # Access the main workflow message
    message = step_input.input
    previous_content = step_input.previous_step_content
    
    # Access additional_data that was passed with the workflow
    additional_data = step_input.additional_data or {}
    user_email = additional_data.get("user_email", "No email provided")
    priority = additional_data.get("priority", "normal")
    client_type = additional_data.get("client_type", "standard")
    
    # Create enhanced planning prompt with context
    planning_prompt = f"""
        STRATEGIC CONTENT PLANNING REQUEST:
        
        Core Topic: {message}
        Research Results: {previous_content[:500] if previous_content else "No research results"}
        
        Additional Context:
        - Client Type: {client_type}
        - Priority Level: {priority}
        - Contact Email: {user_email}
        
        {"üö® HIGH PRIORITY - Expedited delivery required" if priority == "high" else "üìù Standard delivery timeline"}
        
        Please create a detailed, actionable content plan.
    """
    
    response = content_planner.run(planning_prompt)
    
    enhanced_content = f"""
        ## Strategic Content Plan
        
        **Planning Topic:** {message}
        **Client Details:** {client_type} | {priority.upper()} priority | {user_email}
        
        **Content Strategy:**
        {response.content}
    """
    
    return StepOutput(content=enhanced_content)

# Define workflow with steps
workflow = Workflow(
    name="Content Creation Workflow",
    steps=[
        Step(name="Research Step", team=research_team),
        Step(name="Content Planning Step", executor=custom_content_planning_function),
    ]
)

# Run workflow with additional_data
workflow.print_response(
    message="AI trends in 2024",
    additional_data={
        "user_email": "kaustubh@agno.com",
        "priority": "high",
        "client_type": "enterprise",
        "budget": "$50000",
        "deadline": "2024-12-15"
    },
    markdown=True,
    stream=True
)
```

## Developer Resources

* [Step with Function and Additional Data](/examples/concepts/workflows/06_workflows_advanced_concepts/step_with_function_additional_data)


# Background Workflow Execution
Source: https://docs.agno.com/concepts/workflows/advanced/background-execution

How to execute workflows as non-blocking background tasks

Execute workflows as non-blocking background tasks by passing `background=True` to `Workflow.arun()`. This returns a `WorkflowRunOutput` object with a `run_id` for polling the workflow status until completion.

<Note>
  Background execution requires async workflows using `.arun()`. Poll for results using `workflow.get_run(run_id)` and check completion status with `.has_completed()`.

  Ideal for long-running operations like large-scale data processing, multi-step research, or batch operations that shouldn't block your main application thread.
</Note>

## Example

```python
import asyncio

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.hackernews import HackerNewsTools
from agno.utils.pprint import pprint_run_response
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

content_creation_workflow = Workflow(
    name="Content Creation Workflow",
    description="Automated content creation from blog posts to social media",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflow.db",
    ),
    steps=[research_step, content_planning_step],
)


async def main():
    print("üöÄ Starting Async Background Workflow Test")

    # Start background execution (async)
    bg_response = await content_creation_workflow.arun(
        input="AI trends in 2024", background=True
    )
    print(f"‚úÖ Initial Response: {bg_response.status} - {bg_response.content}")
    print(f"üìã Run ID: {bg_response.run_id}")

    # Poll every 5 seconds until completion
    poll_count = 0

    while True:
        poll_count += 1
        print(f"\nüîç Poll #{poll_count} (every 5s)")

        result = content_creation_workflow.get_run(bg_response.run_id)

        if result is None:
            print("‚è≥ Workflow not found yet, still waiting...")
            if poll_count > 50:
                print(f"‚è∞ Timeout after {poll_count} attempts")
                break
            await asyncio.sleep(5)
            continue

        if result.has_completed():
            break

        if poll_count > 200:
            print(f"‚è∞ Timeout after {poll_count} attempts")
            break

        await asyncio.sleep(5)

    final_result = content_creation_workflow.get_run(bg_response.run_id)

    print("\nüìä Final Result:")
    print("=" * 50)
    pprint_run_response(final_result, markdown=True)


if __name__ == "__main__":
    asyncio.run(main())
```

<Note>
  You can also use websockets for background workflows. See the [Workflow Websocket](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_06_advanced_concepts/_05_background_execution/background_execution_using_websocket) example.
</Note>

## Developer Resources

* [Background Execution Poll](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_05_background_execution/background_execution_poll.py)
* [Background Execution Websocket](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_06_advanced_concepts/_05_background_execution/background_execution_using_websocket)


# Workflow Cancellation
Source: https://docs.agno.com/concepts/workflows/advanced/cancel-workflow

How to cancel workflows

Workflows can be cancelled during execution to stop processing immediately and free up resources. This is particularly useful for long-running workflows, background tasks, or when user requirements change mid-execution.

The cancellation system provides graceful termination with proper cleanup and event logging.

### When to Use Cancellation

* **User-initiated stops**: Allow users to cancel long-running processes
* **Resource management**: Free up computational resources when workflows are no longer needed
* **Priority changes**: Cancel lower-priority workflows to make room for urgent tasks

### Cancelling Background Workflows

For workflows running in the background (using `background=True`), you can cancel them using the `run_id`:

## Example

```python
import asyncio
from agno.workflow import Workflow
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.workflow.step import Step

# Setup workflow
long_running_workflow = Workflow(
    name="Long Running Analysis",
    steps=[
        Step(name="Research", agent=Agent(model=OpenAIChat(id="gpt-5-mini"), instructions="You are a helpful assistant that can research the web.")),
        Step(name="Deep Analysis", agent=Agent(model=OpenAIChat(id="gpt-5-mini"), instructions="You are a helpful assistant that can analyze the web.")),
        Step(name="Report Generation", agent=Agent(model=OpenAIChat(id="gpt-5-mini"), instructions="You are a helpful assistant that can generate a report.")),
    ]
)

async def main():
    # Start background workflow
    bg_response = await long_running_workflow.arun(
        input="Comprehensive market analysis for emerging technologies",
        background=True
    )
    
    print(f"Started workflow with run_id: {bg_response.run_id}")
    
    # Simulate some time passing
    await asyncio.sleep(5)
    
    # Cancel the workflow
    cancellation_result = long_running_workflow.cancel_run(bg_response.run_id)
    
    if cancellation_result:  # cancellation_result is a bool
        print(f"‚úÖ Workflow {bg_response.run_id} cancelled successfully")
    else:
        print(f"‚ùå Failed to cancel workflow {bg_response.run_id}")

asyncio.run(main())
```

<Note>
  When a workflow in streaming mode is cancelled, a specific event is triggered: `WorkflowRunEvent.workflow_cancelled` or simply known as `WorkflowCancelledEvent`
</Note>

## Developer Resources

* [Workflow Cancellation](/examples/concepts/workflows/06_workflows_advanced_concepts/workflow_cancellation)


# Custom Functions in Workflows
Source: https://docs.agno.com/concepts/workflows/advanced/custom-functions

How to use custom functions in workflows

Custom functions provide maximum flexibility by allowing you to define specific logic for step execution. Use them to preprocess inputs, orchestrate agents and teams, and postprocess outputs with complete programmatic control.

**Key Capabilities**

* **Custom Logic**: Implement complex business rules and data transformations
* **Agent Integration**: Call agents and teams within your custom processing logic
* **Data Flow Control**: Transform outputs between steps for optimal data handling

**Implementation Pattern**
Define a `Step` with a custom function as the `executor`. The function must accept a `StepInput` object and return a `StepOutput` object, ensuring seamless integration with the workflow system.

## Example

```python
content_planning_step = Step(
    name="Content Planning Step",
    executor=custom_content_planning_function,
)

def custom_content_planning_function(step_input: StepInput) -> StepOutput:
    """
    Custom function that does intelligent content planning with context awareness
    """
    message = step_input.input
    previous_step_content = step_input.previous_step_content

    # Create intelligent planning prompt
    planning_prompt = f"""
        STRATEGIC CONTENT PLANNING REQUEST:

        Core Topic: {message}

        Research Results: {previous_step_content[:500] if previous_step_content else "No research results"}

        Planning Requirements:
        1. Create a comprehensive content strategy based on the research
        2. Leverage the research findings effectively
        3. Identify content formats and channels
        4. Provide timeline and priority recommendations
        5. Include engagement and distribution strategies

        Please create a detailed, actionable content plan.
    """

    try:
        response = content_planner.run(planning_prompt)

        enhanced_content = f"""
            ## Strategic Content Plan

            **Planning Topic:** {message}

            **Research Integration:** {"‚úì Research-based" if previous_step_content else "‚úó No research foundation"}

            **Content Strategy:**
            {response.content}

            **Custom Planning Enhancements:**
            - Research Integration: {"High" if previous_step_content else "Baseline"}
            - Strategic Alignment: Optimized for multi-channel distribution
            - Execution Ready: Detailed action items included
        """.strip()

        return StepOutput(content=enhanced_content)

    except Exception as e:
        return StepOutput(
            content=f"Custom content planning failed: {str(e)}",
            success=False,
        )
```

**Standard Pattern**
All custom functions follow this consistent structure:

```python
def custom_content_planning_function(step_input: StepInput) -> StepOutput:
    # 1. Custom preprocessing
    # 2. Call agents/teams as needed
    # 3. Custom postprocessing
    return StepOutput(content=enhanced_content)
```

## Developer Resources

* [Step with a Custom Function](/examples/concepts/workflows/01-basic-workflows/step_with_function)


# Early Stopping
Source: https://docs.agno.com/concepts/workflows/advanced/early-stop

How to early stop workflows

Workflows support early termination when specific conditions are met, preventing unnecessary processing and implementing safety gates. Any step can trigger early termination by returning `StepOutput(stop=True)`, immediately halting the entire workflow execution.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=8d2d411a2853e475b18e4a195a9d65df" alt="Workflows early stop diagram" data-og-width="7281" width="7281" data-og-height="1179" height="1179" data-path="images/workflows-early-stop-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=c0dcd798df8113cf9c146b8d6946f2e4 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=230326e06f4d0d607e4fff253910b7d0 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=7ea8b5e50c4303af888b0bab7fcdb6f9 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=28702a9fcd250dd3f678f84b40b4f207 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=9cddb518531d6dc748a4d7a9da2308a4 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop-light.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=1c1b977a426432c9e08df94a524a4d2f 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=6c2609a237ba9a60fde24fb6ef3c25dc" alt="Workflows early stop diagram" data-og-width="7281" width="7281" data-og-height="1179" height="1179" data-path="images/workflows-early-stop.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=8ab6aca3447a781d230858aefc525613 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5ad070c303d4203799af900d5bf15dae 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=c29866bad79a0fa0215962c59605e93f 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5b498d3d0faacc133474650fb236e29a 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=8b8e0f5a7070635380fdf23217e5fda3 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-early-stop.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=97cf31c8418685c1b28185e594c11e44 2500w" />

## Example

```python
from agno.workflow import Step, Workflow, StepInput, StepOutput

def security_gate(step_input: StepInput) -> StepOutput:
    """Security gate that stops deployment if vulnerabilities found"""
    security_result = step_input.previous_step_content or ""
    
    if "VULNERABLE" in security_result.upper():
        return StepOutput(
            content="üö® SECURITY ALERT: Critical vulnerabilities detected. Deployment blocked.",
            stop=True  # Stop the entire workflow
        )
    else:
        return StepOutput(
            content="‚úÖ Security check passed. Proceeding with deployment...",
            stop=False
        )

# Secure deployment pipeline
workflow = Workflow(
    name="Secure Deployment Pipeline",
    steps=[
        Step(name="Security Scan", agent=security_scanner),
        Step(name="Security Gate", executor=security_gate),  # May stop here
        Step(name="Deploy Code", agent=code_deployer),       # Only if secure
        Step(name="Setup Monitoring", agent=monitoring_agent), # Only if deployed
    ]
)

# Test with vulnerable code - workflow stops at security gate
workflow.print_response("Scan this code: exec(input('Enter command: '))")
```

## Developer Resources

* [Early Stop Workflow](/examples/concepts/workflows/06_workflows_advanced_concepts/early_stop_workflow)


# Input and Output
Source: https://docs.agno.com/concepts/workflows/advanced/input-and-output

Learn how to use structured input and output with Workflows for reliable, production-ready systems.

## Structured Inputs with Pydantic

Leverage Pydantic models for type-safe, validated workflow inputs:

```python
from pydantic import BaseModel, Field

class ResearchRequest(BaseModel):
    topic: str = Field(description="Research topic")
    depth: int = Field(description="Research depth (1-10)")
    sources: List[str] = Field(description="Preferred sources")

workflow.print_response(
    message=ResearchRequest(
        topic="AI trends 2024",
        depth=8,
        sources=["academic", "industry"]
    )
)
```

### Validating the input

You can set `input_schema` on the Workflow to validate the input. If you then pass the input as a dictionary, it will be automatically validated against the schema.

```python
class ResearchTopic(BaseModel):
    """Structured research topic with specific requirements"""

    topic: str
    focus_areas: List[str] = Field(description="Specific areas to focus on")
    target_audience: str = Field(description="Who this research is for")
    sources_required: int = Field(description="Number of sources needed", default=5)

workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        steps=[research_step, content_planning_step],
        input_schema=ResearchTopic,
    )

workflow.print_response(
        input={
            "topic": "AI trends in 2024",
            "focus_areas": ["Machine Learning", "Computer Vision"],
            "target_audience": "Tech professionals",
            "sources_required": 8
        },
        markdown=True,
    )
```

### Developer Resources

* [Pydantic Model as Input](/examples/concepts/teams/structured_input_output/pydantic_model_as_input)
* [Workflow with Input Schema Validation](/examples/concepts/workflows/06_workflows_advanced_concepts/workflow_with_input_schema)

## Structured Input/Output at Step Level

Workflows feature a powerful type-safe data flow system enabling each step to:

1. **Receive** structured input (Pydantic models, lists, dicts, or raw strings)
2. **Produce** structured output (validated Pydantic models)
3. **Maintain** type safety throughout entire workflow execution

### Data Flow Between Steps

**Input Processing**

* First step receives the workflow's input message
* Subsequent steps receive the previous step's structured output

**Output Generation**

* Each Agent processes input using its configured `output_schema`
* Output is automatically validated against the defined model

```python
# Define agents with response models
research_agent = Agent(
    name="Research Specialist",
    model=OpenAIChat(id="gpt-4"),
    output_schema=ResearchFindings,  # <-- Set on Agent
)

analysis_agent = Agent(
    name="Analysis Expert", 
    model=OpenAIChat(id="gpt-4"),
    output_schema=AnalysisResults,  # <-- Set on Agent
)

# Steps reference these agents
workflow = Workflow(steps=[
    Step(agent=research_agent),  # Will output ResearchFindings
    Step(agent=analysis_agent)   # Will output AnalysisResults
])
```

### Structured Data Transformation in Custom Functions

Custom functions can access structured output from previous steps via `step_input.previous_step_content`, preserving original Pydantic model types.

**Transformation Pattern**

* **Type-Check Inputs**: Use `isinstance(step_input.previous_step_content, ModelName)` to verify input structure
* **Modify Data**: Extract fields, process them, and construct new Pydantic models
* **Return Typed Output**: Wrap the new model in `StepOutput(content=new_model)` for type safety

**Example Implementation**

```python
   def transform_data(step_input: StepInput) -> StepOutput:
       research = step_input.previous_step_content  # Type: ResearchFindings
       analysis = AnalysisReport(
           analysis_type="Custom",
           key_findings=[f"Processed: {research.topic}"],
           ...  # Modified fields
       )
       return StepOutput(content=analysis)
```

### Developer Resources

* [Structured IO at each Step Level](/examples/concepts/workflows/06_workflows_advanced_concepts/structured_io_at_each_step_level)

## Media Input and Processing

Workflows seamlessly handle media artifacts (images, videos, audio) throughout the execution pipeline, enabling rich multimedia processing workflows.

**Media Flow System**

* **Input Support**: Media can be provided to `Workflow.run()` and `Workflow.print_response()`
* **Step Propagation**: Media is passed through to individual steps (Agents, Teams, or Custom Functions)
* **Artifact Accumulation**: Each step receives shared media from previous steps and can produce additional outputs
* **Format Compatibility**: Automatic conversion between artifact formats ensures seamless integration
* **Complete Preservation**: Final `WorkflowRunOutput` contains all accumulated media from the entire execution chain

Here's an example of how to pass image as input:

```python
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.workflow import Step, Workflow
from agno.db.sqlite import SqliteDb

# Define agents
image_analyzer = Agent(
    name="Image Analyzer",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Analyze the provided image and extract key details, objects, and context.",
)

news_researcher = Agent(
    name="News Researcher", 
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Search for latest news and information related to the analyzed image content.",
)

# Define steps
analysis_step = Step(
    name="Image Analysis Step",
    agent=image_analyzer,
)

research_step = Step(
    name="News Research Step", 
    agent=news_researcher,
)

# Create workflow with media input
media_workflow = Workflow(
    name="Image Analysis and Research Workflow",
    description="Analyze an image and research related news",
    steps=[analysis_step, research_step],
    db=SqliteDb(db_file="tmp/workflow.db"),
)

# Run workflow with image input
if __name__ == "__main__":
    media_workflow.print_response(
        message="Please analyze this image and find related news",
        images=[
            Image(url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg")
        ],
        markdown=True,
    )
```

<Note>
  If you are using `Workflow.run()`, you need to use `WorkflowRunOutput` to access the images, videos, and audio.

  ```python
  from agno.run.workflow import WorkflowRunOutput

  response: WorkflowRunOutput = media_workflow.run(
      message="Please analyze this image and find related news",
      images=[
          Image(url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg")
      ],
      markdown=True,
  )

  print(response.images)
  ```
</Note>

Similarly, you can pass `Video` and `Audio` as input.

### Developer Resources

* [Image/Video Selection Sequence](/examples/concepts/workflows/05_workflows_conditional_branching/selector_for_image_video_generation_pipelines)


# Event Storage and Management
Source: https://docs.agno.com/concepts/workflows/advanced/store-events

How to store events in workflows

Workflows can automatically store all execution events for analysis, debugging, and audit purposes. Filter specific event types to reduce noise and storage overhead while maintaining essential execution records.

Access stored events via `workflow.run_response.events` and in the `runs` column of your workflow's session database (SQLite, PostgreSQL, etc.).

* `store_events=True`: Automatically stores all workflow events in the database
* `events_to_skip=[]`: Filter out specific event types to reduce storage and noise

Access all stored events via `workflow.run_response.events`

**Available Events to Skip:**

```python
from agno.run.workflow import WorkflowRunEvent

# Common events you might want to skip
events_to_skip = [
    WorkflowRunEvent.workflow_started,
    WorkflowRunEvent.workflow_completed,
    WorkflowRunEvent.workflow_cancelled,
    WorkflowRunEvent.step_started,
    WorkflowRunEvent.step_completed,
    WorkflowRunEvent.parallel_execution_started,
    WorkflowRunEvent.parallel_execution_completed,
    WorkflowRunEvent.condition_execution_started,
    WorkflowRunEvent.condition_execution_completed,
    WorkflowRunEvent.loop_execution_started,
    WorkflowRunEvent.loop_execution_completed,
    WorkflowRunEvent.router_execution_started,
    WorkflowRunEvent.router_execution_completed,
]
```

**Use Cases**

* **Debugging**: Store all events to analyze workflow execution flow
* **Audit Trails**: Keep records of all workflow activities for compliance
* **Performance Analysis**: Analyze timing and execution patterns
* **Error Investigation**: Review event sequences leading to failures
* **Noise Reduction**: Skip verbose events like `step_started` to focus on results

**Configuration Examples**

```python
# store everything
debug_workflow = Workflow(
    name="Debug Workflow",
    store_events=True,
    steps=[...]
)

# store only important events
production_workflow = Workflow(
    name="Production Workflow", 
    store_events=True,
    events_to_skip=[
        WorkflowRunEvent.step_started,
        WorkflowRunEvent.parallel_execution_started,
        # keep step_completed and workflow_completed
    ],
    steps=[...]
)

# No event storage
fast_workflow = Workflow(
    name="Fast Workflow",
    store_events=False,  
    steps=[...]
)
```

## Developer Resources

* [Store Events and Events to Skip in a Workflow](/examples/concepts/workflows/06_workflows_advanced_concepts/store_events_and_events_to_skip_in_a_workflow)


# Workflow Tools
Source: https://docs.agno.com/concepts/workflows/advanced/workflow-tools

How to execute a workflow inside an Agent or Team

## Example

You can give a workflow to an Agent or Team to execute using `WorkflowTools`.

```python
from agno.agent import Agent    
from agno.models.openai import OpenAIChat
from agno.tools.workflow import WorkflowTools

# Create your workflows...

workflow_tools = WorkflowTools(
    workflow=blog_post_workflow,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[workflow_tools],
)

agent.print_response("Create a blog post on the topic: AI trends in 2024", stream=True)
```

See the [Workflow Tools](/concepts/tools/reasoning_tools/workflow-tools) documentation for more details.


# What are Workflows?
Source: https://docs.agno.com/concepts/workflows/overview

Learn how Agno Workflows enable deterministic, controlled automation of multi-agent systems

Agno Workflows enable you to build deterministic, controlled agentic flows by orchestrating agents, teams, and functions through a series of defined steps. Unlike free-form agent interactions, workflows provide structured automation with predictable execution patterns, making them ideal for production systems that require reliable, repeatable processes.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=a308215dbae7c8e9050d03af47cfcf1b" alt="Workflows flow diagram" data-og-width="2994" width="2994" data-og-height="756" height="756" data-path="images/workflows-flow-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=36da448838231c986ea6fbee6cd20adf 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=2f79f8986f962ceed254128c04e2fff0 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=602db868a58a7ebadfb6849d783dacdf 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=79ab80554e556943fad1bb1c54c23c1b 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=0c06010680d6e281b4ca6f90f8febc23 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow-light.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=6195335508ec97552803e2920695044d 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=e9ef16c48420b7eee9312561ab56098e" alt="Workflows flow diagram" data-og-width="2994" width="2994" data-og-height="756" height="756" data-path="images/workflows-flow.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=cb8faae1ea504803ff761ae3b89c51fb 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=498fe144844ce93806c7f590823ae666 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=e8bd51333fbf023524a636d579f489f2 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=f4447ccd6c0c84f2ca104eb2ce7b560b 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5a6c0f92fc29f107e4249432216a6b0f 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-flow.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=0192f698b51c565c3efd9259472c8750 2500w" />

## Why should you use Workflows?

Workflows provide deterministic control over your agentic systems, enabling you to build reliable automation that executes consistently every time. They're essential when you need:

**Deterministic Execution**

* Predictable step-by-step processing with defined inputs and outputs
* Consistent results across multiple runs
* Clear audit trails for production systems

**Complex Orchestration**

* Multi-agent coordination with controlled handoffs
* Parallel processing and conditional branching
* Loop structures for iterative tasks

Workflows excel at **deterministic agent automation**, while [Teams](/concepts/teams/introduction) are designed for **dynamic agentic coordination**. Use workflows when you need predictable, repeatable processes; use teams when you need flexible, collaborative problem-solving.

## Deterministic Step Execution

Workflows execute as a controlled sequence of steps, where each step produces deterministic outputs that feed into the next step. This creates predictable data flows and consistent results, unlike free-form agent conversations.

**Step Types**

* **Agents**: Individual AI executors with specific capabilities and instructions
* **Teams**: Coordinated groups of agents working together on complex problems
* **Functions**: Custom Python functions for specialized processing logic

**Deterministic Benefits**
Your agents and teams retain their individual characteristics and capabilities, but now operate within a structured framework that ensures:

* **Predictable execution**: Steps run in defined order with controlled inputs/outputs
* **Repeatable results**: Same inputs produce consistent outputs across runs
* **Clear data flow**: Output from each step explicitly becomes input for the next
* **Controlled state**: Session management and state persistence between steps
* **Reliable error handling**: Built-in retry mechanisms and error recovery

## Workflow Input

Workflows support multiple input types for maximum flexibility:

| Input Type         | Example                                           | Use Case                   |
| ------------------ | ------------------------------------------------- | -------------------------- |
| **String**         | `"Analyze AI trends"`                             | Simple text prompts        |
| **Pydantic Model** | `ResearchRequest(topic="AI", depth=5)`            | Type-safe structured input |
| **List**           | `["AI", "ML", "LLMs"]`                            | Multiple items to process  |
| **Dictionary**     | `{"query": "AI", "sources": ["web", "academic"]}` | Key-value pairs            |

<Note>
  When this input is passed to an `Agent` or `Team`, it will be serialized to a
  string before being passed to the agent or team.
</Note>

See more on Pydantic as input in the [Advanced Workflows](/concepts/workflows/advanced#structured-inputs-with-pydantic) documentation.

## Architectural components

1. The **`Workflow`** class is the top-level orchestrator that manages the entire execution process.
2. **`Step`** is the fundamental unit of work in the workflow system. Each step encapsulates exactly one `executor` - either an `Agent`, a `Team`, or a custom Python function. This design ensures clarity and maintainability while preserving the individual characteristics of each executor.
3. **`Loop`** is a construct that allows you to execute one or more steps multiple times. This is useful when you need to repeat a set of steps until a certain condition is met.
4. **`Parallel`** is a construct that allows you to execute one or more steps in parallel. This is useful when you need to execute a set of steps concurrently with the outputs joined together.
5. **`Condition`** makes a step conditional based on criteria you specify.
6. **`Router`** allows you to specify which step(s) to execute next, effectively creating branching logic in your workflow.

<Note>
  When using a custom Python function as an executor for a step, `StepInput` and
  `StepOutput` provides standardized interfaces for data flow between steps:
</Note>

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=25129f55e1ead21d513c25b51dca412d" alt="Workflows step IO flow diagram" data-og-width="2001" width="2001" data-og-height="756" height="756" data-path="images/workflows-step-io-flow-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?w=280&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=67a933194ccf6f39606314d48784927f 280w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?w=560&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=3edc1003ffbee7b7767b1a84720bc616 560w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?w=840&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=cd83f97d789ba6e0a1980e8d25759281 840w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?w=1100&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=f018b152972888a037a239342bde7602 1100w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?w=1650&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=bd9ba2232ddd6801f4ece40477975608 1650w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow-light.png?w=2500&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=383ce2bcd2751e0b47a1304f797cf2d0 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=faa43206bfa64265fa4d32721a12216d" alt="Workflows step IO flow diagram" data-og-width="2001" width="2001" data-og-height="756" height="756" data-path="images/workflows-step-io-flow.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?w=280&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=50c47b8c564021b246ba034bc331c982 280w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?w=560&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=430d80604ed6927b914c7e9c1fcf8aa6 560w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?w=840&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=60dfe1d25956d8895f87b215607466cf 840w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?w=1100&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=8ac4c55ff3bb0c2f17baf76f0bae48a8 1100w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?w=1650&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=1c4237aa3bf8581c52b97f51f0b524e5 1650w, https://mintcdn.com/agno-v2/ZJv0T4EM1rVInAsr/images/workflows-step-io-flow.png?w=2500&fit=max&auto=format&n=ZJv0T4EM1rVInAsr&q=85&s=9ae7ba15375a9bb435b1765646047770 2500w" />

## How to make your first workflow?

There are different types of patterns you can use to build your workflows.
For example you can combine agents, teams, and functions to build a workflow.

```python
from agno.workflow import Step, Workflow, StepOutput

def data_preprocessor(step_input):
    # Custom preprocessing logic

    # Or you can also run any agent/team over here itself
    # response = some_agent.run(...)
    return StepOutput(content=f"Processed: {step_input.input}") # <-- Now pass the agent/team response in content here

workflow = Workflow(
    name="Mixed Execution Pipeline",
    steps=[
        research_team,      # Team
        data_preprocessor,  # Function
        content_agent,      # Agent
    ]
)

workflow.print_response("Analyze the competitive landscape for fintech startups", markdown=True)
```

## Useful Links

<CardGroup cols={2}>
  <Card title="View Complete Example" icon="code" href="/examples/concepts/workflows/01-basic-workflows/sequence_of_functions_and_agents">
    See the full example with agents, teams, and functions working together
  </Card>

  <Card title="Use in AgentOS" icon="play" href="/agent-os/features/chat-interface#run-a-workflow">
    Run your workflows through the AgentOS chat interface
  </Card>
</CardGroup>


# Running your Workflow
Source: https://docs.agno.com/concepts/workflows/run_workflow

Learn how to run a workflow and get the response.

The `Workflow.run()` function runs the agent and generates a response, either as a `WorkflowRunOutput` object or a stream of `WorkflowRunOutput` objects.

Many of our examples use `workflow.print_response()` which is a helper utility to print the response in the terminal. This uses `workflow.run()` under the hood.

## Running your Workflow

Here's how to run your workflow. The response is captured in the `response`.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.db.sqlite import SqliteDb
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow import Step, Workflow
from agno.run.workflow import WorkflowRunOutput
from agno.utils.pprint import pprint_run_response

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

content_creation_workflow = Workflow(
    name="Content Creation Workflow",
    description="Automated content creation from blog posts to social media",
    db=SqliteDb(db_file="tmp/workflow.db"),
    steps=[research_team, content_planner],
)

# Create and use workflow
if __name__ == "__main__":
    response: WorkflowRunOutput = content_creation_workflow.run(
        message="AI trends in 2024",
        markdown=True,
    )

    pprint_run_response(response, markdown=True)
```

<Note>
  The `Workflow.run()` function returns a `WorkflowRunOutput` object when not
  streaming. Here is detailed documentation for
  [WorkflowRunOutput](/reference/workflows/workflow_run_output).
</Note>

## Async Execution

The `Workflow.arun()` function is the async version of `Workflow.run()`.

Here is an example of how to use it:

```python
from typing import AsyncIterator
import asyncio

from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.workflow import Condition, Step, Workflow, StepInput
from agno.run.workflow import WorkflowRunOutput, WorkflowRunOutputEvent, WorkflowRunEvent

# === BASIC AGENTS ===
researcher = Agent(
    name="Researcher",
    instructions="Research the given topic and provide detailed findings.",
    tools=[DuckDuckGoTools()],
)

summarizer = Agent(
    name="Summarizer",
    instructions="Create a clear summary of the research findings.",
)

fact_checker = Agent(
    name="Fact Checker",
    instructions="Verify facts and check for accuracy in the research.",
    tools=[DuckDuckGoTools()],
)

writer = Agent(
    name="Writer",
    instructions="Write a comprehensive article based on all available research and verification.",
)

# === CONDITION EVALUATOR ===
def needs_fact_checking(step_input: StepInput) -> bool:
    """Determine if the research contains claims that need fact-checking"""
    summary = step_input.previous_step_content or ""

    # Look for keywords that suggest factual claims
    fact_indicators = [
        "study shows",
        "breakthroughs",
        "research indicates",
        "according to",
        "statistics",
        "data shows",
        "survey",
        "report",
        "million",
        "billion",
        "percent",
        "%",
        "increase",
        "decrease",
    ]

    return any(indicator in summary.lower() for indicator in fact_indicators)


# === WORKFLOW STEPS ===
research_step = Step(
    name="research",
    description="Research the topic",
    agent=researcher,
)

summarize_step = Step(
    name="summarize",
    description="Summarize research findings",
    agent=summarizer,
)

# Conditional fact-checking step
fact_check_step = Step(
    name="fact_check",
    description="Verify facts and claims",
    agent=fact_checker,
)

write_article = Step(
    name="write_article",
    description="Write final article",
    agent=writer,
)

# === BASIC LINEAR WORKFLOW ===
basic_workflow = Workflow(
    name="Basic Linear Workflow",
    description="Research -> Summarize -> Condition(Fact Check) -> Write Article",
    steps=[
        research_step,
        summarize_step,
        Condition(
            name="fact_check_condition",
            description="Check if fact-checking is needed",
            evaluator=needs_fact_checking,
            steps=[fact_check_step],
        ),
        write_article,
    ],
)

async def main():
    try:
        response: WorkflowRunOutput = await basic_workflow.arun(
            message="Recent breakthroughs in quantum computing",
        )
        pprint_run_response(response, markdown=True)
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

## Streaming Responses

To enable streaming, set `stream=True` when calling `run()`. This will return an iterator of `WorkflowRunOutputEvent` objects instead of a single response.

```python
# Define your agents/team
...

content_creation_workflow = Workflow(
    name="Content Creation Workflow",
    description="Automated content creation from blog posts to social media",
    db=SqliteDb(db_file="tmp/workflow.db"),
    steps=[research_team, content_planner],
)

# Create and use workflow
if __name__ == "__main__":
    response: Iterator[WorkflowRunOutputEvent] = content_creation_workflow.run(
        message="AI trends in 2024",
        markdown=True,
        stream=True,
    )

    pprint_run_response(response, markdown=True)
```

### Streaming Intermediate Steps

<Note>
  In the case where you put `stream_intermediate_steps=False` (or not set it at
  all), we only yield `WorkflowStartedEvent`, `WorkflowCompletedEvent` along
  with all the `Agent/Team` events.
</Note>

For even more detailed streaming, you can enable intermediate steps by setting `stream_intermediate_steps=True`. This will provide real-time updates about each step of the workflow.

```python
from typing import Iterator

from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.workflow import Condition, Step, Workflow, StepInput
from agno.run.workflow import WorkflowRunOutput, WorkflowRunOutputEvent, WorkflowRunEvent

# === BASIC AGENTS ===
researcher = Agent(
    name="Researcher",
    instructions="Research the given topic and provide detailed findings.",
    tools=[DuckDuckGoTools()],
)

summarizer = Agent(
    name="Summarizer",
    instructions="Create a clear summary of the research findings.",
)

fact_checker = Agent(
    name="Fact Checker",
    instructions="Verify facts and check for accuracy in the research.",
    tools=[DuckDuckGoTools()],
)

writer = Agent(
    name="Writer",
    instructions="Write a comprehensive article based on all available research and verification.",
)

# === CONDITION EVALUATOR ===
def needs_fact_checking(step_input: StepInput) -> bool:
    """Determine if the research contains claims that need fact-checking"""
    summary = step_input.previous_step_content or ""

    # Look for keywords that suggest factual claims
    fact_indicators = [
        "study shows",
        "breakthroughs",
        "research indicates",
        "according to",
        "statistics",
        "data shows",
        "survey",
        "report",
        "million",
        "billion",
        "percent",
        "%",
        "increase",
        "decrease",
    ]

    return any(indicator in summary.lower() for indicator in fact_indicators)


# === WORKFLOW STEPS ===
research_step = Step(
    name="research",
    description="Research the topic",
    agent=researcher,
)

summarize_step = Step(
    name="summarize",
    description="Summarize research findings",
    agent=summarizer,
)

# Conditional fact-checking step
fact_check_step = Step(
    name="fact_check",
    description="Verify facts and claims",
    agent=fact_checker,
)

write_article = Step(
    name="write_article",
    description="Write final article",
    agent=writer,
)

# === BASIC LINEAR WORKFLOW ===
basic_workflow = Workflow(
    name="Basic Linear Workflow",
    description="Research -> Summarize -> Condition(Fact Check) -> Write Article",
    steps=[
        research_step,
        summarize_step,
        Condition(
            name="fact_check_condition",
            description="Check if fact-checking is needed",
            evaluator=needs_fact_checking,
            steps=[fact_check_step],
        ),
        write_article,
    ],
)

if __name__ == "__main__":
    try:
        response: Iterator[WorkflowRunOutputEvent] = basic_workflow.run(
            message="Recent breakthroughs in quantum computing",
            stream=True,
            stream_intermediate_steps=True,
        )
        for event in response:
            if event.event == WorkflowRunEvent.condition_execution_started.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.condition_execution_completed.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.workflow_started.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.step_started.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.step_completed.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.workflow_completed.value:
                print(event)
                print()
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback

        traceback.print_exc()
```

### Async Streaming

The `Workflow.arun(stream=True)` returns an async iterator of `WorkflowRunOutputEvent` objects instead of a single response.
So for example, if you want to stream the response, you can do the following:

```Python

# Define your workflow
...

async def main():
    try:
        response: AsyncIterator[WorkflowRunOutputEvent] = await basic_workflow.arun(
            message="Recent breakthroughs in quantum computing",
            stream=True,
            stream_intermediate_steps=True,
        )
        async for event in response:
            if event.event == WorkflowRunEvent.condition_execution_started.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.condition_execution_completed.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.workflow_started.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.step_started.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.step_completed.value:
                print(event)
                print()
            elif event.event == WorkflowRunEvent.workflow_completed.value:
                print(event)
                print()
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
```

### Event Types

The following events are yielded by the `Workflow.run()` and `Workflow.arun()` functions depending on the workflow's configuration:

#### Core Events

| Event Type          | Description                                         |
| ------------------- | --------------------------------------------------- |
| `WorkflowStarted`   | Indicates the start of a workflow run               |
| `WorkflowCompleted` | Signals successful completion of the workflow run   |
| `WorkflowError`     | Indicates an error occurred during the workflow run |

#### Step Events

| Event Type      | Description                               |
| --------------- | ----------------------------------------- |
| `StepStarted`   | Indicates the start of a step             |
| `StepCompleted` | Signals successful completion of a step   |
| `StepError`     | Indicates an error occurred during a step |

#### Step Output Events (For custom functions)

| Event Type   | Description                    |
| ------------ | ------------------------------ |
| `StepOutput` | Indicates the output of a step |

#### Parallel Execution Events

| Event Type                   | Description                                      |
| ---------------------------- | ------------------------------------------------ |
| `ParallelExecutionStarted`   | Indicates the start of a parallel step           |
| `ParallelExecutionCompleted` | Signals successful completion of a parallel step |

#### Condition Execution Events

| Event Type                    | Description                                  |
| ----------------------------- | -------------------------------------------- |
| `ConditionExecutionStarted`   | Indicates the start of a condition           |
| `ConditionExecutionCompleted` | Signals successful completion of a condition |

#### Loop Execution Events

| Event Type                    | Description                                       |
| ----------------------------- | ------------------------------------------------- |
| `LoopExecutionStarted`        | Indicates the start of a loop                     |
| `LoopIterationStartedEvent`   | Indicates the start of a loop iteration           |
| `LoopIterationCompletedEvent` | Signals successful completion of a loop iteration |
| `LoopExecutionCompleted`      | Signals successful completion of a loop           |

#### Router Execution Events

| Event Type                 | Description                               |
| -------------------------- | ----------------------------------------- |
| `RouterExecutionStarted`   | Indicates the start of a router           |
| `RouterExecutionCompleted` | Signals successful completion of a router |

#### Steps Execution Events

| Event Type                | Description                                        |
| ------------------------- | -------------------------------------------------- |
| `StepsExecutionStarted`   | Indicates the start of `Steps` being executed      |
| `StepsExecutionCompleted` | Signals successful completion of `Steps` execution |

See detailed documentation in the [WorkflowRunOutputEvent](/reference/workflows/workflow_run_output) documentation.

## Agno Telemetry

Agno logs which model an workflow used so we can prioritize updates to the most popular providers. You can disable this by setting `AGNO_TELEMETRY=false` in your environment or by setting `telemetry=False` on the workflow.

```bash
export AGNO_TELEMETRY=false
```

or:

```python
workflow = Workflow(..., telemetry=False)
```

See the [Workflow class reference](/reference/workflows/workflow) for more details.

## Developer Resources

* View the [Workflow reference](/reference/workflows/workflow)
* View the [WorkflowRunOutput schema](/reference/workflows/workflow_run_output)
* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/README.md)


# Advanced Workflow Patterns
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/advanced-workflow-patterns

Combine multiple workflow patterns to build sophisticated, production-ready automation systems

**Pattern Combination**: Conditional Logic + Parallel Execution + Iterative Loops + Custom Processing + Dynamic Routing

This example demonstrates how deterministic patterns can be composed to create complex yet predictable workflows.

```python advanced_workflow_patterns.py
from agno.workflow import Condition, Loop, Parallel, Router, Step, Workflow

def research_post_processor(step_input) -> StepOutput:
    """Post-process and consolidate research data from parallel conditions"""
    research_data = step_input.previous_step_content or ""

    try:
        # Analyze research quality and completeness
        word_count = len(research_data.split())
        has_tech_content = any(keyword in research_data.lower()
                              for keyword in ["technology", "ai", "software", "tech"])
        has_business_content = any(keyword in research_data.lower()
                                  for keyword in ["market", "business", "revenue", "strategy"])

        # Create enhanced research summary
        enhanced_summary = f"""
            ## Research Analysis Report

            **Data Quality:** {"‚úì High-quality" if word_count > 200 else "‚ö† Limited data"}

            **Content Coverage:**
            - Technical Analysis: {"‚úì Completed" if has_tech_content else "‚úó Not available"}
            - Business Analysis: {"‚úì Completed" if has_business_content else "‚úó Not available"}

            **Research Findings:**
            {research_data}
        """.strip()

        return StepOutput(
            content=enhanced_summary,
            success=True,
        )

    except Exception as e:
        return StepOutput(
            content=f"Research post-processing failed: {str(e)}",
            success=False,
            error=str(e)
        )

# Complex workflow combining multiple patterns
workflow = Workflow(
    name="Advanced Multi-Pattern Workflow",
    steps=[
        Parallel(
            Condition(
                name="Tech Check",
                evaluator=is_tech_topic,
                steps=[Step(name="Tech Research", agent=tech_researcher)]
            ),
            Condition(
                name="Business Check",
                evaluator=is_business_topic,
                steps=[
                    Loop(
                        name="Deep Business Research",
                        steps=[Step(name="Market Research", agent=market_researcher)],
                        end_condition=research_quality_check,
                        max_iterations=3
                    )
                ]
            ),
            name="Conditional Research Phase"
        ),
        Step(
            name="Research Post-Processing",
            executor=research_post_processor,
            description="Consolidate and analyze research findings with quality metrics"
        ),
        Router(
            name="Content Type Router",
            selector=content_type_selector,
            choices=[blog_post_step, social_media_step, report_step]
        ),
        Step(name="Final Review", agent=reviewer),
    ]
)

workflow.print_response("Create a comprehensive analysis of sustainable technology trends and their business impact for 2024", markdown=True)
```

**More Examples**:

* [Condition and Parallel Steps (Streaming Example)](/examples/concepts/workflows/02-workflows-conditional-execution/condition_and_parallel_steps_stream)
* [Loop with Parallel Steps (Streaming Example)](/examples/concepts/workflows/03_workflows_loop_execution/loop_with_parallel_steps_stream)
* [Router with Loop Steps](/examples/concepts/workflows/05_workflows_conditional_branching/router_with_loop_steps)


# Branching Workflow
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/branching-workflow

Complex decision trees requiring dynamic path selection based on content analysis

**Example Use-Cases**: Expert routing, content type detection, multi-path processing

Dynamic routing workflows provide intelligent path selection while maintaining predictable execution within each chosen branch.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=11256e6d5ebe78ee137ba56647bb732c" alt="Workflows router steps diagram" data-og-width="2493" width="2493" data-og-height="921" height="921" data-path="images/workflows-router-steps-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?w=280&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=bbbf338fb349e3d6e9e66f92873ca74b 280w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?w=560&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=3c341c1b87faa0eca3092ea8f93c5d0b 560w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?w=840&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=75dabdfd37b0806915bd56520c176d0a 840w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?w=1100&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=8e91a1cb88327098c3420a0bd4994e69 1100w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?w=1650&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=e948b1e5b7f48fde2637265f2daef7f5 1650w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps-light.png?w=2500&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=74139a11491c79a755974923831ad406 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=593bc69b1647af6571151c051145e7c6" alt="Workflows router steps diagram" data-og-width="2493" width="2493" data-og-height="921" height="921" data-path="images/workflows-router-steps.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?w=280&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=575bc73e719bb2ccf703278e5aaaa4b3 280w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?w=560&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=6886d723d73a9fc1ffec318b2fe33d3c 560w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?w=840&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=0c364bb81456fc509a64fcac0cb8373a 840w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?w=1100&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=d9ede7db094389fc173c590ea28aa21c 1100w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?w=1650&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=117488ab5bcecbf9e982474dd91580e8 1650w, https://mintcdn.com/agno-v2/6A2IKapU7R02zCpZ/images/workflows-router-steps.png?w=2500&fit=max&auto=format&n=6A2IKapU7R02zCpZ&q=85&s=e0f5a19e133076f0ba74ced4f21ba411 2500w" />

## Example

```python branching_workflow.py
from agno.workflow import Router, Step, Workflow

def route_by_topic(step_input) -> List[Step]:
    topic = step_input.input.lower()

    if "tech" in topic:
        return [Step(name="Tech Research", agent=tech_expert)]
    elif "business" in topic:
        return [Step(name="Business Research", agent=biz_expert)]
    else:
        return [Step(name="General Research", agent=generalist)]

workflow = Workflow(
    name="Expert Routing",
    steps=[
        Router(
            name="Topic Router",
            selector=route_by_topic,
            choices=[tech_step, business_step, general_step]
        ),
        Step(name="Synthesis", agent=synthesizer),
    ]
)

workflow.print_response("Latest developments in artificial intelligence and machine learning", markdown=True)
```

## Developer Resources

* [Router Steps Workflow](/examples/concepts/workflows/05_workflows_conditional_branching/router_steps_workflow)

## Reference

For complete API documentation, see [Router Steps Reference](/reference/workflows/router-steps).


# Conditional Workflow
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/conditional-workflow

Deterministic branching based on input analysis or business rules

**Example Use-Cases**: Content type routing, topic-specific processing, quality-based decisions

Conditional workflows provide predictable branching logic while maintaining deterministic execution paths.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=7bc060741f060c43747d9866246d0587" alt="Workflows condition steps diagram" data-og-width="3441" width="3441" data-og-height="756" height="756" data-path="images/workflows-condition-steps-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=051009cf50418538acbc49a9c690cdf8 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5f8e6a2ed1301cf1d4edda7804c5ec08 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=65a6ba82ef0a22a0927439644a6c7912 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=f5d676c0bf82f2045e61f31126b66a42 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=408f8ed2a78755b289c7a0b4e07d6f0e 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps-light.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=548ca991ffb6e9e5d7669bf37e98fed2 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=de3fa0bc3fc9b4079e7dd3596d6e589a" alt="Workflows condition steps diagram" data-og-width="3441" width="3441" data-og-height="756" height="756" data-path="images/workflows-condition-steps.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=3b0eb6ed78b037dd85346647665f373e 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=9c5e9785043d807c36b6ee130fde63ef 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5044466baae4103aadf462fb81b9be60 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=d67a6cb9bb25245259a4001be56f7d91 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=ff169ab64d750cfb21073305fdedd213 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-condition-steps.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=0f44b53b13a00c51b26314825d605013 2500w" />

## Example

```python conditional_workflow.py
from agno.workflow import Condition, Step, Workflow

def is_tech_topic(step_input) -> bool:
    topic = step_input.input.lower()
    return any(keyword in topic for keyword in ["ai", "tech", "software"])

workflow = Workflow(
    name="Conditional Research",
    steps=[
        Condition(
            name="Tech Topic Check",
            evaluator=is_tech_topic,
            steps=[Step(name="Tech Research", agent=tech_researcher)]
        ),
        Step(name="General Analysis", agent=general_analyst),
    ]
)

workflow.print_response("Comprehensive analysis of AI and machine learning trends", markdown=True)
```

## Developer Resources

* [Condition Steps Workflow](/examples/concepts/workflows/02-workflows-conditional-execution/condition_steps_workflow_stream)
* [Condition with List of Steps](/examples/concepts/workflows/02-workflows-conditional-execution/condition_with_list_of_steps)

## Reference

For complete API documentation, see [Condition Steps Reference](/reference/workflows/conditional-steps).


# Fully Python Workflow
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/fully-python-workflow

Keep it Simple with Pure Python, in v1 workflows style

**Keep it Simple with Pure Python**: If you prefer the Workflows 1.0 approach or need maximum flexibility, you can still use a single Python function to handle everything.
This approach gives you complete control over the execution flow while still benefiting from workflow features like storage, streaming, and session management.

Replace all the steps in the workflow with a single executable function where you can control everything.

```python fully_python_workflow.py
from agno.workflow import Workflow, WorkflowExecutionInput

def custom_workflow_function(workflow: Workflow, execution_input: WorkflowExecutionInput):
    # Custom orchestration logic
    research_result = research_team.run(execution_input.message)
    analysis_result = analysis_agent.run(research_result.content)
    return f"Final: {analysis_result.content}"

workflow = Workflow(
    name="Function-Based Workflow",
    steps=custom_workflow_function  # Single function replaces all steps
)

workflow.print_response("Evaluate the market potential for quantum computing applications", markdown=True)
```

**See Example**:

* [Function-Based Workflow](/examples/concepts/workflows/01-basic-workflows/function_instead_of_steps) - Complete function-based workflow

For migration from 1.0 style workflows, refer to the page for [Migrating to Workflows 2.0](/how-to/v2-migration)


# Grouped Steps Workflow
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/grouped-steps-workflow

Organize multiple steps into reusable, logical sequences for complex workflows with clean separation of concerns

**Key Benefits**: Reusable sequences, cleaner branching logic, modular workflow design

Grouped steps enable modular workflow architecture with reusable components and clear logical boundaries.

## Basic Example

```python grouped_steps_workflow.py
from agno.workflow import Steps, Step, Workflow

# Create a reusable content creation sequence
article_creation_sequence = Steps(
    name="ArticleCreation",
    description="Complete article creation workflow from research to final edit",
    steps=[
        Step(name="research", agent=researcher),
        Step(name="writing", agent=writer),
        Step(name="editing", agent=editor),
    ],
)

# Use the sequence in a workflow
workflow = Workflow(
    name="Article Creation Workflow",
    steps=[article_creation_sequence]  # Single sequence
)

workflow.print_response("Write an article about renewable energy", markdown=True)
```

## Steps with Router

This is where `Steps` really shines - creating distinct sequences for different content types or workflows:

```python
from agno.workflow import Steps, Router, Step, Workflow

# Define two completely different workflows as Steps
image_sequence = Steps(
    name="image_generation",
    description="Complete image generation and analysis workflow",
    steps=[
        Step(name="generate_image", agent=image_generator),
        Step(name="describe_image", agent=image_describer),
    ],
)

video_sequence = Steps(
    name="video_generation",
    description="Complete video production and analysis workflow",
    steps=[
        Step(name="generate_video", agent=video_generator),
        Step(name="describe_video", agent=video_describer),
    ],
)

def media_sequence_selector(step_input) -> List[Step]:
    """Route to appropriate media generation pipeline"""
    if not step_input.input:
        return [image_sequence]

    message_lower = step_input.input.lower()

    if "video" in message_lower:
        return [video_sequence]
    elif "image" in message_lower:
        return [image_sequence]
    else:
        return [image_sequence]  # Default

# Clean workflow with clear branching
media_workflow = Workflow(
    name="AI Media Generation Workflow",
    description="Generate and analyze images or videos using AI agents",
    steps=[
        Router(
            name="Media Type Router",
            description="Routes to appropriate media generation pipeline",
            selector=media_sequence_selector,
            choices=[image_sequence, video_sequence],  # Clear choices
        )
    ],
)

# Usage examples
media_workflow.print_response("Create an image of a magical forest", markdown=True)
media_workflow.print_response("Create a cinematic video of city timelapse", markdown=True)
```

## Developer Resources

* [`workflow_using_steps.py`](/examples/concepts/workflows/01-basic-workflows/workflow_using_steps)
* [`workflow_using_steps_nested.py`](/examples/concepts/workflows/01-basic-workflows/workflow_using_steps_nested)
* [`selector_for_image_video_generation_pipelines.py`](/examples/concepts/workflows/05_workflows_conditional_branching/selector_for_image_video_generation_pipelines)

## Reference

For complete API documentation, see [Steps Reference](/reference/workflows/steps-step).


# Iterative Workflow
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/iterative-workflow

Quality-driven processes requiring repetition until specific conditions are met

**Example Use-Cases**: Quality improvement loops, retry mechanisms, iterative refinement

Iterative workflows provide controlled repetition with deterministic exit conditions, ensuring consistent quality standards.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=edba198de555846a2ea8b2e5b65c6d8e" alt="Workflows loop steps diagram" data-og-width="3441" width="3441" data-og-height="756" height="756" data-path="images/workflows-loop-steps-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=96d954f1d665b4b01e0fb030c0544504 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=f4ce273ba17af6b0b5b417ec2e73385c 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=15eb9ff0487ff79dccaa1a046ad7c32d 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=ac3e8fb6db4326f2e78948c467924f7c 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=45c09671d2bb3190bb14f23ecab28f85 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps-light.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=05a4004d7c8228caefbacbc21a2efd2f 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=30027b401899598a38a73c6038d1d988" alt="Workflows loop steps diagram" data-og-width="3441" width="3441" data-og-height="756" height="756" data-path="images/workflows-loop-steps.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=aa15df4e2e353012150474b5fa26d5c5 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=f411273ea9e60981989e16324940fbc0 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=a71354c338a1520f27797ca6e53dc378 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=cf1495378fc757cd5995b96c734cda71 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=3d32977904938d0cc22407d61c6efd8e 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-loop-steps.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=e3e1c672c2953455defceb971b803bce 2500w" />

## Example

```python iterative_workflow.py
from agno.workflow import Loop, Step, Workflow

def quality_check(outputs) -> bool:
    # Return True to break loop, False to continue
    return any(len(output.content) > 500 for output in outputs)

workflow = Workflow(
    name="Quality-Driven Research",
    steps=[
        Loop(
            name="Research Loop",
            steps=[Step(name="Deep Research", agent=researcher)],
            end_condition=quality_check,
            max_iterations=3
        ),
        Step(name="Final Analysis", agent=analyst),
    ]
)

workflow.print_response("Research the impact of renewable energy on global markets", markdown=True)
```

## Developer Resources

* [Loop Steps Workflow](/examples/concepts/workflows/03_workflows_loop_execution/loop_steps_workflow)

## Reference

For complete API documentation, see [Loop Steps Reference](/reference/workflows/loop-steps).


# Workflow Patterns
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/overview

Master deterministic workflow patterns including sequential, parallel, conditional, and looping execution for reliable multi-agent automation.

Build deterministic, production-ready workflows that orchestrate agents, teams, and functions with predictable execution patterns. This comprehensive guide covers all workflow types, from simple sequential processes to complex branching logic with parallel execution and dynamic routing.

Unlike free-form agent interactions, these patterns provide structured automation with consistent, repeatable results ideal for production systems.

## Building Blocks

The core building blocks of Agno Workflows are:

| Component     | Purpose                         |
| ------------- | ------------------------------- |
| **Step**      | Basic execution unit            |
| **Agent**     | AI assistant with specific role |
| **Team**      | Coordinated group of agents     |
| **Function**  | Custom Python logic             |
| **Parallel**  | Concurrent execution            |
| **Condition** | Conditional execution           |
| **Loop**      | Iterative execution             |
| **Router**    | Dynamic routing                 |

Agno Workflows support multiple execution patterns that can be combined to build sophisticated automation systems.
Each pattern serves specific use cases and can be composed together for complex workflows.

<CardGroup cols={2}>
  <Card title="Sequential Workflows" icon="arrow-right" href="/concepts/workflows/workflow-patterns/sequential">
    Linear execution with step-by-step processing
  </Card>

  <Card title="Parallel Workflows" icon="arrows-split-up-and-left" href="/concepts/workflows/workflow-patterns/parallel-workflow">
    Concurrent execution for independent tasks
  </Card>

  <Card title="Conditional Workflows" icon="code-branch" href="/concepts/workflows/workflow-patterns/conditional-workflow">
    Branching logic based on conditions
  </Card>

  <Card title="Iterative Workflows" icon="rotate" href="/concepts/workflows/workflow-patterns/iterative-workflow">
    Loop-based execution with quality controls
  </Card>

  <Card title="Branching Workflows" icon="sitemap" href="/concepts/workflows/workflow-patterns/branching-workflow">
    Dynamic routing and path selection
  </Card>

  <Card title="Grouped Steps" icon="layer-group" href="/concepts/workflows/workflow-patterns/grouped-steps-workflow">
    Reusable step sequences and modular design
  </Card>
</CardGroup>

## Advanced Patterns

<CardGroup cols={2}>
  <Card title="Function-Based Workflows" icon="function" href="/concepts/workflows/workflow-patterns/fully-python-workflow">
    Pure Python workflows with complete control
  </Card>

  <Card title="Multi-Pattern Combinations" icon="puzzle-piece" href="/concepts/workflows/workflow-patterns/advanced-workflow-patterns">
    Complex workflows combining multiple patterns
  </Card>
</CardGroup>


# Parallel Workflow
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/parallel-workflow

Independent, concurrent tasks that can execute simultaneously for improved efficiency

**Example Use-Cases**: Multi-source research, parallel analysis, concurrent data processing

Parallel workflows maintain deterministic results while dramatically reducing execution time for independent operations.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=afda5268ab0637c6064ace8edd6f35e5" alt="Workflows parallel steps diagram" data-og-width="3441" width="3441" data-og-height="756" height="756" data-path="images/workflows-parallel-steps-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=c153b9934fa98b2b886a9435022b020a 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=17253f58b485bb6180827516f7f947be 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=b067f30b291f2de8cb6a04e208ee61cc 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=a814e829581fb1d7c64e49fa87ca847e 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=1cd456c3e949af82fd6325b3f3865f23 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps-light.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=52fcc51f72ee6e1df2648612451cae70 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=ec4f6c7c9a6ef76cec8f0866eb1acc5b" alt="Workflows parallel steps diagram" data-og-width="3441" width="3441" data-og-height="756" height="756" data-path="images/workflows-parallel-steps.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=39624cca7177ba0064491bb64c645db2 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=c3e5cde671f164b7dd13eb417f5f74db 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=db6672401fdf35e0eb616e72016ec41c 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=831053d087a3bf26e966f8f896ac9b61 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=445e07ea13a74913e67e2a2a9c8e9c5f 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-parallel-steps.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=77083544c8387f660207dfaf645bdaf0 2500w" />

## Example

```python parallel_workflow.py
from agno.workflow import Parallel, Step, Workflow

workflow = Workflow(
    name="Parallel Research Pipeline",
    steps=[
        Parallel(
            Step(name="HackerNews Research", agent=hn_researcher),
            Step(name="Web Research", agent=web_researcher),
            Step(name="Academic Research", agent=academic_researcher),
            name="Research Step"
        ),
        Step(name="Synthesis", agent=synthesizer),  # Combines the results and produces a report
    ]
)

workflow.print_response("Write about the latest AI developments", markdown=True)
```

## Developer Resources

* [Parallel Steps Workflow](/examples/concepts/workflows/04-workflows-parallel-execution/parallel_steps_workflow)

## Reference

For complete API documentation, see [Parallel Steps Reference](/reference/workflows/parallel-steps).


# Sequential Workflows
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/sequential

Linear, deterministic processes where each step depends on the output of the previous step.

Sequential workflows ensure predictable execution order and clear data flow between steps.

**Example Flow**: Research ‚Üí Data Processing ‚Üí Content Creation ‚Üí Final Review

Sequential workflows ensure predictable execution order and clear data flow between steps.

```python sequential_workflow.py
from agno.workflow import Step, Workflow, StepOutput

def data_preprocessor(step_input):
    # Custom preprocessing logic

    # Or you can also run any agent/team over here itself
    # response = some_agent.run(...)
    return StepOutput(content=f"Processed: {step_input.input}") # <-- Now pass the agent/team response in content here

workflow = Workflow(
    name="Mixed Execution Pipeline",
    steps=[
        research_team,      # Team
        data_preprocessor,  # Function
        content_agent,      # Agent
    ]
)

workflow.print_response("Analyze the competitive landscape for fintech startups", markdown=True)
```

<Note>
  For more information on how to use custom functions, refer to the
  [Advanced](/concepts/workflows/advanced) page.
</Note>

**See Example**:

* [Sequence of Functions and Agents](/examples/concepts/workflows/01-basic-workflows/sequence_of_functions_and_agents) - Complete workflow with functions and agents

<Note>
  `StepInput` and `StepOutput` provides standardized interfaces for data flow between steps:
  So if you make a custom function as an executor for a step, make sure that the input and output types are compatible with the `StepInput` and `StepOutput` interfaces.
  This will ensure that your custom function can seamlessly integrate into the workflow system.

  Take a look at the schemas for [`StepInput`](/reference/workflows/step_input) and [`StepOutput`](/reference/workflows/step_output).
</Note>


# Step-Based Workflows
Source: https://docs.agno.com/concepts/workflows/workflow-patterns/step-based-workflow

Named steps for better logging and support on the AgentOS chat page

**You can name your steps** for better logging and future support on the Agno platform.
This also changes the name of a step when accessing that step's output inside a `StepInput` object.

## Example

```python
from agno.workflow import Step, Workflow

# Named steps for better tracking
workflow = Workflow(
    name="Content Creation Pipeline",
    steps=[
        Step(name="Research Phase", team=researcher),
        Step(name="Analysis Phase", executor=custom_function),
        Step(name="Writing Phase", agent=writer),
    ]
)

workflow.print_response(
    "AI trends in 2024",
    markdown=True,
)
```

## Developer Resources

* [Sequence of Steps](/examples/concepts/workflows/01-basic-workflows/sequence_of_steps)
* [Step with a Custom Function](/examples/concepts/workflows/01-basic-workflows/step_with_function)

## Reference

For complete API documentation, see [Step Reference](/reference/workflows/step).


# How does shared state work between workflows, teams and agents?
Source: https://docs.agno.com/concepts/workflows/workflow_session_state

Learn to handle shared state between the different components of a Workflow

Workflow session state enables persistent data sharing across all components within a workflow - agents, teams, and custom functions. This shared state maintains continuity and enables sophisticated coordination between different workflow components, making it essential for building stateful, deterministic automation systems.

<img className="block dark:hidden" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=eb9f2f37de2699763ae1cab8b26e5792" alt="Workflows session state diagram" data-og-width="2199" width="2199" data-og-height="1203" height="1203" data-path="images/workflows-session-state-light.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=be8235601f44c3d5c899e769bd7e10a7 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=c54d2a340511cf08b6f62ee2dc725ab6 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=a8704d97da7f5fd6490acd6e9e847f21 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=88b25555c12572fbb92d1b7724e77cc6 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=e0c24367b61326e2115cfa74059d1316 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state-light.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=c5d4f68f953670a714b4a5d334f9b5fb 2500w" />

<img className="hidden dark:block" src="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5e56bc8354bbb79f31d6c4140e5dea2e" alt="Workflows session state diagram" data-og-width="2199" width="2199" data-og-height="1203" height="1203" data-path="images/workflows-session-state.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?w=280&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=494e73f94a71a1611b068a2561ed6c7a 280w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?w=560&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=3c754db0830ab28e7640f553c9dd93a9 560w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?w=840&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=fa17e5cf5ebf2d45a85a328abbd52bf7 840w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?w=1100&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=e82eae67add368163f04fcb09dab4271 1100w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?w=1650&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=d66bd915da648ef787dd86aa2a5eede6 1650w, https://mintcdn.com/agno-v2/JYIBgMrzFEujZh3_/images/workflows-session-state.png?w=2500&fit=max&auto=format&n=JYIBgMrzFEujZh3_&q=85&s=5bf1239ad621457d50d67b28153b9a1b 2500w" />

## How Workflow Session State Works

### 1. State Initialization

Initialize session state when creating a workflow. The state can start empty or with predefined data that all workflow components can access and modify.

```python
shopping_workflow = Workflow(
    name="Shopping List Workflow",
    steps=[manage_items_step, view_list_step],
    session_state={"shopping_list": []},  # Initialize with structured data
)
```

### 2. State Access and Modification

All workflow components - agents, teams, and functions - can read from and write to the shared session state. This enables persistent data flow and coordination across the entire workflow execution.

**Example: Shopping List Management**

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai.chat import OpenAIChat
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

db = SqliteDb(db_file="tmp/workflow.db")


# Define tools to manage a shopping list in workflow session state
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list in workflow session state.

    Args:
        item (str): The item to add to the shopping list
    """
    # Check if item already exists (case-insensitive)
    existing_items = [
        existing_item.lower() for existing_item in session_state["shopping_list"]
    ]
    if item.lower() not in existing_items:
        session_state["shopping_list"].append(item)
        return f"Added '{item}' to the shopping list."
    else:
        return f"'{item}' is already in the shopping list."


def remove_item(session_state, item: str) -> str:
    """Remove an item from the shopping list in workflow session state.

    Args:
        item (str): The item to remove from the shopping list
    """
    if len(session_state["shopping_list"]) == 0:
        return f"Shopping list is empty. Cannot remove '{item}'."

    # Find and remove item (case-insensitive)
    shopping_list = session_state["shopping_list"]
    for i, existing_item in enumerate(shopping_list):
        if existing_item.lower() == item.lower():
            removed_item = shopping_list.pop(i)
            return f"Removed '{removed_item}' from the shopping list."

    return f"'{item}' not found in the shopping list."


def remove_all_items(session_state) -> str:
    """Remove all items from the shopping list in workflow session state."""
    session_state["shopping_list"] = []
    return "Removed all items from the shopping list."


def list_items(session_state) -> str:
    """List all items in the shopping list from workflow session state."""
    if len(session_state["shopping_list"]) == 0:
        return "Shopping list is empty."

    items = session_state["shopping_list"]
    items_str = "\n".join([f"- {item}" for item in items])
    return f"Shopping list:\n{items_str}"


# Create agents with tools that use workflow session state
shopping_assistant = Agent(
    name="Shopping Assistant",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[add_item, remove_item, list_items],
    instructions=[
        "You are a helpful shopping assistant.",
        "You can help users manage their shopping list by adding, removing, and listing items.",
        "Always use the provided tools to interact with the shopping list.",
        "Be friendly and helpful in your responses.",
    ],
)

list_manager = Agent(
    name="List Manager",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[list_items, remove_all_items],
    instructions=[
        "You are a list management specialist.",
        "You can view the current shopping list and clear it when needed.",
        "Always show the current list when asked.",
        "Confirm actions clearly to the user.",
    ],
)

# Create steps
manage_items_step = Step(
    name="manage_items",
    description="Help manage shopping list items (add/remove)",
    agent=shopping_assistant,
)

view_list_step = Step(
    name="view_list",
    description="View and manage the complete shopping list",
    agent=list_manager,
)

# Create workflow with workflow_session_state
shopping_workflow = Workflow(
    name="Shopping List Workflow",
    db=db,
    steps=[manage_items_step, view_list_step],
    session_state={"shopping_list": []},
)

if __name__ == "__main__":
    # Example 1: Add items to the shopping list
    print("=== Example 1: Adding Items ===")
    shopping_workflow.print_response(
        input="Please add milk, bread, and eggs to my shopping list."
    )
    print("Workflow session state:", shopping_workflow.get_session_state())

    # Example 2: Add more items and view list
    print("\n=== Example 2: Adding More Items ===")
    shopping_workflow.print_response(
        input="Add apples and bananas to the list, then show me the complete list."
    )
    print("Workflow session state:", shopping_workflow.get_session_state())

    # Example 3: Remove items
    print("\n=== Example 3: Removing Items ===")
    shopping_workflow.print_response(
        input="Remove bread from the list and show me what's left."
    )
    print("Workflow session state:", shopping_workflow.get_session_state())

    # Example 4: Clear the entire list
    print("\n=== Example 4: Clearing List ===")
    shopping_workflow.print_response(
        input="Clear the entire shopping list and confirm it's empty."
    )
    print("Final workflow session state:", shopping_workflow.get_session_state())
```

### 3. `session_state` as a parameter for custom python functions step in workflow

You can use the `session_state` as a parameter for custom python functions step in workflow to access and modify the session state.

<Note>
  On the function of the custom python function step for a workflow

  ```python
  def custom_function_step(step_input: StepInput, session_state):
      session_state["test"] = test_1 # updates the workflow session state
  ```
</Note>

See [examples](/examples/concepts/workflows/06_workflows_advanced_concepts/access_session_state_in_custom_python_function_step) for more details.

## Key Benefits

**Persistent State Management**

* Data persists across all workflow steps and components
* Enables complex, stateful workflows with memory
* Supports deterministic execution with consistent state

**Cross-Component Coordination**

* Agents, teams, and functions share the same state object
* Enables sophisticated collaboration patterns
* Maintains data consistency across workflow execution

**Flexible Data Structure**

* Use any Python data structure (dictionaries, lists, objects)
* Structure data to match your workflow requirements
* Access and modify state through standard Python operations

<Note>
  The `session_state` is automatically passed to all agents and teams within a
  workflow, enabling seamless collaboration and data sharing between different
  components without manual state management.
</Note>

## Useful Links

<CardGroup cols={2}>
  <Card title="Agent Examples" icon="user" href="https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_06_advanced_concepts/_04_shared_session_state/shared_session_state_with_agent.py">
    See how agents interact with shared session state
  </Card>

  <Card title="Team Examples" icon="users" href="https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_06_advanced_concepts/_04_shared_session_state/shared_session_state_with_team.py">
    Learn how teams coordinate using shared state
  </Card>
</CardGroup>


# Deploy your AgentOS
Source: https://docs.agno.com/deploy/introduction

How to take your AgentOS to production

## Overview

You can build, test, and improve your AgentOS locally, but to run it in production you‚Äôll need to deploy it to your own infrastructure. Because it‚Äôs pure Python code, you‚Äôre free to deploy AgentOS anywhere. To make things easier, we‚Äôve also put together a set of ready to use templates - standardized codebases you can use to quickly deploy AgentOS to your own infrastructure.

Currently supported templates:

Docker Template: [agent-infra-docker](https://github.com/agno-agi/agent-infra-docker)
AWS Template: [agent-infra-aws](https://github.com/agno-agi/agent-infra-aws)

Coming soon:

* Modal Template
* Railway Template
* Render Template
* GCP Template

## What is A Template?

A template is a standardized codebase for a production AgentOS. It contains:

* An AgentOS instance using FastAPI.
* A Database for storing Sessions, Memories, Knowledge and Evals.

They are setup to run locally using docker and on cloud providers. They're a fantastic starting point and exactly what we use for our customers. You'll definitely need to customize them to fit your specific needs, but they'll get you started much faster.

## Here's How They Work

**Step 1**: Create your codebase using: `ag infra create` and choose a template.

This will clone one of our templates and give you a starting point.

**Step 2**: `cd` into your codebase and run locally using docker: `ag infra up`

This will start your AgentOS instance and PostgreSQL database locally using docker.

**Step 3 (For AWS template)**: Run on AWS: `ag infra up prd:aws`

This will start your AgentOS instance and PostgreSQL database on AWS.

We recommend starting with the `agent-infra-docker` template and taking it from there.

<CardGroup cols={2}>
  <Card title="Agent Infra Docker " icon="server" href="/templates/agent-infra-docker/local">
    An AgentOS template with a docker compose file.
  </Card>

  <Card title="Agent Infra AWS" icon="server" href="/templates/agent-infra-aws/local">
    An AgentOS template with a AWS infrastructure.
  </Card>
</CardGroup>


# Accuracy Evals
Source: https://docs.agno.com/evals/accuracy

Learn how to evaluate your Agno Agents and Teams for accuracy using LLM-as-a-judge methodology with input/output pairs.

Accuracy evals aim at measuring how well your Agents and Teams perform against a gold-standard answer.

You will provide an input and the ideal, expected output. Then the Agent's real answer will be compared against the given ideal output.

## Basic Example

In this example, the `AccuracyEval` will run the Agent with the input, then use a different model (`o4-mini`) to score the Agent's response according to the guidelines provided.

```python accuracy.py
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    name="Calculator Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    additional_guidelines="Agent output should include the steps and the final answer.",
    num_iterations=3,
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```

### Evaluator Agent

To evaluate the accuracy of the Agent's response, we use another Agent. This strategy is usually referred to as "LLM-as-a-judge".

You can adjust the evaluator Agent to make it fit the criteria you want to evaluate:

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyAgentResponse, AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

# Setup your evaluator Agent
evaluator_agent = Agent(
    model=OpenAIChat(id="gpt-5"),
    output_schema=AccuracyAgentResponse,  # We want the evaluator agent to return an AccuracyAgentResponse
    # You can provide any additional evaluator instructions here:
    # instructions="",
)

evaluation = AccuracyEval(
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[CalculatorTools()]),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    # Use your evaluator Agent
    evaluator_agent=evaluator_agent,
    # Further adjusting the guidelines
    additional_guidelines="Agent output should include the steps and the final answer.",
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```

<Frame>
  <img height="200" src="https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=60f989f94bfe8b9147e0fe439e1d27d2" style={{ borderRadius: '8px' }} data-og-width="2046" data-og-height="1354" data-path="images/evals/accuracy_basic.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?w=280&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=a37037fd28a47087de5fedc599c4346b 280w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?w=560&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=b73acf915f02a759ae8c2353fdf6ec77 560w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?w=840&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=dc6425d6eb0243364b9fafd500495a15 840w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?w=1100&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=33690c95f75c292fb1347da676cfaa53 1100w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?w=1650&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=28e03442ad38b0576c1607a6abcd1593 1650w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/accuracy_basic.png?w=2500&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=60af642df61c82e5f7eaa7833d9df73f 2500w" />
</Frame>

## Accuracy with Tools

You can also run the `AccuracyEval` with tools.

```python accuracy_with_tools.py
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    name="Tools Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10!?",
    expected_output="3628800",
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```

## Accuracy with given output

For comprehensive evaluation, run with a given output:

```python accuracy_with_given_answer.py
from typing import Optional

from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat

evaluation = AccuracyEval(
    name="Given Answer Evaluation",
    model=OpenAIChat(id="o4-mini"),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
)
result_with_given_answer: Optional[AccuracyResult] = evaluation.run_with_output(
    output="2500", print_results=True
)
assert result_with_given_answer is not None and result_with_given_answer.avg_score >= 8
```

## Accuracy with asynchronous functions

Evaluate accuracy with asynchronous functions:

```python async_accuracy.py
"""This example shows how to run an Accuracy evaluation asynchronously."""

import asyncio
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    additional_guidelines="Agent output should include the steps and the final answer.",
    num_iterations=3,
)

# Run the evaluation calling the arun method.
result: Optional[AccuracyResult] = asyncio.run(evaluation.arun(print_results=True))
assert result is not None and result.avg_score >= 8

```

## Accuracy with Teams

Evaluate accuracy with a team:

```python accuracy_with_team.py
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.team.team import Team

# Setup a team with two members
english_agent = Agent(
    name="English Agent",
    role="You only answer in English",
    model=OpenAIChat(id="gpt-5-mini"),
)
spanish_agent = Agent(
    name="Spanish Agent",
    role="You can only answer in Spanish",
    model=OpenAIChat(id="gpt-5-mini"),
)

multi_language_team = Team(
    name="Multi Language Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[english_agent, spanish_agent],
    respond_directly=True,
    markdown=True,
    instructions=[
        "You are a language router that directs questions to the appropriate language agent.",
        "If the user asks in a language whose agent is not a team member, respond in English with:",
        "'I can only answer in the following languages: English and Spanish.",
        "Always check the language of the user's input before routing to an agent.",
    ],
)

# Evaluate the accuracy of the Team's responses
evaluation = AccuracyEval(
    name="Multi Language Team",
    model=OpenAIChat(id="o4-mini"),
    team=multi_language_team,
    input="Comment allez-vous?",
    expected_output="I can only answer in the following languages: English and Spanish.",
    num_iterations=1,
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8

```

## Accuracy with Number Comparison

This example demonstrates evaluating an agent's ability to make correct numerical comparisons, which can be tricky for LLMs when dealing with decimal numbers:

```python accuracy_comparison.py
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    name="Number Comparison Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
        instructions="You must use the calculator tools for comparisons.",
    ),
    input="9.11 and 9.9 -- which is bigger?",
    expected_output="9.9",
    additional_guidelines="Its ok for the output to include additional text or information relevant to the comparison.",
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Basic Accuracy Example">
    <CodeGroup>
      ```bash Mac
      python accuracy.py
      ```

      ```bash Windows
      python accuracy.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Accuracy with Tools">
    <CodeGroup>
      ```bash Mac
      python accuracy_with_tools.py
      ```

      ```bash Windows
      python accuracy_with_tools.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test with Given Answer">
    <CodeGroup>
      ```bash Mac
      python accuracy_with_given_answer.py
      ```

      ```bash Windows
      python accuracy_with_given_answer.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Async Accuracy">
    <CodeGroup>
      ```bash Mac
      python async_accuracy.py
      ```

      ```bash Windows
      python async_accuracy.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Team Accuracy">
    <CodeGroup>
      ```bash Mac
      python accuracy_with_team.py
      ```

      ```bash Windows
      python accuracy_with_team.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Number Comparison">
    <CodeGroup>
      ```bash Mac
      python accuracy_comparison.py
      ```

      ```bash Windows
      python accuracy_comparison.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Track Evals in your AgentOS

The best way to track your Agno Evals is with the AgentOS platform.

<video autoPlay muted controls className="w-full aspect-video" src="https://mintcdn.com/agno-v2/hzelS2cST9lEqMuM/videos/eval_platform.mp4?fit=max&auto=format&n=hzelS2cST9lEqMuM&q=85&s=9329eaac5cd0f551081e51656cc0227c" data-path="videos/eval_platform.mp4" />

```python evals_demo.py

"""Simple example creating a evals and using the AgentOS."""

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.accuracy import AccuracyEval
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.tools.calculator import CalculatorTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

# Setup the agent
basic_agent = Agent(
    id="basic-agent",
    name="Calculator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    markdown=True,
    instructions="You are an assistant that can answer arithmetic questions. Always use the Calculator tools you have.",
    tools=[CalculatorTools()],
)

# Setting up and running an eval for our agent
evaluation = AccuracyEval(
    db=db,  # Pass the database to the evaluation. Results will be stored in the database.
    name="Calculator Evaluation",
    model=OpenAIChat(id="gpt-5-mini"),
    input="Should I post my password online? Answer yes or no.",
    expected_output="No",
    num_iterations=1,
    # Agent or team to evaluate:
    agent=basic_agent,
    # team=basic_team,
)
# evaluation.run(print_results=True)

# Setup the Agno API App
agent_os = AgentOS(
    description="Example app for basic agent with eval capabilities",
    os_id="eval-demo",
    agents=[basic_agent],
)
app = agent_os.get_app()


if __name__ == "__main__":
    """ Run your AgentOS:
    Now you can interact with your eval runs using the API. Examples:
    - http://localhost:8001/eval/{index}/eval-runs
    - http://localhost:8001/eval/{index}/eval-runs/123
    - http://localhost:8001/eval/{index}/eval-runs?agent_id=123
    - http://localhost:8001/eval/{index}/eval-runs?limit=10&page=0&sort_by=created_at&sort_order=desc
    - http://localhost:8001/eval/{index}/eval-runs/accuracy
    - http://localhost:8001/eval/{index}/eval-runs/performance
    - http://localhost:8001/eval/{index}/eval-runs/reliability
    """
    agent_os.serve(app="evals_demo:app", reload=True)

```

<Steps>
  <Step title="Run the Evals Demo">
    <CodeGroup>
      ```bash Mac
      python evals_demo.py
      ```
    </CodeGroup>
  </Step>

  <Step title="View the Evals Demo">
    Head over to <a href="https://os.agno.com/evaluation">[https://os.agno.com/evaluation](https://os.agno.com/evaluation)</a> to view the evals.
  </Step>
</Steps>


# Simple Agent Evals
Source: https://docs.agno.com/evals/introduction

Learn how to evaluate your Agno Agents and Teams across three key dimensions - accuracy (using LLM-as-a-judge), performance (runtime and memory), and reliability (tool calls).

**Evals** is a way to measure the quality of your Agents and Teams. Agno provides 3 dimensions for evaluating Agents:

## Evaluation Dimensions

<CardGroup cols={3}>
  <Card title="Accuracy" icon="bullseye" href="/evals/accuracy">
    How complete/correct/accurate is the Agent's response using LLM-as-a-judge methodology.
  </Card>

  <Card title="Performance" icon="stopwatch" href="/evals/performance">
    How fast does the Agent respond and what's the memory footprint?
  </Card>

  <Card title="Reliability" icon="shield-check" href="/evals/reliability">
    Does the Agent make the expected tool calls and handle errors gracefully?
  </Card>
</CardGroup>

## Quick Start

Here's a simple example of running an accuracy evaluation:

```python quick_eval.py
from typing import Optional
from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

# Create an evaluation
evaluation = AccuracyEval(
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(model=OpenAIChat(id="gpt-5-mini"), tools=[CalculatorTools()]),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    additional_guidelines="Agent output should include the steps and the final answer.",
)

# Run the evaluation
result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```

## Best Practices

* **Start Simple:** Begin with basic accuracy tests before moving to complex performance and reliability evaluations
* **Use Multiple Test Cases:** Don't rely on a single test case - create comprehensive test suites
* **Track Over Time:** Monitor your eval results as you make changes to your agents
* **Combine Dimensions:** Use all three evaluation dimensions for a complete picture of agent quality

## Next Steps

Dive deeper into each evaluation dimension:

1. **[Accuracy Evals](/evals/accuracy)** - Learn LLM-as-a-judge techniques and multiple test case strategies
2. **[Performance Evals](/evals/performance)** - Measure latency, memory usage, and compare different configurations
3. **[Reliability Evals](/evals/reliability)** - Test tool calls, error handling, and rate limiting behavior


# Performance Evals
Source: https://docs.agno.com/evals/performance

Learn how to measure the latency and memory footprint of your Agno Agents and Teams.

Performance evals measure the latency and memory footprint of an Agent or Team.

## Basic Example

```python simple.py
"""Run `pip install openai agno memory_profiler` to install dependencies."""

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
    )

    response = agent.run("What is the capital of France?")
    print(f"Agent response: {response.content}")

    return response


simple_response_perf = PerformanceEval(
    name="Simple Performance Evaluation",
    func=run_agent,
    num_iterations=1,
    warmup_runs=0,
)

if __name__ == "__main__":
    simple_response_perf.run(print_results=True, print_summary=True)
```

<Frame>
  <img height="200" src="https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=ed1f5ecf303b83d454af05ae6e3a14d7" data-og-width="1528" data-og-height="748" data-path="images/evals/performance_basic.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?w=280&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=037bf59b601e8c9b8cf5779ca66cd302 280w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?w=560&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=3c79dff6bf7eca3de5abad855b0598a0 560w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?w=840&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=d4fd86aa92eecfba7a32c9608a23abb3 840w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?w=1100&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=59b2683492b2a8473b66800c0bb13129 1100w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?w=1650&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=a1ee1c1d8b8e01abdbabbe6e49fbac60 1650w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/performance_basic.png?w=2500&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=2efdebf30a5a05f1303f4baaa840db11 2500w" />
</Frame>

## Tool Usage Performance

Compare how tools affects your agent's performance:

```python tools_performance.py
"""Run `pip install agno openai memory_profiler` to install dependencies."""

from typing import Literal

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in nyc"
    elif city == "sf":
        return "It's always sunny in sf"


tools = [get_weather]


def instantiate_agent():
    return Agent(model=OpenAIChat(id="gpt-5-mini"), tools=tools)  # type: ignore


instantiation_perf = PerformanceEval(
    name="Tool Instantiation Performance", func=instantiate_agent, num_iterations=1000
)

if __name__ == "__main__":
    instantiation_perf.run(print_results=True, print_summary=True)

```

## Performance with asyncronous functions

Evaluate agent performance with asyncronous functions:

```python async_performance.py

"""This example shows how to run a Performance evaluation on an async function."""

import asyncio

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


# Simple async function to run an Agent.
async def arun_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
    )
    response = await agent.arun("What is the capital of France?")
    return response


performance_eval = PerformanceEval(func=arun_agent, num_iterations=10)

# Because we are evaluating an async function, we use the arun method.
asyncio.run(performance_eval.arun(print_summary=True, print_results=True))
```

## Agent Performace with Memory Updates

Test agent performance with memory updates:

```python memory_performance.py
"""Run `pip install openai agno memory_profiler` to install dependencies."""

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat

# Memory creation requires a db to be provided
db = SqliteDb(db_file="tmp/memory.db")


def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
        db=db,
        enable_user_memories=True,
    )

    response = agent.run("My name is Tom! I'm 25 years old and I live in New York.")
    print(f"Agent response: {response.content}")

    return response


response_with_memory_updates_perf = PerformanceEval(
    name="Memory Updates Performance",
    func=run_agent,
    num_iterations=5,
    warmup_runs=0,
)

if __name__ == "__main__":
    response_with_memory_updates_perf.run(print_results=True, print_summary=True)

```

## Agent Performance with Storage

Test agent performance with storage:

```python storage_performance.py
"""Run `pip install openai agno` to install dependencies."""

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat

db = SqliteDb(db_file="tmp/storage.db")


def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
        add_history_to_context=True,
        db=db,
    )
    response_1 = agent.run("What is the capital of France?")
    print(response_1.content)

    response_2 = agent.run("How many people live there?")
    print(response_2.content)

    return response_2.content


response_with_storage_perf = PerformanceEval(
    name="Storage Performance",
    func=run_agent,
    num_iterations=1,
    warmup_runs=0,
)

if __name__ == "__main__":
    response_with_storage_perf.run(print_results=True, print_summary=True)
```

## Agent Instantiation Performance

Test agent instantiation performance:

```python agent_instantiation.py
"""Run `pip install agno openai` to install dependencies."""

from agno.agent import Agent
from agno.eval.performance import PerformanceEval


def instantiate_agent():
    return Agent(system_message="Be concise, reply with one sentence.")


instantiation_perf = PerformanceEval(
    name="Instantiation Performance", func=instantiate_agent, num_iterations=1000
)

if __name__ == "__main__":
    instantiation_perf.run(print_results=True, print_summary=True)
```

## Team Instantiation Performance

Test team instantiation performance:

```python team_instantiation.py
"""Run `pip install agno openai` to install dependencies."""

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat
from agno.team import Team

team_member = Agent(model=OpenAIChat(id="gpt-5-mini"))


def instantiate_team():
    return Team(members=[team_member])


instantiation_perf = PerformanceEval(
    name="Instantiation Performance Team", func=instantiate_team, num_iterations=1000
)

if __name__ == "__main__":
    instantiation_perf.run(print_results=True, print_summary=True)
```

## Team Performance with Memory Updates

Test team performance with memory updates:

```python team_performance_with_memory_updates.py

"""Run `pip install agno openai` to install dependencies."""

import asyncio
import random

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat
from agno.team import Team

cities = [
    "New York",
    "Los Angeles",
    "Chicago",
    "Houston",
    "Miami",
    "San Francisco",
    "Seattle",
    "Boston",
    "Washington D.C.",
    "Atlanta",
    "Denver",
    "Las Vegas",
]


# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)


def get_weather(city: str) -> str:
    return f"The weather in {city} is sunny."


weather_agent = Agent(
    id="weather_agent",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Weather Agent",
    description="You are a helpful assistant that can answer questions about the weather.",
    instructions="Be concise, reply with one sentence.",
    tools=[get_weather],
    db=db,
    enable_user_memories=True,
    add_history_to_context=True,
)

team = Team(
    members=[weather_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Be concise, reply with one sentence.",
    db=db,
    markdown=True,
    enable_user_memories=True,
    add_history_to_context=True,
)


async def run_team():
    random_city = random.choice(cities)
    _ = team.arun(
        input=f"I love {random_city}! What weather can I expect in {random_city}?",
        stream=True,
        stream_intermediate_steps=True,
    )

    return "Successfully ran team"


team_response_with_memory_impact = PerformanceEval(
    name="Team Memory Impact",
    func=run_team,
    num_iterations=5,
    warmup_runs=0,
    measure_runtime=False,
    debug_mode=True,
    memory_growth_tracking=True,
)

if __name__ == "__main__":
    asyncio.run(
        team_response_with_memory_impact.arun(print_results=True, print_summary=True)
    )

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno memory_profiler
    ```
  </Step>

  <Step title="Run Basic Performance Test">
    <CodeGroup>
      ```bash Mac
      python simple.py
      ```

      ```bash Windows
      python simple.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Tool Performance Impact">
    <CodeGroup>
      ```bash Mac
      python tools_performance.py
      ```

      ```bash Windows
      python tools_performance.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Async Performance">
    <CodeGroup>
      ```bash Mac
      python async_performance.py
      ```

      ```bash Windows
      python async_performance.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Memory Performance">
    <CodeGroup>
      ```bash Mac
      python memory_performance.py
      ```

      ```bash Windows
      python memory_performance.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Storage Performance">
    <CodeGroup>
      ```bash Mac
      python storage_performance.py
      ```

      ```bash Windows
      python storage_performance.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Agent Instantiation">
    <CodeGroup>
      ```bash Mac
      python agent_instantiation.py
      ```

      ```bash Windows
      python agent_instantiation.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Team Instantiation">
    <CodeGroup>
      ```bash Mac
      python team_instantiation.py
      ```

      ```bash Windows
      python team_instantiation.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Team Memory Performance">
    <CodeGroup>
      ```bash Mac
      python team_performance_with_memory_updates.py
      ```

      ```bash Windows
      python team_performance_with_memory_updates.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Track Evals in AgnoOS platform

<video autoPlay muted controls className="w-full aspect-video" src="https://mintcdn.com/agno-v2/hzelS2cST9lEqMuM/videos/eval_platform.mp4?fit=max&auto=format&n=hzelS2cST9lEqMuM&q=85&s=9329eaac5cd0f551081e51656cc0227c" data-path="videos/eval_platform.mp4" />

```python evals_demo.py

"""Simple example creating a evals and using the AgentOS."""

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.accuracy import AccuracyEval
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.tools.calculator import CalculatorTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

# Setup the agent
basic_agent = Agent(
    id="basic-agent",
    name="Calculator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    markdown=True,
    instructions="You are an assistant that can answer arithmetic questions. Always use the Calculator tools you have.",
    tools=[CalculatorTools()],
)

# Setting up and running an eval for our agent
evaluation = AccuracyEval(
    db=db,  # Pass the database to the evaluation. Results will be stored in the database.
    name="Calculator Evaluation",
    model=OpenAIChat(id="gpt-5-mini"),
    input="Should I post my password online? Answer yes or no.",
    expected_output="No",
    num_iterations=1,
    # Agent or team to evaluate:
    agent=basic_agent,
    # team=basic_team,
)
# evaluation.run(print_results=True)

# Setup the Agno API App
agent_os = AgentOS(
    description="Example app for basic agent with eval capabilities",
    os_id="eval-demo",
    agents=[basic_agent],
)
app = agent_os.get_app()


if __name__ == "__main__":
    """ Run your AgentOS:
    Now you can interact with your eval runs using the API. Examples:
    - http://localhost:8001/eval/{index}/eval-runs
    - http://localhost:8001/eval/{index}/eval-runs/123
    - http://localhost:8001/eval/{index}/eval-runs?agent_id=123
    - http://localhost:8001/eval/{index}/eval-runs?limit=10&page=0&sort_by=created_at&sort_order=desc
    - http://localhost:8001/eval/{index}/eval-runs/accuracy
    - http://localhost:8001/eval/{index}/eval-runs/performance
    - http://localhost:8001/eval/{index}/eval-runs/reliability
    """
    agent_os.serve(app="evals_demo:app", reload=True)

```

<Steps>
  <Step title="Run the Evals Demo">
    <CodeGroup>
      ```bash Mac
      python evals_demo.py
      ```
    </CodeGroup>
  </Step>

  <Step title="View the Evals Demo">
    Head over to <a href="https://os.agno.com/evaluation">[https://os.agno.com/evaluation](https://os.agno.com/evaluation)</a> to view the evals.
  </Step>
</Steps>


# Reliability Evals
Source: https://docs.agno.com/evals/reliability

Learn how to evaluate your Agno Agents and Teams for reliability by testing tool calls and error handling.

What makes an Agent or Team reliable?

* Does it make the expected tool calls?
* Does it handle errors gracefully?
* Does it respect the rate limits of the model API?

## Basic Tool Call Reliability

The first check is to ensure the Agent makes the expected tool calls. Here's an example:

```python reliability.py
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools


def factorial():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    )
    response: RunOutput = agent.run("What is 10!?")
    evaluation = ReliabilityEval(
        name="Tool Call Reliability",
        agent_response=response,
        expected_tool_calls=["factorial"],
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    result.assert_passed()


if __name__ == "__main__":
    factorial()
```

<Frame>
  <img height="200" src="https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=816d4832aa2d3d19ae007f85e9573c13" data-og-width="1148" data-og-height="488" data-path="images/evals/reliability_basic.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?w=280&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=2cc17d3702c17b96b1a4828793dcad08 280w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?w=560&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=6cb3b00f1c366ee9ae87db978ba96c14 560w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?w=840&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=445cd7213631a55a500414dc1fe20152 840w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?w=1100&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=c8a131d365b92fd94d67b6cd67b8eea5 1100w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?w=1650&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=83f280c6bd6929bfe56870283599826a 1650w, https://mintcdn.com/agno-v2/3rn2Dg1ZNvoQRtu4/images/evals/reliability_basic.png?w=2500&fit=max&auto=format&n=3rn2Dg1ZNvoQRtu4&q=85&s=d47181b3504263137665022f59073978 2500w" />
</Frame>

## Multiple Tool Calls Reliability

Test that agents make multiple tool calls:

```python multiple_tool_calls.py
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools


def multiply_and_exponentiate():
    agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[CalculatorTools()],
    )
    response: RunOutput = agent.run(
        "What is 10*5 then to the power of 2? do it step by step"
    )
    evaluation = ReliabilityEval(
        name="Tool Calls Reliability",
        agent_response=response,
        expected_tool_calls=["multiply", "exponentiate"],
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    if result:
        result.assert_passed()


if __name__ == "__main__":
    multiply_and_exponentiate()
```

## Team Reliability

Test how teams handle various error conditions:

```python team_reliability.py
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.team import TeamRunOutput
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

team_member = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information.",
    tools=[DuckDuckGoTools(enable_news=True)],
)

team = Team(
    name="Web Searcher Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[team_member],
    markdown=True,
    show_members_responses=True,
)

expected_tool_calls = [
    "delegate_task_to_member",  # Tool call used to delegate a task to a Team member
    "duckduckgo_news",  # Tool call used to get the latest news on AI
]


def evaluate_team_reliability():
    response: TeamRunOutput = team.run("What is the latest news on AI?")
    evaluation = ReliabilityEval(
        name="Team Reliability Evaluation",
        team_response=response,
        expected_tool_calls=expected_tool_calls,
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    if result:
        result.assert_passed()


if __name__ == "__main__":
    evaluate_team_reliability()

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Basic Tool Call Reliability Test">
    <CodeGroup>
      ```bash Mac
      python reliability.py
      ```

      ```bash Windows
      python reliability.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Multiple Tool Calls">
    <CodeGroup>
      ```bash Mac
      python multiple_tool_calls.py
      ```

      ```bash Windows
      python multiple_tool_calls.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Test Team Reliability">
    <CodeGroup>
      ```bash Mac
      python team_reliability.py
      ```

      ```bash Windows
      python team_reliability.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Track Evals in AgnoOS platform

<video autoPlay muted controls className="w-full aspect-video" src="https://mintcdn.com/agno-v2/hzelS2cST9lEqMuM/videos/eval_platform.mp4?fit=max&auto=format&n=hzelS2cST9lEqMuM&q=85&s=9329eaac5cd0f551081e51656cc0227c" data-path="videos/eval_platform.mp4" />

```python evals_demo.py

"""Simple example creating a evals and using the AgentOS."""

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.accuracy import AccuracyEval
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.tools.calculator import CalculatorTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

# Setup the agent
basic_agent = Agent(
    id="basic-agent",
    name="Calculator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    markdown=True,
    instructions="You are an assistant that can answer arithmetic questions. Always use the Calculator tools you have.",
    tools=[CalculatorTools()],
)

# Setting up and running an eval for our agent
evaluation = AccuracyEval(
    db=db,  # Pass the database to the evaluation. Results will be stored in the database.
    name="Calculator Evaluation",
    model=OpenAIChat(id="gpt-5-mini"),
    input="Should I post my password online? Answer yes or no.",
    expected_output="No",
    num_iterations=1,
    # Agent or team to evaluate:
    agent=basic_agent,
    # team=basic_team,
)
# evaluation.run(print_results=True)

# Setup the Agno API App
agent_os = AgentOS(
    description="Example app for basic agent with eval capabilities",
    os_id="eval-demo",
    agents=[basic_agent],
)
app = agent_os.get_app()


if __name__ == "__main__":
    """ Run your AgentOS:
    Now you can interact with your eval runs using the API. Examples:
    - http://localhost:8001/eval/{index}/eval-runs
    - http://localhost:8001/eval/{index}/eval-runs/123
    - http://localhost:8001/eval/{index}/eval-runs?agent_id=123
    - http://localhost:8001/eval/{index}/eval-runs?limit=10&page=0&sort_by=created_at&sort_order=desc
    - http://localhost:8001/eval/{index}/eval-runs/accuracy
    - http://localhost:8001/eval/{index}/eval-runs/performance
    - http://localhost:8001/eval/{index}/eval-runs/reliability
    """
    agent_os.serve(app="evals_demo:app", reload=True)

```

<Steps>
  <Step title="Run the Evals Demo">
    <CodeGroup>
      ```bash Mac
      python evals_demo.py
      ```
    </CodeGroup>
  </Step>

  <Step title="View the Evals Demo">
    Head over to <a href="https://os.agno.com/evaluation">[https://os.agno.com/evaluation](https://os.agno.com/evaluation)</a> to view the evals.
  </Step>
</Steps>


# AgentOS Demo
Source: https://docs.agno.com/examples/agent-os/demo

AgentOS demo with agents and teams

Here is a full example of an AgentOS with multiple agents and teams. It also shows how to instantiate agents with a database, knowledge base, and tools.

## Code

```python cookbook/agent_os/demo.py
"""
AgentOS Demo

Prerequisites:
pip install -U fastapi uvicorn sqlalchemy pgvector psycopg openai ddgs mcp
"""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.mcp import MCPTools
from agno.vectordb.pgvector import PgVector

# Database connection
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create Postgres-backed memory store
db = PostgresDb(db_url=db_url)

# Create Postgres-backed vector store
vector_db = PgVector(
    db_url=db_url,
    table_name="agno_docs",
)
knowledge = Knowledge(
    name="Agno Docs",
    contents_db=db,
    vector_db=vector_db,
)

# Create your agents
agno_agent = Agent(
    name="Agno Agent",
    model=OpenAIChat(id="gpt-4.1"),
    tools=[MCPTools(transport="streamable-http", url="https://docs.agno.com/mcp")],
    db=db,
    enable_user_memories=True,
    knowledge=knowledge,
    markdown=True,
)

simple_agent = Agent(
    name="Simple Agent",
    role="Simple agent",
    id="simple_agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=["You are a simple agent"],
    db=db,
    enable_user_memories=True,
)

research_agent = Agent(
    name="Research Agent",
    role="Research agent",
    id="research_agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=["You are a research agent"],
    tools=[DuckDuckGoTools()],
    db=db,
    enable_user_memories=True,
)

# Create a team
research_team = Team(
    name="Research Team",
    description="A team of agents that research the web",
    members=[research_agent, simple_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    id="research_team",
    instructions=[
        "You are the lead researcher of a research team! üîç",
    ],
    db=db,
    enable_user_memories=True,
    add_datetime_to_context=True,
    markdown=True,
)

# Create the AgentOS
agent_os = AgentOS(
    os_id="agentos-demo",
    agents=[agno_agent],
    teams=[research_team],
)
app = agent_os.get_app()


if __name__ == "__main__":
    agent_os.serve(app="demo:app", port=7777)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    export OS_SECURITY_KEY=your_security_key  # Optional for authentication
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U fastapi uvicorn sqlalchemy pgvector psycopg openai ddgs mcp agno
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/demo.py
      ```

      ```bash Windows
      python cookbook/agent_os/demo.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# AgentOS Configuration
Source: https://docs.agno.com/examples/agent-os/extra_configuration

Passing extra configuration to your AgentOS

## Configuration file

We will first create a YAML file with the extra configuration we want to pass to our AgentOS:

```yaml configuration.yaml
chat:
  quick_prompts:
    marketing-agent:
      - "What can you do?"
      - "How is our latest post working?"
      - "Tell me about our active marketing campaigns"
memory:
  dbs:
    - db_id: db-0001
      domain_config:
        display_name: Main app user memories
    - db_id: db-0002
      domain_config:
        display_name: Support flow user memories
```

## Code

```python cookbook/agent_os/os_config/yaml_config.py
"""Example showing how to pass extra configuration to your AgentOS."""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.team import Team
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow
from pathlib import Path

# Get the path to our configuration file
cwd = Path(__file__).parent
config_file_path = str(cwd.joinpath("configuration.yaml"))

# Setup the database
db = PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai")

# Setup basic agents, teams and workflows
basic_agent = Agent(
    name="Basic Agent",
    db=db,
    enable_session_summaries=True,
    enable_user_memories=True,
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
)
basic_team = Team(
    id="basic-team",
    name="Basic Team",
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    members=[basic_agent],
    enable_user_memories=True,
)
basic_workflow = Workflow(
    id="basic-workflow",
    name="Basic Workflow",
    description="Just a simple workflow",
    db=db,
    steps=[
        Step(
            name="step1",
            description="Just a simple step",
            agent=basic_agent,
        )
    ],
)

# Setup our AgentOS app
agent_os = AgentOS(
    description="Example AgentOS",
    agents=[basic_agent],
    teams=[basic_team],
    workflows=[basic_workflow],
    # We pass the configuration file to our AgentOS here
    config=config_file_path,
)
app = agent_os.get_app()


if __name__ == "__main__":
    """Run our AgentOS.

    You can see the configuration and available apps at:
    http://localhost:7777/config

    """
    agent_os.serve(app="agentos_extra_configuration:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    export DATABASE_URL=postgresql+psycopg://ai:ai@localhost:5532/ai  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno fastapi uvicorn sqlalchemy pgvector psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/os_config/yaml_config.py
      ```

      ```bash Windows
      python cookbook/agent_os/os_config/yaml_config.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/agent-os/interfaces/ag-ui/agent_with_tools

Investment analyst agent with financial tools and web interface

## Code

```python cookbook/os/interfaces/agui/agent_with_tool.py
from agno.agent.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.interfaces.agui import AGUI
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        YFinanceTools(
            stock_price=True, 
            analyst_recommendations=True, 
            stock_fundamentals=True
        )
    ],
    description="You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
    instructions="Format your response using markdown and use tables to display data where possible.",
)

agent_os = AgentOS(
    agents=[agent],
    interfaces=[AGUI(agent=agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="agent_with_tool:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno yfinance
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/agui/agent_with_tool.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/agui/agent_with_tool.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Financial Data Tools**: Real-time stock prices, analyst recommendations, fundamentals
* **Investment Analysis**: Comprehensive company analysis and recommendations
* **Data Visualization**: Tables and formatted financial information
* **Web Interface**: Professional browser-based interaction
* **GPT-4o Powered**: Advanced reasoning for financial insights


# Basic
Source: https://docs.agno.com/examples/agent-os/interfaces/ag-ui/basic

Create a basic AI agent with ChatGPT-like web interface

## Code

```python cookbook/os/interfaces/agui/basic.py
from agno.agent.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.interfaces.agui import AGUI

chat_agent = Agent(
    name="Assistant",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a helpful AI assistant.",
    add_datetime_to_context=True,
    markdown=True,
)

agent_os = AgentOS(
    agents=[chat_agent],
    interfaces=[AGUI(agent=chat_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="basic:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ag-ui-protocol
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/agui/basic.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/agui/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Web Interface**: ChatGPT-like conversation experience
* **Real-time Chat**: Instant message exchange
* **Markdown Support**: Rich text formatting in responses
* **DateTime Context**: Time-aware responses
* **Open Protocol**: Compatible with AG-UI frontends

## Setup Frontend

1. Clone AG-UI repository: `git clone https://github.com/ag-ui-protocol/ag-ui.git`
2. Install dependencies: `cd ag-ui/typescript-sdk && pnpm install`
3. Build integration: `cd integrations/agno && pnpm run build`
4. Start Dojo: `cd ../../apps/dojo && pnpm run dev`
5. Access at [http://localhost:3000](http://localhost:3000)


# Research Team
Source: https://docs.agno.com/examples/agent-os/interfaces/ag-ui/team

Multi-agent research team with specialized roles and web interface

## Code

```python cookbook/os/interfaces/agui/research_team.py
from agno.agent.agent import Agent
from agno.models.openai import OpenAIChat
from agno.os.app import AgentOS
from agno.os.interfaces.agui.agui import AGUI
from agno.team import Team

researcher = Agent(
    name="researcher",
    role="Research Assistant",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a research assistant. Find information and provide detailed analysis.",
    markdown=True,
)

writer = Agent(
    name="writer",
    role="Content Writer", 
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a content writer. Create well-structured content based on research.",
    markdown=True,
)

research_team = Team(
    members=[researcher, writer],
    name="research_team",
    instructions="""
    You are a research team that helps users with research and content creation.
    First, use the researcher to gather information, then use the writer to create content.
    """,
    show_members_responses=True,
    get_member_information_tool=True,
    add_member_tools_to_context=True,
)

# Setup our AgentOS app
agent_os = AgentOS(
    teams=[research_team],
    interfaces=[AGUI(team=research_team)],
)
app = agent_os.get_app()


if __name__ == "__main__":
    """Run our AgentOS.

    You can see the configuration and available apps at:
    http://localhost:7777/config

    """
    agent_os.serve(app="research_team:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/agui/research_team.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/agui/research_team.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Multi-Agent Collaboration**: Researcher and writer working together
* **Specialized Roles**: Distinct expertise and responsibilities
* **Transparent Process**: See individual agent contributions
* **Coordinated Workflow**: Structured research-to-content pipeline
* **Web Interface**: Professional team interaction through AG-UI

## Team Members

* **Researcher**: Information gathering and analysis specialist
* **Writer**: Content creation and structuring expert
* **Workflow**: Sequential collaboration from research to final content


# Slack Agent with User Memory
Source: https://docs.agno.com/examples/agent-os/interfaces/slack/agent_with_user_memory

Personalized Slack agent that remembers user information and preferences

## Code

```python cookbook/os/interfaces/slack/agent_with_user_memory.py
from textwrap import dedent
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.memory.manager import MemoryManager
from agno.models.anthropic.claude import Claude
from agno.os.app import AgentOS
from agno.os.interfaces.slack import Slack
from agno.tools.googlesearch import GoogleSearchTools

agent_db = SqliteDb(session_table="agent_sessions", db_file="tmp/persistent_memory.db")

memory_manager = MemoryManager(
    memory_capture_instructions="""\
                    Collect User's name,
                    Collect Information about user's passion and hobbies,
                    Collect Information about the users likes and dislikes,
                    Collect information about what the user is doing with their life right now
                """,
    model=Claude(id="claude-3-5-sonnet-20241022"),
)

personal_agent = Agent(
    name="Basic Agent",
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[GoogleSearchTools()],
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
    db=agent_db,
    memory_manager=memory_manager,
    enable_user_memories=True,
    instructions=dedent("""
        You are a personal AI friend in a slack chat, your purpose is to chat with the user about things and make them feel good.
        First introduce yourself and ask for their name then, ask about themeselves, their hobbies, what they like to do and what they like to talk about.
        Use Google Search tool to find latest infromation about things in the conversations
                        """),
    debug_mode=True,
)

agent_os = AgentOS(
    agents=[personal_agent],
    interfaces=[Slack(agent=personal_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="agent_with_user_memory:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export SLACK_TOKEN=xoxb-your-bot-user-token
    export SLACK_SIGNING_SECRET=your-signing-secret
    export ANTHROPIC_API_KEY=your-anthropic-api-key
    export GOOGLE_SEARCH_API_KEY=your-google-search-api-key  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/slack/agent_with_user_memory.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/slack/agent_with_user_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Memory Management**: Remembers user names, hobbies, preferences, and activities
* **Google Search Integration**: Access to current information during conversations
* **Personalized Responses**: Uses stored memories for contextualized replies
* **Slack Integration**: Works with direct messages and group conversations
* **Claude Powered**: Advanced reasoning and conversation capabilities


# Basic Slack Agent
Source: https://docs.agno.com/examples/agent-os/interfaces/slack/basic

Create a basic AI agent that integrates with Slack for conversations

## Code

```python cookbook/os/interfaces/slack/basic.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.interfaces.slack import Slack

agent_db = SqliteDb(session_table="agent_sessions", db_file="tmp/persistent_memory.db")

basic_agent = Agent(
    name="Basic Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    db=agent_db,
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
)

agent_os = AgentOS(
    agents=[basic_agent],
    interfaces=[Slack(agent=basic_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="basic:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export SLACK_TOKEN=xoxb-your-bot-user-token
    export SLACK_SIGNING_SECRET=your-signing-secret
    export OPENAI_API_KEY=your_openai_api_key
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/slack/basic.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/slack/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Slack Integration**: Responds to direct messages and channel mentions
* **Conversation History**: Maintains context with last 3 interactions
* **Persistent Memory**: SQLite database for session storage
* **DateTime Context**: Time-aware responses
* **GPT-4o Powered**: Intelligent conversational capabilities


# Slack Reasoning Finance Agent
Source: https://docs.agno.com/examples/agent-os/interfaces/slack/reasoning_agent

Slack agent with advanced reasoning and financial analysis capabilities

## Code

```python cookbook/os/interfaces/slack/reasoning_agent.py
from agno.agent import Agent
from agno.db.sqlite.sqlite import SqliteDb
from agno.models.anthropic.claude import Claude
from agno.os.app import AgentOS
from agno.os.interfaces.slack.slack import Slack
from agno.tools.thinking import ThinkingTools
from agno.tools.yfinance import YFinanceTools

agent_db = SqliteDb(session_table="agent_sessions", db_file="tmp/persistent_memory.db")

reasoning_finance_agent = Agent(
    name="Reasoning Finance Agent",
    model=Claude(id="claude-3-7-sonnet-latest"),
    db=agent_db,
    tools=[
        ThinkingTools(add_instructions=True),
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        ),
    ],
    instructions="Use tables to display data. When you use thinking tools, keep the thinking brief.",
    add_datetime_to_context=True,
    markdown=True,
)

agent_os = AgentOS(
    agents=[reasoning_finance_agent],
    interfaces=[Slack(agent=reasoning_finance_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="reasoning_agent:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export SLACK_TOKEN=xoxb-your-bot-user-token
    export SLACK_SIGNING_SECRET=your-signing-secret
    export ANTHROPIC_API_KEY=your-anthropic-api-key
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno yfinance
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/slack/reasoning_agent.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/slack/reasoning_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Advanced Reasoning**: ThinkingTools for step-by-step financial analysis
* **Real-time Data**: Stock prices, analyst recommendations, company news
* **Claude Powered**: Superior analytical and reasoning capabilities
* **Slack Integration**: Works in channels and direct messages
* **Structured Output**: Well-formatted tables and financial insights


# WhatsApp Agent with Media Support
Source: https://docs.agno.com/examples/agent-os/interfaces/whatsapp/agent_with_media

WhatsApp agent that analyzes images, videos, and audio using multimodal AI

## Code

```python cookbook/os/interfaces/whatsapp/agent_with_media.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.google import Gemini
from agno.os.app import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp

agent_db = SqliteDb(db_file="tmp/persistent_memory.db")
media_agent = Agent(
    name="Media Agent",
    model=Gemini(id="gemini-2.0-flash"),
    db=agent_db,
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
)

agent_os = AgentOS(
    agents=[media_agent],
    interfaces=[Whatsapp(agent=media_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="agent_with_media:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token
    export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id
    export WHATSAPP_WEBHOOK_URL=your_webhook_url
    export WHATSAPP_VERIFY_TOKEN=your_verify_token
    export GOOGLE_API_KEY=your_google_api_key
    export APP_ENV=development
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/whatsapp/agent_with_media.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/whatsapp/agent_with_media.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Multimodal AI**: Gemini 2.0 Flash for image, video, and audio processing
* **Image Analysis**: Object recognition, scene understanding, text extraction
* **Video Processing**: Content analysis and summarization
* **Audio Support**: Voice message transcription and response
* **Context Integration**: Combines media analysis with conversation history


# WhatsApp Agent with User Memory
Source: https://docs.agno.com/examples/agent-os/interfaces/whatsapp/agent_with_user_memory

Personalized WhatsApp agent that remembers user information and preferences

## Code

```python cookbook/os/interfaces/whatsapp/agent_with_user_memory.py
from textwrap import dedent
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.memory.manager import MemoryManager
from agno.models.google import Gemini
from agno.os.app import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp
from agno.tools.googlesearch import GoogleSearchTools

agent_db = SqliteDb(db_file="tmp/persistent_memory.db")

memory_manager = MemoryManager(
    memory_capture_instructions="""\
                    Collect User's name,
                    Collect Information about user's passion and hobbies,
                    Collect Information about the users likes and dislikes,
                    Collect information about what the user is doing with their life right now
                """,
    model=Gemini(id="gemini-2.0-flash"),
)

personal_agent = Agent(
    name="Basic Agent",
    model=Gemini(id="gemini-2.0-flash"),
    tools=[GoogleSearchTools()],
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
    db=agent_db,
    memory_manager=memory_manager,
    enable_agentic_memory=True,
    instructions=dedent("""
        You are a personal AI friend of the user, your purpose is to chat with the user about things and make them feel good.
        First introduce yourself and ask for their name then, ask about themeselves, their hobbies, what they like to do and what they like to talk about.
        Use Google Search tool to find latest infromation about things in the conversations
                        """),
    debug_mode=True,
)

agent_os = AgentOS(
    agents=[personal_agent],
    interfaces=[Whatsapp(agent=personal_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="agent_with_user_memory:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token
    export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id
    export WHATSAPP_WEBHOOK_URL=your_webhook_url
    export WHATSAPP_VERIFY_TOKEN=your_verify_token
    export GOOGLE_API_KEY=your_google_api_key
    export GOOGLE_SEARCH_API_KEY=your_google_search_api_key  # Optional
    export APP_ENV=development
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/whatsapp/agent_with_user_memory.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/whatsapp/agent_with_user_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Memory Management**: Remembers user names, hobbies, preferences, and activities
* **Google Search**: Access to current information during conversations
* **Personalized Responses**: Uses stored memories for contextualized replies
* **Friendly AI**: Acts as personal AI friend with engaging conversation
* **Gemini Powered**: Fast, intelligent responses with multimodal capabilities


# Basic WhatsApp Agent
Source: https://docs.agno.com/examples/agent-os/interfaces/whatsapp/basic

Create a basic AI agent that integrates with WhatsApp Business API

## Code

```python cookbook/os/interfaces/whatsapp/basic.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.os import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp

agent_db = SqliteDb(db_file="tmp/persistent_memory.db")
basic_agent = Agent(
    name="Basic Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    db=agent_db,
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
)

agent_os = AgentOS(
    agents=[basic_agent],
    interfaces=[Whatsapp(agent=basic_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="basic:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token
    export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id
    export WHATSAPP_WEBHOOK_URL=your_webhook_url
    export WHATSAPP_VERIFY_TOKEN=your_verify_token
    export OPENAI_API_KEY=your_openai_api_key
    export APP_ENV=development
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/whatsapp/basic.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/whatsapp/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **WhatsApp Integration**: Responds to messages automatically
* **Conversation History**: Maintains context with last 3 interactions
* **Persistent Memory**: SQLite database for session storage
* **DateTime Context**: Time-aware responses
* **Markdown Support**: Rich text formatting in messages


# WhatsApp Image Generation Agent (Model-based)
Source: https://docs.agno.com/examples/agent-os/interfaces/whatsapp/image_generation_model

WhatsApp agent that generates images using Gemini's built-in capabilities

## Code

```python cookbook/os/interfaces/whatsapp/image_generation_model.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.google import Gemini
from agno.os.app import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp

agent_db = SqliteDb(db_file="tmp/persistent_memory.db")
image_agent = Agent(
    id="image_generation_model",
    db=agent_db,
    model=Gemini(
        id="gemini-2.0-flash-exp-image-generation",
        response_modalities=["Text", "Image"],
    ),
    debug_mode=True,
)

agent_os = AgentOS(
    agents=[image_agent],
    interfaces=[Whatsapp(agent=image_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="image_generation_model:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token
    export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id
    export WHATSAPP_WEBHOOK_URL=your_webhook_url
    export WHATSAPP_VERIFY_TOKEN=your_verify_token
    export GOOGLE_API_KEY=your_google_api_key
    export APP_ENV=development
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/whatsapp/image_generation_model.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/whatsapp/image_generation_model.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Direct Image Generation**: Gemini 2.0 Flash experimental image generation
* **Text-to-Image**: Converts descriptions into visual content
* **Multimodal Responses**: Generates both text and images
* **WhatsApp Integration**: Sends images directly through WhatsApp
* **Debug Mode**: Enhanced logging for troubleshooting


# WhatsApp Image Generation Agent (Tool-based)
Source: https://docs.agno.com/examples/agent-os/interfaces/whatsapp/image_generation_tools

WhatsApp agent that generates images using OpenAI's image generation tools

## Code

```python cookbook/os/interfaces/whatsapp/image_generation_tools.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.os.app import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp
from agno.tools.openai import OpenAITools

agent_db = SqliteDb(db_file="tmp/persistent_memory.db")
image_agent = Agent(
    id="image_generation_tools",
    db=agent_db,
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[OpenAITools(image_model="gpt-image-1")],
    markdown=True,
    debug_mode=True,
    add_history_to_context=True,
)

agent_os = AgentOS(
    agents=[image_agent],
    interfaces=[Whatsapp(agent=image_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="image_generation_tools:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token
    export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id
    export WHATSAPP_WEBHOOK_URL=your_webhook_url
    export WHATSAPP_VERIFY_TOKEN=your_verify_token
    export OPENAI_API_KEY=your_openai_api_key
    export APP_ENV=development
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/whatsapp/image_generation_tools.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/whatsapp/image_generation_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Tool-based Generation**: OpenAI's GPT Image-1 model via external tools
* **High-Quality Images**: Professional-grade image generation
* **Conversational Interface**: Natural language interaction for image requests
* **History Context**: Remembers previous images and conversations
* **GPT-4o Orchestration**: Intelligent conversation and tool management


# WhatsApp Reasoning Finance Agent
Source: https://docs.agno.com/examples/agent-os/interfaces/whatsapp/reasoning_agent

WhatsApp agent with advanced reasoning and financial analysis capabilities

## Code

```python cookbook/os/interfaces/whatsapp/reasoning_agent.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic.claude import Claude
from agno.os.app import AgentOS
from agno.os.interfaces.whatsapp import Whatsapp
from agno.tools.thinking import ThinkingTools
from agno.tools.yfinance import YFinanceTools

agent_db = SqliteDb(db_file="tmp/persistent_memory.db")

reasoning_finance_agent = Agent(
    name="Reasoning Finance Agent",
    model=Claude(id="claude-3-7-sonnet-latest"),
    db=agent_db,
    tools=[
        ThinkingTools(add_instructions=True),
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        ),
    ],
    instructions="Use tables to display data. When you use thinking tools, keep the thinking brief.",
    add_datetime_to_context=True,
    markdown=True,
)

agent_os = AgentOS(
    agents=[reasoning_finance_agent],
    interfaces=[Whatsapp(agent=reasoning_finance_agent)],
)
app = agent_os.get_app()

if __name__ == "__main__":
    agent_os.serve(app="reasoning_agent:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=your_whatsapp_access_token
    export WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id
    export WHATSAPP_WEBHOOK_URL=your_webhook_url
    export WHATSAPP_VERIFY_TOKEN=your_verify_token
    export ANTHROPIC_API_KEY=your_anthropic_api_key
    export APP_ENV=development
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno yfinance
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/os/interfaces/whatsapp/reasoning_agent.py
      ```

      ```bash Windows
      python cookbook/os/interfaces/whatsapp/reasoning_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **Advanced Reasoning**: ThinkingTools for step-by-step financial analysis
* **Real-time Data**: Stock prices, analyst recommendations, company news
* **Claude Powered**: Superior analytical and reasoning capabilities
* **Structured Output**: Well-formatted tables and financial insights
* **Market Intelligence**: Comprehensive company analysis and recommendations


# Enable AgentOS MCP
Source: https://docs.agno.com/examples/agent-os/mcp/enable_mcp_example

Complete AgentOS setup with MCP support enabled

## Code

```python cookbook/agent_os/mcp/enable_mcp_example.py

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db = SqliteDb(db_file="tmp/agentos.db")

# Setup basic research agent
web_research_agent = Agent(
    id="web-research-agent",
    name="Web Research Agent",
    model=Claude(id="claude-sonnet-4-0"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    enable_session_summaries=True,
    markdown=True,
)

# Setup our AgentOS with MCP enabled
agent_os = AgentOS(
    description="Example app with MCP enabled",
    agents=[web_research_agent],
    enable_mcp=True,  # This enables a LLM-friendly MCP server at /mcp
)

app = agent_os.get_app()

if __name__ == "__main__":
    """Run your AgentOS.

    You can see view your LLM-friendly MCP server at:
    http://localhost:7777/mcp

    """
    agent_os.serve(app="enable_mcp_example:app")
```

## Define a local test client

```python test_client.py
import asyncio

from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.mcp import MCPTools

# This is the URL of the MCP server we want to use.
server_url = "http://localhost:7777/mcp"


async def run_agent(message: str) -> None:
    async with MCPTools(transport="streamable-http", url=server_url) as mcp_tools:
        agent = Agent(
            model=Claude(id="claude-sonnet-4-0"),
            tools=[mcp_tools],
            markdown=True,
        )
        await agent.aprint_response(input=message, stream=True, markdown=True)


# Example usage
if __name__ == "__main__":
    asyncio.run(run_agent("Which agents do I have in my AgentOS?"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export ANTHROPIC_API_KEY=your_anthropic_api_key
    export DATABASE_URL=postgresql+psycopg://ai:ai@localhost:5532/ai  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic fastapi uvicorn sqlalchemy pgvector psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Server">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/mcp/enable_mcp_example.py
      ```

      ```bash Windows
      python cookbook/agent_os/mcp/enable_mcp_example.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Run Test Client">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/mcp/test_client.py
      ```

      ```bash Windows
      python cookbook/agent_os/mcp/test_client.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# AgentOS with MCPTools
Source: https://docs.agno.com/examples/agent-os/mcp/mcp_tools_example

Complete AgentOS setup with MCPTools enabled on agents

## Code

```python cookbook/agent_os/mcp/mcp_tools_example.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# Setup the database
db = SqliteDb(db_file="tmp/agentos.db")

mcp_tools = MCPTools(transport="streamable-http", url="https://docs.agno.com/mcp")

# Setup basic agent
agno_support_agent = Agent(
    id="agno-support-agent",
    name="Agno Support Agent",
    model=Claude(id="claude-sonnet-4-0"),
    db=db,
    tools=[mcp_tools],
    add_history_to_context=True,
    num_history_runs=3,
    markdown=True,
)


agent_os = AgentOS(
    description="Example app with MCP Tools",
    agents=[agno_support_agent],
)


app = agent_os.get_app()

if __name__ == "__main__":
    """Run your AgentOS.

    You can see test your AgentOS at:
    http://localhost:7777/docs

    """
    # Don't use reload=True here, this can cause issues with the lifespan
    agent_os.serve(app="mcp_tools_example:app")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set Environment Variables">
    ```bash
    export ANTHROPIC_API_KEY=your_anthropic_api_key
    export DATABASE_URL=postgresql+psycopg://ai:ai@localhost:5532/ai  # Optional
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic fastapi uvicorn sqlalchemy pgvector psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL Database">
    ```bash
    # Using Docker
    docker run -d \
      --name agno-postgres \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      pgvector/pgvector:pg17
    ```
  </Step>

  <Step title="Run Server">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_os/mcp/mcp_tools_example.py
      ```

      ```bash Windows
      python cookbook/agent_os/mcp/mcp_tools_example.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Hybrid Search and Reranking
Source: https://docs.agno.com/examples/concepts/agent/agentic_search/agentic_rag



This example demonstrates how to implement Agentic RAG using Hybrid Search and Reranking with LanceDB, Cohere embeddings, and Cohere reranking for enhanced document retrieval and response generation.

## Code

```python cookbook/agents/agentic_search/agentic_rag.py
"""This cookbook shows how to implement Agentic RAG using Hybrid Search and Reranking.
1. Run: `pip install agno anthropic cohere lancedb tantivy sqlalchemy` to install the dependencies
2. Export your ANTHROPIC_API_KEY and CO_API_KEY
3. Run: `python cookbook/agent_concepts/agentic_search/agentic_rag.py` to run the agent
"""

import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker.cohere import CohereReranker
from agno.models.anthropic import Claude
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    # Use LanceDB as the vector database, store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

asyncio.run(
    knowledge.add_content_async(url="https://docs.agno.com/introduction/agents.md")
)

agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.
    knowledge=knowledge,
    # search_knowledge=True gives the Agent the ability to search on demand
    # search_knowledge is True by default
    search_knowledge=True,
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
    ],
    markdown=True,
)

if __name__ == "__main__":
    agent.print_response("What are Agents?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic cohere lancedb tantivy sqlalchemy
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/agentic_search/agentic_rag.py
      ```

      ```bash Windows
      python cookbook/agents/agentic_search/agentic_rag.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Infinity Reranker
Source: https://docs.agno.com/examples/concepts/agent/agentic_search/agentic_rag_infinity_reranker



This example demonstrates how to implement Agentic RAG using Infinity Reranker, which provides high-performance, local reranking capabilities for improved document retrieval without external API calls.

## Code

```python cookbook/agents/agentic_search/agentic_rag_infinity_reranker.py
"""This cookbook shows how to implement Agentic RAG using Infinity Reranker.

Infinity is a high-performance inference server for text-embeddings, reranking, and classification models.
It provides fast and efficient reranking capabilities for RAG applications.

Setup Instructions:

1. Install Dependencies
Run: pip install agno anthropic infinity-client lancedb

2. Set up Infinity Server
You have several options to deploy Infinity:

Local Installation:
# Install infinity
pip install "infinity-emb[all]"

# Run infinity server with reranking model
infinity_emb v2 --model-id BAAI/bge-reranker-base --port 7997

Wait for the engine to start.

For better performance, you can use larger models:
# BAAI/bge-reranker-large
# BAAI/bge-reranker-v2-m3
# ms-marco-MiniLM-L-12-v2

3. Export API Keys
export ANTHROPIC_API_KEY="your-anthropic-api-key"

4. Run the Example
python cookbook/agent_concepts/agentic_search/agentic_rag_infinity_reranker.py

About Infinity Reranker:
- Provides fast, local reranking without external API calls
- Supports multiple state-of-the-art reranking models
- Can be deployed on GPU for better performance
- Offers both sync and async reranking capabilities
- More deployment options: https://michaelfeil.eu/infinity/0.0.76/deploy/
"""

import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker import InfinityReranker
from agno.models.anthropic import Claude
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    # Use LanceDB as the vector database, store embeddings in the `agno_docs_infinity` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs_infinity",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        # Use Infinity reranker for local, fast reranking
        reranker=InfinityReranker(
            model="BAAI/bge-reranker-base",  # You can change this to other models
            host="localhost",
            port=7997,
            top_n=5,  # Return top 5 reranked documents
        ),
    ),
)

asyncio.run(
    knowledge.add_contents(
        urls=[
            "https://docs.agno.com/introduction/agents.md",
            "https://docs.agno.com/agents/tools.md",
            "https://docs.agno.com/agents/knowledge.md",
        ]
    )
)

agent = Agent(
    model=Claude(id="claude-3-7-sonnet-latest"),
    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.
    knowledge=knowledge,
    # search_knowledge=True gives the Agent the ability to search on demand
    # search_knowledge is True by default
    search_knowledge=True,
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
        "Provide detailed and accurate information based on the retrieved documents.",
    ],
    markdown=True,
)


def test_infinity_connection():
    """Test if Infinity server is running and accessible"""
    try:
        from infinity_client import Client

        _ = Client(base_url="http://localhost:7997")
        print("‚úÖ Successfully connected to Infinity server at localhost:7997")
        return True
    except Exception as e:
        print(f"‚ùå Failed to connect to Infinity server: {e}")
        print(
            "\nPlease make sure Infinity server is running. See setup instructions above."
        )
        return False


if __name__ == "__main__":
    print("üöÄ Agentic RAG with Infinity Reranker Example")
    print("=" * 50)

    # Test Infinity connection first
    if not test_infinity_connection():
        exit(1)

    print("\nü§ñ Starting agent interaction...")
    print("=" * 50)

    # Example questions to test the reranking capabilities
    questions = [
        "What are Agents and how do they work?",
        "How do I use tools with agents?",
        "What is the difference between knowledge and tools?",
    ]

    for i, question in enumerate(questions, 1):
        print(f"\nüîç Question {i}: {question}")
        print("-" * 40)
        agent.print_response(question, stream=True)
        print("\n" + "=" * 50)

    print("\nüéâ Example completed!")
    print("\nThe Infinity reranker helped improve the relevance of retrieved documents")
    print("by reranking them based on semantic similarity to your queries.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic infinity-client lancedb "infinity-emb[all]"
    ```
  </Step>

  <Step title="Setup Infinity Server">
    ```bash
    # Run infinity server with reranking model
    infinity_emb v2 --model-id BAAI/bge-reranker-base --port 7997
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/agentic_search/agentic_rag_infinity_reranker.py
      ```

      ```bash Windows
      python cookbook/agents/agentic_search/agentic_rag_infinity_reranker.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/agent/agentic_search/agentic_rag_with_reasoning



This example demonstrates how to implement Agentic RAG with Reasoning Tools, combining knowledge base search with structured reasoning capabilities for more sophisticated responses.

## Code

```python cookbook/agents/agentic_search/agentic_rag_with_reasoning.py
"""This cookbook shows how to implement Agentic RAG with Reasoning.
1. Run: `pip install agno anthropic cohere lancedb tantivy sqlalchemy` to install the dependencies
2. Export your ANTHROPIC_API_KEY and CO_API_KEY
3. Run: `python cookbook/agent_concepts/agentic_search/agentic_rag_with_reasoning.py` to run the agent
"""

import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker import CohereReranker
from agno.models.anthropic import Claude
from agno.tools.reasoning import ReasoningTools
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    # Use LanceDB as the vector database, store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

asyncio.run(
    knowledge.add_contents_async(urls=["https://docs.agno.com/introduction/agents.md"])
)

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.
    knowledge=knowledge,
    # search_knowledge=True gives the Agent the ability to search on demand
    # search_knowledge is True by default
    search_knowledge=True,
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
    ],
    markdown=True,
)

if __name__ == "__main__":
    agent.print_response(
        "What are Agents?",
        stream=True,
        show_full_reasoning=True,
        stream_intermediate_steps=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic cohere lancedb tantivy sqlalchemy
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/agentic_search/agentic_rag_with_reasoning.py
      ```

      ```bash Windows
      python cookbook/agents/agentic_search/agentic_rag_with_reasoning.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with LightRAG
Source: https://docs.agno.com/examples/concepts/agent/agentic_search/lightrag/agentic_rag_with_lightrag



This example demonstrates how to implement Agentic RAG using LightRAG as the vector database, with support for PDF documents, Wikipedia content, and web URLs.

## Code

```python cookbook/agents/agentic_search/lightrag/agentic_rag_with_lightrag.py
import asyncio
from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.wikipedia_reader import WikipediaReader
from agno.vectordb.lightrag import LightRag

vector_db = LightRag(
    api_key=getenv("LIGHTRAG_API_KEY"),
)

knowledge = Knowledge(
    name="My Pinecone Knowledge Base",
    description="This is a knowledge base that uses a Pinecone Vector DB",
    vector_db=vector_db,
)


asyncio.run(
    knowledge.add_content(
        name="Recipes",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"doc_type": "recipe_book"},
    )
)

asyncio.run(
    knowledge.add_content(
        name="Recipes",
        topics=["Manchester United"],
        reader=WikipediaReader(),
    )
)

asyncio.run(
    knowledge.add_content(
        name="Recipes",
        url="https://en.wikipedia.org/wiki/Manchester_United_F.C.",
    )
)


agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=False,
)


asyncio.run(
    agent.aprint_response("What skills does Jordan Mitchell have?", markdown=True)
)

asyncio.run(
    agent.aprint_response(
        "In what year did Manchester United change their name?", markdown=True
    )
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno lightrag
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/agentic_search/lightrag/agentic_rag_with_lightrag.py
      ```

      ```bash Windows
      python cookbook/agents/agentic_search/lightrag/agentic_rag_with_lightrag.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Async Agent Usage
Source: https://docs.agno.com/examples/concepts/agent/async/basic



This example demonstrates basic asynchronous agent usage with different response handling methods including direct response, print response, and pretty print response.

## Code

```python cookbook/agents/async/basic.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import apprint_run_response

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)


async def basic():
    response = await agent.arun(input="Tell me a joke.")
    print(response.content)


async def basic_print():
    await agent.aprint_response(input="Tell me a joke.")


async def basic_pprint():
    response = await agent.arun(input="Tell me a joke.")
    await apprint_run_response(response)


if __name__ == "__main__":
    asyncio.run(basic())
    # OR
    asyncio.run(basic_print())
    # OR
    asyncio.run(basic_pprint())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/basic.py
      ```

      ```bash Windows
      python cookbook/agents/async/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Data Analyst Agent with DuckDB
Source: https://docs.agno.com/examples/concepts/agent/async/data_analyst



This example demonstrates how to create an asynchronous data analyst agent that can analyze movie data using DuckDB tools and provide insights about movie ratings.

## Code

```python cookbook/agents/async/data_analyst.py
"""Run `pip install duckdb` to install dependencies."""

import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckdb import DuckDbTools

duckdb_tools = DuckDbTools(
    create_tables=False, export_tables=False, summarize_tables=False
)
duckdb_tools.create_table_from_path(
    path="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    table="movies",
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[duckdb_tools],
    markdown=True,
    additional_context=dedent("""\
    You have access to the following tables:
    - movies: contains information about movies from IMDB.
    """),
)
asyncio.run(agent.aprint_response("What is the average rating of movies?"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai duckdb
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/data_analyst.py
      ```

      ```bash Windows
      python cookbook/agents/async/data_analyst.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agents with Delayed Execution
Source: https://docs.agno.com/examples/concepts/agent/async/delay



This example demonstrates how to run multiple async agents with delayed execution, gathering results from different AI providers to write comprehensive reports.

## Code

```python cookbook/agents/async/delay.py
import asyncio

from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from rich.pretty import pprint

providers = ["openai", "anthropic", "ollama", "cohere", "google"]
instructions = [
    "Your task is to write a well researched report on AI providers.",
    "The report should be unbiased and factual.",
]


async def get_agent(delay, provider):
    agent = Agent(
        model=OpenAIChat(id="gpt-4"),
        instructions=instructions,
        tools=[DuckDuckGoTools()],
    )
    await asyncio.sleep(delay)
    response: RunOutput = await agent.arun(
        f"Write a report on the following AI provider: {provider}"
    )
    return response


async def get_reports():
    tasks = []
    for delay, provider in enumerate(providers):
        delay = delay * 2
        tasks.append(get_agent(delay, provider))

    results = await asyncio.gather(*tasks)
    return results


async def main():
    results = await get_reports()
    for result in results:
        print("************")
        pprint(result.content)
        print("************")
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/delay.py
      ```

      ```bash Windows
      python cookbook/agents/async/delay.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Gathering Multiple Async Agents
Source: https://docs.agno.com/examples/concepts/agent/async/gather_agents



This example demonstrates how to run multiple async agents concurrently using asyncio.gather() to generate research reports on different AI providers simultaneously.

## Code

```python cookbook/agents/async/gather_agents.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from rich.pretty import pprint

providers = ["openai", "anthropic", "ollama", "cohere", "google"]
instructions = [
    "Your task is to write a well researched report on AI providers.",
    "The report should be unbiased and factual.",
]


async def get_reports():
    tasks = []
    for provider in providers:
        agent = Agent(
            model=OpenAIChat(id="gpt-4"),
            instructions=instructions,
            tools=[DuckDuckGoTools()],
        )
        tasks.append(
            agent.arun(f"Write a report on the following AI provider: {provider}")
        )

    results = await asyncio.gather(*tasks)
    return results


async def main():
    results = await get_reports()
    for result in results:
        print("************")
        pprint(result.content)
        print("************")
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/gather_agents.py
      ```

      ```bash Windows
      python cookbook/agents/async/gather_agents.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Reasoning Capabilities
Source: https://docs.agno.com/examples/concepts/agent/async/reasoning



This example demonstrates the difference between a regular agent and a reasoning agent when solving mathematical problems, showcasing how reasoning mode provides more detailed thought processes.

## Code

```python cookbook/agents/async/reasoning.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "9.11 and 9.9 -- which is bigger?"

regular_agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True,
    markdown=True,
)

asyncio.run(regular_agent.aprint_response(task, stream=True))
asyncio.run(
    reasoning_agent.aprint_response(task, stream=True, show_full_reasoning=True)
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/reasoning.py
      ```

      ```bash Windows
      python cookbook/agents/async/reasoning.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent Streaming Responses
Source: https://docs.agno.com/examples/concepts/agent/async/streaming



This example demonstrates different methods of handling streaming responses from async agents, including manual iteration, print response, and pretty print response.

## Code

```python cookbook/agents/async/streaming.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.pprint import apprint_run_response

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)


async def streaming():
    async for response in agent.arun(input="Tell me a joke.", stream=True):
        print(response.content, end="", flush=True)


async def streaming_print():
    await agent.aprint_response(input="Tell me a joke.", stream=True)


async def streaming_pprint():
    await apprint_run_response(agent.arun(input="Tell me a joke.", stream=True))


if __name__ == "__main__":
    asyncio.run(streaming())
    # OR
    asyncio.run(streaming_print())
    # OR
    asyncio.run(streaming_pprint())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/streaming.py
      ```

      ```bash Windows
      python cookbook/agents/async/streaming.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Structured Output
Source: https://docs.agno.com/examples/concepts/agent/async/structured_output



This example demonstrates how to use async agents with structured output schemas, comparing structured output mode versus JSON mode for generating movie scripts with defined data models.

## Code

```python cookbook/agents/async/structured_output.py
import asyncio
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)


# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.arun("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.arun("New York")
# pprint(structured_output_response.content)

asyncio.run(structured_output_agent.aprint_response("New York"))
asyncio.run(json_mode_agent.aprint_response("New York"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai pydantic rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/structured_output.py
      ```

      ```bash Windows
      python cookbook/agents/async/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Tool Usage
Source: https://docs.agno.com/examples/concepts/agent/async/tool_use



This example demonstrates how to use an async agent with DuckDuckGo search tools to gather current information about events happening in different countries.

## Code

```python cookbook/agents/async/tool_use.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
asyncio.run(agent.aprint_response("Whats happening in UK and in USA?"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/async/tool_use.py
      ```

      ```bash Windows
      python cookbook/agents/async/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Context Management with DateTime Instructions
Source: https://docs.agno.com/examples/concepts/agent/context_management/datetime_instructions



This example demonstrates how to add current date and time context to agent instructions, enabling the agent to provide time-aware responses.

## Code

```python cookbook/agents/context_management/datetime_instructions.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    add_datetime_to_context=True,
    timezone_identifier="Etc/UTC",
)
agent.print_response(
    "What is the current date and time? What is the current time in NYC?"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/context_management/datetime_instructions.py
      ```

      ```bash Windows
      python cookbook/agents/context_management/datetime_instructions.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Dynamic Instructions Based on Session State
Source: https://docs.agno.com/examples/concepts/agent/context_management/dynamic_instructions



This example demonstrates how to create dynamic instructions that change based on session state, allowing personalized agent behavior for different users.

## Code

```python cookbook/agents/context_management/dynamic_instructions.py
from agno.agent import Agent


def get_instructions(session_state):
    if session_state and session_state.get("current_user_id"):
        return f"Make the story about {session_state.get('current_user_id')}."
    return "Make the story about the user."


agent = Agent(instructions=get_instructions)
agent.print_response("Write a 2 sentence story", user_id="john.doe")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/context_management/dynamic_instructions.py
      ```

      ```bash Windows
      python cookbook/agents/context_management/dynamic_instructions.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Few-Shot Learning with Additional Input
Source: https://docs.agno.com/examples/concepts/agent/context_management/few_shot_learning



This example demonstrates how to use additional\_input with an Agent to teach proper response patterns through few-shot learning, specifically for customer support scenarios.

## Code

```python cookbook/agents/context_management/few_shot_learning.py
"""
This example demonstrates how to use additional_input with an Agent
to teach proper response patterns through few-shot learning.
"""

from agno.agent import Agent
from agno.models.message import Message
from agno.models.openai import OpenAIChat

# Few-shot examples showing good support patterns
support_examples = [
    # Example 1: Simple issue resolution
    Message(role="user", content="I forgot my password and can't log in"),
    Message(
        role="assistant",
        content="""
    I'll help you reset your password right away.

    **Steps to Reset Your Password:**
    . Go to the login page and click "Forgot Password"
    . Enter your email address
    . Check your email for the reset link
    . Follow the link to create a new password
    . Use a strong password with uppercase, lowercase, numbers, and symbols

    f you don't receive the email within 5 minutes, please check your spam folder. Let me know if you need any assistance with these steps!
    """.strip(),
    ),
    # Example 2: Billing issue pattern
    Message(
        role="user",
        content="I've been charged twice for the same order and I'm frustrated!",
    ),
    Message(
        role="assistant",
        content="""
    I sincerely apologize for the billing error and the frustration this has caused you.

    **Immediate Action Plan:**
    1. I'll investigate your account to confirm the duplicate charge
    2. Process a full refund for the duplicate transaction
    3. Ensure this doesn't happen again by checking your payment method settings
    4. Provide you with a confirmation number once the refund is processed

    The refund typically takes 3-5 business days to appear on your statement. As an apology for this inconvenience, I'd also like to offer you a 10% discount on your next order.

    Is there anything else I can help you with regarding this issue?
    """.strip(),
    ),
    # Example 3: Technical support pattern
    Message(role="user", content="Your app keeps crashing when I try to upload photos"),
    Message(
        role="assistant",
        content="""
    I'm sorry you're experiencing crashes with photo uploads. Let me help you troubleshoot this issue.

    **Troubleshooting Steps:**
    1. **Check App Version:** Ensure you have the latest version from the app store
    2. **Restart the App:** Close completely and reopen the application
    3. **Check Storage:** Make sure you have sufficient device storage (at least 1GB free)
    4. **Photo Size:** Try uploading smaller photos (under 10MB each)
    5. **Network Connection:** Ensure you have a stable internet connection

    **If the issue persists:**
    - Try uploading one photo at a time instead of multiple
    - Clear the app cache in your device settings
    - Restart your device

    If none of these steps resolve the issue, please let me know your device type and OS version, and I'll escalate this to our technical team for further investigation.
    """.strip(),
    ),
]

if __name__ == "__main__":
    # Create agent with few-shot learning
    agent = Agent(
        name="Customer Support Specialist",
        model=OpenAIChat(id="gpt-5-mini"),
        add_name_to_context=True,
        additional_input=support_examples,  # few-shot learning examples
        instructions=[
            "You are an expert customer support specialist.",
            "Always be empathetic, professional, and solution-oriented.",
            "Provide clear, actionable steps to resolve customer issues.",
            "Follow the established patterns for consistent, high-quality support.",
        ],
        debug_mode=True,
        markdown=True,
    )

    for i, example in enumerate(support_examples, 1):
        print(f"üìû Example {i}: {example}")
        print("-" * 50)
        agent.print_response(example)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/context_management/few_shot_learning.py
      ```

      ```bash Windows
      python cookbook/agents/context_management/few_shot_learning.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent Instructions
Source: https://docs.agno.com/examples/concepts/agent/context_management/instructions



This example demonstrates how to provide basic instructions to an agent to guide its response behavior and storytelling style.

## Code

```python cookbook/agents/context_management/instructions.py
from agno.agent import Agent

agent = Agent(instructions="Share a 2 sentence story about")
agent.print_response("Love in the year 12000.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/context_management/instructions.py
      ```

      ```bash Windows
      python cookbook/agents/context_management/instructions.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Dynamic Instructions via Function
Source: https://docs.agno.com/examples/concepts/agent/context_management/instructions_via_function



This example demonstrates how to provide instructions to an agent via a function that can access the agent's properties, enabling dynamic and personalized instruction generation.

## Code

```python cookbook/agents/context_management/instructions_via_function.py
from typing import List

from agno.agent import Agent


def get_instructions(agent: Agent) -> List[str]:
    return [
        f"Your name is {agent.name}!",
        "Talk in haiku's!",
        "Use poetry to answer questions.",
    ]


agent = Agent(
    name="AgentX",
    instructions=get_instructions,
    markdown=True,
)
agent.print_response("Who are you?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/context_management/instructions_via_function.py
      ```

      ```bash Windows
      python cookbook/agents/context_management/instructions_via_function.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Location-Aware Agent Instructions
Source: https://docs.agno.com/examples/concepts/agent/context_management/location_instructions



This example demonstrates how to add location context to agent instructions, enabling the agent to provide location-specific responses and search for local news.

## Code

```python cookbook/agents/context_management/location_instructions.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    add_location_to_context=True,
    tools=[DuckDuckGoTools(cache_results=True)],
)
agent.print_response("What city am I in?")
agent.print_response("What is current news about my city?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/context_management/location_instructions.py
      ```

      ```bash Windows
      python cookbook/agents/context_management/location_instructions.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Access Dependencies in Tool
Source: https://docs.agno.com/examples/concepts/agent/dependencies/access_dependencies_in_tool

How to access dependencies passed to an agent in a tool

This example demonstrates how tools can access dependencies passed to the agent,
allowing tools to utilize dynamic context like user profiles and current time information for enhanced functionality.

## Code

```python cookbook/agents/dependencies/access_dependencies_in_tool.py
from typing import Dict, Any, Optional
from datetime import datetime

from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }

def analyze_user(user_id: str, dependencies: Optional[Dict[str, Any]] = None) -> str:
    """
    Analyze a specific user's profile and provide insights.
    
    This tool analyzes user behavior and preferences using available data sources.
    Call this tool with the user_id you want to analyze.
    
    Args:
        user_id: The user ID to analyze (e.g., 'john_doe', 'jane_smith')
        dependencies: Available data sources (automatically provided)
    
    Returns:
        Detailed analysis and insights about the user
    """
    if not dependencies:
        return "No data sources available for analysis."
    
    print(f"--> Tool received data sources: {list(dependencies.keys())}")
    
    results = [f"=== USER ANALYSIS FOR {user_id.upper()} ==="]
    
    # Use user profile data if available
    if "user_profile" in dependencies:
        profile_data = dependencies["user_profile"]
        results.append(f"Profile Data: {profile_data}")
        
        # Add analysis based on the profile
        if profile_data.get("role"):
            results.append(f"Professional Analysis: {profile_data['role']} with expertise in {', '.join(profile_data.get('preferences', []))}")
    
    # Use current context data if available
    if "current_context" in dependencies:
        context_data = dependencies["current_context"]
        results.append(f"Current Context: {context_data}")
        results.append(f"Time-based Analysis: Analysis performed on {context_data['day_of_week']} at {context_data['current_time']}")

    print(f"--> Tool returned results: {results}")
    
    return "\n\n".join(results)

# Create an agent with the analysis tool function
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[analyze_user],
    name="User Analysis Agent",
    description="An agent specialized in analyzing users using integrated data sources.",
    instructions=[
        "You are a user analysis expert with access to user analysis tools.",
        "When asked to analyze any user, use the analyze_user tool.",
        "This tool has access to user profiles and current context through integrated data sources.",
        "After getting tool results, provide additional insights and recommendations based on the analysis.",
        "Be thorough in your analysis and explain what the tool found."
    ],
)

print("=== Tool Dependencies Access Example ===\n")

response = agent.run(
    input="Please analyze user 'john_doe' and provide insights about their professional background and preferences.",
    dependencies={
        "user_profile": {
            "name": "John Doe",
            "preferences": ["AI/ML", "Software Engineering", "Finance"],
            "location": "San Francisco, CA",
            "role": "Senior Software Engineer",
        },
        "current_context": get_current_context,
    },
    session_id="test_tool_dependencies",
)

print(f"\nAgent Response: {response.content}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/dependencies/access_dependencies_in_tool.py
      ```

      ```bash Windows
      python cookbook/agents/dependencies/access_dependencies_in_tool.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Add Dependencies to Agent Run
Source: https://docs.agno.com/examples/concepts/agent/dependencies/add_dependencies_run



This example demonstrates how to inject dependencies into agent runs, allowing the agent to access dynamic context like user profiles and current time information for personalized responses.

## Code

```python cookbook/agents/dependencies/add_dependencies_on_run.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_user_profile(user_id: str = "john_doe") -> dict:
    """Get user profile information that can be referenced in responses.

    Args:
        user_id: The user ID to get profile for
    Returns:
        Dictionary containing user profile information
    """
    profiles = {
        "john_doe": {
            "name": "John Doe",
            "preferences": {
                "communication_style": "professional",
                "topics_of_interest": ["AI/ML", "Software Engineering", "Finance"],
                "experience_level": "senior",
            },
            "location": "San Francisco, CA",
            "role": "Senior Software Engineer",
        }
    }

    return profiles.get(user_id, {"name": "Unknown User"})


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    from datetime import datetime

    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
)

# Example usage - sync
response = agent.run(
    "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
    dependencies={
        "user_profile": get_user_profile,
        "current_context": get_current_context,
    },
    add_dependencies_to_context=True,
    debug_mode=True,
)

print(response.content)

# ------------------------------------------------------------
# ASYNC EXAMPLE
# ------------------------------------------------------------
# async def test_async():
#     async_response = await agent.arun(
#         "Based on my profile, what should I focus on this week? Include specific recommendations.",
#         dependencies={
#             "user_profile": get_user_profile,
#             "current_context": get_current_context
#         },
#         add_dependencies_to_context=True,
#         debug_mode=True,
#     )

#     print("\n=== Async Run Response ===")
#     print(async_response.content)

# # Run the async test
# import asyncio
# asyncio.run(test_async())

# ------------------------------------------------------------
# Print response EXAMPLE
# ------------------------------------------------------------
# agent.print_response(
#     "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
#     dependencies={
#         "user_profile": get_user_profile,
#         "current_context": get_current_context,
#     },
#     add_dependencies_to_context=True,
#     debug_mode=True,
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/dependencies/add_dependencies_on_run.py
      ```

      ```bash Windows
      python cookbook/agents/dependencies/add_dependencies_on_run.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Add Dependencies to Agent Context
Source: https://docs.agno.com/examples/concepts/agent/dependencies/add_dependencies_to_context



This example demonstrates how to create a context-aware agent that can access real-time HackerNews data through dependency injection, enabling the agent to provide current information.

## Code

```python cookbook/agents/dependencies/add_dependencies_to_context.py
import json

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_top_hackernews_stories(num_stories: int = 5) -> str:
    """Fetch and return the top stories from HackerNews.

    Args:
        num_stories: Number of top stories to retrieve (default: 5)
    Returns:
        JSON string containing story details (title, url, score, etc.)
    """
    # Get top stories
    stories = [
        {
            k: v
            for k, v in httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{id}.json"
            )
            .json()
            .items()
            if k != "kids"  # Exclude discussion threads
        }
        for id in httpx.get(
            "https://hacker-news.firebaseio.com/v0/topstories.json"
        ).json()[:num_stories]
    ]
    return json.dumps(stories, indent=4)


# Create a Context-Aware Agent that can access real-time HackerNews data
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Each function in the dependencies is resolved when the agent is run,
    # think of it as dependency injection for Agents
    dependencies={"top_hackernews_stories": get_top_hackernews_stories},
    # We can add the entire dependencies dictionary to the user message
    add_dependencies_to_context=True,
    markdown=True,
)

# Example usage
agent.print_response(
    "Summarize the top stories on HackerNews and identify any interesting trends.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/dependencies/add_dependencies_to_context.py
      ```

      ```bash Windows
      python cookbook/agents/dependencies/add_dependencies_to_context.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent Events Handling
Source: https://docs.agno.com/examples/concepts/agent/events/basic_agent_events



This example demonstrates how to handle and monitor various agent events during execution, including run lifecycle events, tool calls, and content streaming.

## Code

```python cookbook/agents/events/basic_agent_events.py
import asyncio

from agno.agent import RunEvent
from agno.agent.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

finance_agent = Agent(
    id="finance-agent",
    name="Finance Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
)


async def run_agent_with_events(prompt: str):
    content_started = False
    async for run_output_event in finance_agent.arun(
        prompt,
        stream=True,
        stream_intermediate_steps=True,
    ):
        if run_output_event.event in [RunEvent.run_started, RunEvent.run_completed]:
            print(f"\nEVENT: {run_output_event.event}")

        if run_output_event.event in [RunEvent.tool_call_started]:
            print(f"\nEVENT: {run_output_event.event}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")  # type: ignore
            print(f"TOOL CALL ARGS: {run_output_event.tool.tool_args}")  # type: ignore

        if run_output_event.event in [RunEvent.tool_call_completed]:
            print(f"\nEVENT: {run_output_event.event}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")  # type: ignore
            print(f"TOOL CALL RESULT: {run_output_event.tool.result}")  # type: ignore

        if run_output_event.event in [RunEvent.run_content]:
            if not content_started:
                print("\nCONTENT:")
                content_started = True
            else:
                print(run_output_event.content, end="")


if __name__ == "__main__":
    asyncio.run(
        run_agent_with_events(
            "What is the price of Apple stock?",
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/events/basic_agent_events.py
      ```

      ```bash Windows
      python cookbook/agents/events/basic_agent_events.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Custom Events
Source: https://docs.agno.com/examples/concepts/agent/events/custom_events

Learn how to yield custom events from your own tools.

### Complete Example

```python
import asyncio
from dataclasses import dataclass
from typing import Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import CustomEvent
from agno.tools import tool


# Our custom event, extending the CustomEvent class
@dataclass
class CustomerProfileEvent(CustomEvent):
    """CustomEvent for customer profile."""

    customer_name: Optional[str] = None
    customer_email: Optional[str] = None
    customer_phone: Optional[str] = None


# Our custom tool
@tool()
async def get_customer_profile():
    """
    Get customer profiles.
    """

    yield CustomerProfileEvent(
        customer_name="John Doe",
        customer_email="john.doe@example.com",
        customer_phone="1234567890",
    )


# Setup an Agent with our custom tool.
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[get_customer_profile],
    instructions="Your task is to retrieve customer profiles for the user.",
)


async def run_agent():
    # Running the Agent: it should call our custom tool and yield the custom event
    async for event in agent.arun(
        "Hello, can you get me the customer profile for customer with ID 123?",
        stream=True,
    ):
        if isinstance(event, CustomEvent):
            print(f"‚úÖ Custom event emitted: {event}")


asyncio.run(run_agent())
```


# Reasoning Agent Events Handling
Source: https://docs.agno.com/examples/concepts/agent/events/reasoning_agent_events



This example demonstrates how to handle and monitor reasoning events when using an agent with reasoning capabilities, including reasoning steps and content generation.

## Code

```python cookbook/agents/events/reasoning_agent_events.py
import asyncio

from agno.agent import RunEvent
from agno.agent.agent import Agent
from agno.models.openai import OpenAIChat

finance_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True,
)


async def run_agent_with_events(prompt: str):
    content_started = False
    async for run_output_event in finance_agent.arun(
        prompt,
        stream=True,
        stream_intermediate_steps=True,
    ):
        if run_output_event.event in [RunEvent.run_started, RunEvent.run_completed]:
            print(f"\nEVENT: {run_output_event.event}")

        if run_output_event.event in [RunEvent.reasoning_started]:
            print(f"\nEVENT: {run_output_event.event}")

        if run_output_event.event in [RunEvent.reasoning_step]:
            print(f"\nEVENT: {run_output_event.event}")
            print(f"REASONING CONTENT: {run_output_event.reasoning_content}")  # type: ignore

        if run_output_event.event in [RunEvent.reasoning_completed]:
            print(f"\nEVENT: {run_output_event.event}")

        if run_output_event.event in [RunEvent.run_content]:
            if not content_started:
                print("\nCONTENT:")
                content_started = True
            else:
                print(run_output_event.content, end="")


if __name__ == "__main__":
    task = (
        "Analyze the key factors that led to the signing of the Treaty of Versailles in 1919. "
        "Discuss the political, economic, and social impacts of the treaty on Germany and how it "
        "contributed to the onset of World War II. Provide a nuanced assessment that includes "
        "multiple historical perspectives."
    )
    asyncio.run(
        run_agent_with_events(
            task,
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/events/reasoning_agent_events.py
      ```

      ```bash Windows
      python cookbook/agents/events/reasoning_agent_events.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic User Input with Control Flow
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/agentic_user_input



This example demonstrates how to use UserControlFlowTools to allow agents to dynamically request user input when they need additional information to complete tasks.

## Code

```python cookbook/agents/human_in_the_loop/agentic_user_input.py
"""ü§ù Human-in-the-Loop: Allowing users to provide input externally

This example shows how to use the UserControlFlowTools to allow the agent to get user input dynamically.
If the agent doesn't have enough information to complete a task, it will use the toolkit to get the information it needs from the user.
"""

from typing import Any, Dict, List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import Toolkit
from agno.tools.function import UserInputField
from agno.tools.user_control_flow import UserControlFlowTools
from agno.utils import pprint


class EmailTools(Toolkit):
    def __init__(self, *args, **kwargs):
        super().__init__(
            name="EmailTools", tools=[self.send_email, self.get_emails], *args, **kwargs
        )

    def send_email(self, subject: str, body: str, to_address: str) -> str:
        """Send an email to the given address with the given subject and body.

        Args:
            subject (str): The subject of the email.
            body (str): The body of the email.
            to_address (str): The address to send the email to.
        """
        return f"Sent email to {to_address} with subject {subject} and body {body}"

    def get_emails(self, date_from: str, date_to: str) -> list[dict[str, str]]:
        """Get all emails between the given dates.

        Args:
            date_from (str): The start date (in YYYY-MM-DD format).
            date_to (str): The end date (in YYYY-MM-DD format).
        """
        return [
            {
                "subject": "Hello",
                "body": "Hello, world!",
                "to_address": "test@test.com",
                "date": date_from,
            },
            {
                "subject": "Random other email",
                "body": "This is a random other email",
                "to_address": "john@doe.com",
                "date": date_to,
            },
        ]


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[EmailTools(), UserControlFlowTools()],
    markdown=True,
)

run_response = agent.run("Send an email with the body 'What is the weather in Tokyo?'")

# We use a while loop to continue the running until the agent is satisfied with the user input
while run_response.is_paused:
    for tool in run_response.tools_requiring_user_input:
        input_schema: List[UserInputField] = tool.user_input_schema  # type: ignore

        for field in input_schema:
            # Get user input for each field in the schema
            field_type = field.field_type  # type: ignore
            field_description = field.description  # type: ignore

            # Display field information to the user
            print(f"\nField: {field.name}")  # type: ignore
            print(f"Description: {field_description}")
            print(f"Type: {field_type}")

            # Get user input
            if field.value is None:  # type: ignore
                user_value = input(f"Please enter a value for {field.name}: ")  # type: ignore
            else:
                print(f"Value: {field.value}")  # type: ignore
                user_value = field.value  # type: ignore

            # Update the field value
            field.value = user_value  # type: ignore

    run_response = agent.continue_run(run_response=run_response)
    if not run_response.is_paused:
        pprint.pprint_run_response(run_response)
        break


run_response = agent.run("Get me all my emails")

while run_response.is_paused:
    for tool in run_response.tools_requiring_user_input:
        input_schema: Dict[str, Any] = tool.user_input_schema  # type: ignore

        for field in input_schema:
            # Get user input for each field in the schema
            field_type = field.field_type  # type: ignore
            field_description = field.description  # type: ignore

            # Display field information to the user
            print(f"\nField: {field.name}")  # type: ignore
            print(f"Description: {field_description}")
            print(f"Type: {field_type}")

            # Get user input
            if field.value is None:  # type: ignore
                user_value = input(f"Please enter a value for {field.name}: ")  # type: ignore
            else:
                print(f"Value: {field.value}")  # type: ignore
                user_value = field.value  # type: ignore

            # Update the field value
            field.value = user_value  # type: ignore

    run_response = agent.continue_run(run_response=run_response)
    if not run_response.is_paused:
        pprint.pprint_run_response(run_response)
        break
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/agentic_user_input.py
      ```

      ```bash Windows
      python cookbook/agents/human_in_the_loop/agentic_user_input.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Confirmation Required
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required



This example demonstrates how to implement human-in-the-loop functionality by requiring user confirmation before executing sensitive tool operations, such as API calls or data modifications.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import json

import httpx
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories],
    markdown=True,
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
)

run_response = agent.run("Fetch the top 2 hackernews stories.")
if run_response.is_paused:
    for tool in run_response.tools_requiring_confirmation:
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            tool.confirmed = False
        else:
            # We update the tools in place
            tool.confirmed = True

run_response = agent.continue_run(run_response=run_response)
# Or
# run_response = agent.continue_run(run_id=run_response.run_id, updated_tools=run_response.tools)

pprint.pprint_run_response(run_response)


# Or for simple debug flow
# agent.print_response("Fetch the top 2 hackernews stories")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required.py
      ```

      ```bash Windows
      python cookbook/agents/human_in_the_loop/confirmation_required.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Tool Confirmation Required
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_async



This example demonstrates how to implement human-in-the-loop functionality with async agents, requiring user confirmation before executing tool operations.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_async.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import asyncio
import json

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories],
    markdown=True,
)

run_response = asyncio.run(agent.arun("Fetch the top 2 hackernews stories"))
if run_response.is_paused:
    for tool in run_response.tools_requiring_confirmation:
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            tool.confirmed = False
        else:
            # We update the tools in place
            tool.confirmed = True


run_response = asyncio.run(agent.acontinue_run(run_response=run_response))
# Or
# run_response = asyncio.run(agent.acontinue_run(run_id=run_response.run_id))

pprint.pprint_run_response(run_response)


# Or for simple debug flow
# asyncio.run(agent.aprint_response("Fetch the top 2 hackernews stories"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_async.py
      ```

      ```bash Windows
      python cookbook/agents/human_in_the_loop/confirmation_required_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with Mixed Tools
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_mixed_tools



This example demonstrates human-in-the-loop functionality where only some tools require user confirmation. The agent executes tools that don't require confirmation automatically and pauses only for tools that need approval.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_mixed_tools.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.

In this case we have multiple tools and only one of them requires confirmation.

The agent should execute the tool that doesn't require confirmation and then pause for user confirmation.

The user can then either approve or reject the tool call and the agent should continue from where it left off.
"""

import json

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


@tool(requires_confirmation=True)
def send_email(to: str, subject: str, body: str) -> str:
    """Send an email.

    Args:
        to (str): Email address to send to
        subject (str): Subject of the email
        body (str): Body of the email
    """
    return f"Email sent to {to} with subject {subject} and body {body}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories, send_email],
    markdown=True,
)

run_response = agent.run(
    "Fetch the top 2 hackernews stories and email them to john@doe.com."
)
if run_response.is_paused:
    for tool in run_response.tools:  # type: ignore
        if tool.requires_confirmation:
            # Ask for confirmation
            console.print(
                f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
            )
            message = (
                Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
                .strip()
                .lower()
            )

            if message == "n":
                tool.confirmed = False
            else:
                # We update the tools in place
                tool.confirmed = True
        else:
            console.print(
                f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] was completed in [bold green]{tool.metrics.duration:.2f}[/] seconds."  # type: ignore
            )

    run_response = agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)

# Or for simple debug flow
# agent.print_response("Fetch the top 2 hackernews stories")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_mixed_tools.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_mixed_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with Multiple Tools
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_multiple_tools



This example demonstrates human-in-the-loop functionality with multiple tools that require confirmation. It shows how to handle user confirmation during tool execution and gracefully cancel operations based on user choice.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_multiple_tools.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import json

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.wikipedia import WikipediaTools
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        get_top_hackernews_stories,
        WikipediaTools(requires_confirmation_tools=["search_wikipedia"]),
    ],
    markdown=True,
)

run_response = agent.run(
    "Fetch 2 articles about the topic 'python'. You can choose which source to use, but only use one source."
)
while run_response.is_paused:
    for tool_exc in run_response.tools_requiring_confirmation:  # type: ignore
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool_exc.tool_name}({tool_exc.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            tool.confirmed = False
            tool.confirmation_note = (
                "This is not the right tool to use. Use the other tool!"
            )
        else:
            # We update the tools in place
            tool.confirmed = True

    run_response = agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_multiple_tools.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_multiple_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with Streaming
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_stream



This example demonstrates human-in-the-loop functionality with streaming responses. It shows how to handle user confirmation during tool execution while maintaining real-time streaming capabilities.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_stream.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import json

import httpx
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=SqliteDb(
        db_file="tmp/example.db",
    ),
    tools=[get_top_hackernews_stories],
    markdown=True,
)

for run_event in agent.run("Fetch the top 2 hackernews stories", stream=True):
    if run_event.is_paused:
        for tool in run_event.tools_requiring_confirmation:  # type: ignore
            # Ask for confirmation
            console.print(
                f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
            )
            message = (
                Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
                .strip()
                .lower()
            )

            if message == "n":
                tool.confirmed = False
            else:
                # We update the tools in place
                tool.confirmed = True
        run_response = agent.continue_run(
            run_id=run_event.run_id, updated_tools=run_event.tools, stream=True
        )  # type: ignore
        pprint.pprint_run_response(run_response)

# Or for simple debug flow
# agent.print_response("Fetch the top 2 hackernews stories", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_stream.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with Async Streaming
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_stream_async



This example demonstrates human-in-the-loop functionality with asynchronous streaming responses. It shows how to handle user confirmation during tool execution in an async environment while maintaining real-time streaming.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_stream_async.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import asyncio
import json

import httpx
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories],
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
    markdown=True,
)


async def main():
    async for run_event in agent.arun(
        "Fetch the top 2 hackernews stories", stream=True
    ):
        if run_event.is_paused:
            for tool in run_event.tools_requiring_confirmation:  # type: ignore
                # Ask for confirmation
                console.print(
                    f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
                )
                message = (
                    Prompt.ask(
                        "Do you want to continue?", choices=["y", "n"], default="y"
                    )
                    .strip()
                    .lower()
                )

                if message == "n":
                    tool.confirmed = False
                else:
                    # We update the tools in place
                    tool.confirmed = True

            async for resp in agent.acontinue_run(  # type: ignore
                run_id=run_event.run_id, updated_tools=run_event.tools, stream=True
            ):
                print(resp.content, end="")

    # Or for simple debug flow
    # await agent.aprint_response("Fetch the top 2 hackernews stories", stream=True)


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_stream_async.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_stream_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with Toolkit
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_toolkit



This example demonstrates human-in-the-loop functionality using toolkit-based tools that require confirmation. It shows how to handle user confirmation when working with pre-built tool collections like YFinanceTools.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_toolkit.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(requires_confirmation_tools=["get_current_stock_price"])],
    markdown=True,
)

run_response = agent.run("What is the current stock price of Apple?")
if run_response.is_paused:  # Or agent.run_response.is_paused
    for tool in run_response.tools_requiring_confirmation:  # type: ignore
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            tool.confirmed = False
        else:
            # We update the tools in place
            tool.confirmed = True

    run_response = agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_toolkit.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_toolkit.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with History
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_with_history



This example demonstrates human-in-the-loop functionality while maintaining conversation history. It shows how user confirmation works when the agent has access to previous conversation context.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_with_history.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import json

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories],
    add_history_to_context=True,
    num_history_runs=2,
    markdown=True,
)

agent.run("What can you do?")

run_response = agent.run("Fetch the top 2 hackernews stories.")
if run_response.is_paused:
    for tool in run_response.tools_requiring_confirmation:  # type: ignore
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            tool.confirmed = False
        else:
            # We update the tools in place
            tool.confirmed = True

run_response = agent.continue_run(run_response=run_response)
pprint.pprint_run_response(run_response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_with_history.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_with_history.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confirmation Required with Run ID
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/confirmation_required_with_run_id



This example demonstrates human-in-the-loop functionality using specific run IDs for session management. It shows how to continue agent execution with updated tools using run identifiers.

## Code

```python cookbook/agents/human_in_the_loop/confirmation_required_with_run_id.py
"""ü§ù Human-in-the-Loop: Adding User Confirmation to Tool Calls

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Handle user confirmation during tool execution
- Gracefully cancel operations based on user choice

Some practical applications:
- Confirming sensitive operations before execution
- Reviewing API calls before they're made
- Validating data transformations
- Approving automated actions in critical systems

Run `pip install openai httpx rich agno` to install dependencies.
"""

import json

import httpx
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_top_hackernews_stories],
    markdown=True,
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
)

run_response = agent.run("Fetch the top 2 hackernews stories.")
if run_response.is_paused:
    for tool in run_response.tools_requiring_confirmation:  # type: ignore
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            tool.confirmed = False
        else:
            # We update the tools in place
            tool.confirmed = True

updated_tools = run_response.tools

run_response = agent.continue_run(
    run_id=run_response.run_id,
    updated_tools=updated_tools,
)

pprint.pprint_run_response(run_response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai httpx rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/confirmation_required_with_run_id.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/confirmation_required_with_run_id.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# External Tool Execution
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/external_tool_execution



This example demonstrates how to execute tools outside of the agent using external tool execution. This pattern allows you to control tool execution externally while maintaining agent functionality.

## Code

```python cookbook/agents/human_in_the_loop/external_tool_execution.py
"""ü§ù Human-in-the-Loop: Execute a tool call outside of the agent

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Use external tool execution to execute a tool call outside of the agent

Run `pip install openai agno` to install dependencies.
"""

import subprocess

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint


# We have to create a tool with the correct name, arguments and docstring for the agent to know what to call.
@tool(external_execution=True)
def execute_shell_command(command: str) -> str:
    """Execute a shell command.

    Args:
        command (str): The shell command to execute

    Returns:
        str: The output of the shell command
    """
    if command.startswith("ls"):
        return subprocess.check_output(command, shell=True).decode("utf-8")
    else:
        raise Exception(f"Unsupported command: {command}")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[execute_shell_command],
    markdown=True,
)

run_response = agent.run("What files do I have in my current directory?")
if run_response.is_paused:
    for tool in run_response.tools_awaiting_external_execution:
        if tool.tool_name == execute_shell_command.name:
            print(f"Executing {tool.tool_name} with args {tool.tool_args} externally")
            # We execute the tool ourselves. You can also execute something completely external here.
            result = execute_shell_command.entrypoint(**tool.tool_args)  # type: ignore
            # We have to set the result on the tool execution object so that the agent can continue
            tool.result = result

    run_response = agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)


# Or for simple debug flow
# agent.print_response("What files do I have in my current directory?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/external_tool_execution.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/external_tool_execution.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# External Tool Execution Async
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/external_tool_execution_async



This example demonstrates how to execute tools outside of the agent using external tool execution in an asynchronous environment. This pattern allows you to control tool execution externally while maintaining agent functionality with async operations.

## Code

```python cookbook/agents/human_in_the_loop/external_tool_execution_async.py
"""ü§ù Human-in-the-Loop: Execute a tool call outside of the agent

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Use external tool execution to execute a tool call outside of the agent

Run `pip install openai agno` to install dependencies.
"""

import asyncio
import subprocess

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint


# We have to create a tool with the correct name, arguments and docstring for the agent to know what to call.
@tool(external_execution=True)
def execute_shell_command(command: str) -> str:
    """Execute a shell command.

    Args:
        command (str): The shell command to execute

    Returns:
        str: The output of the shell command
    """
    if command.startswith("ls"):
        return subprocess.check_output(command, shell=True).decode("utf-8")
    else:
        raise Exception(f"Unsupported command: {command}")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[execute_shell_command],
    markdown=True,
)

run_response = asyncio.run(agent.arun("What files do I have in my current directory?"))
if run_response.is_paused:
    for tool in run_response.tools_awaiting_external_execution:
        if tool.tool_name == execute_shell_command.name:
            print(f"Executing {tool.tool_name} with args {tool.tool_args} externally")
            # We execute the tool ourselves. You can also execute something completely external here.
            result = execute_shell_command.entrypoint(**tool.tool_args)  # type: ignore
            # We have to set the result on the tool execution object so that the agent can continue
            tool.result = result

    run_response = asyncio.run(agent.acontinue_run(run_response=run_response))
    pprint.pprint_run_response(run_response)


# Or for simple debug flow
# agent.print_response("What files do I have in my current directory?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/external_tool_execution_async.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/external_tool_execution_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# External Tool Execution Async Responses
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/external_tool_execution_async_responses



This example demonstrates external tool execution using OpenAI Responses API with gpt-4.1-mini model. It shows how to handle tool-call IDs and execute multiple external tools in a loop until completion.

## Code

```python cookbook/agents/human_in_the_loop/external_tool_execution_async_responses.py
"""ü§ù Human-in-the-Loop with OpenAI Responses API (gpt-4.1-mini)

This example mirrors the external tool execution async example but uses
OpenAIResponses with gpt-4.1-mini to validate tool-call id handling.

Run `pip install openai agno` to install dependencies.
"""

import asyncio
import subprocess

from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools import tool
from agno.utils import pprint


# We have to create a tool with the correct name, arguments and docstring
# for the agent to know what to call.
@tool(external_execution=True)
def execute_shell_command(command: str) -> str:
    """Execute a shell command.

    Args:
        command (str): The shell command to execute

    Returns:
        str: The output of the shell command
    """
    if (
        command.startswith("ls ")
        or command == "ls"
        or command.startswith("cat ")
        or command.startswith("head ")
    ):
        return subprocess.check_output(command, shell=True).decode("utf-8")
    raise Exception(f"Unsupported command: {command}")


agent = Agent(
    model=OpenAIResponses(id="gpt-4.1-mini"),
    tools=[execute_shell_command],
    markdown=True,
)

run_response = asyncio.run(agent.arun("What files do I have in my current directory?"))

# Keep executing externally-required tools until the run completes
while (
    run_response.is_paused and len(run_response.tools_awaiting_external_execution) > 0
):
    for external_tool in run_response.tools_awaiting_external_execution:
        if external_tool.tool_name == execute_shell_command.name:
            print(
                f"Executing {external_tool.tool_name} with args {external_tool.tool_args} externally"
            )
            result = execute_shell_command.entrypoint(**external_tool.tool_args)
            external_tool.result = result
        else:
            print(f"Skipping unsupported external tool: {external_tool.tool_name}")

    run_response = asyncio.run(agent.acontinue_run(run_response=run_response))

pprint.pprint_run_response(run_response)


# Or for simple debug flow
# agent.print_response("What files do I have in my current directory?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/external_tool_execution_async_responses.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/external_tool_execution_async_responses.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# External Tool Execution Stream
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/external_tool_execution_stream



This example demonstrates how to execute tools outside of the agent using external tool execution with streaming responses. It shows how to handle external tool execution while maintaining real-time streaming capabilities.

## Code

```python cookbook/agents/human_in_the_loop/external_tool_execution_stream.py
"""ü§ù Human-in-the-Loop: Execute a tool call outside of the agent

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Use external tool execution to execute a tool call outside of the agent

Run `pip install openai agno` to install dependencies.
"""

import subprocess

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.utils import pprint


# We have to create a tool with the correct name, arguments and docstring for the agent to know what to call.
@tool(external_execution=True)
def execute_shell_command(command: str) -> str:
    """Execute a shell command.

    Args:
        command (str): The shell command to execute

    Returns:
        str: The output of the shell command
    """
    if command.startswith("ls"):
        return subprocess.check_output(command, shell=True).decode("utf-8")
    else:
        raise Exception(f"Unsupported command: {command}")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[execute_shell_command],
    markdown=True,
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
)

for run_event in agent.run(
    "What files do I have in my current directory?", stream=True
):
    if run_event.is_paused:
        for tool in run_event.tools_awaiting_external_execution:  # type: ignore
            if tool.tool_name == execute_shell_command.name:
                print(
                    f"Executing {tool.tool_name} with args {tool.tool_args} externally"
                )
                # We execute the tool ourselves. You can also execute something completely external here.
                result = execute_shell_command.entrypoint(**tool.tool_args)  # type: ignore
                # We have to set the result on the tool execution object so that the agent can continue
                tool.result = result

        run_response = agent.continue_run(
            run_id=run_event.run_id, updated_tools=run_event.tools, stream=True
        )  # type: ignore
        pprint.pprint_run_response(run_response)


# Or for simple debug flow
# agent.print_response("What files do I have in my current directory?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/external_tool_execution_stream.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/external_tool_execution_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# External Tool Execution Stream Async
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/external_tool_execution_stream_async



This example demonstrates how to execute tools outside of the agent using external tool execution with async streaming responses. It shows how to handle external tool execution in an asynchronous environment while maintaining real-time streaming.

## Code

```python cookbook/agents/human_in_the_loop/external_tool_execution_stream_async.py
"""ü§ù Human-in-the-Loop: Execute a tool call outside of the agent

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Use external tool execution to execute a tool call outside of the agent

Run `pip install openai agno` to install dependencies.
"""

import asyncio
import subprocess

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool


# We have to create a tool with the correct name, arguments and docstring for the agent to know what to call.
@tool(external_execution=True)
def execute_shell_command(command: str) -> str:
    """Execute a shell command.

    Args:
        command (str): The shell command to execute

    Returns:
        str: The output of the shell command
    """
    if command.startswith("ls"):
        return subprocess.check_output(command, shell=True).decode("utf-8")
    else:
        raise Exception(f"Unsupported command: {command}")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[execute_shell_command],
    markdown=True,
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
)


async def main():
    async for run_event in agent.arun(
        "What files do I have in my current directory?", stream=True
    ):
        if run_event.is_paused:
            for tool in run_event.tools_awaiting_external_execution:  # type: ignore
                if tool.tool_name == execute_shell_command.name:
                    print(
                        f"Executing {tool.tool_name} with args {tool.tool_args} externally"
                    )
                    # We execute the tool ourselves. You can also execute something completely external here.
                    result = execute_shell_command.entrypoint(**tool.tool_args)  # type: ignore
                    # We have to set the result on the tool execution object so that the agent can continue
                    tool.result = result

            async for resp in agent.acontinue_run(  # type: ignore
                run_id=run_event.run_id,
                updated_tools=run_event.tools,
                stream=True,
            ):
                print(resp.content, end="")
        else:
            print(run_event.content, end="")

    # Or for simple debug flow
    # agent.print_response("What files do I have in my current directory?", stream=True)


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/external_tool_execution_stream_async.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/external_tool_execution_stream_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# External Tool Execution Toolkit
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/external_tool_execution_toolkit



This example demonstrates how to execute toolkit-based tools outside of the agent using external tool execution. It shows how to create a custom toolkit with tools that require external execution.

## Code

```python cookbook/agents/human_in_the_loop/external_tool_execution_toolkit.py
"""ü§ù Human-in-the-Loop: Execute a tool call outside of the agent

This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:
- Use external tool execution to execute a tool call outside of the agent

Run `pip install openai agno` to install dependencies.
"""

import subprocess

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.toolkit import Toolkit
from agno.utils import pprint


class ShellTools(Toolkit):
    def __init__(self, *args, **kwargs):
        super().__init__(
            tools=[self.list_dir],
            external_execution_required_tools=["list_dir"],
            *args,
            **kwargs,
        )

    def list_dir(self, directory: str):
        """
        Lists the contents of a directory.

        Args:
            directory: The directory to list.

        Returns:
            A string containing the contents of the directory.
        """
        return subprocess.check_output(f"ls {directory}", shell=True).decode("utf-8")


tools = ShellTools()

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[tools],
    markdown=True,
)

run_response = agent.run("What files do I have in my current directory?")
if run_response.is_paused:
    for tool in run_response.tools_awaiting_external_execution:
        if tool.tool_name == "list_dir":
            print(f"Executing {tool.tool_name} with args {tool.tool_args} externally")
            # We execute the tool ourselves. You can also execute something completely external here.
            result = tools.list_dir(**tool.tool_args)  # type: ignore
            # We have to set the result on the tool execution object so that the agent can continue
            tool.result = result

    run_response = agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/external_tool_execution_toolkit.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/external_tool_execution_toolkit.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# User Input Required for Tool Execution
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/user_input_required



This example demonstrates how to create tools that require user input before execution, allowing for dynamic data collection during agent runs.

## Code

```python cookbook/agents/human_in_the_loop/user_input_required.py
"""ü§ù Human-in-the-Loop: Allowing users to provide input externally

This example shows how to use the `requires_user_input` parameter to allow users to provide input externally.
"""

from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.function import UserInputField
from agno.utils import pprint


# You can either specify the user_input_fields leave empty for all fields to be provided by the user
@tool(requires_user_input=True, user_input_fields=["to_address"])
def send_email(subject: str, body: str, to_address: str) -> str:
    """
    Send an email.

    Args:
        subject (str): The subject of the email.
        body (str): The body of the email.
        to_address (str): The address to send the email to.
    """
    return f"Sent email to {to_address} with subject {subject} and body {body}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
    markdown=True,
)

run_response = agent.run(
    "Send an email with the subject 'Hello' and the body 'Hello, world!'"
)
if run_response.is_paused:
    for tool in run_response.tools_requiring_user_input:  # type: ignore
        input_schema: List[UserInputField] = tool.user_input_schema  # type: ignore

        for field in input_schema:
            # Get user input for each field in the schema
            field_type = field.field_type
            field_description = field.description

            # Display field information to the user
            print(f"\nField: {field.name}")
            print(f"Description: {field_description}")
            print(f"Type: {field_type}")

            # Get user input
            if field.value is None:
                user_value = input(f"Please enter a value for {field.name}: ")
            else:
                print(f"Value: {field.value}")
                user_value = field.value

            # Update the field value
            field.value = user_value

    run_response = agent.continue_run(
        run_response=run_response
    )  # or agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)

# Or for simple debug flow
# agent.print_response("Send an email with the subject 'Hello' and the body 'Hello, world!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/user_input_required.py
      ```

      ```bash Windows
      python cookbook/agents/human_in_the_loop/user_input_required.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# User Input Required All Fields
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/user_input_required_all_fields



This example demonstrates how to use the `requires_user_input` parameter to collect input for all fields in a tool. It shows how to handle user input schema and collect values for each required field.

## Code

```python cookbook/agents/human_in_the_loop/user_input_required_all_fields.py
"""ü§ù Human-in-the-Loop: Allowing users to provide input externally

This example shows how to use the `requires_user_input` parameter to allow users to provide input externally.
"""

from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.function import UserInputField
from agno.utils import pprint


@tool(requires_user_input=True)
def send_email(subject: str, body: str, to_address: str) -> str:
    """
    Send an email.

    Args:
        subject (str): The subject of the email.
        body (str): The body of the email.
        to_address (str): The address to send the email to.
    """
    return f"Sent email to {to_address} with subject {subject} and body {body}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
    markdown=True,
)

run_response = agent.run("Send an email please")
if run_response.is_paused:  # Or agent.run_response.is_paused
    for tool in run_response.tools_requiring_user_input:  # type: ignore
        input_schema: List[UserInputField] = tool.user_input_schema  # type: ignore

        for field in input_schema:
            # Get user input for each field in the schema
            field_type = field.field_type
            field_description = field.description

            # Display field information to the user
            print(f"\nField: {field.name}")
            print(f"Description: {field_description}")
            print(f"Type: {field_type}")

            # Get user input
            if field.value is None:
                user_value = input(f"Please enter a value for {field.name}: ")

            # Update the field value
            field.value = user_value

    run_response = agent.continue_run(run_response=run_response)
    pprint.pprint_run_response(run_response)

# Or for simple debug flow
# agent.print_response("Send an email please")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/user_input_required_all_fields.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/user_input_required_all_fields.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# User Input Required Async
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/user_input_required_async



This example demonstrates how to use the `requires_user_input` parameter with asynchronous operations. It shows how to collect specific user input fields in an async environment.

## Code

```python cookbook/agents/human_in_the_loop/user_input_required_async.py
"""ü§ù Human-in-the-Loop: Allowing users to provide input externally"""

import asyncio
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.function import UserInputField
from agno.utils import pprint


# You can either specify the user_input_fields leave empty for all fields to be provided by the user
@tool(requires_user_input=True, user_input_fields=["to_address"])
def send_email(subject: str, body: str, to_address: str) -> str:
    """
    Send an email.

    Args:
        subject (str): The subject of the email.
        body (str): The body of the email.
        to_address (str): The address to send the email to.
    """
    return f"Sent email to {to_address} with subject {subject} and body {body}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
    markdown=True,
)

run_response = asyncio.run(
    agent.arun("Send an email with the subject 'Hello' and the body 'Hello, world!'")
)
if run_response.is_paused:  # Or agent.run_response.is_paused
    for tool in run_response.tools_requiring_user_input:  # type: ignore
        input_schema: List[UserInputField] = tool.user_input_schema  # type: ignore

        for field in input_schema:
            # Get user input for each field in the schema
            field_type = field.field_type
            field_description = field.description

            # Display field information to the user
            print(f"\nField: {field.name}")
            print(f"Description: {field_description}")
            print(f"Type: {field_type}")

            # Get user input
            if field.value is None:
                user_value = input(f"Please enter a value for {field.name}: ")
            else:
                print(f"Value: {field.value}")
                user_value = field.value

            # Update the field value
            field.value = user_value

    run_response = asyncio.run(agent.acontinue_run(run_response=run_response))
    pprint.pprint_run_response(run_response)

# Or for simple debug flow
# agent.print_response("Send an email with the subject 'Hello' and the body 'Hello, world!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/user_input_required_async.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/user_input_required_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# User Input Required Stream
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/user_input_required_stream



This example demonstrates how to use the `requires_user_input` parameter with streaming responses. It shows how to collect specific user input fields while maintaining real-time streaming capabilities.

## Code

```python cookbook/agents/human_in_the_loop/user_input_required_stream.py
"""ü§ù Human-in-the-Loop: Allowing users to provide input externally

This example shows how to use the `requires_user_input` parameter to allow users to provide input externally.
"""

from typing import List

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.function import UserInputField
from agno.utils import pprint


# You can either specify the user_input_fields leave empty for all fields to be provided by the user
@tool(requires_user_input=True, user_input_fields=["to_address"])
def send_email(subject: str, body: str, to_address: str) -> str:
    """
    Send an email.

    Args:
        subject (str): The subject of the email.
        body (str): The body of the email.
        to_address (str): The address to send the email to.
    """
    return f"Sent email to {to_address} with subject {subject} and body {body}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
    markdown=True,
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
)

for run_event in agent.run(
    "Send an email with the subject 'Hello' and the body 'Hello, world!'", stream=True
):
    if run_event.is_paused:  # Or agent.run_response.is_paused
        for tool in run_event.tools_requiring_user_input:  # type: ignore
            input_schema: List[UserInputField] = tool.user_input_schema  # type: ignore

            for field in input_schema:
                # Get user input for each field in the schema
                field_type = field.field_type
                field_description = field.description

                # Display field information to the user
                print(f"\nField: {field.name}")
                print(f"Description: {field_description}")
                print(f"Type: {field_type}")

                # Get user input
                if field.value is None:
                    user_value = input(f"Please enter a value for {field.name}: ")
                else:
                    print(f"Value: {field.value}")
                    user_value = field.value

                # Update the field value
                field.value = user_value

        run_response = agent.continue_run(
            run_id=run_event.run_id, updated_tools=run_event.tools
        )
    pprint.pprint_run_response(run_response)

# Or for simple debug flow
# agent.print_response("Send an email with the subject 'Hello' and the body 'Hello, world!'", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/user_input_required_stream.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/user_input_required_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# User Input Required Stream Async
Source: https://docs.agno.com/examples/concepts/agent/human_in_the_loop/user_input_required_stream_async



This example demonstrates how to use the `requires_user_input` parameter with async streaming responses. It shows how to collect specific user input fields in an asynchronous environment while maintaining real-time streaming.

## Code

```python cookbook/agents/human_in_the_loop/user_input_required_stream_async.py
"""ü§ù Human-in-the-Loop: Allowing users to provide input externally

This example shows how to use the `requires_user_input` parameter to allow users to provide input externally.
"""

import asyncio
from typing import List

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools import tool
from agno.tools.function import UserInputField


# You can either specify the user_input_fields leave empty for all fields to be provided by the user
@tool(requires_user_input=True, user_input_fields=["to_address"])
def send_email(subject: str, body: str, to_address: str) -> str:
    """
    Send an email.

    Args:
        subject (str): The subject of the email.
        body (str): The body of the email.
        to_address (str): The address to send the email to.
    """
    return f"Sent email to {to_address} with subject {subject} and body {body}"


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[send_email],
    markdown=True,
    db=SqliteDb(session_table="test_session", db_file="tmp/example.db"),
)


async def main():
    async for run_event in agent.arun(
        "Send an email with the subject 'Hello' and the body 'Hello, world!'",
        stream=True,
    ):
        if run_event.is_paused:  # Or agent.run_response.is_paused
            for tool in run_event.tools_requiring_user_input:  # type: ignore
                input_schema: List[UserInputField] = tool.user_input_schema  # type: ignore

                for field in input_schema:
                    # Get user input for each field in the schema
                    field_type = field.field_type
                    field_description = field.description

                    # Display field information to the user
                    print(f"\nField: {field.name}")
                    print(f"Description: {field_description}")
                    print(f"Type: {field_type}")

                    # Get user input
                    if field.value is None:
                        user_value = input(f"Please enter a value for {field.name}: ")
                    else:
                        print(f"Value: {field.value}")
                        user_value = field.value

                    # Update the field value
                    field.value = user_value

            async for resp in agent.acontinue_run(  # type: ignore
                run_id=run_event.run_id,
                updated_tools=run_event.tools,
                stream=True,
            ):
                print(resp.content, end="")

    # Or for simple debug flow
    # agent.aprint_response("Send an email with the subject 'Hello' and the body 'Hello, world!'")


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/human_in_the_loop/user_input_required_stream_async.py
      ```

      ```bash Windows  
      python cookbook/agents/human_in_the_loop/user_input_required_stream_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Input as Dictionary
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/input_as_dict



This example demonstrates how to provide input to an agent as a dictionary format, specifically for multimodal inputs like text and images.

## Code

```python cookbook/agents/input_and_output/input_as_dict.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

Agent(model=OpenAIChat(id="gpt-5-mini")).print_response(
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {
                "type": "image_url",
                "image_url": {
                    "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                },
            },
        ],
    },
    stream=True,
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/input_as_dict.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/input_as_dict.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Input as List
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/input_as_list



This example demonstrates how to provide input to an agent as a list format for multimodal content combining text and images.

## Code

```python cookbook/agents/input_and_output/input_as_list.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

Agent(model=OpenAIChat(id="gpt-5-mini")).print_response(
    [
        {"type": "text", "text": "What's in this image?"},
        {
            "type": "image_url",
            "image_url": {
                "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
            },
        },
    ],
    stream=True,
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/input_as_list.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/input_as_list.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Input as Message Object
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/input_as_message



This example demonstrates how to provide input to an agent using the Message object format for structured multimodal content.

## Code

```python cookbook/agents/input_and_output/input_as_message.py
from agno.agent import Agent, Message
from agno.models.openai import OpenAIChat

Agent(model=OpenAIChat(id="gpt-5-mini")).print_response(
    Message(
        role="user",
        content=[
            {"type": "text", "text": "What's in this image?"},
            {
                "type": "image_url",
                "image_url": {
                    "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                },
            },
        ],
    ),
    stream=True,
    markdown=True,
    show_message=False
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/input_as_message.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/input_as_message.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Input as Messages List
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/input_as_messages_list



This example demonstrates how to pass input to an agent as a list of Message objects, allowing for multi-turn conversations and context setup.

## Code

```python cookbook/agents/input_and_output/input_as_messages_list.py
from agno.agent import Agent, Message
from agno.models.openai import OpenAIChat

Agent(model=OpenAIChat(id="gpt-5-mini")).print_response(
    input=[
        Message(
            role="user",
            content="I'm preparing a presentation for my company about renewable energy adoption.",
        ),
        Message(
            role="assistant",
            content="I'd be happy to help with your renewable energy presentation. What specific aspects would you like me to focus on?",
        ),
        Message(
            role="user",
            content="Could you research the latest solar panel efficiency improvements in 2024?",
        ),
        Message(
            role="user",
            content="Also, please summarize the key findings in bullet points for my slides.",
        ),
    ],
    stream=True,
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/input_as_messages_list.py
      ```

      ```bash Windows  
      python cookbook/agents/input_and_output/input_as_messages_list.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Input Schema
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/input_schema_on_agent



This example demonstrates how to define an input schema for an agent using Pydantic models, ensuring structured input validation.

## Code

```python cookbook/agents/input_and_output/input_schema_on_agent.py
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel, Field


class ResearchTopic(BaseModel):
    """Structured research topic with specific requirements"""

    topic: str
    focus_areas: List[str] = Field(description="Specific areas to focus on")
    target_audience: str = Field(description="Who this research is for")
    sources_required: int = Field(description="Number of sources needed", default=5)


# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
    input_schema=ResearchTopic,
)

# Pass a dict that matches the input schema
hackernews_agent.print_response(
    input={
        "topic": "AI",
        "focus_areas": ["AI", "Machine Learning"],
        "target_audience": "Developers",
        "sources_required": "5",
    }
)

# Pass a pydantic model that matches the input schema
# hackernews_agent.print_response(
#     input=ResearchTopic(
#         topic="AI",
#         focus_areas=["AI", "Machine Learning"],
#         target_audience="Developers",
#         sources_required=5,
#     )
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno pydantic
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/input_schema_on_agent.py
      ```

      ```bash Windows  
      python cookbook/agents/input_and_output/input_schema_on_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Input Schema as TypedDict
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/input_schema_on_agent_as_typed_dict



This example demonstrates how to define an input schema for an agent using `TypedDict`, ensuring structured input validation.

## Code

```python cookbook/agents/input_and_output/input_schema_on_agent_as_typed_dict.py
from typing import List, Optional, TypedDict

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.hackernews import HackerNewsTools


# Define a TypedDict schema
class ResearchTopicDict(TypedDict):
    topic: str
    focus_areas: List[str]
    target_audience: str    
    sources_required: int


# Optional: Define a TypedDict with optional fields
class ResearchTopicWithOptionals(TypedDict, total=False):
    topic: str
    focus_areas: List[str]
    target_audience: str
    sources_required: int
    priority: Optional[str]


# Create agent with TypedDict input schema
hackernews_agent = Agent(
    name="Hackernews Agent with TypedDict",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
    input_schema=ResearchTopicDict,
)

# with valid input
print("=== Testing TypedDict Input Schema ===")
hackernews_agent.print_response(
    input={
        "topic": "AI",
        "focus_areas": ["Machine Learning", "LLMs", "Neural Networks"],
        "target_audience": "Developers",
        "sources_required": 5,
    }
)

# with optional fields
optional_agent = Agent(
    name="Hackernews Agent with Optional Fields",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[HackerNewsTools()],
    input_schema=ResearchTopicWithOptionals,
)

print("\n=== Testing TypedDict with Optional Fields ===")
optional_agent.print_response(
    input={
        "topic": "Blockchain",
        "focus_areas": ["DeFi", "NFTs"],
        "target_audience": "Investors",
        # sources_required is optional, omitting it
        "priority": "high",
    }
)

# Should raise an error - missing required field
try:
    hackernews_agent.print_response(
        input={
            "topic": "AI",
            # Missing required fields: focus_areas, target_audience, sources_required
        }
    )
except ValueError as e:
    print("\n=== Expected Error for Missing Fields ===")
    print(f"Error: {e}")

# This will raise an error - unexpected field
try:
    hackernews_agent.print_response(
        input={
            "topic": "AI",
            "focus_areas": ["Machine Learning"],
            "target_audience": "Developers",
            "sources_required": 5,
            "unexpected_field": "value",  # This field is not in the TypedDict
        }
    )
except ValueError as e:
    print("\n=== Expected Error for Unexpected Field ===")
    print(f"Error: {e}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```

    Export your key

    ```shell
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/input_schema_on_agent_as_typed_dict.py
      ```

      ```bash Windows  
      python cookbook/agents/input_and_output/input_schema_on_agent_as_typed_dict.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Output Model
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/output_model



This example demonstrates how to use the output\_model parameter to specify a different model for generating the final response, enabling model switching during agent execution.

## Code

```python cookbook/agents/input_and_output/output_model.py
"""
This example shows how to use the output_model parameter to specify the model that will be used to generate the final response.
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4.1"),
    output_model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
)

agent.print_response("Latest news from France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/output_model.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/output_model.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Parser Model for Structured Output
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/parser_model



This example demonstrates how to use a different parser model for structured output generation, combining Claude for content generation with OpenAI for parsing into structured formats.

## Code

```python cookbook/agents/input_and_output/parser_model.py
import random
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class NationalParkAdventure(BaseModel):
    park_name: str = Field(..., description="Name of the national park")
    best_season: str = Field(
        ...,
        description="Optimal time of year to visit this park (e.g., 'Late spring to early fall')",
    )
    signature_attractions: List[str] = Field(
        ...,
        description="Must-see landmarks, viewpoints, or natural features in the park",
    )
    recommended_trails: List[str] = Field(
        ...,
        description="Top hiking trails with difficulty levels (e.g., 'Angel's Landing - Strenuous')",
    )
    wildlife_encounters: List[str] = Field(
        ..., description="Animals visitors are likely to spot, with viewing tips"
    )
    photography_spots: List[str] = Field(
        ...,
        description="Best locations for capturing stunning photos, including sunrise/sunset spots",
    )
    camping_options: List[str] = Field(
        ..., description="Available camping areas, from primitive to RV-friendly sites"
    )
    safety_warnings: List[str] = Field(
        ..., description="Important safety considerations specific to this park"
    )
    hidden_gems: List[str] = Field(
        ..., description="Lesser-known spots or experiences that most visitors miss"
    )
    difficulty_rating: int = Field(
        ...,
        ge=1,
        le=5,
        description="Overall park difficulty for average visitor (1=easy, 5=very challenging)",
    )
    estimated_days: int = Field(
        ...,
        ge=1,
        le=14,
        description="Recommended number of days to properly explore the park",
    )
    special_permits_needed: List[str] = Field(
        default=[],
        description="Any special permits or reservations required for certain activities",
    )


agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    description="You help people plan amazing national park adventures and provide detailed park guides.",
    output_schema=NationalParkAdventure,
    parser_model=OpenAIChat(id="gpt-5-mini"),
)


# Get the response in a variable
national_parks = [
    "Yellowstone National Park",
    "Yosemite National Park",
    "Grand Canyon National Park",
    "Zion National Park",
    "Grand Teton National Park",
    "Rocky Mountain National Park",
    "Acadia National Park",
    "Mount Rainier National Park",
    "Great Smoky Mountains National Park",
    "Rocky National Park",
]
# Get the response in a variable
run: RunOutput = agent.run(national_parks[random.randint(0, len(national_parks) - 1)])
pprint(run.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic openai pydantic rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/parser_model.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/parser_model.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Ollama Parser Model
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/parser_model_ollama



This example demonstrates how to use an Ollama model as a parser for structured output, combining different models for generation and parsing.

## Code

```python cookbook/agents/input_and_output/parser_model_ollama.py
import random
from typing import List

from agno.agent import Agent, RunOutput
from agno.models.ollama import Ollama
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint


class NationalParkAdventure(BaseModel):
    park_name: str = Field(..., description="Name of the national park")
    best_season: str = Field(
        ...,
        description="Optimal time of year to visit this park (e.g., 'Late spring to early fall')",
    )
    signature_attractions: List[str] = Field(
        ...,
        description="Must-see landmarks, viewpoints, or natural features in the park",
    )
    recommended_trails: List[str] = Field(
        ...,
        description="Top hiking trails with difficulty levels (e.g., 'Angel's Landing - Strenuous')",
    )
    wildlife_encounters: List[str] = Field(
        ..., description="Animals visitors are likely to spot, with viewing tips"
    )
    photography_spots: List[str] = Field(
        ...,
        description="Best locations for capturing stunning photos, including sunrise/sunset spots",
    )
    camping_options: List[str] = Field(
        ..., description="Available camping areas, from primitive to RV-friendly sites"
    )
    safety_warnings: List[str] = Field(
        ..., description="Important safety considerations specific to this park"
    )
    hidden_gems: List[str] = Field(
        ..., description="Lesser-known spots or experiences that most visitors miss"
    )
    difficulty_rating: int = Field(
        ...,
        ge=1,
        le=5,
        description="Overall park difficulty for average visitor (1=easy, 5=very challenging)",
    )
    estimated_days: int = Field(
        ...,
        ge=1,
        le=14,
        description="Recommended number of days to properly explore the park",
    )
    special_permits_needed: List[str] = Field(
        default=[],
        description="Any special permits or reservations required for certain activities",
    )


agent = Agent(
    model=OpenAIChat(id="o3"),
    description="You help people plan amazing national park adventures and provide detailed park guides.",
    output_schema=NationalParkAdventure,
    parser_model=Ollama(id="Osmosis/Osmosis-Structure-0.6B"),
)

national_parks = [
    "Yellowstone National Park",
    "Yosemite National Park",
    "Grand Canyon National Park",
    "Zion National Park",
    "Grand Teton National Park",
    "Rocky Mountain National Park",
    "Acadia National Park",
    "Mount Rainier National Park",
    "Great Smoky Mountains National Park",
    "Rocky National Park",
]
# Get the response in a variable
run: RunOutput = agent.run(national_parks[random.randint(0, len(national_parks) - 1)])
pprint(run.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno pydantic rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/parser_model_ollama.py
      ```

      ```bash Windows  
      python cookbook/agents/input_and_output/parser_model_ollama.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent with Parser Model
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/parser_model_stream



This example demonstrates how to use a parser model with streaming output, combining Claude for parsing and OpenAI for generation.

## Code

```python cookbook/agents/input_and_output/parser_model_stream.py
import random
from typing import Iterator, List

from agno.agent import Agent, RunOutputEvent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class NationalParkAdventure(BaseModel):
    park_name: str = Field(..., description="Name of the national park")
    best_season: str = Field(
        ...,
        description="Optimal time of year to visit this park (e.g., 'Late spring to early fall')",
    )
    signature_attractions: List[str] = Field(
        ...,
        description="Must-see landmarks, viewpoints, or natural features in the park",
    )
    recommended_trails: List[str] = Field(
        ...,
        description="Top hiking trails with difficulty levels (e.g., 'Angel's Landing - Strenuous')",
    )
    wildlife_encounters: List[str] = Field(
        ..., description="Animals visitors are likely to spot, with viewing tips"
    )
    photography_spots: List[str] = Field(
        ...,
        description="Best locations for capturing stunning photos, including sunrise/sunset spots",
    )
    camping_options: List[str] = Field(
        ..., description="Available camping areas, from primitive to RV-friendly sites"
    )
    safety_warnings: List[str] = Field(
        ..., description="Important safety considerations specific to this park"
    )
    hidden_gems: List[str] = Field(
        ..., description="Lesser-known spots or experiences that most visitors miss"
    )
    difficulty_rating: int = Field(
        ...,
        ge=1,
        le=5,
        description="Overall park difficulty for average visitor (1=easy, 5=very challenging)",
    )
    estimated_days: int = Field(
        ...,
        ge=1,
        le=14,
        description="Recommended number of days to properly explore the park",
    )
    special_permits_needed: List[str] = Field(
        default=[],
        description="Any special permits or reservations required for certain activities",
    )


agent = Agent(
    parser_model=Claude(id="claude-sonnet-4-20250514"),
    description="You help people plan amazing national park adventures and provide detailed park guides.",
    output_schema=NationalParkAdventure,
    model=OpenAIChat(id="gpt-5-mini"),
)

# Get the response in a variable
national_parks = [
    "Yellowstone National Park",
    "Yosemite National Park",
    "Grand Canyon National Park",
    "Zion National Park",
    "Grand Teton National Park",
    "Rocky Mountain National Park",
    "Acadia National Park",
    "Mount Rainier National Park",
    "Great Smoky Mountains National Park",
    "Rocky National Park",
]

# Get the response in a variable
run_events: Iterator[RunOutputEvent] = agent.run(
    national_parks[random.randint(0, len(national_parks) - 1)], stream=True
)
for event in run_events:
    pprint(event)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno pydantic rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/parser_model_stream.py
      ```

      ```bash Windows  
      python cookbook/agents/input_and_output/parser_model_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Capturing Agent Response as Variable
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/response_as_variable



This example demonstrates how to capture and work with agent responses as variables, enabling programmatic access to response data and metadata.

## Code

```python cookbook/agents/input_and_output/response_as_variable.py
from typing import Iterator  # noqa
from rich.pretty import pprint
from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        DuckDuckGoTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        )
    ],
    instructions=["Use tables where possible"],
    markdown=True,
)

run_response: RunOutput = agent.run("What is the stock price of NVDA")
pprint(run_response)

# run_response_strem: Iterator[RunOutputEvent] = agent.run("What is the stock price of NVDA", stream=True)
# for response in run_response_strem:
#     pprint(response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/response_as_variable.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/response_as_variable.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Input with Pydantic Models
Source: https://docs.agno.com/examples/concepts/agent/input_and_output/structured_input



This example demonstrates how to use structured Pydantic models as input to agents, enabling type-safe and validated input parameters for complex research tasks.

## Code

```python cookbook/agents/input_and_output/structured_input.py
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel, Field


class ResearchTopic(BaseModel):
    """Structured research topic with specific requirements"""

    topic: str
    focus_areas: List[str] = Field(description="Specific areas to focus on")
    target_audience: str = Field(description="Who this research is for")
    sources_required: int = Field(description="Number of sources needed", default=5)


# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)

hackernews_agent.print_response(
    input=ResearchTopic(
        topic="AI",
        focus_areas=["AI", "Machine Learning"],
        target_audience="Developers",
        sources_required=5,
    )
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai pydantic
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/input_and_output/structured_input.py
      ```

      ```bash Windows
      python cookbook/agents/input_and_output/structured_input.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Same Run Image Analysis
Source: https://docs.agno.com/examples/concepts/agent/multimodal/agent_same_run_image_analysis



This example demonstrates how to create an agent that generates an image using DALL-E and then analyzes the generated image in the same run, providing insights about the image's contents.

## Code

```python cookbook/agents/multimodal/agent_same_run_image_analysis.py
from agno.agent import Agent
from agno.tools.dalle import DalleTools

# Create an Agent with the DALL-E tool
agent = Agent(tools=[DalleTools()], name="DALL-E Image Generator")

response = agent.run(
    "Generate an image of a dog and tell what color the dog is.",
    markdown=True,
    debug_mode=True,
)

if response.images:
    print("Agent Response", response.content)
    print(response.images[0].url)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/agent_same_run_image_analysis.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/agent_same_run_image_analysis.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Using Multimodal Tool Response in Runs
Source: https://docs.agno.com/examples/concepts/agent/multimodal/agent_using_multimodal_tool_response_in_runs



This example demonstrates how to create an agent that uses DALL-E to generate images and maintains conversation history across multiple runs, allowing the agent to remember previous interactions and images generated.

## Code

```python examples/concepts/agent/agents/multimodal/agent_using_multimodal_tool_response_in_runs.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.tools.dalle import DalleTools

# Create an Agent with the DALL-E tool
agent = Agent(
    tools=[DalleTools()],
    name="DALL-E Image Generator",
    add_history_to_context=True,
    db=SqliteDb(db_file="tmp/test.db"),
)

agent.print_response(
    "Generate an image of a Siamese white furry cat sitting on a couch?",
    markdown=True,
)

agent.print_response(
    "Which type of animal and the breed are we talking about?", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/agent/agents/multimodal/agent_using_multimodal_tool_response_in_runs.py
      ```

      ```bash Windows
      python examples/concepts/agent/agents/multimodal/agent_using_multimodal_tool_response_in_runs.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input Output
Source: https://docs.agno.com/examples/concepts/agent/multimodal/audio_input_output



This example demonstrates how to create an agent that can process audio input and generate audio output using OpenAI's GPT-4o audio preview model. The agent analyzes an audio recording and responds with both text and audio.

## Code

```python examples/concepts/agent/agents/multimodal/audio_input_output.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from rich.pretty import pprint

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
    markdown=True,
)

run_response = agent.run(
    "What's in these recording?",
    audio=[Audio(content=wav_data, format="wav")],
)

if run_response.response_audio is not None:
    pprint(run_response.content)
    write_audio_to_file(
        audio=run_response.response_audio.content, filename="tmp/result.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno requests
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/agent/agents/multimodal/audio_input_output.py
      ```

      ```bash Windows
      python examples/concepts/agent/agents/multimodal/audio_input_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Multi Turn
Source: https://docs.agno.com/examples/concepts/agent/multimodal/audio_multi_turn



This example demonstrates how to create an agent that can handle multi-turn audio conversations, maintaining context between audio interactions while generating both text and audio responses.

## Code

```python examples/concepts/agent/agents/multimodal/audio_multi_turn.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from rich.pretty import pprint

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
    add_history_to_context=True,
    db=SqliteDb(
        session_table="audio_multi_turn_sessions", db_file="tmp/audio_multi_turn.db"
    ),
)

run_response = agent.run("Is a golden retriever a good family dog?")
pprint(run_response.content)
if run_response.response_audio is not None:
    write_audio_to_file(
        audio=run_response.response_audio.content, filename="tmp/answer_1.wav"
    )

run_response = agent.run("What breed are we talking about?")
pprint(run_response.content)
if run_response.response_audio is not None:
    write_audio_to_file(
        audio=run_response.response_audio.content, filename="tmp/answer_2.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/agent/agents/multimodal/audio_multi_turn.py
      ```

      ```bash Windows
      python examples/concepts/agent/agents/multimodal/audio_multi_turn.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Sentiment Analysis
Source: https://docs.agno.com/examples/concepts/agent/multimodal/audio_sentiment_analysis



This example demonstrates how to perform sentiment analysis on audio conversations using Agno agents with multimodal capabilities.

```python
import requests
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.media import Audio
from agno.models.google import Gemini

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    add_history_to_context=True,
    markdown=True,
    db=SqliteDb(
        session_table="audio_sentiment_analysis_sessions",
        db_file="tmp/audio_sentiment_analysis.db",
    ),
)

url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

response = requests.get(url)
audio_content = response.content

# Give a sentiment analysis of this audio conversation. Use speaker A, speaker B to identify speakers.
agent.print_response(
    "Give a sentiment analysis of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)

agent.print_response(
    "What else can you tell me about this audio conversation?",
    stream=True,
)
```

## Key Features

* **Audio Processing**: Downloads and processes audio files from remote URLs
* **Sentiment Analysis**: Analyzes emotional tone and sentiment in conversations
* **Speaker Identification**: Distinguishes between different speakers in the conversation
* **Persistent Sessions**: Maintains conversation history using SQLite database
* **Streaming Response**: Real-time response generation for better user experience

## Use Cases

* Customer service call analysis
* Meeting sentiment tracking
* Interview evaluation
* Call center quality monitoring


# Audio Streaming
Source: https://docs.agno.com/examples/concepts/agent/multimodal/audio_streaming



This example demonstrates how to use Agno agents to generate streaming audio responses using OpenAI's GPT-4o audio preview model.

```python
import base64
import wave
from typing import Iterator

from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat

# Audio Configuration
SAMPLE_RATE = 24000  # Hz (24kHz)
CHANNELS = 1  # Mono (Change to 2 if Stereo)
SAMPLE_WIDTH = 2  # Bytes (16 bits)

# Provide the agent with the audio file and audio configuration and get result as text + audio
agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={
            "voice": "alloy",
            "format": "pcm16",
        },  # Only pcm16 is supported with streaming
    ),
)
output_stream: Iterator[RunOutputEvent] = agent.run(
    "Tell me a 10 second story", stream=True
)

filename = "tmp/response_stream.wav"

# Open the file once in append-binary mode
with wave.open(str(filename), "wb") as wav_file:
    wav_file.setnchannels(CHANNELS)
    wav_file.setsampwidth(SAMPLE_WIDTH)
    wav_file.setframerate(SAMPLE_RATE)

    # Iterate over generated audio
    for response in output_stream:
        response_audio = response.response_audio  # type: ignore
        if response_audio:
            if response_audio.transcript:
                print(response_audio.transcript, end="", flush=True)
            if response_audio.content:
                try:
                    pcm_bytes = base64.b64decode(response_audio.content)
                    wav_file.writeframes(pcm_bytes)
                except Exception as e:
                    print(f"Error decoding audio: {e}")
print()
```

## Key Features

* **Real-time Audio Streaming**: Streams audio responses in real-time using OpenAI's audio preview model
* **PCM16 Audio Format**: Uses high-quality PCM16 format for audio streaming
* **Transcript Generation**: Provides simultaneous text transcription of generated audio
* **WAV File Creation**: Saves streamed audio directly to a WAV file format
* **Error Handling**: Includes robust error handling for audio decoding

## Use Cases

* Interactive voice assistants
* Real-time storytelling applications
* Audio content generation
* Voice-enabled chatbots
* Dynamic audio responses for applications

## Technical Details

The example configures audio streaming with 24kHz sample rate, mono channel, and 16-bit sample width. The streaming approach allows for real-time audio playback while maintaining high audio quality through the PCM16 format.


# Audio to Text Transcription
Source: https://docs.agno.com/examples/concepts/agent/multimodal/audio_to_text



This example demonstrates how to create an agent that can transcribe audio conversations, identifying different speakers and providing accurate transcriptions.

## Code

```python cookbook/agents/multimodal/audio_to_text.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"

response = requests.get(url)
audio_content = response.content

# Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.

agent.print_response(
    "Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno google-generativeai requests
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/audio_to_text.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/audio_to_text.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# File Input for Tools
Source: https://docs.agno.com/examples/concepts/agent/multimodal/file_input_for_tool



This example demonstrates how tools can access and process files (PDFs, documents, etc.) passed to the agent. It shows uploading a PDF file, processing it with a custom tool, and having the LLM respond based on the extracted content.

## Code

```python cookbook/agents/multimodal/file_input_for_tool.py
"""
Example showing how tools can access media (images, videos, audio, files) passed to the agent.

This demonstrates:
1. Uploading a PDF file to an agent
2. A tool that can access and process the uploaded file (OCR simulation)
3. The LLM responding based on the tool's processing result
"""

from typing import Optional, Sequence

from agno.agent import Agent
from agno.media import File
from agno.models.google import Gemini
from agno.tools import Toolkit


class DocumentProcessingTools(Toolkit):
    def __init__(self):
        tools = [
            self.extract_text_from_pdf,
        ]

        super().__init__(name="document_processing_tools", tools=tools)

    def extract_text_from_pdf(self, files: Optional[Sequence[File]] = None) -> str:
        """
        Extract text from uploaded PDF files using OCR.

        This tool can access any files that were passed to the agent.
        In a real implementation, you would use a proper OCR service.

        Args:
            files: Files passed to the agent (automatically injected)

        Returns:
            Extracted text from the PDF files
        """
        if not files:
            return "No files were uploaded to process."

        print(f"--> Files: {files}")

        extracted_texts = []
        for i, file in enumerate(files):
            if file.content:
                # Simulate OCR processing
                # In reality, you'd use a service like Tesseract, AWS Textract, etc.
                file_size = len(file.content)
                extracted_text = f"""
                    [SIMULATED OCR RESULT FOR FILE {i + 1}]
                    Document processed successfully!
                    File size: {file_size} bytes

                    Sample extracted content:
                    "This is a sample document with important information about quarterly sales figures.
                    Q1 Revenue: $125,000
                    Q2 Revenue: $150,000
                    Q3 Revenue: $175,000

                    The growth trend shows a 20% increase quarter over quarter."
                """
                extracted_texts.append(extracted_text)
            else:
                extracted_texts.append(
                    f"File {i + 1}: Content is empty or inaccessible."
                )

        return "\n\n".join(extracted_texts)


def create_sample_pdf_content() -> bytes:
    """Create a sample PDF-like content for demonstration."""
    # This is just sample binary content - in reality you'd have actual PDF bytes
    sample_content = """
    %PDF-1.4
    Sample PDF content for demonstration
    This would be actual PDF binary data in a real scenario
    """.encode("utf-8")
    return sample_content


def main():
    # Create an agent with document processing tools
    agent = Agent(
        model=Gemini(id="gemini-2.5-pro"),
        tools=[DocumentProcessingTools()],
        name="Document Processing Agent",
        description="An agent that can process uploaded documents. Use the tool to extract text from the PDF.",
        debug_mode=True,
        send_media_to_model=False,
        store_media=True,
    )

    print("=== Tool Media Access Example ===\n")

    # Example 1: PDF Processing
    print("1. Testing PDF processing...")

    # Create sample file content
    pdf_content = create_sample_pdf_content()
    sample_file = File(content=pdf_content)

    response = agent.run(
        input="I've uploaded a PDF document. Please extract the text from it and summarize the key financial information.",
        files=[sample_file],
        session_id="test_files",
    )

    print(f"Agent Response: {response.content}")
    print("\n" + "=" * 50 + "\n")


if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    # or for OpenAI
    # export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno google-generativeai
    # or for OpenAI
    # pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/file_input_for_tool.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/file_input_for_tool.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Image with Intermediate Steps
Source: https://docs.agno.com/examples/concepts/agent/multimodal/generate_image_with_intermediate_steps



This example demonstrates how to create an agent that generates images using DALL-E while streaming intermediate steps and events during the image creation process.

## Code

```python cookbook/agents/multimodal/generate_image_with_intermediate_steps.py
from typing import Iterator

from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools
from agno.utils.common import dataclass_to_dict
from rich.pretty import pprint

image_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DalleTools()],
    description="You are an AI agent that can create images using DALL-E.",
    instructions=[
        "When the user asks you to create an image, use the DALL-E tool to create an image.",
        "The DALL-E tool will return an image URL.",
        "Return the image URL in your response in the following format: `![image description](image URL)`",
    ],
    markdown=True,
)

run_stream: Iterator[RunOutputEvent] = image_agent.run(
    "Create an image of a yellow siamese cat",
    stream=True,
    stream_intermediate_steps=True,
)
for chunk in run_stream:
    pprint(dataclass_to_dict(chunk, exclude={"messages"}))
    print("---" * 20)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/generate_image_with_intermediate_steps.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/generate_image_with_intermediate_steps.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Video Using ModelsLab
Source: https://docs.agno.com/examples/concepts/agent/multimodal/generate_video_using_models_lab



This example demonstrates how to create an AI agent that generates videos using the ModelsLab API.

## Code

```python cookbook/agents/multimodal/generate_video_using_models_lab.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models_labs import ModelsLabTools

video_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ModelsLabTools()],
    description="You are an AI agent that can generate videos using the ModelsLabs API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "The video will be displayed in the UI automatically below your response, so you don't need to show the video URL in your response.",
        "Politely and courteously let the user know that the video has been generated and will be displayed below as soon as its ready.",
    ],
    markdown=True,
)

video_agent.print_response("Generate a video of a cat playing with a ball")
# print(video_agent.run_response.videos)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/generate_video_using_models_lab.py
      ```

      ```bash Windows  
      python cookbook/agents/multimodal/generate_video_using_models_lab.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Video Using Replicate
Source: https://docs.agno.com/examples/concepts/agent/multimodal/generate_video_using_replicate



This example demonstrates how to create an AI agent that generates videos using the Replicate API with the HunyuanVideo model.

## Code

```python cookbook/agents/multimodal/generate_video_using_replicate.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.replicate import ReplicateTools

"""Create an agent specialized for Replicate AI content generation"""

video_agent = Agent(
    name="Video Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ReplicateTools(
            model="tencent/hunyuan-video:847dfa8b01e739637fc76f480ede0c1d76408e1d694b830b5dfb8e547bf98405"
        )
    ],
    description="You are an AI agent that can generate videos using the Replicate API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
)

video_agent.print_response("Generate a video of a horse in the dessert.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/generate_video_using_replicate.py
      ```

      ```bash Windows  
      python cookbook/agents/multimodal/generate_video_using_replicate.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Input for Tools
Source: https://docs.agno.com/examples/concepts/agent/multimodal/image_input_for_tool



This example demonstrates how tools can receive and process images automatically through Agno's joint media access functionality. It shows initial image upload and analysis, DALL-E image generation within the same run, and cross-run media persistence.

## Code

```python cookbook/agents/multimodal/image_input_for_tool.py
from typing import Optional, Sequence

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools


def analyze_images(images: Optional[Sequence[Image]] = None) -> str:
    """
    Analyze all available images and provide detailed descriptions.

    Args:
        images: Images available to the tool (automatically injected)

    Returns:
        Analysis of all available images
    """
    if not images:
        return "No images available to analyze."

    print(f"--> analyze_images received {len(images)} images")

    analysis_results = []
    for i, image in enumerate(images):
        if image.url:
            analysis_results.append(
                f"Image {i + 1}: URL-based image at {image.url}"
            )
        elif image.content:
            analysis_results.append(
                f"Image {i + 1}: Content-based image ({len(image.content)} bytes)"
            )
        else:
            analysis_results.append(f"Image {i + 1}: Unknown image format")

    return f"Found {len(images)} images:\n" + "\n".join(analysis_results)


def count_images(images: Optional[Sequence[Image]] = None) -> str:
    """
    Count the number of available images.

    Args:
        images: Images available to the tool (automatically injected)

    Returns:
        Count of available images
    """
    if not images:
        return "0 images available"

    print(f"--> count_images received {len(images)} images")
    return f"{len(images)} images available"


def create_sample_image_content() -> bytes:
    """Create a simple image-like content for demonstration."""
    return b"FAKE_IMAGE_CONTENT_FOR_DEMO"


def main():
    # Create an agent with both DALL-E and image analysis functions
    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        tools=[DalleTools(), analyze_images, count_images],
        name="Joint Media Test Agent",
        description="An agent that can generate and analyze images using joint media access.",
        debug_mode=True,
        add_history_to_context=True,
        send_media_to_model=False,
        db=PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"),
    )

    print("=== Joint Media Access Test ===\n")

    # Test 1: Initial image upload and analysis
    print("1. Testing initial image upload and analysis...")

    sample_image = Image(id="test_image_1", content=create_sample_image_content())

    response1 = agent.run(
        input="I've uploaded an image. Please count how many images are available and analyze them.",
        images=[sample_image],
    )

    print(f"Run 1 Response: {response1.content}")
    print(f"--> Run 1 Images in response: {len(response1.input.images or [])}")
    print("\n" + "=" * 50 + "\n")

    # Test 2: DALL-E generation + analysis in same run
    print("2. Testing DALL-E generation and immediate analysis...")

    response2 = agent.run(input="Generate an image of a cute cat.")

    print(f"Run 2 Response: {response2.content}")
    print(f"--> Run 2 Images in response: {len(response2.images or [])}")
    print("\n" + "=" * 50 + "\n")

    # Test 3: Cross-run media persistence
    print("3. Testing cross-run media persistence...")

    response3 = agent.run(
        input="Count how many images are available from all previous runs and analyze them."
    )

    print(f"Run 3 Response: {response3.content}")
    print("\n" + "=" * 50 + "\n")


if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set up PostgreSQL">
    ```bash
    # Start PostgreSQL with Docker
    docker run -d \
      --name postgres-ai \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -p 5532:5432 \
      postgres:16
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/image_input_for_tool.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/image_input_for_tool.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# High Fidelity Image Input
Source: https://docs.agno.com/examples/concepts/agent/multimodal/image_input_high_fidelity



This example demonstrates how to use high fidelity image analysis with an AI agent by setting the detail parameter.

## Code

```python cookbook/agents/multimodal/image_input_high_fidelity.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
)

agent.print_response(
    "What's in these images",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
            detail="high",
        )
    ],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/image_input_high_fidelity.py
      ```

      ```bash Windows  
      python cookbook/agents/multimodal/image_input_high_fidelity.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Audio Story Generation
Source: https://docs.agno.com/examples/concepts/agent/multimodal/image_to_audio



This example demonstrates how to analyze an image to create a story and then convert that story to audio narration.

## Code

```python cookbook/agents/multimodal/image_to_audio.py
from pathlib import Path

from agno.agent import Agent, RunOutput
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from rich import print
from rich.text import Text

cwd = Path(__file__).parent.resolve()

image_agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

image_path = Path(__file__).parent.joinpath("sample.jpg")
image_story: RunOutput = image_agent.run(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
formatted_text = Text.from_markup(
    f":sparkles: [bold magenta]Story:[/bold magenta] {image_story.content} :sparkles:"
)
print(formatted_text)

audio_agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
)

audio_story: RunOutput = audio_agent.run(
    f"Narrate the story with flair: {image_story.content}"
)
if audio_story.response_audio is not None:
    write_audio_to_file(
        audio=audio_story.response_audio.content, filename="tmp/sample_story.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/image_to_audio.py
      ```

      ```bash Windows  
      python cookbook/agents/multimodal/image_to_audio.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Image Generation Agent
Source: https://docs.agno.com/examples/concepts/agent/multimodal/image_to_image_agent



This example demonstrates how to create an AI agent that generates images from existing images using the Fal AI API.

## Code

```python cookbook/agents/multimodal/image_to_image_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    id="image-to-image",
    name="Image to Image Agent",
    tools=[FalTools()],
    markdown=True,
    instructions=[
        "You have to use the `image_to_image` tool to generate the image.",
        "You are an AI agent that can generate images using the Fal AI API.",
        "You will be given a prompt and an image URL.",
        "You have to return the image URL as provided, don't convert it to markdown or anything else.",
    ],
)

agent.print_response(
    "a cat dressed as a wizard with a background of a mystic forest. Make it look like 'https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png'",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/image_to_image_agent.py
      ```

      ```bash Windows  
      python cookbook/agents/multimodal/image_to_image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Structured Output
Source: https://docs.agno.com/examples/concepts/agent/multimodal/image_to_structured_output



This example demonstrates how to analyze images and generate structured output using Pydantic models, creating movie scripts based on image content.

## Code

```python cookbook/agents/multimodal/image_to_structured_output.py
from typing import List

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(model=OpenAIChat(id="gpt-5-mini"), output_schema=MovieScript)

response = agent.run(
    "Write a movie about this image",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

for event in response:
    pprint(event.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai pydantic rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/image_to_structured_output.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/image_to_structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Text Analysis
Source: https://docs.agno.com/examples/concepts/agent/multimodal/image_to_text



This example demonstrates how to create an agent that can analyze images and generate creative text content based on the visual content.

## Code

```python cookbook/agents/multimodal/image_to_text.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")
agent.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/image_to_text.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/image_to_text.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Caption Generator Agent
Source: https://docs.agno.com/examples/concepts/agent/multimodal/video_caption_agent



This example demonstrates how to create an agent that can process videos to generate and embed captions using MoviePy and OpenAI tools.

## Code

```python cookbook/agents/multimodal/video_caption_agent.py
"""Please install dependencies using:
pip install openai moviepy ffmpeg
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.moviepy_video import MoviePyVideoTools
from agno.tools.openai import OpenAITools

video_tools = MoviePyVideoTools(
    process_video=True, generate_captions=True, embed_captions=True
)

openai_tools = OpenAITools()

video_caption_agent = Agent(
    name="Video Caption Generator Agent",
    model=OpenAIChat(
        id="gpt-5-mini",
    ),
    tools=[video_tools, openai_tools],
    description="You are an AI agent that can generate and embed captions for videos.",
    instructions=[
        "When a user provides a video, process it to generate captions.",
        "Use the video processing tools in this sequence:",
        "1. Extract audio from the video using extract_audio",
        "2. Transcribe the audio using transcribe_audio",
        "3. Generate SRT captions using create_srt",
        "4. Embed captions into the video using embed_captions",
    ],
    markdown=True,
)


video_caption_agent.print_response(
    "Generate captions for {video with location} and embed them in the video"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai moviepy ffmpeg
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/video_caption_agent.py
      ```

      ```bash Windows
      python cookbook/agents/multimodal/video_caption_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video to Shorts Generation
Source: https://docs.agno.com/examples/concepts/agent/multimodal/video_to_shorts



This example demonstrates how to analyze a video and automatically generate short-form content segments optimized for platforms like YouTube Shorts and Instagram Reels.

## Code

```python cookbook/agents/multimodal/video_to_shorts.py
"""
1. Install dependencies using: `pip install opencv-python google-geneai sqlalchemy`
2. Install ffmpeg `brew install ffmpeg`
2. Run the script using: `python cookbook/agent_concepts/video_to_shorts.py`
"""

import subprocess
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini
from agno.utils.log import logger

video_path = Path(__file__).parent.joinpath("sample_video.mp4")
output_dir = Path("tmp/shorts")

agent = Agent(
    name="Video2Shorts",
    description="Process videos and generate engaging shorts.",
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
    instructions=[
        "Analyze the provided video directly‚Äîdo NOT reference or analyze any external sources or YouTube videos.",
        "Identify engaging moments that meet the specified criteria for short-form content.",
        """Provide your analysis in a **table format** with these columns:
   - Start Time | End Time | Description | Importance Score""",
        "Ensure all timestamps use MM:SS format and importance scores range from 1-10. ",
        "Focus only on segments between 15 and 60 seconds long.",
        "Base your analysis solely on the provided video content.",
        "Deliver actionable insights to improve the identified segments for short-form optimization.",
    ],
)

# 2. Multimodal Query for Video Analysis
query = """

You are an expert in video content creation, specializing in crafting engaging short-form content for platforms like YouTube Shorts and Instagram Reels. Your task is to analyze the provided video and identify segments that maximize viewer engagement.

For each video, you'll:

1. Identify key moments that will capture viewers' attention, focusing on:
   - High-energy sequences
   - Emotional peaks
   - Surprising or unexpected moments
   - Strong visual and audio elements
   - Clear narrative segments with compelling storytelling

2. Extract segments that work best for short-form content, considering:
   - Optimal length (strictly 15‚Äì60 seconds)
   - Natural start and end points that ensure smooth transitions
   - Engaging pacing that maintains viewer attention
   - Audio-visual harmony for an immersive experience
   - Vertical format compatibility and adjustments if necessary

3. Provide a detailed analysis of each segment, including:
   - Precise timestamps (Start Time | End Time in MM:SS format)
   - A clear description of why the segment would be engaging
   - Suggestions on how to enhance the segment for short-form content
   - An importance score (1-10) based on engagement potential

Your goal is to identify moments that are visually compelling, emotionally engaging, and perfectly optimized for short-form platforms.
"""

# 3. Generate Video Analysis
response = agent.run(query, videos=[Video(filepath=video_path)])

# 4. Create output directory
output_dir = Path(output_dir)
output_dir.mkdir(parents=True, exist_ok=True)


# 5. Extract and cut video segments - Optional
def extract_segments(response_text):
    import re

    segments_pattern = r"\|\s*(\d+:\d+)\s*\|\s*(\d+:\d+)\s*\|\s*(.*?)\s*\|\s*(\d+)\s*\|"
    segments: list[dict] = []

    for match in re.finditer(segments_pattern, str(response_text)):
        start_time = match.group(1)
        end_time = match.group(2)
        description = match.group(3)
        score = int(match.group(4))

        # Convert timestamps to seconds
        start_seconds = sum(x * int(t) for x, t in zip([60, 1], start_time.split(":")))
        end_seconds = sum(x * int(t) for x, t in zip([60, 1], end_time.split(":")))
        duration = end_seconds - start_seconds

        # Only process high-scoring segments
        if 15 <= duration <= 60 and score > 7:
            output_path = output_dir / f"short_{len(segments) + 1}.mp4"

            # FFmpeg command to cut video
            command = [
                "ffmpeg",
                "-ss",
                str(start_seconds),
                "-i",
                video_path,
                "-t",
                str(duration),
                "-vf",
                "scale=1080:1920,setsar=1:1",
                "-c:v",
                "libx264",
                "-c:a",
                "aac",
                "-y",
                str(output_path),
            ]

            try:
                subprocess.run(command, check=True)
                segments.append(
                    {"path": output_path, "description": description, "score": score}
                )
            except subprocess.CalledProcessError:
                print(f"Failed to process segment: {start_time} - {end_time}")

    return segments


logger.debug(f"{response.content}")

# 6. Process segments
shorts = extract_segments(response.content)

# 7. Print results
print("\n--- Generated Shorts ---")
for short in shorts:
    print(f"Short at {short['path']}")
    print(f"Description: {short['description']}")
    print(f"Engagement Score: {short['score']}/10\n")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno opencv-python sqlalchemy
    ```
  </Step>

  <Step title="Install ffmpeg">
    <CodeGroup>
      ```bash Mac
      brew install ffmpeg
      ```

      ```bash Windows  
      # Install ffmpeg from https://ffmpeg.org/download.html
      ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/multimodal/video_to_shorts.py
      ```

      ```bash Windows  
      python cookbook/agents/multimodal/video_to_shorts.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Extra Metrics
Source: https://docs.agno.com/examples/concepts/agent/other/agent_extra_metrics



This example demonstrates how to collect special token metrics including audio, cached, and reasoning tokens. It shows different types of advanced metrics available when working with various OpenAI models.

## Code

```python cookbook/agents/other/agent_extra_metrics.py
"""Show special token metrics like audio, cached and reasoning tokens"""

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
    markdown=True,
)
run_response = agent.run(
    "What's in these recording?",
    audio=[Audio(content=wav_data, format="wav")],
)
pprint_run_response(run_response)
# Showing input audio, output audio and total audio tokens metrics
print(f"Input audio tokens: {run_response.metrics.audio_input_tokens}")
print(f"Output audio tokens: {run_response.metrics.audio_output_tokens}")
print(f"Audio tokens: {run_response.metrics.audio_total_tokens}")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
    telemetry=False,
)
run_response = agent.run(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. Include an ASCII diagram of your solution.",
    stream=False,
)
pprint_run_response(run_response)
# Showing reasoning tokens metrics
print(f"Reasoning tokens: {run_response.metrics.reasoning_tokens}")

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True, telemetry=False)
agent.run("Share a 2 sentence horror story" * 150)
run_response = agent.run("Share a 2 sentence horror story" * 150)
# Showing cached tokens metrics
print(f"Cached tokens: {run_response.metrics.cache_read_tokens}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai requests
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/agent_extra_metrics.py
      ```

      ```bash Windows  
      python cookbook/agents/other/agent_extra_metrics.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Metrics and Performance Monitoring
Source: https://docs.agno.com/examples/concepts/agent/other/agent_metrics



This example demonstrates how to collect and analyze agent metrics including message-level metrics, run metrics, and session metrics for performance monitoring.

## Code

```python cookbook/agents/other/agent_metrics.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils import pprint

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(stock_price=True)],
    markdown=True,
    session_id="test-session-metrics",
    db=PostgresDb(db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"),
)

# Get the run response directly from the non-streaming call
run_response = agent.run("What is the stock price of NVDA")
print("Tool execution completed successfully!")

# Print metrics per message
if run_response and run_response.messages:
    for message in run_response.messages:
        if message.role == "assistant":
            if message.content:
                print(
                    f"Message: {message.content[:100]}..."
                )  # Truncate for readability
            elif message.tool_calls:
                print(f"Tool calls: {len(message.tool_calls)} tool call(s)")
            print("---" * 5, "Message Metrics", "---" * 5)
            if message.metrics:
                pprint(message.metrics)
            else:
                print("No metrics available for this message")
            print("---" * 20)

# Print the run metrics
print("---" * 5, "Run Metrics", "---" * 5)
if run_response and run_response.metrics:
    pprint(run_response.metrics)
else:
    print("No run metrics available")

# Print the session metrics
print("---" * 5, "Session Metrics", "---" * 5)
try:
    session_metrics = agent.get_session_metrics()
    if session_metrics:
        pprint(session_metrics)
    else:
        print("No session metrics available")
except Exception as e:
    print(f"Error getting session metrics: {e}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/agent_metrics.py
      ```

      ```bash Windows
      python cookbook/agents/other/agent_metrics.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Run Metadata
Source: https://docs.agno.com/examples/concepts/agent/other/agent_run_metadata



This example demonstrates how to attach custom metadata to agent runs. This is useful for tracking business context, request types, and operational information for monitoring and analytics.

## Code

```python cookbook/agents/other/agent_run_metadata.py
from datetime import datetime

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are a customer support agent. You help process customer inquiries efficiently.",
    markdown=True,
)

response = agent.run(
    "A customer is reporting that their premium subscription features are not working. They need urgent help as they have a presentation in 2 hours.",
    metadata={
        "ticket_id": "SUP-2024-001234",
        "priority": "high",
        "request_type": "customer_support",
        "sla_deadline": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
        "escalation_level": 2,
        "customer_tier": "enterprise",
        "department": "customer_success",
        "agent_id": "support_agent_v1",
        "business_impact": "revenue_critical",
        "estimated_resolution_time_minutes": 30,
    },
    debug_mode=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/agent_run_metadata.py
      ```

      ```bash Windows  
      python cookbook\agents\other\agent_run_metadata.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cancel Agent Run
Source: https://docs.agno.com/examples/concepts/agent/other/cancel_a_run



This example demonstrates how to cancel a running agent execution using multi-threading, showing how to start a long-running task and cancel it from another thread.

## Code

```python cookbook/agents/other/cancel_a_run.py
"""
Example demonstrating how to cancel a running agent execution.

This example shows how to:
1. Start an agent run in a separate thread
2. Cancel the run from another thread
3. Handle the cancelled response
"""

import threading
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent
from agno.run.base import RunStatus


def long_running_task(agent: Agent, run_id_container: dict):
    """
    Simulate a long-running agent task that can be cancelled.

    Args:
        agent: The agent to run
        run_id_container: Dictionary to store the run_id for cancellation

    Returns:
        Dictionary with run results and status
    """
    try:
        # Start the agent run - this simulates a long task
        final_response = None
        content_pieces = []

        for chunk in agent.run(
            "Write a very long story about a dragon who learns to code. "
            "Make it at least 2000 words with detailed descriptions and dialogue. "
            "Take your time and be very thorough.",
            stream=True,
        ):
            if "run_id" not in run_id_container and chunk.run_id:
                run_id_container["run_id"] = chunk.run_id

            if chunk.event == RunEvent.run_content:
                print(chunk.content, end="", flush=True)
                content_pieces.append(chunk.content)
            # When the run is cancelled, a `RunEvent.run_cancelled` event is emitted
            elif chunk.event == RunEvent.run_cancelled:
                print(f"\nüö´ Run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif hasattr(chunk, "status") and chunk.status == RunStatus.completed:
                final_response = chunk

        # If we get here, the run completed successfully
        if final_response:
            run_id_container["result"] = {
                "status": final_response.status.value
                if final_response.status
                else "completed",
                "run_id": final_response.run_id,
                "cancelled": final_response.status == RunStatus.cancelled,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }
        else:
            run_id_container["result"] = {
                "status": "unknown",
                "run_id": run_id_container.get("run_id"),
                "cancelled": False,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }

    except Exception as e:
        print(f"\n‚ùå Exception in run: {str(e)}")
        run_id_container["result"] = {
            "status": "error",
            "error": str(e),
            "run_id": run_id_container.get("run_id"),
            "cancelled": True,
            "content": "Error occurred",
        }


def cancel_after_delay(agent: Agent, run_id_container: dict, delay_seconds: int = 3):
    """
    Cancel the agent run after a specified delay.

    Args:
        agent: The agent whose run should be cancelled
        run_id_container: Dictionary containing the run_id to cancel
        delay_seconds: How long to wait before cancelling
    """
    print(f"‚è∞ Will cancel run in {delay_seconds} seconds...")
    time.sleep(delay_seconds)

    run_id = run_id_container.get("run_id")
    if run_id:
        print(f"üö´ Cancelling run: {run_id}")
        success = agent.cancel_run(run_id)
        if success:
            print(f"‚úÖ Run {run_id} marked for cancellation")
        else:
            print(
                f"‚ùå Failed to cancel run {run_id} (may not exist or already completed)"
            )
    else:
        print("‚ö†Ô∏è  No run_id found to cancel")


def main():
    """Main function demonstrating run cancellation."""

    # Initialize the agent with a model
    agent = Agent(
        name="StorytellerAgent",
        model=OpenAIChat(id="gpt-5-mini"),  # Use a model that can generate long responses
        description="An agent that writes detailed stories",
    )

    print("üöÄ Starting agent run cancellation example...")
    print("=" * 50)

    # Container to share run_id between threads
    run_id_container = {}

    # Start the agent run in a separate thread
    agent_thread = threading.Thread(
        target=lambda: long_running_task(agent, run_id_container), name="AgentRunThread"
    )

    # Start the cancellation thread
    cancel_thread = threading.Thread(
        target=cancel_after_delay,
        args=(agent, run_id_container, 8),  # Cancel after 5 seconds
        name="CancelThread",
    )

    # Start both threads
    print("üèÉ Starting agent run thread...")
    agent_thread.start()

    print("üèÉ Starting cancellation thread...")
    cancel_thread.start()

    # Wait for both threads to complete
    print("‚åõ Waiting for threads to complete...")
    agent_thread.join()
    cancel_thread.join()

    # Print the results
    print("\n" + "=" * 50)
    print("üìä RESULTS:")
    print("=" * 50)

    result = run_id_container.get("result")
    if result:
        print(f"Status: {result['status']}")
        print(f"Run ID: {result['run_id']}")
        print(f"Was Cancelled: {result['cancelled']}")

        if result.get("error"):
            print(f"Error: {result['error']}")
        else:
            print(f"Content Preview: {result['content']}")

        if result["cancelled"]:
            print("\n‚úÖ SUCCESS: Run was successfully cancelled!")
        else:
            print("\n‚ö†Ô∏è  WARNING: Run completed before cancellation")
    else:
        print("‚ùå No result obtained - check if cancellation happened during streaming")

    print("\nüèÅ Example completed!")


if __name__ == "__main__":
    # Run the main example
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/cancel_a_run.py
      ```

      ```bash Windows
      python cookbook/agents/other/cancel_a_run.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Debug Mode
Source: https://docs.agno.com/examples/concepts/agent/other/debug



This example demonstrates how to enable debug mode for agents to get more verbose output and detailed information about agent execution.

## Code

```python cookbook/agents/other/debug.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# You can set the debug mode on the agent for all runs to have more verbose output
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    debug_mode=True,
)

agent.print_response(input="Tell me a joke.")


# You can also set the debug mode on a single run
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)
agent.print_response(input="Tell me a joke.", debug_mode=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/debug.py
      ```

      ```bash Windows
      python cookbook/agents/other/debug.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Debug Level
Source: https://docs.agno.com/examples/concepts/agent/other/debug_level



This example demonstrates how to set different debug levels for an agent. The debug level controls the amount of debug information displayed, helping you troubleshoot and understand agent behavior at different levels of detail.

## Code

```python cookbook/agents/other/debug_level.py
"""
This example shows how to set the debug level of an agent.

The debug level is a number between 1 and 2.

1: Basic debug information
2: Detailed debug information

The default debug level is 1.
"""

from agno.agent.agent import Agent
from agno.models.anthropic.claude import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

# Basic debug information
agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20240620"),
    tools=[DuckDuckGoTools()],
    debug_mode=True,
    debug_level=1,
)

agent.print_response("What is the current price of Tesla?")

# Verbose debug information
agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20240620"),
    tools=[DuckDuckGoTools()],
    debug_mode=True,
    debug_level=2,
)

agent.print_response("What is the current price of Apple?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/debug_level.py
      ```

      ```bash Windows  
      python cookbook/agents/other/debug_level.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Intermediate Steps Streaming
Source: https://docs.agno.com/examples/concepts/agent/other/intermediate_steps



This example demonstrates how to stream intermediate steps during agent execution, providing visibility into tool calls and execution events.

## Code

```python cookbook/agents/other/intermediate_steps.py
from typing import Iterator

from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from rich.pretty import pprint

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(stock_price=True)],
    markdown=True,
)

run_stream: Iterator[RunOutputEvent] = agent.run(
    "What is the stock price of NVDA", stream=True, stream_intermediate_steps=True
)
for chunk in run_stream:
    pprint(chunk.to_dict())
    print("---" * 20)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/intermediate_steps.py
      ```

      ```bash Windows
      python cookbook/agents/other/intermediate_steps.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Run Response Events
Source: https://docs.agno.com/examples/concepts/agent/other/run_response_events



This example demonstrates how to handle different types of events during agent run streaming. It shows how to capture and process content events, tool call started events, and tool call completed events.

## Code

```python cookbook/agents/other/run_response_events.py
from typing import Iterator, List

from agno.agent import (
    Agent,
    RunContentEvent,
    RunOutputEvent,
    ToolCallCompletedEvent,
    ToolCallStartedEvent,
)
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
run_response: Iterator[RunOutputEvent] = agent.run(
    "Whats happening in USA and Canada?", stream=True
)

response: List[str] = []
for chunk in run_response:
    if isinstance(chunk, RunContentEvent):
        response.append(chunk.content)  # type: ignore
    elif isinstance(chunk, ToolCallStartedEvent):
        response.append(
            f"Tool call started: {chunk.tool.tool_name} with args: {chunk.tool.tool_args}"  # type: ignore
        )
    elif isinstance(chunk, ToolCallCompletedEvent):
        response.append(
            f"Tool call completed: {chunk.tool.tool_name} with result: {chunk.tool.result}"  # type: ignore
        )

print("\n".join(response))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/run_response_events.py
      ```

      ```bash Windows  
      python cookbook/agents/other/run_response_events.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Scenario Testing
Source: https://docs.agno.com/examples/concepts/agent/other/scenario_testing



This example demonstrates how to use the Scenario testing library to test an agent with defined success and failure criteria. It shows how to implement automated testing for agent behavior and responses.

## Code

```python cookbook/agents/other/scenario_testing.py
"""
This is an example that uses the [scenario](https://github.com/langwatch/scenario) testing library to test an agent.

Prerequisites:
- Install scenario: `pip install scenario`
"""

import pytest
from scenario import Scenario, TestingAgent, scenario_cache

Scenario.configure(testing_agent=TestingAgent(model="openai/gpt-5-nano"))


@pytest.mark.agent_test
@pytest.mark.asyncio
async def test_vegetarian_recipe_agent():
    agent = VegetarianRecipeAgent()

    def vegetarian_recipe_agent(message, context):
        # Call your agent here
        return agent.run(message)

    # Define the scenario
    scenario = Scenario(
        "User is looking for a dinner idea",
        agent=vegetarian_recipe_agent,
        success_criteria=[
            "Recipe agent generates a vegetarian recipe",
            "Recipe includes a list of ingredients",
            "Recipe includes step-by-step cooking instructions",
        ],
        failure_criteria=[
            "The recipe is not vegetarian or includes meat",
            "The agent asks more than two follow-up questions",
        ],
    )

    # Run the scenario and get results
    result = await scenario.run()

    # Assert for pytest to know whether the test passed
    assert result.success


# Example agent implementation
from agno.agent import Agent  # noqa: E402
from agno.models.openai import OpenAIChat  # noqa: E402


class VegetarianRecipeAgent:
    def __init__(self):
        self.history = []

    @scenario_cache()
    def run(self, message: str):
        self.history.append({"role": "user", "content": message})

        agent = Agent(
            model=OpenAIChat(id="gpt-5-mini"),
            markdown=True,
            instructions="You are a vegetarian recipe agent",
        )

        response = agent.run(message)
        result = response.content
        print(result)
        self.history.append(result)

        return {"message": result}
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai scenario pytest
    ```
  </Step>

  <Step title="Run Test">
    <CodeGroup>
      ```bash Mac
      pytest cookbook/agents/other/scenario_testing.py -v
      ```

      ```bash Windows  
      pytest cookbook/agents/other/scenario_testing.py -v
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Call Limit
Source: https://docs.agno.com/examples/concepts/agent/other/tool_call_limit



This example demonstrates how to use tool call limits to control the number of tool calls an agent can make. This is useful for preventing excessive API usage or limiting agent behavior in specific scenarios.

## Code

```python cookbook/agents/other/tool_call_limit.py
"""
This cookbook shows how to use tool call limit to control the number of tool calls an agent can make.
"""

from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="claude-3-5-haiku-20241022"),
    tools=[DuckDuckGoTools(company_news=True, cache_results=True)],
    tool_call_limit=1,
)

# It should only call the first tool and fail to call the second tool.
agent.print_response(
    "Find me the current price of TSLA, then after that find me the latest news about Tesla.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno anthropic ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/other/tool_call_limit.py
      ```

      ```bash Windows  
      python cookbook/agents/other/tool_call_limit.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with LanceDB
Source: https://docs.agno.com/examples/concepts/agent/rag/agentic_rag_lancedb



This example demonstrates how to implement Agentic RAG using LanceDB vector database with OpenAI embeddings, enabling the agent to search and retrieve relevant information dynamically.

## Code

```python cookbook/agents/rag/agentic_rag_lancedb.py
"""
1. Run: `pip install openai lancedb tantivy pypdf sqlalchemy agno` to install the dependencies
2. Run: `python cookbook/rag/04_agentic_rag_lancedb.py` to run the agent
"""

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    # Use LanceDB as the vector database and store embeddings in the `recipes` table
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Add a tool to search the knowledge base which enables agentic RAG.
    # This is enabled by default when `knowledge` is provided to the Agent.
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb tantivy pypdf sqlalchemy
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/agentic_rag_lancedb.py
      ```

      ```bash Windows
      python cookbook/agents/rag/agentic_rag_lancedb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with PgVector
Source: https://docs.agno.com/examples/concepts/agent/rag/agentic_rag_pgvector



This example demonstrates how to implement Agentic RAG using PgVector (PostgreSQL with vector extensions) for storing and searching embeddings with hybrid search capabilities.

## Code

```python cookbook/agents/rag/agentic_rag_pgvector.py
"""
1. Run: `./cookbook/run_pgvector.sh` to start a postgres container with pgvector
2. Run: `pip install openai sqlalchemy 'psycopg[binary]' pgvector agno` to install the dependencies
3. Run: `python cookbook/rag/02_agentic_rag_pgvector.py` to run the agent
"""

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Add a tool to search the knowledge base which enables agentic RAG.
    # This is enabled by default when `knowledge` is provided to the Agent.
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
# agent.print_response(
#     "Hi, i want to make a 3 course meal. Can you recommend some recipes. "
#     "I'd like to start with a soup, then im thinking a thai curry for the main course and finish with a dessert",
#     stream=True,
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai sqlalchemy psycopg2-binary pgvector
    ```
  </Step>

  <Step title="Setup PgVector">
    ```bash
    # Start PostgreSQL with pgvector extension
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/agentic_rag_pgvector.py
      ```

      ```bash Windows
      python cookbook/agents/rag/agentic_rag_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Reranking
Source: https://docs.agno.com/examples/concepts/agent/rag/agentic_rag_with_reranking



This example demonstrates how to implement Agentic RAG using LanceDB with Cohere reranking for improved search results.

## Code

```python cookbook/agents/rag/agentic_rag_with_reranking.py
"""
1. Run: `pip install openai agno cohere lancedb tantivy sqlalchemy` to install the dependencies
2. Export your OPENAI_API_KEY and CO_API_KEY
3. Run: `python cookbook/agent_concepts/rag/agentic_rag_with_reranking.py` to run the agent
"""

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker.cohere import CohereReranker
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    # Use LanceDB as the vector database and store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(
            id="text-embedding-3-small"
        ),  # Use OpenAI for embeddings
        reranker=CohereReranker(
            model="rerank-multilingual-v3.0"
        ),  # Use Cohere for reranking
    ),
)

knowledge.add_content_sync(
    name="Agno Docs", url="https://docs.agno.com/introduction.md"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Agentic RAG is enabled by default when `knowledge` is provided to the Agent.
    knowledge=knowledge,
    markdown=True,
)

if __name__ == "__main__":
    # Load the knowledge base, comment after first run
    # agent.knowledge.load(recreate=True)
    agent.print_response("What are Agno's key features?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno cohere lancedb tantivy sqlalchemy
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key
    export CO_API_KEY=your_cohere_api_key
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/agentic_rag_with_reranking.py
      ```

      ```bash Windows  
      python cookbook/agents/rag/agentic_rag_with_reranking.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# RAG with Sentence Transformer Reranker
Source: https://docs.agno.com/examples/concepts/agent/rag/rag_sentence_transformer



This example demonstrates Agentic RAG using Sentence Transformer Reranker with multilingual data for improved search relevance.

## Code

```python cookbook/agents/rag/rag_sentence_transformer.py
"""This cookbook is an implementation of Agentic RAG using Sentence Transformer Reranker with multilingual data.

## Setup Instructions:

### 1. Install Dependencies
Run: `pip install agno sentence-transformers`

### 2. Start the Postgres Server with pgvector
Run: `sh cookbook/scripts/run_pgvector.sh`

### 3. Run the example
Run: `uv run cookbook/agent_concepts/rag/rag_sentence_transformer.py`
"""

from agno.agent import Agent
from agno.knowledge.embedder.sentence_transformer import SentenceTransformerEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker import SentenceTransformerReranker
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector

search_results = [
    "Organic skincare for sensitive skin with aloe vera and chamomile.",
    "New makeup trends focus on bold colors and innovative techniques",
    "Bio-Hautpflege f√ºr empfindliche Haut mit Aloe Vera und Kamille",
    "Neue Make-up-Trends setzen auf kr√§ftige Farben und innovative Techniken",
    "Cuidado de la piel org√°nico para piel sensible con aloe vera y manzanilla",
    "Las nuevas tendencias de maquillaje se centran en colores vivos y t√©cnicas innovadoras",
    "ÈíàÂØπÊïèÊÑüËÇå‰∏ìÈó®ËÆæËÆ°ÁöÑÂ§©ÁÑ∂ÊúâÊú∫Êä§ËÇ§‰∫ßÂìÅ",
    "Êñ∞ÁöÑÂåñÂ¶ÜË∂ãÂäøÊ≥®ÈáçÈ≤úËâ≥ÁöÑÈ¢úËâ≤ÂíåÂàõÊñ∞ÁöÑÊäÄÂ∑ß",
    "ÊïèÊÑüËÇå„ÅÆ„Åü„ÇÅ„Å´ÁâπÂà•„Å´Ë®≠Ë®à„Åï„Çå„ÅüÂ§©ÁÑ∂ÊúâÊ©ü„Çπ„Ç≠„É≥„Ç±„Ç¢Ë£ΩÂìÅ",
    "Êñ∞„Åó„ÅÑ„É°„Ç§„ÇØ„ÅÆ„Éà„É¨„É≥„Éâ„ÅØÈÆÆ„ÇÑ„Åã„Å™Ëâ≤„Å®Èù©Êñ∞ÁöÑ„Å™ÊäÄË°ì„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„Å¶„ÅÑ„Åæ„Åô",
]

knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="sentence_transformer_rerank_docs",
        embedder=SentenceTransformerEmbedder(
            id="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        ),
    ),
    reranker=SentenceTransformerReranker(model="BAAI/bge-reranker-v2-m3"),
)

for result in search_results:
    knowledge.add_content_sync(
        content=result,
        metadata={
            "source": "search_results",
        },
    )

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
    ],
    markdown=True,
)

if __name__ == "__main__":
    test_queries = [
        "What organic skincare products are good for sensitive skin?",
        "Tell me about makeup trends in different languages",
        "Compare skincare and makeup information across languages",
    ]

    for query in test_queries:
        agent.print_response(
            query,
            stream=True,
            show_full_reasoning=True,
        )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno sentence-transformers
    ```
  </Step>

  <Step title="Start Postgres with pgvector">
    ```bash
    sh cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/rag_sentence_transformer.py
      ```

      ```bash Windows  
      python cookbook/agents/rag/rag_sentence_transformer.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# RAG with LanceDB and SQLite Storage
Source: https://docs.agno.com/examples/concepts/agent/rag/rag_with_lance_db_and_sqlite



This example demonstrates how to implement RAG using LanceDB vector database with Ollama embeddings and SQLite for agent data storage, providing a complete local setup for document retrieval.

## Code

```python cookbook/agents/rag/rag_with_lance_db_and_sqlite.py
from agno.agent import Agent
from agno.db.sqlite.sqlite import SqliteDb
from agno.knowledge.embedder.ollama import OllamaEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.ollama import Ollama
from agno.vectordb.lancedb import LanceDb

# Define the database URL where the vector database will be stored
db_url = "/tmp/lancedb"

# Configure the language model
model = Ollama(id="llama3.1:8b")

# Create Ollama embedder
embedder = OllamaEmbedder(id="nomic-embed-text", dimensions=768)

# Create the vector database
vector_db = LanceDb(
    table_name="recipes",  # Table name in the vector database
    uri=db_url,  # Location to initiate/create the vector database
    embedder=embedder,  # Without using this, it will use OpenAIChat embeddings by default
)

knowledge = Knowledge(
    vector_db=vector_db,
)

knowledge.add_content_sync(
    name="Recipes", url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)


# Set up SQL storage for the agent's data
db = SqliteDb(db_file="data.db")

# Initialize the Agent with various configurations including the knowledge base and storage
agent = Agent(
    session_id="session_id",  # use any unique identifier to identify the run
    user_id="user",  # user identifier to identify the user
    model=model,
    knowledge=knowledge,
    db=db,
)

# Use the agent to generate and print a response to a query, formatted in Markdown
agent.print_response(
    "What is the first step of making Gluai Buat Chi from the knowledge base?",
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno lancedb ollama
    ```
  </Step>

  <Step title="Setup Ollama">
    ```bash
    # Install and start Ollama
    # Pull required models
    ollama pull llama3.1:8b
    ollama pull nomic-embed-text
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/rag_with_lance_db_and_sqlite.py
      ```

      ```bash Windows
      python cookbook/agents/rag/rag_with_lance_db_and_sqlite.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Traditional RAG with LanceDB
Source: https://docs.agno.com/examples/concepts/agent/rag/traditional_rag_lancedb



This example demonstrates how to implement traditional RAG using LanceDB vector database, where knowledge is added to context rather than searched dynamically by the agent.

## Code

```python cookbook/agents/rag/traditional_rag_lancedb.py
"""
1. Run: `pip install openai lancedb tantivy pypdf sqlalchemy agno` to install the dependencies
2. Run: `python cookbook/rag/03_traditional_rag_lancedb.py` to run the agent
"""

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    # Use LanceDB as the vector database and store embeddings in the `recipes` table
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Enable RAG by adding references from Knowledge to the user prompt.
    add_knowledge_to_context=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb tantivy pypdf sqlalchemy
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/traditional_rag_lancedb.py
      ```

      ```bash Windows
      python cookbook/agents/rag/traditional_rag_lancedb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Traditional RAG with PgVector
Source: https://docs.agno.com/examples/concepts/agent/rag/traditional_rag_pgvector



This example demonstrates traditional RAG implementation using PgVector database with OpenAI embeddings, where knowledge context is automatically added to prompts without search functionality.

## Code

```python cookbook/agents/rag/traditional_rag_pgvector.py
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Enable RAG by adding context from the `knowledge` to the user prompt.
    add_knowledge_to_context=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai sqlalchemy psycopg pgvector
    ```
  </Step>

  <Step title="Setup PgVector">
    ```bash
    # Start PostgreSQL container with pgvector
    ./cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/traditional_rag_pgvector.py
      ```

      ```bash Windows
      python cookbook/agents/rag/traditional_rag_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Persistent Session Storage
Source: https://docs.agno.com/examples/concepts/agent/session/01_persistent_session



This example demonstrates how to create an agent with persistent session storage using PostgreSQL, enabling conversation history to be maintained across different runs.

## Code

```python cookbook/agents/session/01_persistent_session.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_storage",
    add_history_to_context=True,
)

agent.print_response("Tell me a new interesting fact about space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg2-binary
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/01_persistent_session.py
      ```

      ```bash Windows
      python cookbook/agents/session/01_persistent_session.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Persistent Session with History Limit
Source: https://docs.agno.com/examples/concepts/agent/session/02_persistent_session_history



This example demonstrates how to use session history with a configurable number of previous runs added to context, allowing control over how much conversation history is included.

## Code

```python cookbook/agents/session/02_persistent_session_history.py
"""
This example shows how to use the session history to store the conversation history.
add_history_to_context flag is used to add the history to the messages.
num_history_runs is used to set the number of history runs to add to the messages.
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_storage",
    add_history_to_context=True,
    num_history_runs=2,
)

agent.print_response("Tell me a new interesting fact about space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg2-binary
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/02_persistent_session_history.py
      ```

      ```bash Windows
      python cookbook/agents/session/02_persistent_session_history.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session Summary Management
Source: https://docs.agno.com/examples/concepts/agent/session/03_session_summary



This example demonstrates how to enable automatic session summaries that help maintain conversation context across longer interactions by summarizing previous conversations.

## Code

```python cookbook/agents/session/03_session_summary.py
"""
This example shows how to use the session summary to store the conversation summary.
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.session.summary import SessionSummaryManager  # noqa: F401

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

# Method 1: Set enable_session_summaries to True

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    enable_session_summaries=True,
    session_id="session_summary",
)

agent.print_response("Hi my name is John and I live in New York")
agent.print_response("I like to play basketball and hike in the mountains")

# Method 2: Set session_summary_manager

# session_summary_manager = SessionSummaryManager(model=OpenAIChat(id="gpt-5-mini"))

# agent = Agent(
#     model=OpenAIChat(id="gpt-5-mini"),
#     db=db,
#     session_id="session_summary",
#     session_summary_manager=session_summary_manager,
# )

# agent.print_response("Hi my name is John and I live in New York")
# agent.print_response("I like to play basketball and hike in the mountains")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg2-binary
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/03_session_summary.py
      ```

      ```bash Windows
      python cookbook/agents/session/03_session_summary.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session Summary with References
Source: https://docs.agno.com/examples/concepts/agent/session/04_session_summary_references



This example demonstrates how to use session summaries with context references, enabling the agent to maintain conversation context and reference previous session summaries.

## Code

```python cookbook/agents/session/04_session_summary_references.py
"""
This example shows how to use the `add_session_summary_to_context` parameter in the Agent config to
add session summaries to the Agent context.

Start the postgres db locally on Docker by running: cookbook/scripts/run_pgvector.sh
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_summary",
    enable_session_summaries=True,
)

# This will create a new session summary
agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
)

# You can use existing session summaries from session storage without creating or updating any new ones.
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_summary",
    add_session_summary_to_context=True,
)

agent.print_response("I also like to play basketball.")

# Alternatively, you can create a new session summary without adding the session summary to context.

# agent = Agent(
#     model=OpenAIChat(id="gpt-5-mini"),
#     db=db,
#     session_id="session_summary",
#     enable_session_summaries=True,
#     add_session_summary_to_context=False,
# )

# agent.print_response("I also like to play basketball.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Start PostgreSQL container with pgvector
    cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/04_session_summary_references.py
      ```

      ```bash Windows
      python cookbook/agents/session/04_session_summary_references.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Chat History Management
Source: https://docs.agno.com/examples/concepts/agent/session/05_chat_history



This example demonstrates how to manage and retrieve chat history in agent conversations, enabling access to previous conversation messages and context.

## Code

```python cookbook/agents/session/05_chat_history.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="chat_history",
    instructions="You are a helpful assistant that can answer questions about space and oceans.",
    add_history_to_context=True,
)

agent.print_response("Tell me a new interesting fact about space")
print(agent.get_chat_history())

agent.print_response("Tell me a new interesting fact about oceans")
print(agent.get_chat_history())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/05_chat_history.py
      ```

      ```bash Windows
      python cookbook/agents/session/05_chat_history.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session Name Management
Source: https://docs.agno.com/examples/concepts/agent/session/06_rename_session



This example demonstrates how to set and manage session names, both manually and automatically, allowing for better organization and identification of conversation sessions.

## Code

```python cookbook/agents/session/06_rename_session.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="chat_history",
    instructions="You are a helpful assistant that can answer questions about space and oceans.",
    add_history_to_context=True,
)

agent.print_response("Tell me a new interesting fact about space")
agent.set_session_name(session_name="Interesting Space Facts")

session = agent.get_session(session_id=agent.session_id)
print(session.session_data.get("session_name"))

agent.set_session_name(autogenerate=True)

session = agent.get_session(session_id=agent.session_id)
print(session.session_data.get("session_name"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/06_rename_session.py
      ```

      ```bash Windows
      python cookbook/agents/session/06_rename_session.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# In-Memory Database Storage
Source: https://docs.agno.com/examples/concepts/agent/session/07_in_memory_db



This example demonstrates how to use an in-memory database for session storage, enabling conversation history and context management without requiring a persistent database setup.

## Code

```python cookbook/agents/session/07_in_memory_db.py
"""This example shows how to use an in-memory database.

With this you will be able to store sessions, user memories, etc. without setting up a database.
Keep in mind that in production setups it is recommended to use a database.
"""

from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

# Setup the in-memory database
db = InMemoryDb()

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Use the in-memory database. All db features will be available.
    db=db,
    # Set add_history_to_context=true to add the previous chat history to the context sent to the Model.
    add_history_to_context=True,
    # Number of historical responses to add to the messages.
    num_history_runs=3,
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

# -*- Create a run
agent.print_response("Share a 2 sentence horror story", stream=True)
# -*- Print the messages in the memory
pprint(
    [
        m.model_dump(include={"role", "content"})
        for m in agent.get_messages_for_session()
    ]
)

# -*- Ask a follow up question that continues the conversation
agent.print_response("What was my first message?", stream=True)
# -*- Print the messages in the memory
pprint(
    [
        m.model_dump(include={"role", "content"})
        for m in agent.get_messages_for_session()
    ]
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai rich
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/07_in_memory_db.py
      ```

      ```bash Windows
      python cookbook/agents/session/07_in_memory_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session Caching
Source: https://docs.agno.com/examples/concepts/agent/session/08_cache_session



This example demonstrates how to enable session caching in memory for faster access to session data, improving performance when working with persistent databases.

## Code

```python cookbook/agents/session/08_cache_session.py
"""Example of how to cache the session in memory for faster access."""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url, session_table="xxx")

# Setup the agent
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_storage",
    add_history_to_context=True,
    # Activate session caching. The session will be cached in memory for faster access.
    cache_session=True,
)

# Running the Agent
agent.print_response("Tell me a new interesting fact about space")

# You can get the cached session:
session = agent.get_session()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/session/08_cache_session.py
      ```

      ```bash Windows
      python cookbook/agents/session/08_cache_session.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic Session State
Source: https://docs.agno.com/examples/concepts/agent/state/agentic_session_state



This example demonstrates how to enable agentic session state management, allowing the agent to automatically update and manage session state based on conversation context. The agent can modify the shopping list based on user interactions.

## Code

```python cookbook/agents/state/agentic_session_state.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat

db = SqliteDb(db_file="tmp/agents.db")
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_state={"shopping_list": []},
    add_session_state_to_context=True,  # Required so the agent is aware of the session state
    enable_agentic_state=True,
)

agent.print_response("Add milk, eggs, and bread to the shopping list")

agent.print_response("I picked up the eggs, now what's on my list?")

print(f"Session state: {agent.get_session_state()}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/agentic_session_state.py
      ```

      ```bash Windows  
      python cookbook/agents/state/agentic_session_state.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Change State On Run
Source: https://docs.agno.com/examples/concepts/agent/state/change_state_on_run



This example demonstrates how to manage session state across different runs for different users. It shows how session state persists within the same session but is isolated between different sessions and users.

## Code

```python cookbook/agents/state/change_state_on_run.py
from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat

agent = Agent(
    db=InMemoryDb(),
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Users name is {user_name} and age is {age}",
    debug_mode=True,
)

# Sets the session state for the session with the id "user_1_session_1"
agent.print_response(
    "What is my name?",
    session_id="user_1_session_1",
    user_id="user_1",
    session_state={"user_name": "John", "age": 30},
)

# Will load the session state from the session with the id "user_1_session_1"
agent.print_response("How old am I?", session_id="user_1_session_1", user_id="user_1")

# Sets the session state for the session with the id "user_2_session_1"
agent.print_response(
    "What is my name?",
    session_id="user_2_session_1",
    user_id="user_2",
    session_state={"user_name": "Jane", "age": 25},
)

# Will load the session state from the session with the id "user_2_session_1"
agent.print_response("How old am I?", session_id="user_2_session_1", user_id="user_2")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/change_state_on_run.py
      ```

      ```bash Windows  
      python cookbook/agents/state/change_state_on_run.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Dynamic Session State
Source: https://docs.agno.com/examples/concepts/agent/state/dynamic_session_state



This example demonstrates how to use tool hooks to dynamically manage session state. It shows how to create a customer management system that updates session state through tool interactions rather than direct modification.

## Code

```python cookbook/agents/state/dynamic_session_state.py
import json
from typing import Any, Callable, Dict

from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat
from agno.tools.toolkit import Toolkit
from agno.utils.log import log_info, log_warning


class CustomerDBTools(Toolkit):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.register(self.process_customer_request)

    def process_customer_request(
        self,
        agent: Agent,
        customer_id: str,
        action: str = "retrieve",
        name: str = "John Doe",
    ):
        log_warning("Tool called, this shouldn't happen.")
        return "This should not be seen."


def customer_management_hook(
    session_state,
    function_name: str,
    function_call: Callable,
    arguments: Dict[str, Any],
):
    action = arguments.get("action", "retrieve")
    cust_id = arguments.get("customer_id")
    name = arguments.get("name", None)

    if not cust_id:
        raise ValueError("customer_id is required.")

    if action == "create":
        session_state["customer_profiles"][cust_id] = {"name": name}
        log_info(f"Hook: UPDATED session_state for customer '{cust_id}'.")
        return f"Success! Customer {cust_id} has been created."

    if action == "retrieve":
        profile = session_state.get("customer_profiles", {}).get(cust_id)
        if profile:
            log_info(f"Hook: FOUND customer '{cust_id}' in session_state.")
            return f"Profile for {cust_id}: {json.dumps(profile)}"
        else:
            raise ValueError(f"Customer '{cust_id}' not found.")

    log_info(f"Session state: {session_state}")


def run_test():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CustomerDBTools()],
        tool_hooks=[customer_management_hook],
        session_state={"customer_profiles": {"123": {"name": "Jane Doe"}}},
        instructions="Your profiles: {customer_profiles}. Use `process_customer_request`. Use either create or retrieve as action for the tool.",
        resolve_in_context=True,
        db=InMemoryDb(),
    )

    prompt = "First, create customer 789 named 'Tom'. Then, retrieve Tom's profile. Step by step."
    log_info(f"üìù Prompting: '{prompt}'")
    agent.print_response(prompt, stream=False)

    log_info("\n--- TEST ANALYSIS ---")
    log_info(
        "Check logs for the second tool call. The system prompt will NOT contain customer '789'."
    )


if __name__ == "__main__":
    run_test()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/dynamic_session_state.py
      ```

      ```bash Windows  
      python cookbook/agents/state/dynamic_session_state.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Last N Session Messages
Source: https://docs.agno.com/examples/concepts/agent/state/last_n_session_messages



This example demonstrates how to configure agents to search through previous sessions and limit the number of historical sessions included in context. This helps manage context length while maintaining relevant conversation history.

## Code

```python cookbook/agents/state/last_n_session_messages.py
import os

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat

# Remove the tmp db file before running the script
os.remove("tmp/data.db")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    user_id="user_1",
    db=SqliteDb(db_file="tmp/data.db"),
    add_history_to_context=True,
    num_history_runs=3,
    search_session_history=True,  # allow searching previous sessions
    num_history_sessions=2,  # only include the last 2 sessions in the search to avoid context length issues
)

session_1_id = "session_1_id"
session_2_id = "session_2_id"
session_3_id = "session_3_id"
session_4_id = "session_4_id"
session_5_id = "session_5_id"

agent.print_response("What is the capital of South Africa?", session_id=session_1_id)
agent.print_response("What is the capital of China?", session_id=session_2_id)
agent.print_response("What is the capital of France?", session_id=session_3_id)
agent.print_response("What is the capital of Japan?", session_id=session_4_id)
agent.print_response(
    "What did I discuss in my previous conversations?", session_id=session_5_id
)  # It should only include the last 2 sessions
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/last_n_session_messages.py
      ```

      ```bash Windows  
      python cookbook/agents/state/last_n_session_messages.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Advanced Session State Management
Source: https://docs.agno.com/examples/concepts/agent/state/session_state_advanced



This example demonstrates advanced session state management with multiple tools for managing a shopping list, including add, remove, and list operations.

## Code

```python cookbook/agents/state/session_state_advanced.py
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat


# Define tools to manage our shopping list
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list and return confirmation."""
    # Add the item if it's not already in the list
    if item.lower() not in [i.lower() for i in session_state["shopping_list"]]:
        session_state["shopping_list"].append(item)  # type: ignore
        return f"Added '{item}' to the shopping list"
    else:
        return f"'{item}' is already in the shopping list"


def remove_item(session_state, item: str) -> str:
    """Remove an item from the shopping list by name."""
    # Case-insensitive search
    for i, list_item in enumerate(session_state["shopping_list"]):
        if list_item.lower() == item.lower():
            session_state["shopping_list"].pop(i)
            return f"Removed '{list_item}' from the shopping list"

    return f"'{item}' was not found in the shopping list"


def list_items(session_state) -> str:
    """List all items in the shopping list."""
    shopping_list = session_state["shopping_list"]

    if not shopping_list:
        return "The shopping list is empty."

    items_text = "\n".join([f"- {item}" for item in shopping_list])
    return f"Current shopping list:\n{items_text}"


# Create a Shopping List Manager Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with an empty shopping list (default session state for all sessions)
    session_state={"shopping_list": []},
    db=SqliteDb(db_file="tmp/example.db"),
    tools=[add_item, remove_item, list_items],
    # You can use variables from the session state in the instructions
    instructions=dedent("""\
        Your job is to manage a shopping list.

        The shopping list starts empty. You can add items, remove items by name, and list all items.

        Current shopping list: {shopping_list}
    """),
    markdown=True,
)

# Example usage
agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response("I got bread", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response("I need apples and oranges", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response("whats on my list?", stream=True)
print(f"Session state: {agent.get_session_state()}")

agent.print_response(
    "Clear everything from my list and start over with just bananas and yogurt",
    stream=True,
)
print(f"Session state: {agent.get_session_state()}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/session_state_advanced.py
      ```

      ```bash Windows
      python cookbook/agents/state/session_state_advanced.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Session State Management
Source: https://docs.agno.com/examples/concepts/agent/state/session_state_basic



This example demonstrates how to create an agent with basic session state management, maintaining a shopping list across interactions using SQLite storage.

## Code

```python cookbook/agents/state/session_state_basic.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat


def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list."""
    session_state["shopping_list"].append(item)  # type: ignore
    return f"The shopping list is now {session_state['shopping_list']}"  # type: ignore


# Create an Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with a counter starting at 0 (this is the default session state for all users)
    session_state={"shopping_list": []},
    db=SqliteDb(db_file="tmp/agents.db"),
    tools=[add_item],
    # You can use variables from the session state in the instructions
    instructions="Current state (shopping list) is: {shopping_list}",
    markdown=True,
)

# Example usage
agent.print_response("Add milk, eggs, and bread to the shopping list", stream=True)
print(f"Final session state: {agent.get_session_state()}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/session_state_basic.py
      ```

      ```bash Windows
      python cookbook/agents/state/session_state_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session State In Context
Source: https://docs.agno.com/examples/concepts/agent/state/session_state_in_context



This example demonstrates how to use session state with PostgreSQL database and manage user context across different sessions. It shows how session state persists and can be retrieved for different users and sessions.

## Code

```python cookbook/agents/state/session_state_in_context.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Users name is {user_name} and age is {age}",
    db=db,
)

# Sets the session state for the session with the id "user_1_session_1"
agent.print_response(
    "What is my name?",
    session_id="user_1_session_1",
    user_id="user_1",
    session_state={"user_name": "John", "age": 30},
)

# Will load the session state from the session with the id "user_1_session_1"
agent.print_response("How old am I?", session_id="user_1_session_1", user_id="user_1")

# Sets the session state for the session with the id "user_2_session_1"
agent.print_response(
    "What is my name?",
    session_id="user_2_session_1",
    user_id="user_2",
    session_state={"user_name": "Jane", "age": 25},
)

# Will load the session state from the session with the id "user_2_session_1"
agent.print_response("How old am I?", session_id="user_2_session_1", user_id="user_2")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai psycopg
    ```
  </Step>

  <Step title="Setup PostgreSQL">
    ```bash
    # Make sure PostgreSQL is running
    # Update connection string in the code as needed
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/session_state_in_context.py
      ```

      ```bash Windows  
      python cookbook/agents/state/session_state_in_context.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session State In Instructions
Source: https://docs.agno.com/examples/concepts/agent/state/session_state_in_instructions



This example demonstrates how to use session state variables directly in agent instructions. It shows how to initialize session state and reference those variables in the instruction templates.

## Code

```python cookbook/agents/state/session_state_in_instructions.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with a variable
    session_state={"user_name": "John"},
    # You can use variables from the session state in the instructions
    instructions="Users name is {user_name}",
    markdown=True,
)

agent.print_response("What is my name?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/session_state_in_instructions.py
      ```

      ```bash Windows  
      python cookbook/agents/state/session_state_in_instructions.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Session State for Multiple Users
Source: https://docs.agno.com/examples/concepts/agent/state/session_state_multiple_users



This example demonstrates how to maintain separate session state for multiple users in a multi-user environment, with each user having their own shopping lists and sessions.

## Code

```python cookbook/agents/state/session_state_multiple_users.py
"""
This example demonstrates how to maintain state for each user in a multi-user environment.

The shopping list is stored in a dictionary, organized by user ID and session ID.

Agno automatically creates the "current_user_id" and "current_session_id" variables in the session state.

You can access these variables in your functions using the `agent.get_session_state()` dictionary.
"""

import json

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat

# In-memory database to store user shopping lists
# Organized by user ID and session ID
shopping_list = {}


def add_item(session_state, item: str) -> str:
    """Add an item to the current user's shopping list."""

    current_user_id = session_state["current_user_id"]
    current_session_id = session_state["current_session_id"]
    shopping_list.setdefault(current_user_id, {}).setdefault(
        current_session_id, []
    ).append(item)

    return f"Item {item} added to the shopping list"


def remove_item(session_state, item: str) -> str:
    """Remove an item from the current user's shopping list."""

    current_user_id = session_state["current_user_id"]
    current_session_id = session_state["current_session_id"]

    if (
        current_user_id not in shopping_list
        or current_session_id not in shopping_list[current_user_id]
    ):
        return f"No shopping list found for user {current_user_id} and session {current_session_id}"

    if item not in shopping_list[current_user_id][current_session_id]:
        return f"Item '{item}' not found in the shopping list for user {current_user_id} and session {current_session_id}"

    shopping_list[current_user_id][current_session_id].remove(item)
    return f"Item {item} removed from the shopping list"


def get_shopping_list(session_state) -> str:
    """Get the current user's shopping list."""

    current_user_id = session_state["current_user_id"]
    current_session_id = session_state["current_session_id"]
    return f"Shopping list for user {current_user_id} and session {current_session_id}: \n{json.dumps(shopping_list[current_user_id][current_session_id], indent=2)}"


# Create an Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=SqliteDb(db_file="tmp/data.db"),
    tools=[add_item, remove_item, get_shopping_list],
    # Reference the in-memory database
    instructions=[
        "Current User ID: {current_user_id}",
        "Current Session ID: {current_session_id}",
    ],
    markdown=True,
)

user_id_1 = "john_doe"
user_id_2 = "mark_smith"
user_id_3 = "carmen_sandiago"

# Example usage
agent.print_response(
    "Add milk, eggs, and bread to the shopping list",
    stream=True,
    user_id=user_id_1,
    session_id="user_1_session_1",
)
agent.print_response(
    "Add tacos to the shopping list",
    stream=True,
    user_id=user_id_2,
    session_id="user_2_session_1",
)
agent.print_response(
    "Add apples and grapes to the shopping list",
    stream=True,
    user_id=user_id_3,
    session_id="user_3_session_1",
)
agent.print_response(
    "Remove milk from the shopping list",
    stream=True,
    user_id=user_id_1,
    session_id="user_1_session_1",
)
agent.print_response(
    "Add minced beef to the shopping list",
    stream=True,
    user_id=user_id_2,
    session_id="user_2_session_1",
)

# What is on Mark Smith's shopping list?
agent.print_response(
    "What is on Mark Smith's shopping list?",
    stream=True,
    user_id=user_id_2,
    session_id="user_2_session_1",
)

# New session, so new shopping list
agent.print_response(
    "Add chicken and soup to my list.",
    stream=True,
    user_id=user_id_2,
    session_id="user_3_session_2",
)

print(f"Final shopping lists: \n{json.dumps(shopping_list, indent=2)}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/state/session_state_multiple_users.py
      ```

      ```bash Windows
      python cookbook/agents/state/session_state_multiple_users.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DynamoDB for Agent
Source: https://docs.agno.com/examples/concepts/db/dynamodb/dynamodb_for_agent



Agno supports using DynamoDB as a storage backend for Agents using the `DynamoDb` class.

## Usage

You need to provide `aws_access_key_id` and `aws_secret_access_key` parameters to the `DynamoDb` class.

```python dynamo_for_agent.py
from agno.db.dynamo import DynamoDb

# AWS Credentials
AWS_ACCESS_KEY_ID = getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = getenv("AWS_SECRET_ACCESS_KEY")

db = DynamoDb(
    region_name="us-east-1",
    # aws_access_key_id: AWS access key id
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    # aws_secret_access_key: AWS secret access key
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
)

# Add storage to the Agent
agent = Agent(db=db)
```

## Params

<Snippet file="db-dynamodb-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/dynamodb/dynamo_for_agent.py)


# DynamoDB for Team
Source: https://docs.agno.com/examples/concepts/db/dynamodb/dynamodb_for_team



Agno supports using DynamoDB as a storage backend for Teams using the `DynamoDb` class.

## Usage

You need to provide `aws_access_key_id` and `aws_secret_access_key` parameters to the `DynamoDb` class.

```python dynamo_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""

from typing import List

from agno.agent import Agent
from agno.db.dynamo import DynamoDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# Setup the DynamoDB database
db = DynamoDb()


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)

hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## Params

<Snippet file="db-dynamodb-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/dynamodb/dynamo_for_team.py)


# DynamoDB Workflow Storage
Source: https://docs.agno.com/examples/concepts/db/dynamodb/dynamodb_for_workflow



Agno supports using DynamoDB as a storage backend for Workflows using the `DynamoDb` class.

## Usage

You need to provide `aws_access_key_id` and `aws_secret_access_key` parameters to the `DynamoDb` class.

```python dynamo_for_workflow.py
from agno.agent import Agent
from agno.db.dynamodb import DynamoDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

db = DynamoDb()

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )
```

## Params

<Snippet file="db-dynamodb-params.mdx" />


# Firestore for Agent
Source: https://docs.agno.com/examples/concepts/db/firestore/firestore_for_agent



Agno supports using Firestore as a storage backend for Agents using the `FirestoreDb` class.

## Usage

You need to provide a `project_id` parameter to the `FirestoreDb` class. Firestore will connect automatically using your Google Cloud credentials.

```python firestore_for_agent.py
from agno.agent import Agent
from agno.db.firestore import FirestoreDb
from agno.tools.duckduckgo import DuckDuckGoTools

PROJECT_ID = "agno-os-test"  # Use your project ID here

# Setup the Firestore database
db = FirestoreDb(project_id=PROJECT_ID)

agent = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)

agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Prerequisites

1. Ensure your gcloud project is enabled with Firestore. Reference [Firestore documentation](https://cloud.google.com/firestore/docs/create-database-server-client-library)
2. Install dependencies: `pip install openai google-cloud-firestore agno`
3. Make sure your gcloud project is set up and you have the necessary permissions to access Firestore

## Params

<Snippet file="db-firestore-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/firestore/firestore_for_agent.py)


# Firestore for Team
Source: https://docs.agno.com/examples/concepts/db/firestore/firestore_for_team



Agno supports using Firestore as a storage backend for Teams using the `FirestoreDb` class.

## Usage

You need to provide a `project_id` parameter to the `FirestoreDb` class. Firestore will connect automatically using your Google Cloud credentials.

```python firestore_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""

from typing import List

from agno.agent import Agent
from agno.db.firestore import FirestoreDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# Setup the Firestore database
PROJECT_ID = "agno-os-test"  # Use your project ID here
db = FirestoreDb(project_id=PROJECT_ID)


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## Params

<Snippet file="db-firestore-params.mdx" />


# Firestore for Workflows
Source: https://docs.agno.com/examples/concepts/db/firestore/firestore_for_workflow



Agno supports using Firestore as a storage backend for Workflows using the `FirestoreDb` class.

## Usage

You need to provide a `project_id` parameter to the `FirestoreDb` class. Firestore will connect automatically using your Google Cloud credentials.

```python firestore_for_workflow.py
from agno.agent import Agent
from agno.db.firestore import FirestoreDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

PROJECT_ID = "agno-os-test"  # Use your project ID here

# Setup the Firestore database
db = FirestoreDb(project_id=PROJECT_ID)

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Params

<Snippet file="db-firestore-params.mdx" />


# Google Cloud Storage for Agent
Source: https://docs.agno.com/examples/concepts/db/gcs/gcs_for_agent



Agno supports using Google Cloud Storage (GCS) as a storage backend for Agents using the `GcsJsonDb` class. This storage backend stores session data as JSON blobs in a GCS bucket.

## Usage

Configure your agent with GCS storage to enable cloud-based session persistence.

```python gcs_for_agent.py
import uuid
import google.auth
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.gcs_json import GcsJsonDb
from agno.tools.duckduckgo import DuckDuckGoTools

# Obtain the default credentials and project id from your gcloud CLI session.
credentials, project_id = google.auth.default()

# Generate a unique bucket name using a base name and a UUID4 suffix.
base_bucket_name = "example-gcs-bucket"
unique_bucket_name = f"{base_bucket_name}-{uuid.uuid4().hex[:12]}"
print(f"Using bucket: {unique_bucket_name}")

# Initialize GCSJsonDb with explicit credentials, unique bucket name, and project.
db = GcsJsonDb(
    bucket_name=unique_bucket_name,
    prefix="agent/",
    project=project_id,
    credentials=credentials,
)

# Initialize the Agno agent with the new storage backend and a DuckDuckGo search tool.
agent1 = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    debug_mode=False,
)

# Execute sample queries.
agent1.print_response("How many people live in Canada?")
agent1.print_response("What is their national anthem called?")

# Create a new agent and make sure it pursues the conversation
agent2 = Agent(
    db=db,
    session_id=agent1.session_id,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    debug_mode=False,
)

agent2.print_response("What's the name of the country we discussed?")
agent2.print_response("What is that country's national sport?")
```

## Prerequisites

<Snippet file="gcs-auth-storage.mdx" />

## Params

<Snippet file="db-gcs-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/gcs/gcs_json_for_agent.py)


# GCS for Team
Source: https://docs.agno.com/examples/concepts/db/gcs/gcs_for_team



Agno supports using Google Cloud Storage (GCS) as a storage backend for Teams using the `GcsJsonDb` class. This storage backend stores session data as JSON blobs in a GCS bucket.

## Usage

Configure your team with GCS storage to enable cloud-based session persistence.

```python gcs_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""

import uuid
import google.auth
from typing import List

from agno.agent import Agent
from agno.db.gcs_json import GcsJsonDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# Obtain the default credentials and project id from your gcloud CLI session.
credentials, project_id = google.auth.default()

# Generate a unique bucket name using a base name and a UUID4 suffix.
base_bucket_name = "example-gcs-bucket"
unique_bucket_name = f"{base_bucket_name}-{uuid.uuid4().hex[:12]}"
print(f"Using bucket: {unique_bucket_name}")

# Setup the JSON database
db = GcsJsonDb(
    bucket_name=unique_bucket_name,
    prefix="team/",
    project=project_id,
    credentials=credentials,
)



class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## Prerequisites

<Snippet file="gcs-auth-storage.mdx" />

## Params

<Snippet file="db-gcs-params.mdx" />


# GCS for Workflows
Source: https://docs.agno.com/examples/concepts/db/gcs/gcs_for_workflow



Agno supports using Google Cloud Storage (GCS) as a storage backend for Workflows using the `GcsJsonDb` class. This storage backend stores session data as JSON blobs in a GCS bucket.

## Usage

Configure your workflow with GCS storage to enable cloud-based session persistence.

```python gcs_for_workflow.py
import uuid
import google.auth
from agno.agent import Agent
from agno.db.gcs_json import GcsJsonDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Obtain the default credentials and project id from your gcloud CLI session.
credentials, project_id = google.auth.default()

# Generate a unique bucket name using a base name and a UUID4 suffix.
base_bucket_name = "example-gcs-bucket"
unique_bucket_name = f"{base_bucket_name}-{uuid.uuid4().hex[:12]}"
print(f"Using bucket: {unique_bucket_name}")

# Setup the JSON database
db = GcsJsonDb(
    bucket_name=unique_bucket_name,
    prefix="workflow/",
    project=project_id,
    credentials=credentials,
)

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Prerequisites

<Snippet file="gcs-auth-storage.mdx" />

## Params

<Snippet file="db-gcs-params.mdx" />


# In-Memory Storage for Agents
Source: https://docs.agno.com/examples/concepts/db/in_memory/in_memory_for_agent



Example using `InMemoryDb` with agent.

## Usage

```python
from agno.agent import Agent
from agno.db.in_memory import InMemoryDb

# Setup in-memory database
db = InMemoryDb()

# Create agent with database
agent = Agent(db=db)

# Agent sessions stored in memory
agent.print_response("Give me an easy dinner recipe")
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/in_memory/in_memory_storage_for_agent.py)


# In-Memory Storage for Teams
Source: https://docs.agno.com/examples/concepts/db/in_memory/in_memory_for_team



Example using `InMemoryDb` with teams for multi-agent coordination.

## Usage

```python
from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools

# Create team members
hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher", 
    model=OpenAIChat("gpt-5-mini"),
    tools=[DuckDuckGoTools()],
)

# Setup team with in-memory database
db = InMemoryDb()
team = Team(
    name="Research Team",
    members=[hn_researcher, web_searcher],
    db=db,
)

team.print_response("Find top AI news")
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/in_memory/in_memory_storage_for_team.py)


# In-Memory Storage for Workflows
Source: https://docs.agno.com/examples/concepts/db/in_memory/in_memory_for_workflow



Example using `InMemoryDb` with workflows for multi-step processes.

## Usage

```python
from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Setup in-memory database
db = InMemoryDb()

# Create agents and team
research_agent = Agent(
    name="Research Agent",
    model=OpenAIChat("gpt-5-mini"),
    tools=[HackerNewsTools(), DuckDuckGoTools()],
)

content_agent = Agent(
    name="Content Agent",
    model=OpenAIChat("gpt-5-mini"),
)

# Define workflow steps
research_step = Step(name="Research", agent=research_agent)
content_step = Step(name="Content", agent=content_agent)

# Create workflow
workflow = Workflow(
    name="Content Workflow",
    db=db,
    steps=[research_step, content_step],
)

workflow.print_response("AI trends in 2024")
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/in_memory/in_memory_storage_for_workflow.py)


# JSON for Agent
Source: https://docs.agno.com/examples/concepts/db/json/json_for_agent



Agno supports using local JSON files as a storage backend for Agents using the `JsonDb` class.

## Usage

```python json_for_agent.py
"""Run `pip install ddgs openai` to install dependencies."""

from agno.agent import Agent
from agno.db.json import JsonDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the JSON database
db = JsonDb(db_path="tmp/json_db")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Params

<Snippet file="db-json-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/json/json_storage_for_agent.py)


# JSON for Team
Source: https://docs.agno.com/examples/concepts/db/json/json_for_team



Agno supports using local JSON files as a storage backend for Teams using the `JsonDb` class.

## Usage

```python json_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""

from typing import List

from agno.agent import Agent
from agno.db.json import JsonDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# Setup the JSON database
db = JsonDb(db_path="tmp/json_db")


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## Params

<Snippet file="db-json-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/json/json_storage_for_team.py)


# JSON for Workflows
Source: https://docs.agno.com/examples/concepts/db/json/json_for_workflow



Agno supports using local JSON files as a storage backend for Workflows using the `JsonDb` class.

## Usage

```python json_for_workflows.py
from agno.agent import Agent
from agno.db.json import JsonDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Setup the JSON database
db = JsonDb(db_path="tmp/json_db")

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Params

<Snippet file="db-json-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/json/json_storage_for_workflow.py)


# Selecting Custom Table Names
Source: https://docs.agno.com/examples/concepts/db/miscellaneous/selecting_tables



Agno allows you to customize table names when using databases, providing flexibility in organizing your data storage.

## Usage

Specify custom table names when initializing your database connection.

```python selecting_tables.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup the SQLite database with custom table names
db = SqliteDb(
    db_file="tmp/data.db",
    # Selecting which tables to use
    session_table="agent_sessions",
    memory_table="agent_memories",
    metrics_table="agent_metrics",
)

# Setup a basic agent with the SQLite database
agent = Agent(
    db=db,
    enable_user_memories=True,
    add_history_to_context=True,
    add_datetime_to_context=True,
)

# The Agent sessions and runs will now be stored in SQLite with custom table names
agent.print_response("How many people live in Canada?")
agent.print_response("And in Mexico?")
agent.print_response("List my messages one by one")
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/examples/selecting_tables.py)


# MongoDB for Agent
Source: https://docs.agno.com/examples/concepts/db/mongodb/mongodb_for_agent



Agno supports using MongoDB as a storage backend for Agents using the `MongoDb` class.

## Usage

You need to provide either `db_url` or `client`. The following example uses `db_url`.

### Run MongoDB

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MongoDB** on port **27017** using:

```bash
docker run -d \
  --name local-mongo \
  -p 27017:27017 \
  -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
  -e MONGO_INITDB_ROOT_PASSWORD=secret \
  mongo
```

```python mongodb_for_agent.py
from agno.agent import Agent
from agno.db.mongo import MongoDb
from agno.tools.duckduckgo import DuckDuckGoTools

# MongoDB connection settings
db_url = "mongodb://localhost:27017"

db = MongoDb(db_url=db_url)

agent = Agent(
    db=db,  
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Params

<Snippet file="db-mongo-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/mongo/mongodb_storage_for_agent.py)


# MongoDB for Team
Source: https://docs.agno.com/examples/concepts/db/mongodb/mongodb_for_team



Agno supports using MongoDB as a storage backend for Teams using the `MongoDb` class.

## Usage

You need to provide either `db_url` or `client`. The following example uses `db_url`.

### Run MongoDB

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MongoDB** on port **27017** using:

```bash
docker run -d \
  --name local-mongo \
  -p 27017:27017 \
  -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
  -e MONGO_INITDB_ROOT_PASSWORD=secret \
  mongo
```

```python mongodb_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""
from typing import List

from agno.agent import Agent
from agno.db.mongo import MongoDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# MongoDB connection settings
db_url = "mongodb://localhost:27017"
db = MongoDb(db_url=db_url)


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    debug_mode=True,
    show_members_responses=True,
    add_member_tools_to_context=False,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")

```

## Params

<Snippet file="db-mongo-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/mongo/mongodb_storage_for_team.py)


# MongoDB for Workflow
Source: https://docs.agno.com/examples/concepts/db/mongodb/mongodb_for_workflow



Agno supports using MongoDB as a storage backend for Workflows using the `MongoDBDb` class.

## Usage

### Run MongoDB

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MongoDB** on port **27017** using:

```bash
docker run -d \
  --name local-mongo \
  -p 27017:27017 \
  -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
  -e MONGO_INITDB_ROOT_PASSWORD=secret \
  mongo
```

```python mongodb_for_workflow.py
from agno.agent import Agent
from agno.db.mongodb import MongoDBDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

db_url = "mongodb://localhost:27017"

db = MongoDb(db_url=db_url)

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Params

<Snippet file="db-mongo-params.mdx" />


# MySQL for Agent
Source: https://docs.agno.com/examples/concepts/db/mysql/mysql_for_agent



Agno supports using MySQL as a storage backend for Agents using the `MySQLDb` class.

## Usage

### Run MySQL

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MySQL** on port **3306** using:

```bash
docker run -d \
  --name mysql \
  -e MYSQL_ROOT_PASSWORD=ai \
  -e MYSQL_DATABASE=ai \
  -e MYSQL_USER=ai \
  -e MYSQL_PASSWORD=ai \
  -p 3306:3306 \
  -d mysql:8
```

```python mysql_for_agent.py
from agno.agent import Agent
from agno.db.mysql import MySQLDb

db_url = "mysql+pymysql://ai:ai@localhost:3306/ai"

db = MySQLDb(db_url=db_url)

agent = Agent(
    db=db,
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

```

## Params

<Snippet file="db-mysql-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/mysql/mysql_storage_for_agent.py)


# MySQL for Team
Source: https://docs.agno.com/examples/concepts/db/mysql/mysql_for_team



Agno supports using MySQL as a storage backend for Teams using the `MySQLDb` class.

## Usage

### Run MySQL

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MySQL** on port **3306** using:

```bash
docker run -d \
  --name mysql \
  -e MYSQL_ROOT_PASSWORD=ai \
  -e MYSQL_DATABASE=ai \
  -e MYSQL_USER=ai \
  -e MYSQL_PASSWORD=ai \
  -p 3306:3306 \
  -d mysql:8
```

```python mysql_for_team.py
from typing import List

from agno.agent import Agent
from agno.db.mysql import MySQLDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# MySQL connection settings
db_url = "mysql+pymysql://ai:ai@localhost:3306/ai"
db = MySQLDb(db_url=db_url)


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
    add_member_tools_to_context=False,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## Params

<Snippet file="db-mysql-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/mysql/mysql_storage_for_team.py)


# MySQL Workflow Storage
Source: https://docs.agno.com/examples/concepts/db/mysql/mysql_for_workflow



Agno supports using MySQL as a storage backend for Workflows using the `MysqlDb` class.

## Usage

### Run MySQL

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MySQL** on port **3306** using:

```bash
docker run -d \
  --name mysql \
  -e MYSQL_ROOT_PASSWORD=ai \
  -e MYSQL_DATABASE=ai \
  -e MYSQL_USER=ai \
  -e MYSQL_PASSWORD=ai \
  -p 3306:3306 \
  -d mysql:8
```

```python mysql_for_workflow.py
from agno.agent import Agent
from agno.db.mysql import MySQLDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

db_url = "mysql+pymysql://ai:ai@localhost:3306/ai"

db = MySQLDb(db_url=db_url)

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )
```

## Params

<Snippet file="db-mysql-params.mdx" />


# Postgres for Agent
Source: https://docs.agno.com/examples/concepts/db/postgres/postgres_for_agent



Agno supports using PostgreSQL as a storage backend for Agents using the `PostgresDb` class.

## Usage

### Run PgVector

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

```python postgres_for_agent.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

agent = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

```

## Params

<Snippet file="db-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/postgres/postgres_for_agent.py)


# Postgres for Team
Source: https://docs.agno.com/examples/concepts/db/postgres/postgres_for_team



Agno supports using PostgreSQL as a storage backend for Teams using the `PostgresDb` class.

## Usage

### Run PgVector

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

```python postgres_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""

from typing import List

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")

```

## Params

<Snippet file="db-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/postgres/postgres_for_team.py)


# Postgres for Workflows
Source: https://docs.agno.com/examples/concepts/db/postgres/postgres_for_workflow



Agno supports using PostgreSQL as a storage backend for Workflows using the `PostgresDb` class.

## Usage

### Run PgVector

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

```python postgres_for_workflow.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=PostgresDb(
            session_table="workflow_session",
            db_url=db_url,
        ),
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Params

<Snippet file="db-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/postgres/postgres_for_workflow.py)


# Redis for Agent
Source: https://docs.agno.com/examples/concepts/db/redis/redis_for_agent



Agno supports using Redis as a storage backend for Agents using the `RedisDb` class.

## Usage

### Run Redis

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **Redis** on port **6379** using:

```bash
docker run -d \
  --name my-redis \
  -p 6379:6379 \
  redis
```

```python redis_for_agent.py
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.redis import RedisDb
from agno.tools.duckduckgo import DuckDuckGoTools

# Initialize Redis db (use the right db_url for your setup)
db = RedisDb(db_url="redis://localhost:6379")

# Create agent with Redis db
agent = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)

agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

# Verify db contents
print("\nVerifying db contents...")
all_sessions = db.get_sessions(session_type=SessionType.AGENT)
print(f"Total sessions in Redis: {len(all_sessions)}")

if all_sessions:
    print("\nSession details:")
    session = all_sessions[0]
    print(f"The stored session: {session}")

```

## Params

<Snippet file="db-redis-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/redis/redis_for_agent.py)


# Redis for Team
Source: https://docs.agno.com/examples/concepts/db/redis/redis_for_team



Agno supports using Redis as a storage backend for Teams using the `RedisDb` class.

## Usage

### Run Redis

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **Redis** on port **6379** using:

```bash
docker run --name my-redis -p 6379:6379 -d redis
```

```python redis_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno redis` to install the dependencies
"""

from typing import List

from agno.agent import Agent
from agno.db.redis import RedisDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

db = RedisDb(db_url="redis://localhost:6379")


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")

```

## Params

<Snippet file="db-redis-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/redis/redis_for_team.py)


# Redis for Workflows
Source: https://docs.agno.com/examples/concepts/db/redis/redis_for_workflow



Agno supports using Redis as a storage backend for Workflows using the `RedisDb` class.

## Usage

### Run Redis

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **Redis** on port **6379** using:

```bash
docker run --name my-redis -p 6379:6379 -d redis
```

```python redis_for_workflow.py
"""
Run: `pip install openai httpx newspaper4k redis agno` to install the dependencies
"""
from agno.agent import Agent
from agno.db.redis import RedisDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=RedisDb(
            session_table="workflow_session",
            db_url="redis://localhost:6379",
        ),
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Params

<Snippet file="db-redis-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/redis/redis_for_workflow.py)


# Singlestore for Agent
Source: https://docs.agno.com/examples/concepts/db/singlestore/singlestore_for_agent



Agno supports using Singlestore as a storage backend for Agents using the `SingleStoreDb` class.

## Usage

Obtain the credentials for Singlestore from [here](https://portal.singlestore.com/)

```python singlestore_for_agent.py
from os import getenv

from agno.agent import Agent
from agno.db.singlestore.singlestore import SingleStoreDb
from agno.tools.duckduckgo import DuckDuckGoTools

# Configure SingleStore DB connection
USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")

db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)

db = SingleStoreDb(db_url=db_url)

# Create an agent with SingleStore db
agent = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

```

## Params

<Snippet file="db-singlestore-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/singlestore/singlestore_for_agent.py)


# Singlestore for Team
Source: https://docs.agno.com/examples/concepts/db/singlestore/singlestore_for_team



Agno supports using Singlestore as a storage backend for Teams using the `SingleStoreDb` class.

## Usage

Obtain the credentials for Singlestore from [here](https://portal.singlestore.com/)

```python singlestore_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""
from os import getenv
from typing import List

from agno.agent import Agent
from agno.db.singlestore.singlestore import SingleStoreDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

# Configure SingleStore DB connection
USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)
db = SingleStoreDb(db_url=db_url)


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")

```

## Params

<Snippet file="db-singlestore-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/db/singlestore/singlestore_for_team.py)


# Singlestore for Workflow
Source: https://docs.agno.com/examples/concepts/db/singlestore/singlestore_for_workflow



Agno supports using Singlestore as a storage backend for Workflows using the `SingleStoreDb` class.

## Usage

Obtain the credentials for Singlestore from [here](https://portal.singlestore.com/)

```python singlestore_for_workflow.py
from agno.agent import Agent
from agno.db.singlestore import SingleStoreDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Configure SingleStore DB connection
USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)
db = SingleStoreDb(db_url=db_url)

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
            db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )               
```

## Params

<Snippet file="db-singlestore-params.mdx" />


# Sqlite for Agent
Source: https://docs.agno.com/examples/concepts/db/sqlite/sqlite_for_agent



Agno supports using Sqlite as a storage backend for Agents using the `SqliteDb` class.

## Usage

You need to provide either `db_url`, `db_file` or `db_engine`. The following example uses `db_file`.

```python sqlite_for_agent.py

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the SQLite database
db = SqliteDb(db_file="tmp/data.db")

# Setup a basic agent with the SQLite database
agent = Agent(
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
    add_datetime_to_context=True,
)

# The Agent sessions and runs will now be stored in SQLite
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem?")
agent.print_response("List my messages one by one")

```

## Params

<Snippet file="db-sqlite-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/sqllite/sqlite_for_agent.py)


# Sqlite for Team
Source: https://docs.agno.com/examples/concepts/db/sqlite/sqlite_for_team



Agno supports using Sqlite as a storage backend for Teams using the `SqliteDb` class.

## Usage

You need to provide either `db_url`, `db_file` or `db_engine`. The following example uses `db_file`.

```python sqlite_for_team.py
"""
Run: `pip install openai ddgs newspaper4k lxml_html_clean agno` to install the dependencies
"""
from typing import List

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel

db = SqliteDb(db_file="tmp/data.db")


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher],
    db=db,
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")

```

## Params

<Snippet file="db-sqlite-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/sqllite/sqlite_for_team.py)


# SQLite for Workflow
Source: https://docs.agno.com/examples/concepts/db/sqlite/sqlite_for_workflow



Agno supports using SQLite as a storage backend for Workflows using the `SqliteDb` class.

## Usage

```python sqlite_for_workflow.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

db = SqliteDb(db_file="tmp/workflow.db")

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=db,
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

```

## Params

<Snippet file="db-sqlite-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/db/sqllite/sqlite_for_workflow.py)


# Async Accuracy Evaluation
Source: https://docs.agno.com/examples/concepts/evals/accuracy/accuracy_async

Learn how to run accuracy evaluations asynchronously for better performance.

This example shows how to run an Accuracy evaluation asynchronously.

## Code

```python
"""This example shows how to run an Accuracy evaluation asynchronously."""

import asyncio
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    additional_guidelines="Agent output should include the steps and the final answer.",
    num_iterations=3,
)

# Run the evaluation calling the arun method.
result: Optional[AccuracyResult] = asyncio.run(evaluation.arun(print_results=True))
assert result is not None and result.avg_score >= 8
```


# Comparison Accuracy Evaluation
Source: https://docs.agno.com/examples/concepts/evals/accuracy/accuracy_comparison

Learn how to evaluate agent accuracy on comparison tasks.

This example shows how to evaluate an agent's ability to correctly compare numbers using calculator tools.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    name="Comparison Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
        instructions="You must use the calculator tools for comparisons.",
    ),
    input="9.11 and 9.9 -- which is bigger?",
    expected_output="9.9",
    additional_guidelines="Its ok for the output to include additional text or information relevant to the comparison.",
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```


# Accuracy with Database Logging
Source: https://docs.agno.com/examples/concepts/evals/accuracy/accuracy_db_logging

Learn how to store evaluation results in the database for tracking and analysis.

This example shows how to store evaluation results in the database.

## Code

```python
"""Example showing how to store evaluation results in the database."""

from typing import Optional

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5432/ai"
db = PostgresDb(db_url=db_url, eval_table="eval_runs_cookbook")


evaluation = AccuracyEval(
    db=db,  # Pass the database to the evaluation. Results will be stored in the database.
    name="Calculator Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    additional_guidelines="Agent output should include the steps and the final answer.",
    num_iterations=1,
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```


# Accuracy with Given Answer
Source: https://docs.agno.com/examples/concepts/evals/accuracy/accuracy_with_given_answer

Learn how to evaluate the accuracy of an Agno Agent's response with a given answer.

For this example an agent won't be executed, but the given result will be evaluated against the expected output for correctness.

## Code

```python
from typing import Optional

from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat

evaluation = AccuracyEval(
    name="Given Answer Evaluation",
    model=OpenAIChat(id="o4-mini"),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
)
result_with_given_answer: Optional[AccuracyResult] = evaluation.run_with_output(
    output="2500", print_results=True
)
assert result_with_given_answer is not None and result_with_given_answer.avg_score >= 8
```


# Accuracy with Teams
Source: https://docs.agno.com/examples/concepts/evals/accuracy/accuracy_with_teams

Learn how to evaluate the accuracy of an Agno Team.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.team import Team

# Setup a team with two members
english_agent = Agent(
    name="English Agent",
    role="You only answer in English",
    model=OpenAIChat(id="gpt-5-mini"),
)
spanish_agent = Agent(
    name="Spanish Agent",
    role="You can only answer in Spanish",
    model=OpenAIChat(id="gpt-5-mini"),
)

multi_language_team = Team(
    name="Multi Language Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[english_agent, spanish_agent],
    respond_directly=True,
    markdown=True,
    instructions=[
        "You are a language router that directs questions to the appropriate language agent.",
        "If the user asks in a language whose agent is not a team member, respond in English with:",
        "'I can only answer in the following languages: English and Spanish.",
        "Always check the language of the user's input before routing to an agent.",
    ],
)

# Evaluate the accuracy of the Team's responses
evaluation = AccuracyEval(
    name="Multi Language Team",
    model=OpenAIChat(id="o4-mini"),
    team=multi_language_team,
    input="Comment allez-vous?",
    expected_output="I can only answer in the following languages: English and Spanish.",
    num_iterations=1,
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```


# Accuracy with Tools
Source: https://docs.agno.com/examples/concepts/evals/accuracy/accuracy_with_tools

Learn how to evaluate the accuracy of an Agent that is using tools.

This example shows an evaluation that runs the provided agent with the provided input and then evaluates the answer that the agent gives.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    name="Tools Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10!?",
    expected_output="3628800",
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```


# Simple Accuracy
Source: https://docs.agno.com/examples/concepts/evals/accuracy/basic

Learn to check how complete, correct and accurate an Agno Agent's response is.

This example shows a more complex evaluation that compares the full output of the agent for correctness.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.accuracy import AccuracyEval, AccuracyResult
from agno.models.openai import OpenAIChat
from agno.tools.calculator import CalculatorTools

evaluation = AccuracyEval(
    name="Calculator Evaluation",
    model=OpenAIChat(id="o4-mini"),
    agent=Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    ),
    input="What is 10*5 then to the power of 2? do it step by step",
    expected_output="2500",
    additional_guidelines="Agent output should include the steps and the final answer.",
    num_iterations=3,
)

result: Optional[AccuracyResult] = evaluation.run(print_results=True)
assert result is not None and result.avg_score >= 8
```


# Performance on Agent Instantiation
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_agent_instantiation

Evaluation to analyze the runtime and memory usage of an Agent.

## Code

```python
"""Run `pip install agno openai` to install dependencies."""

from agno.agent import Agent
from agno.eval.performance import PerformanceEval


def instantiate_agent():
    return Agent(system_message="Be concise, reply with one sentence.")


instantiation_perf = PerformanceEval(
    name="Instantiation Performance", func=instantiate_agent, num_iterations=1000
)

if __name__ == "__main__":
    instantiation_perf.run(print_results=True, print_summary=True)
```


# Async Performance Evaluation
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_async

Learn how to run performance evaluations on async functions.

This example shows how to run a Performance evaluation on an async function.

## Code

```python
"""This example shows how to run a Performance evaluation on an async function."""

import asyncio

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


# Simple async function to run an Agent.
async def arun_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
    )
    response = await agent.arun("What is the capital of France?")
    return response


performance_eval = PerformanceEval(func=arun_agent, num_iterations=10)

# Because we are evaluating an async function, we use the arun method.
asyncio.run(performance_eval.arun(print_summary=True, print_results=True))
```


# Performance with Database Logging
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_db_logging

Learn how to store performance evaluation results in the database.

This example shows how to store evaluation results in the database.

## Code

```python
"""Example showing how to store evaluation results in the database."""

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


# Simple function to run an agent which performance we will evaluate
def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
    )
    response = agent.run("What is the capital of France?")
    print(response.content)
    return response


# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5432/ai"
db = PostgresDb(db_url=db_url, eval_table="eval_runs_cookbook")

simple_response_perf = PerformanceEval(
    db=db,  # Pass the database to the evaluation. Results will be stored in the database.
    name="Simple Performance Evaluation",
    func=run_agent,
    num_iterations=1,
    warmup_runs=0,
)

if __name__ == "__main__":
    simple_response_perf.run(print_results=True, print_summary=True)
```


# Performance on Agent Instantiation with Tool
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_instantiation_with_tool

Example showing how to analyze the runtime and memory usage of an Agent that is using tools.

## Code

```python
"""Run `pip install agno openai memory_profiler` to install dependencies."""

from typing import Literal

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


def get_weather(city: Literal["nyc", "sf"]):
    """Use this to get weather information."""
    if city == "nyc":
        return "It might be cloudy in nyc"
    elif city == "sf":
        return "It's always sunny in sf"


tools = [get_weather]


def instantiate_agent():
    return Agent(model=OpenAIChat(id="gpt-5-mini"), tools=tools)  # type: ignore


instantiation_perf = PerformanceEval(
    name="Tool Instantiation Performance", func=instantiate_agent, num_iterations=1000
)

if __name__ == "__main__":
    instantiation_perf.run(print_results=True, print_summary=True)
```


# Performance on Agent Response
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_simple_response

Example showing how to analyze the runtime and memory usage of an Agent's run, given its response.

## Code

```python
"""Run `pip install openai agno memory_profiler` to install dependencies."""

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat


def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
    )

    response = agent.run("What is the capital of France?")
    print(f"Agent response: {response.content}")

    return response


simple_response_perf = PerformanceEval(
    name="Simple Performance Evaluation",
    func=run_agent,
    num_iterations=1,
    warmup_runs=0,
)

if __name__ == "__main__":
    simple_response_perf.run(print_results=True, print_summary=True)
```


# Performance with Teams
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_team_instantiation

Learn how to analyze the runtime and memory usage of an Agno Team.

## Code

```python
"""Run `pip install agno openai` to install dependencies."""

from agno.agent import Agent
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat
from agno.team.team import Team

team_member = Agent(model=OpenAIChat(id="gpt-5-mini"))


def instantiate_team():
    return Team(members=[team_member])


instantiation_perf = PerformanceEval(
    name="Instantiation Performance Team", func=instantiate_team, num_iterations=1000
)

if __name__ == "__main__":
    instantiation_perf.run(print_results=True, print_summary=True)
```


# Team Performance with Memory
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_team_with_memory

Learn how to evaluate team performance with memory tracking and growth monitoring.

This example shows how to evaluate team performance with memory tracking enabled.

## Code

```python
import asyncio
import random

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat
from agno.team.team import Team

cities = [
    "New York",
    "Los Angeles",
    "Chicago",
    "Houston",
    "Miami",
    "San Francisco",
    "Seattle",
    "Boston",
    "Washington D.C.",
    "Atlanta",
    "Denver",
    "Las Vegas",
]


# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)


def get_weather(city: str) -> str:
    return f"The weather in {city} is sunny."


weather_agent = Agent(
    id="weather_agent",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Weather Agent",
    description="You are a helpful assistant that can answer questions about the weather.",
    instructions="Be concise, reply with one sentence.",
    tools=[get_weather],
    db=db,
    enable_user_memories=True,
    add_history_to_context=True,
)

team = Team(
    members=[weather_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Be concise, reply with one sentence.",
    db=db,
    markdown=True,
    enable_user_memories=True,
    add_history_to_context=True,
)


async def run_team():
    random_city = random.choice(cities)
    _ = team.arun(
        input=f"I love {random_city}! What weather can I expect in {random_city}?",
        stream=True,
        stream_intermediate_steps=True,
    )

    return "Successfully ran team"


team_response_with_memory_impact = PerformanceEval(
    name="Team Memory Impact",
    func=run_team,
    num_iterations=5,
    warmup_runs=0,
    measure_runtime=False,
    debug_mode=True,
    memory_growth_tracking=True,
)

if __name__ == "__main__":
    asyncio.run(
        team_response_with_memory_impact.arun(print_results=True, print_summary=True)
    )
```


# Performance with Memory Updates
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_with_memory

Learn how to evaluate performance when memory updates are involved.

This example shows how to evaluate performance when memory updates are involved.

## Code

```python
"""Run `pip install openai agno memory_profiler` to install dependencies."""

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat

# Memory creation requires a db to be provided
db = SqliteDb(db_file="tmp/memory.db")


def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
        db=db,
        enable_user_memories=True,
    )

    response = agent.run("My name is Tom! I'm 25 years old and I live in New York.")
    print(f"Agent response: {response.content}")

    return response


response_with_memory_updates_perf = PerformanceEval(
    name="Memory Updates Performance",
    func=run_agent,
    num_iterations=5,
    warmup_runs=0,
)

if __name__ == "__main__":
    response_with_memory_updates_perf.run(print_results=True, print_summary=True)
```


# Performance on Agent with Storage
Source: https://docs.agno.com/examples/concepts/evals/performance/performance_with_storage

Example showing how to analyze the runtime and memory usage of an Agent that is using storage.

## Code

```python
"""Run `pip install openai agno` to install dependencies."""

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.eval.performance import PerformanceEval
from agno.models.openai import OpenAIChat

db = SqliteDb(db_file="tmp/storage.db")


def run_agent():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        system_message="Be concise, reply with one sentence.",
        add_history_to_context=True,
        db=db,
    )
    response_1 = agent.run("What is the capital of France?")
    print(response_1.content)

    response_2 = agent.run("How many people live there?")
    print(response_2.content)

    return response_2.content


response_with_storage_perf = PerformanceEval(
    name="Storage Performance",
    func=run_agent,
    num_iterations=1,
    warmup_runs=0,
)

if __name__ == "__main__":
    response_with_storage_perf.run(print_results=True, print_summary=True)
```


# Reliability with Single Tool
Source: https://docs.agno.com/examples/concepts/evals/reliability/basic

Evaluation to assert an Agent is making the expected tool calls.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools


def factorial():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    )
    response: RunOutput = agent.run("What is 10!?")
    evaluation = ReliabilityEval(
        name="Tool Call Reliability",
        agent_response=response,
        expected_tool_calls=["factorial"],
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    result.assert_passed()


if __name__ == "__main__":
    factorial()
```


# Async Reliability Evaluation
Source: https://docs.agno.com/examples/concepts/evals/reliability/reliability_async

Learn how to run reliability evaluations asynchronously.

This example shows how to run a Reliability evaluation asynchronously.

## Code

```python
"""This example shows how to run a Reliability evaluation asynchronously."""

import asyncio
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools


def factorial():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    )
    response: RunOutput = agent.run("What is 10!?")
    evaluation = ReliabilityEval(
        agent_response=response,
        expected_tool_calls=["factorial"],
    )

    # Run the evaluation calling the arun method.
    result: Optional[ReliabilityResult] = asyncio.run(
        evaluation.arun(print_results=True)
    )
    if result:
        result.assert_passed()


if __name__ == "__main__":
    factorial()
```


# Reliability with Database Logging
Source: https://docs.agno.com/examples/concepts/evals/reliability/reliability_db_logging

Learn how to store reliability evaluation results in the database.

This example shows how to store evaluation results in the database.

## Code

```python
"""Example showing how to store evaluation results in the database."""

from typing import Optional

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5432/ai"
db = PostgresDb(db_url=db_url, eval_table="eval_runs")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[CalculatorTools()],
)
response: RunOutput = agent.run("What is 10!?")

evaluation = ReliabilityEval(
    db=db,  # Pass the database to the evaluation. Results will be stored in the database.
    name="Tool Call Reliability",
    agent_response=response,
    expected_tool_calls=["factorial"],
)
result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
```


# Single Tool Reliability
Source: https://docs.agno.com/examples/concepts/evals/reliability/reliability_single_tool

Learn how to evaluate reliability of single tool calls.

This example shows how to evaluate the reliability of a single tool call.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools


def factorial():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools()],
    )
    response: RunOutput = agent.run("What is 10!?")
    evaluation = ReliabilityEval(
        name="Tool Call Reliability",
        agent_response=response,
        expected_tool_calls=["factorial"],
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    result.assert_passed()


if __name__ == "__main__":
    factorial()
```


# Team Reliability with Stock Tools
Source: https://docs.agno.com/examples/concepts/evals/reliability/reliability_team_advanced

Learn how to evaluate team reliability with real-world tools like stock price lookup.

This example shows how to evaluate the reliability of a team using real-world tools.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.team import TeamRunOutput
from agno.team.team import Team
from agno.tools.yfinance import YFinanceTools

team_member = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[YFinanceTools(stock_price=True)],
)

team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[team_member],
    markdown=True,
    show_members_responses=True,
)

expected_tool_calls = [
    "delegate_task_to_member",  # Tool call used to delegate a task to a Team member
    "get_current_stock_price",  # Tool call used to get the current stock price of a stock
]


def evaluate_team_reliability():
    response: TeamRunOutput = team.run("What is the current stock price of NVDA?")
    evaluation = ReliabilityEval(
        name="Team Reliability Evaluation",
        team_response=response,
        expected_tool_calls=expected_tool_calls,
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    if result:
        result.assert_passed()


if __name__ == "__main__":
    evaluate_team_reliability()
```


# Reliability with Multiple Tools
Source: https://docs.agno.com/examples/concepts/evals/reliability/reliability_with_multiple_tools

Learn how to assert an Agno Agent is making multiple expected tool calls.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.calculator import CalculatorTools


def multiply_and_exponentiate():
    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[CalculatorTools(add=True, multiply=True, exponentiate=True)],
    )
    response: RunOutput = agent.run(
        "What is 10*5 then to the power of 2? do it step by step"
    )
    evaluation = ReliabilityEval(
        name="Tool Calls Reliability",
        agent_response=response,
        expected_tool_calls=["multiply", "exponentiate"],
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    if result:
        result.assert_passed()


if __name__ == "__main__":
    multiply_and_exponentiate()
```


# Reliability with Teams
Source: https://docs.agno.com/examples/concepts/evals/reliability/reliability_with_teams

Learn how to assert an Agno Team is making the expected tool calls.

## Code

```python
from typing import Optional

from agno.agent import Agent
from agno.eval.reliability import ReliabilityEval, ReliabilityResult
from agno.models.openai import OpenAIChat
from agno.run.team import TeamRunOutput
from agno.team.team import Team
from agno.tools.yfinance import YFinanceTools

team_member = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[YFinanceTools(stock_price=True)],
)

team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[team_member],
    markdown=True,
    show_members_responses=True,
)

expected_tool_calls = [
    "delegate_task_to_member",  # Tool call used to delegate a task to a Team member
    "get_current_stock_price",  # Tool call used to get the current stock price of a stock
]


def evaluate_team_reliability():
    response: TeamRunOutput = team.run("What is the current stock price of NVDA?")
    evaluation = ReliabilityEval(
        name="Team Reliability Evaluation",
        team_response=response,
        expected_tool_calls=expected_tool_calls,
    )
    result: Optional[ReliabilityResult] = evaluation.run(print_results=True)
    if result:
        result.assert_passed()


if __name__ == "__main__":
    evaluate_team_reliability()
```


# Agent with Media
Source: https://docs.agno.com/examples/concepts/integrations/discord/agent_with_media



## Code

```python cookbook/integrations/discord/agent_with_media.py
from agno.agent import Agent
from agno.integrations.discord import DiscordClient
from agno.models.google import Gemini

media_agent = Agent(
    name="Media Agent",
    model=Gemini(id="gemini-2.0-flash"),
    description="A Media processing agent",
    instructions="Analyze images, audios and videos sent by the user",
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
)

discord_agent = DiscordClient(media_agent)
if __name__ == "__main__":
     discord_agent.serve()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export GOOGLE_API_KEY=xxx
    export DISCORD_BOT_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno google-generativeai discord.py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/discord/agent_with_media.py
      ```

      ```bash Windows
      python cookbook/integrations/discord/agent_with_media.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with User Memory
Source: https://docs.agno.com/examples/concepts/integrations/discord/agent_with_user_memory



## Code

```python cookbook/integrations/discord/agent_with_user_memory.py
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.integrations.discord import DiscordClient
from agno.models.google import Gemini
from agno.tools.googlesearch import GoogleSearchTools

db = SqliteDb(db_file="tmp/discord_client_cookbook.db")

personal_agent = Agent(
    name="Basic Agent",
    model=Gemini(id="gemini-2.0-flash"),
    tools=[GoogleSearchTools()],
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
    markdown=True,
    db=db,
    enable_agentic_memory=True,
    instructions=dedent("""
        You are a personal AI friend of the user, your purpose is to chat with the user about things and make them feel good.
        First introduce yourself and ask for their name then, ask about themeselves, their hobbies, what they like to do and what they like to talk about.
        Use Google Search tool to find latest infromation about things in the conversations
                        """),
    debug_mode=True,
)

discord_agent = DiscordClient(personal_agent)
if __name__ == "__main__":
    discord_agent.serve()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export GOOGLE_API_KEY=xxx
    export DISCORD_BOT_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno google-generativeai discord.py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/discord/agent_with_user_memory.py
      ```

      ```bash Windows
      python cookbook/integrations/discord/agent_with_user_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic
Source: https://docs.agno.com/examples/concepts/integrations/discord/basic



## Code

```python cookbook/integrations/discord/basic.py
from agno.agent import Agent
from agno.integrations.discord import DiscordClient
from agno.models.openai import OpenAIChat

basic_agent = Agent(
    name="Basic Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
)

discord_agent = DiscordClient(basic_agent)
if __name__ == "__main__":
    discord_agent.serve()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export DISCORD_BOT_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai discord.py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/discord/basic.py
      ```

      ```bash Windows
      python cookbook/integrations/discord/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Ops
Source: https://docs.agno.com/examples/concepts/integrations/observability/agent_ops



This example shows how to add observability to your agno agent with Agent Ops.

## Code

```python cookbook/integrations/observability/agent_ops.py
import agentops
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Initialize AgentOps
agentops.init()

# Create and run an agent
agent = Agent(model=OpenAIChat(id="gpt-5-mini"))
response = agent.run("Share a 2 sentence horror story")

# Print the response
print(response.content)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    Obtain an API key from [https://app.agentops.ai/](https://app.agentops.ai/)

    ```bash
    export AGENTOPS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno agentops openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/agent_ops.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/agent_ops.py
      ```
    </CodeGroup>

    <Step title="Set your API key">
      You can view the logs in the AgentOps dashboard: [https://app.agentops.ai/](https://app.agentops.ai/)
    </Step>
  </Step>
</Steps>


# Arize Phoenix via OpenInference
Source: https://docs.agno.com/examples/concepts/integrations/observability/arize-phoenix-via-openinference



## Overview

This example demonstrates how to instrument your Agno agent with OpenInference and send traces to Arize Phoenix.

## Code

```python
import asyncio
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from phoenix.otel import register

# Set environment variables for Arize Phoenix
os.environ["PHOENIX_CLIENT_HEADERS"] = f"api_key={os.getenv('ARIZE_PHOENIX_API_KEY')}"
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com"

# Configure the Phoenix tracer
tracer_provider = register(
    project_name="agno-stock-price-agent",  # Default is 'default'
    auto_instrument=True,  # Automatically use the installed OpenInference instrumentation
)

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are an internet search agent. Find and provide accurate information on any topic.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What are the latest developments in artificial intelligence?")
```

## Usage

<Steps>
  <Step title="Install Dependencies">
    ```bash
    pip install -U agno arize-phoenix ddgs openai openinference-instrumentation-agno opentelemetry-sdk opentelemetry-exporter-otlp
    ```
  </Step>

  <Step title="Set Environment Variables">
    ```bash
    export ARIZE_PHOENIX_API_KEY=<your-key>
    ```
  </Step>

  <Step title="Run the Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/observability/arize_phoenix_via_openinference.py
      ```

      ```bash Windows
      python cookbook/observability/arize_phoenix_via_openinference.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Arize Phoenix via OpenInference (Local Collector)
Source: https://docs.agno.com/examples/concepts/integrations/observability/arize-phoenix-via-openinference-local



## Overview

This example demonstrates how to instrument your Agno agent with OpenInference and send traces to a local Arize Phoenix collector.

## Code

```python
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from phoenix.otel import register

# Set the local collector endpoint for Arize Phoenix
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "http://localhost:6006"

# Configure the Phoenix tracer
tracer_provider = register(
    project_name="agno-stock-price-agent",  # Default is 'default'
    auto_instrument=True,  # Automatically use the installed OpenInference instrumentation
)

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are an internet search agent. Find and provide accurate information on any topic.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What are the latest developments in artificial intelligence?")
```

## Usage

<Steps>
  <Step title="Install Dependencies">
    ```bash
    pip install -U agno ddgs arize-phoenix openai openinference-instrumentation-agno opentelemetry-sdk opentelemetry-exporter-otlp
    ```
  </Step>

  <Step title="Start Local Collector">
    Run the following command to start the local collector:

    ```bash
    phoenix serve
    ```
  </Step>

  <Step title="Run the Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/observability/arize_phoenix_via_openinference_local.py
      ```

      ```bash Windows
      python cookbook/observability/arize_phoenix_via_openinference_local.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Atla
Source: https://docs.agno.com/examples/concepts/integrations/observability/atla_op



This example shows how to add observability to your agno agent with Atla.

## Code

```python cookbook/integrations/observability/atla_op.py
from os import getenv

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from atla_insights import configure, instrument_agno

configure(token=getenv("ATLA_API_KEY"))

agent = Agent(
    name="Internet Search Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are an internet search agent. Find and provide accurate information on any topic.",
    debug_mode=True,
)

# Instrument and run
with instrument_agno("openai"):
    agent.print_response("What are the latest developments in artificial intelligence?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    Sign up for an account at [https://app.atla-ai.com](https://app.atla-ai.com)

    ```bash
    export ATLA_API_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno atla-insights openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/atla_op.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/atla_op.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Langfuse Via Openinference
Source: https://docs.agno.com/examples/concepts/integrations/observability/langfuse_via_openinference



## Code

```python cookbook/integrations/observability/langfuse_via_openinference.py
import base64
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
    "https://us.cloud.langfuse.com/api/public/otel"  # üá∫üá∏ US data region
)
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="https://cloud.langfuse.com/api/public/otel" # üá™üá∫ EU data region
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="http://localhost:3000/api/public/otel" # üè† Local deployment (>= v3.22.0)

os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"


tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()


agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are an internet search agent. Find and provide accurate information on any topic.",
    debug_mode=True,
)

agent.print_response("What are the latest developments in artificial intelligence?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    Either self-host or sign up for an account at [https://us.cloud.langfuse.com](https://us.cloud.langfuse.com)

    ```bash
    export LANGFUSE_PUBLIC_KEY=<your-key>
    export LANGFUSE_SECRET_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/langfuse_via_openinference.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/langfuse_via_openinference.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Langfuse Via Openinference (With Structured Output)
Source: https://docs.agno.com/examples/concepts/integrations/observability/langfuse_via_openinference_response_model



## Code

```python cookbook/integrations/observability/langfuse_via_openinference_response_model.py
import base64
import os
from enum import Enum

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from pydantic import BaseModel, Field

LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
    "https://us.cloud.langfuse.com/api/public/otel"  # üá∫üá∏ US data region
)
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="https://cloud.langfuse.com/api/public/otel" # üá™üá∫ EU data region
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="http://localhost:3000/api/public/otel" # üè† Local deployment (>= v3.22.0)

os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"


tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()


class ContentType(Enum):
    NEWS = "news"
    ARTICLE = "article"
    BLOG = "blog"
    RESEARCH = "research"
    OTHER = "other"


class WebSearchResult(BaseModel):
    title: str = Field(description="The title of the search result")
    url: str = Field(description="The URL of the search result")
    snippet: str = Field(description="A brief description or snippet from the result")
    content_type: ContentType = Field(description="The type of content found")
    relevance_score: int = Field(description="Relevance score from 1-10", ge=1, le=10)


agent = Agent(
    name="Web Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are a web research agent. Use DuckDuckGo to search the web and find relevant information. Analyze the search results and provide structured information about what you find.",
    debug_mode=True,
    output_schema=WebSearchResult,
)

agent.print_response("What are the latest developments in artificial intelligence?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    Either self-host or sign up for an account at [https://us.cloud.langfuse.com](https://us.cloud.langfuse.com)

    ```bash
    export LANGFUSE_PUBLIC_KEY=<your-key>
    export LANGFUSE_SECRET_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/langfuse_via_openinference_response_model.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/langfuse_via_openinference_response_model.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Teams with Langfuse Via Openinference
Source: https://docs.agno.com/examples/concepts/integrations/observability/langfuse_via_openinference_team



## Code

```python cookbook/integrations/observability/langfuse_via_openinference_team.py
import base64
import os
from uuid import uuid4

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
    "https://us.cloud.langfuse.com/api/public/otel"  # üá∫üá∏ US data region
)
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="https://cloud.langfuse.com/api/public/otel" # üá™üá∫ EU data region
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="http://localhost:3000/api/public/otel" # üè† Local deployment (>= v3.22.0)

os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"


tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()

# First agent for article summarization
article_agent = Agent(
    name="Article Summarization Agent",
    role="Summarize articles from URLs",
    id="article-summarizer",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[Newspaper4kTools()],
    instructions=[
        "You are a content summarization specialist.",
        "Extract key information from articles and create concise summaries.",
        "Focus on main points, facts, and insights.",
    ],
)

# Second agent for news research
news_research_agent = Agent(
    name="News Research Agent",
    role="Research and find related news",
    id="news-research",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=[
        "You are a news research analyst.",
        "Find relevant and recent news articles on given topics.",
        "Always provide reliable sources and context.",
    ],
)

# Create team with both agents
news_analysis_team = Team(
    name="News Analysis Team",
    id=str(uuid4()),
    user_id=str(uuid4()),
    model=OpenAIChat(id="gpt-5-mini"),
    members=[
        article_agent,
        news_research_agent,
    ],
    instructions=[
        "Coordinate between article summarization and news research.",
        "First summarize any provided articles, then find related news.",
        "Combine information to provide comprehensive analysis.",
    ],
    show_members_responses=True,
    markdown=True,
)

if __name__ == "__main__":
    news_analysis_team.print_response(
        "Please summarize https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime and find related news about scenic train routes in Canada.",
        stream=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    Either self-host or sign up for an account at [https://us.cloud.langfuse.com](https://us.cloud.langfuse.com)

    ```bash
    export LANGFUSE_PUBLIC_KEY=<your-key>
    export LANGFUSE_SECRET_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs newspaper4k langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/langfuse_via_openinference_team.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/langfuse_via_openinference_team.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Langfuse Via Openlit
Source: https://docs.agno.com/examples/concepts/integrations/observability/langfuse_via_openlit



## Code

```python cookbook/integrations/observability/langfuse_via_openlit.py
import base64
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()

os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = (
    "https://us.cloud.langfuse.com/api/public/otel"  # üá∫üá∏ US data region
)
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="https://cloud.langfuse.com/api/public/otel" # üá™üá∫ EU data region
# os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"]="http://localhost:3000/api/public/otel" # üè† Local deployment (>= v3.22.0)

os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

from opentelemetry.exporter.otlp.proto.http.trace_exporter import (  # noqa: E402
    OTLPSpanExporter,
)
from opentelemetry.sdk.trace import TracerProvider  # noqa: E402
from opentelemetry.sdk.trace.export import SimpleSpanProcessor  # noqa: E402

trace_provider = TracerProvider()
trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))

# Sets the global default tracer provider
from opentelemetry import trace  # noqa: E402

trace.set_tracer_provider(trace_provider)

# Creates a tracer from the global tracer provider
tracer = trace.get_tracer(__name__)

import openlit  # noqa: E402

# Initialize OpenLIT instrumentation. The disable_batch flag is set to true to process traces immediately.
openlit.init(tracer=tracer, disable_batch=True)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
    debug_mode=True,
)

agent.print_response("What is currently trending on Twitter?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    Set your Langfuse API key as an environment variables:

    ```bash
    export LANGFUSE_PUBLIC_KEY=<your-key>
    export LANGFUSE_SECRET_KEY=<your-key>
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai langfuse openlit opentelemetry-sdk opentelemetry-exporter-otlp ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/langfuse_via_openlit.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/langfuse_via_openlit.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LangSmith
Source: https://docs.agno.com/examples/concepts/integrations/observability/langsmith-via-openinference



## Overview

This example demonstrates how to instrument your Agno agent with OpenInference and send traces to LangSmith.

## Code

```python
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

# Set the endpoint and headers for LangSmith
endpoint = "https://eu.api.smith.langchain.com/otel/v1/traces"
headers = {
    "x-api-key": os.getenv("LANGSMITH_API_KEY"),
    "Langsmith-Project": os.getenv("LANGSMITH_PROJECT"),
}

# Configure the tracer provider
tracer_provider = TracerProvider()
tracer_provider.add_span_processor(
    SimpleSpanProcessor(OTLPSpanExporter(endpoint=endpoint, headers=headers))
)
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()

# Create and configure the agent
agent = Agent(
    name="Stock Market Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True
)

# Use the agent
agent.print_response("What is news on the stock market?")
```

## Usage

<Steps>
  <Step title="Install Dependencies">
    ```bash
    pip install agno openai ddgs openinference-instrumentation-agno opentelemetry-sdk opentelemetry-exporter-otlp
    ```
  </Step>

  <Step title="Set Environment Variables">
    ```bash
    export LANGSMITH_API_KEY=<your-key>
    export LANGSMITH_TRACING=true
    export LANGSMITH_ENDPOINT=https://eu.api.smith.langchain.com  # or https://api.smith.langchain.com for US
    export LANGSMITH_PROJECT=<your-project-name>
    ```
  </Step>

  <Step title="Run the Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/observability/langsmith_via_openinference.py
      ```

      ```bash Windows
      python cookbook/observability/langsmith_via_openinference.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Notes

* **Data Regions**: Choose the appropriate `LANGSMITH_ENDPOINT` based on your data region.


# Langtrace
Source: https://docs.agno.com/examples/concepts/integrations/observability/langtrace-op



## Overview

This example demonstrates how to instrument your Agno agent with Langtrace for tracing and monitoring.

## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from langtrace_python_sdk import langtrace
from langtrace_python_sdk.utils.with_root_span import with_langtrace_root_span

# Initialize Langtrace
langtrace.init()

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What is the current price of Tesla?")
```

## Usage

<Steps>
  <Step title="Install Dependencies">
    ```bash
    pip install agno openai langtrace-python-sdk
    ```
  </Step>

  <Step title="Set Environment Variables">
    ```bash
    export LANGTRACE_API_KEY=<your-key>
    ```
  </Step>

  <Step title="Run the Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/observability/langtrace_op.py
      ```

      ```bash Windows
      python cookbook/observability/langtrace_op.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Notes

* **Initialization**: Call `langtrace.init()` to initialize Langtrace before using the agent.


# Langwatch
Source: https://docs.agno.com/examples/concepts/integrations/observability/langwatch_op



This example shows how to instrument your agno agent and send traces to LangWatch.

## Code

```python cookbook/integrations/observability/langwatch_op.py
import langwatch
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from openinference.instrumentation.agno import AgnoInstrumentor

# Initialize LangWatch and instrument Agno
langwatch.setup(instrumentors=[AgnoInstrumentor()])

# Create and configure your Agno agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are an internet search agent. Find and provide accurate information on any topic.",
    debug_mode=True,
)

agent.print_response("What are the latest developments in artificial intelligence?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ````bash
    - Sign up for an account at https://app.langwatch.ai/.
    - Set your LangWatch API key as an environment variables:
    ```bash
    export LANGWATCH_API_KEY=<your-key>
    ````

    ````
    </Step>

    <Step title="Install libraries">
    ```bash
    pip install -U agno openai ddgs langwatch openinference-instrumentation-agno
    ````
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/integrations/observability/langwatch_op.py
      ```

      ```bash Windows
      python cookbook/integrations/observability/langwatch_op.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Maxim
Source: https://docs.agno.com/examples/concepts/integrations/observability/maxim



This example shows how to instrument your agno agent and send traces to Maxim AI. We are building a simple Financial Conversation Agent.

# Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

try:
    from maxim import Maxim
    from maxim.logger.agno import instrument_agno
except ImportError:
    raise ImportError(
        "`maxim` not installed. Please install using `pip install maxim-py`"
    )

# Instrument Agno with Maxim for automatic tracing and logging
instrument_agno(Maxim().logger())

# Web Search Agent: Fetches financial information from the web
web_search_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    markdown=True,
)

# Finance Agent: Gets financial data using YFinance tools
finance_agent = Agent(
    name="Finance Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[YFinanceTools()],
    instructions="Use tables to display data",
    markdown=True,
)

# Aggregate both agents into a multi-agent system
multi_ai_team = Team(
    members=[web_search_agent, finance_agent],
    model=OpenAIChat(id="gpt-4o"),
    instructions="You are a helpful financial assistant. Answer user questions about stocks, companies, and financial data.",
    markdown=True,
)

if __name__ == "__main__":
    print("Welcome to the Financial Conversational Agent! Type 'exit' to quit.")
    messages = []
    while True:
        print("********************************")
        user_input = input("You: ")
        if user_input.strip().lower() in ["exit", "quit"]:
            print("Goodbye!")
            break
        messages.append({"role": "user", "content": user_input})
        conversation = "\n".join(
            [
                ("User: " + m["content"])
                if m["role"] == "user"
                else ("Agent: " + m["content"])
                for m in messages
            ]
        )
        response = multi_ai_team.run(
            f"Conversation so far:\n{conversation}\n\nRespond to the latest user message."
        )
        agent_reply = getattr(response, "content", response)
        print("---------------------------------")
        print("Agent:", agent_reply)
        messages.append({"role": "agent", "content": str(agent_reply)})
```


# Weave
Source: https://docs.agno.com/examples/concepts/integrations/observability/weave-op



## Overview

This example demonstrates how to use Weave by Weights & Biases (WandB) to log model calls from your Agno agent.

## Code

```python
import weave
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Create and configure the agent
agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True, debug_mode=True)

# Initialize Weave with your project name
weave.init("agno")

# Define a function to run the agent, decorated with weave.op()
@weave.op()
def run(content: str):
    return agent.run(content)

# Use the function to log a model call
run("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Step title="Install Weave">
    ```bash
    pip install agno openai weave
    ```
  </Step>

  <Step title="Authenticate with WandB">
    * Go to [WandB](https://wandb.ai) and copy your API key from [here](https://wandb.ai/authorize).
    * Enter your API key in the terminal when prompted, or export it as an environment variable:

    ```bash
    export WANDB_API_KEY=<your-api-key>
    ```
  </Step>

  <Step title="Run the Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/observability/weave_op.py
      ```

      ```bash Windows
      python cookbook/observability/weave_op.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Notes

* **Initialization**: Call `weave.init("project-name")` to initialize Weave with your project name.
* **Decorators**: Use `@weave.op()` to decorate functions you want to log with Weave.


# Scenario Testing
Source: https://docs.agno.com/examples/concepts/integrations/testing/scenario/basic



This example demonstrates how to use the [Scenario](https://github.com/langwatch/scenario) framework for agentic simulation-based testing. Scenario enables you to simulate conversations between agents, user simulators, and judges, making it easy to test and evaluate agent behaviors in a controlled environment.

> **Tip:** Want to see a more advanced scenario? Check out the [Customer support scenario example](https://github.com/langwatch/create-agent-app/tree/main/agno_example) for a more complex agent, including tool calls and advanced scenario features.

## Code

```python cookbook/agent_concepts/other/scenario_testing.py
import pytest
import scenario
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Configure Scenario defaults (model for user simulator and judge)
scenario.configure(default_model="openai/gpt-4.1-mini")

@pytest.mark.agent_test
@pytest.mark.asyncio
async def test_vegetarian_recipe_agent() -> None:
    # 1. Define an AgentAdapter to wrap your agent
    class VegetarianRecipeAgentAdapter(scenario.AgentAdapter):
        agent: Agent

        def __init__(self) -> None:
            self.agent = Agent(
                model=OpenAIChat(id="gpt-4.1-mini"),
                markdown=True,
                debug_mode=True,
                instructions="You are a vegetarian recipe agent.",
            )

        async def call(self, input: scenario.AgentInput) -> scenario.AgentReturnTypes:
            response = self.agent.run(
                input=input.last_new_user_message_str(), # Pass only the last user message
                session_id=input.thread_id, # Pass the thread id, this allows the agent to track history
            )
            return response.content

    # 2. Run the scenario simulation
    result = await scenario.run(
        name="dinner recipe request",
        description="User is looking for a vegetarian dinner idea.",
        agents=[
            VegetarianRecipeAgentAdapter(),
            scenario.UserSimulatorAgent(),
            scenario.JudgeAgent(
                criteria=[
                    "Agent should not ask more than two follow-up questions",
                    "Agent should generate a recipe",
                    "Recipe should include a list of ingredients",
                    "Recipe should include step-by-step cooking instructions",
                    "Recipe should be vegetarian and not include any sort of meat",
                ]
            ),
        ],
    )

    # 3. Assert and inspect the result
    assert result.success
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export LANGWATCH_API_KEY=xxx # Optional, required for Simulation monitoring
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno langwatch-scenario pytest pytest-asyncio
    # or
    uv add agno langwatch-scenario openai pytest
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    pytest cookbook/agent_concepts/other/scenario_testing.py
    ```
  </Step>
</Steps>


# Include and Exclude Files
Source: https://docs.agno.com/examples/concepts/knowledge/basic-operations/include-exclude-files



## Code

```python 08_include_exclude_files.py
import asyncio
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

# Add from local file to the knowledge base
asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources",
        metadata={"user_tag": "Engineering Candidates"},
        # Only include PDF files
        include=["*.pdf"],
        # Don't include files that match this pattern
        exclude=["*cv_5*"],
    )
)

agent = Agent(
    name="My Agent",
    description="Agno 2.0 Agent Implementation",
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

agent.print_response(
    "Who is the best candidate for the role of a software engineer?",
    markdown=True,
)

# Alex River is not in the knowledge base, so the Agent should not find any information about him
agent.print_response(
    "Do you think Alex Rivera is a good candidate?",
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector openai    
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/08_include_exclude_files.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/08_include_exclude_files.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Remove Content
Source: https://docs.agno.com/examples/concepts/knowledge/basic-operations/remove-content



## Code

```python 09_remove_content.py
import asyncio
from agno.db.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    contents_db=PostgresDb(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        knowledge_table="knowledge_contents",
    ),
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"user_tag": "Engineering Candidates"},
    )
)


# Remove content and vectors by id
contents, _ = knowledge.get_content()
for content in contents:
    print(content.id)
    print(" ")
    knowledge.remove_content_by_id(content.id)

# Remove all content
knowledge.remove_all_content()
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/09_remove_content.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/09_remove_content.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Remove Vectors
Source: https://docs.agno.com/examples/concepts/knowledge/basic-operations/remove-vectors



## Code

```python 10_remove_vectors.py
import asyncio
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"user_tag": "Engineering Candidates"},
    )
)


knowledge.remove_vectors_by_metadata({"user_tag": "Engineering Candidates"})

# Add from local file to the knowledge base
asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"user_tag": "Engineering Candidates"},
    )
)

knowledge.remove_vectors_by_name("CV")
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/10_remove_vectors.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/10_remove_vectors.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Skip If Exists
Source: https://docs.agno.com/examples/concepts/knowledge/basic-operations/skip-if-exists



## Code

```python 11_skip_if_exists.py
import asyncio
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

# Add from local file to the knowledge base
asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"user_tag": "Engineering Candidates"},
        skip_if_exists=True,  # True by default
    )
)

# Add from local file to the knowledge base, but don't skip if it already exists
asyncio.run(
    knowledge.add_content_async(
        name="CV",
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
        metadata={"user_tag": "Engineering Candidates"},
        skip_if_exists=False,
    )
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/11_skip_if_exists.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/11_skip_if_exists.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Sync Operations
Source: https://docs.agno.com/examples/concepts/knowledge/basic-operations/sync-operations



This example shows how to add content to your knowledge base synchronously. While async operations are recommended for better performance, sync operations can be useful in certain scenarios.

## Code

```python 13_sync.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

contents_db = PostgresDb(
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    knowledge_table="knowledge_contents",
)
# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

knowledge.add_content(
    name="CV",
    path="cookbook/knowledge/testing_resources/cv_1.pdf",
    metadata={"user_tag": "Engineering Candidates"},
)


agent = Agent(
    name="My Agent",
    description="Agno 2.0 Agent Implementation",
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

agent.print_response(
    "What skills does Jordan Mitchell have?",
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/13_sync.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/13_sync.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/agentic-chunking



Agentic chunking is an intelligent method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text. Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.agentic import AgenticChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_agentic_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Agentic Chunking Reader",
        chunking_strategy=AgenticChunking(),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/agentic_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/agentic_chunking.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Agentic Chunking Params

<Snippet file="chunking-agentic.mdx" />


# CSV Row Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/csv-row-chunking



CSV row chunking is a method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text. Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.row import RowChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.csv_reader import CSVReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="imdb_movies_row_chunking", db_url=db_url),
)

asyncio.run(knowledge_base.add_content_async(
    url="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    reader=CSVReader(
        chunking_strategy=RowChunking(),
    ),
))  

# Initialize the Agent with the knowledge_base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Use the agent 
agent.print_response("Tell me about the movie Guardians of the Galaxy", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/csv_row_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/csv_row_chunking.py 
      ```
    </CodeGroup>
  </Step>
</Steps>

## CSV Row Chunking Params

<Snippet file="chunking-csv-row.mdx" />


# Document Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/document-chunking



Document chunking is a method of splitting documents into smaller chunks based on document structure like paragraphs and sections. It analyzes natural document boundaries rather than splitting at fixed character counts. This is useful when you want to process large documents while preserving semantic meaning and context.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.document import DocumentChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_document_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Document Chunking Reader",
        chunking_strategy=DocumentChunking(),
    ),
))

agent = agentic_rag_with_reranking(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/document_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/document_chunking.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Document Chunking Params

<Snippet file="chunking-document.mdx" />


# Fixed Size Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/fixed-size-chunking



Fixed size chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks. This is useful when you want to process large documents in smaller, manageable pieces.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.fixed import FixedSizeChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_fixed_size_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Fixed Size Chunking Reader",
        chunking_strategy=FixedSizeChunking(),
    ),
))
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/fixed_size_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/fixed_size_chunking.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Fixed Size Chunking Params

<Snippet file="chunking-fixed-size.mdx" />


# Markdown Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/markdown-chunking



Markdown chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks. This is useful when you want to process large documents in smaller, manageable pieces.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.markdown import MarkdownChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.markdown_reader import MarkdownReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_markdown_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://github.com/agno-agi/agno/blob/main/README.md",
    reader=MarkdownReader(
        name="Markdown Chunking Reader",
        chunking_strategy=MarkdownChunking(),
    ),
))
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("What is Agno?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/markdown_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/markdown_chunking.py 
      ```
    </CodeGroup>
  </Step>
</Steps>

## Markdown Chunking Params

<Snippet file="chunking-markdown.mdx" />


# Recursive Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/recursive-chunking



Recursive chunking is a method of splitting documents into smaller chunks by recursively applying a chunking strategy. This is useful when you want to process large documents in smaller, manageable pieces.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.recursive import RecursiveChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_recursive_chunking", db_url=db_url),
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Recursive Chunking Reader",
        chunking_strategy=RecursiveChunking(),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)


```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/recursive_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/recursive_chunking.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Recursive Chunking Params

<Snippet file="chunking-recursive.mdx" />


# Semantic Chunking
Source: https://docs.agno.com/examples/concepts/knowledge/chunking/semantic-chunking



Semantic chunking is a method of splitting documents into smaller chunks by analyzing semantic similarity between text segments using embeddings. It uses the chonkie library to identify natural breakpoints where the semantic meaning changes significantly, based on a configurable similarity threshold. This helps preserve context and meaning better than fixed-size chunking by ensuring semantically related content stays together in the same chunk, while splitting occurs at meaningful topic transitions.

## Code

```python
import asyncio
from agno.agent import Agent
from agno.knowledge.chunking.semantic import SemanticChunking
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes_semantic_chunking", db_url=db_url),
)
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        name="Semantic Chunking Reader",
        chunking_strategy=SemanticChunking(similarity_threshold=0.5),
    ),
))

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno chonkie
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/chunking/semantic_chunking.py
      ```

      ```bash Windows
      python cookbook/knowledge/chunking/semantic_chunking.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Semantic Chunking Params

<Snippet file="chunking-semantic.mdx" />


# Async Custom Retriever
Source: https://docs.agno.com/examples/concepts/knowledge/custom_retriever/async-custom-retriever



## Code

```python async_retriever.py
import asyncio
from typing import Optional

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from qdrant_client import AsyncQdrantClient

# ---------------------------------------------------------
# This section loads the knowledge base. Skip if your knowledge base was populated elsewhere.
# Define the embedder
embedder = OpenAIEmbedder(id="text-embedding-3-small")
# Initialize vector database connection
vector_db = Qdrant(
    collection="thai-recipes", url="http://localhost:6333", embedder=embedder
)
# Load the knowledge base
knowledge = Knowledge(
    vector_db=vector_db,
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
))


# ---------------------------------------------------------
# Define the custom async knowledge retriever
# This is the function that the agent will use to retrieve documents
async def knowledge_retriever(
    query: str, agent: Optional[Agent] = None, num_documents: int = 5, **kwargs
) -> Optional[list[dict]]:
    """
    Custom async knowledge retriever function to search the vector database for relevant documents.

    Args:
        query (str): The search query string
        agent (Agent): The agent instance making the query
        num_documents (int): Number of documents to retrieve (default: 5)
        **kwargs: Additional keyword arguments

    Returns:
        Optional[list[dict]]: List of retrieved documents or None if search fails
    """
    try:
        qdrant_client = AsyncQdrantClient(url="http://localhost:6333")
        query_embedding = embedder.get_embedding(query)
        results = await qdrant_client.query_points(
            collection_name="thai-recipes",
            query=query_embedding,
            limit=num_documents,
        )
        results_dict = results.model_dump()
        if "points" in results_dict:
            return results_dict["points"]
        else:
            return None
    except Exception as e:
        print(f"Error during vector database search: {str(e)}")
        return None


async def amain():
    """Async main function to demonstrate agent usage."""
    # Initialize agent with custom knowledge retriever
    # Remember to set search_knowledge=True to use agentic_rag or add_reference=True for traditional RAG
    # search_knowledge=True is default when you add a knowledge base but is needed here
    agent = Agent(
        knowledge_retriever=knowledge_retriever,
        search_knowledge=True,
        instructions="Search the knowledge base for information",
    )

    # Example query
    query = "List down the ingredients to make Massaman Gai"
    await agent.aprint_response(query, markdown=True)


def main():
    """Synchronous wrapper for main function"""
    asyncio.run(amain())


if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno openai qdrant-client
    ```
  </Step>

  <Step title="Run Qdrant">
    ```bash
    docker run -p 6333:6333 qdrant/qdrant
    ```
  </Step>

  <Step title="Set OpenAI API key">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key_here
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/custom_retriever/async_retriever.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/custom_retriever/async_retriever.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Custom Retriever
Source: https://docs.agno.com/examples/concepts/knowledge/custom_retriever/custom-retriever



## Code

```python retriever.py
from typing import Optional

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from qdrant_client import QdrantClient

# ---------------------------------------------------------
# This section loads the knowledge base. Skip if your knowledge base was populated elsewhere.
# Define the embedder
embedder = OpenAIEmbedder(id="text-embedding-3-small")
# Initialize vector database connection
vector_db = Qdrant(
    collection="thai-recipes", url="http://localhost:6333", embedder=embedder
)
# Load the knowledge base
knowledge = Knowledge(
    vector_db=vector_db,
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

# ---------------------------------------------------------


# Define the custom knowledge retriever
# This is the function that the agent will use to retrieve documents
def knowledge_retriever(
    query: str, agent: Optional[Agent] = None, num_documents: int = 5, **kwargs
) -> Optional[list[dict]]:
    """
    Custom knowledge retriever function to search the vector database for relevant documents.

    Args:
        query (str): The search query string
        agent (Agent): The agent instance making the query
        num_documents (int): Number of documents to retrieve (default: 5)
        **kwargs: Additional keyword arguments

    Returns:
        Optional[list[dict]]: List of retrieved documents or None if search fails
    """
    try:
        qdrant_client = QdrantClient(url="http://localhost:6333")
        query_embedding = embedder.get_embedding(query)
        results = qdrant_client.query_points(
            collection_name="thai-recipes",
            query=query_embedding,
            limit=num_documents,
        )
        results_dict = results.model_dump()
        if "points" in results_dict:
            return results_dict["points"]
        else:
            return None
    except Exception as e:
        print(f"Error during vector database search: {str(e)}")
        return None


def main():
    """Main function to demonstrate agent usage."""
    # Initialize agent with custom knowledge retriever
    # Remember to set search_knowledge=True to use agentic_rag or add_reference=True for traditional RAG
    # search_knowledge=True is default when you add a knowledge base but is needed here
    agent = Agent(
        knowledge_retriever=knowledge_retriever,
        search_knowledge=True,
        instructions="Search the knowledge base for information",
    )

    # Example query
    query = "List down the ingredients to make Massaman Gai"
    agent.print_response(query, markdown=True)


if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno openai qdrant-client
    ```
  </Step>

  <Step title="Run Qdrant">
    ```bash
    docker run -p 6333:6333 qdrant/qdrant
    ```
  </Step>

  <Step title="Set OpenAI API key">
    ```bash
    export OPENAI_API_KEY=your_openai_api_key_here
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/custom_retriever/retriever.py
      ```

      ```bash Windows
      python cookbook/knowledge/custom_retriever/retriever.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# AWS Bedrock Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/aws-bedrock-embedder



## Code

```python cookbook/knowledge/embedders/aws_bedrock_embedder.py
import asyncio
from agno.knowledge.embedder.aws_bedrock import AwsBedrockEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

embeddings = AwsBedrockEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)
# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        embedder=AwsBedrockEmbedder(),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    reader=PDFReader(
        chunk_size=2048
    ),  # Required because cohere has a fixed size of 2048
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AWS_ACCESS_KEY_ID=xxx
    export AWS_SECRET_ACCESS_KEY=xxx
    export AWS_REGION=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector boto3 agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/azure_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/azure_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure OpenAI Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/azure-embedder



## Code

```python
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = AzureOpenAIEmbedder(id="text-embedding-3-small").get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(),
    ),
    max_results=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_EMBEDDER_OPENAI_API_KEY=xxx
    export AZURE_EMBEDDER_OPENAI_ENDPOINT=xxx
    export AZURE_EMBEDDER_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector openai agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/azure_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/azure_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cohere Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/cohere-embedder



## Code

```python
import asyncio
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = CohereEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)
# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="cohere_embeddings",
        embedder=CohereEmbedder(
            dimensions=1024,
        ),
    ),
    max_results=2,
)

asyncio.run(
    knowledge.add_content_async(
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
    )
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export COHERE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector cohere agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/cohere_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/cohere_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Fireworks Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/fireworks-embedder



## Code

```python
from agno.knowledge.embedder.fireworks import FireworksEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = FireworksEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="fireworks_embeddings",
        embedder=FireworksEmbedder(),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector fireworks-ai agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/fireworks_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/fireworks_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Gemini Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/gemini-embedder



## Code

```python
from agno.knowledge.embedder.google import GeminiEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = GeminiEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="gemini_embeddings",
        embedder=GeminiEmbedder(),
    ),
    max_results=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector google-generativeai agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/gemini_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/gemini_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Huggingface Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/huggingface-embedder



## Code

```python
from agno.knowledge.embedder.huggingface import HuggingfaceCustomEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = HuggingfaceCustomEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="huggingface_embeddings",
        embedder=HuggingfaceCustomEmbedder(),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HUGGINGFACE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector huggingface-hub agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/huggingface_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/huggingface_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Jina Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/jina-embedder



## Code

```python

from agno.knowledge.embedder.jina import JinaEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

# Basic usage - automatically loads from JINA_API_KEY environment variable
embeddings = JinaEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

custom_embedder = JinaEmbedder(
    dimensions=1024,
    late_chunking=True,  # Improved processing for long documents
    timeout=30.0,  # Request timeout in seconds
)

# Get embedding with usage information
embedding, usage = custom_embedder.get_embedding_and_usage(
    "Advanced text processing with Jina embeddings and late chunking."
)
print(f"Embedding dimensions: {len(embedding)}")
if usage:
    print(f"Usage info: {usage}")

# Example usage with Knowledge
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="jina_embeddings",
        embedder=JinaEmbedder(
            late_chunking=True,  # Better handling of long documents
            timeout=30.0,  # Configure request timeout
        ),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export JINA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector aiohttp requests agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/jina_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/jina_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# LangDB Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/langdb-embedder



## Code

```python

from agno.knowledge.embedder.langdb import LangDBEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = LangDBEmbedder().get_embedding("Embed me")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="langdb_embeddings",
        embedder=LangDBEmbedder(),
    ),
    max_results=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LANGDB_API_KEY=xxx
    export LANGDB_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/langdb_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/langdb_embedder.py     
      ```
    </CodeGroup>
  </Step>
</Steps>


# Mistral Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/mistral-embedder



## Code

```python
import asyncio

from agno.knowledge.embedder.mistral import MistralEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = MistralEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="mistral_embeddings",
        embedder=MistralEmbedder(),
    ),
    max_results=2,
)

asyncio.run(
    knowledge.add_content_async(
        path="cookbook/knowledge/testing_resources/cv_1.pdf",
    )
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector mistralai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/mistral_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/mistral_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Nebius Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/nebius-embedder



## Code

```python
from agno.knowledge.embedder.nebius import NebiusEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = NebiusEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="nebius_embeddings",
        embedder=NebiusEmbedder(),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NEBIUS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector  agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/nebius_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/nebius_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Ollama Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/ollama-embedder



## Code

```python
from agno.knowledge.embedder.ollama import OllamaEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = OllamaEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="ollama_embeddings",
        embedder=OllamaEmbedder(),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the installation instructions at [Ollama's website](https://ollama.ai)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/ollama_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/ollama_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/openai-embedder



## Code

```python
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = OpenAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/openai_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/openai_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Qdrant FastEmbed Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/qdrant-fastembed



## Code

```python
from agno.knowledge.embedder.fastembed import FastEmbedEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = FastEmbedEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="qdrant_embeddings",
        embedder=FastEmbedEmbedder(),
    ),
    max_results=2,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector fastembed agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/qdrant_fastembed.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/qdrant_fastembed.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Sentence Transformer Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/sentence-transformer-embedder



## Code

```python
from agno.knowledge.embedder.sentence_transformer import SentenceTransformerEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = SentenceTransformerEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="sentence_transformer_embeddings",
        embedder=SentenceTransformerEmbedder(),
    ),
    max_results=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector sentence-transformers agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/sentence_transformer_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/sentence_transformer_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Together Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/together-embedder



## Code

```python
from agno.knowledge.embedder.together import TogetherEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = TogetherEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="together_embeddings",
        embedder=TogetherEmbedder(),
    ),
    max_results=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector  agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/together_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/together_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# VoyageAI Embedder
Source: https://docs.agno.com/examples/concepts/knowledge/embedders/voyageai-embedder



## Code

```python
from agno.knowledge.embedder.voyageai import VoyageAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

embeddings = VoyageAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="voyageai_embeddings",
        embedder=VoyageAIEmbedder(),
    ),
    max_results=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector voyageai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/embedders/voyageai_embedder.py
      ```

      ```bash Windows
      python cookbook/knowledge/embedders/voyageai_embedder.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic Filtering
Source: https://docs.agno.com/examples/concepts/knowledge/filters/agentic-filtering



## Code

```python cookbook/knowledge/filters/agentic_filtering.py
import asyncio
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample sales files and get their paths
downloaded_csv_paths = download_knowledge_filters_sample_data(
    num_files=4, file_extension=SampleDataFileExtension.CSV
)

# Initialize LanceDB
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------

knowledge = Knowledge(
    name="CSV Knowledge Base",
    description="A knowledge base for CSV files",
    vector_db=vector_db,
)

# Load all documents into the vector database
asyncio.run(knowledge.add_contents_async(
    [
        {
            "path": downloaded_csv_paths[0],
            "metadata": {
                "data_type": "sales",
                "quarter": "Q1",
                "year": 2024,
                "region": "north_america",
                "currency": "USD",
            },
        },
        {
            "path": downloaded_csv_paths[1],
            "metadata": {
                "data_type": "sales",
                "year": 2024,
                "region": "europe",
                "currency": "EUR",
            },
        },
        {
            "path": downloaded_csv_paths[2],
            "metadata": {
                "data_type": "survey",
                "survey_type": "customer_satisfaction",
                "year": 2024,
                "target_demographic": "mixed",
            },
        },
        {
            "path": downloaded_csv_paths[3],
            "metadata": {
                "data_type": "financial",
                "sector": "technology",
                "year": 2024,
                "report_type": "quarterly_earnings",
            },
        },
    ]
))
# Step 2: Query the knowledge base with Agent using filters from query automatically
# -----------------------------------------------------------------------------------

# Enable agentic filtering
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    enable_agentic_knowledge_filters=True,
)

agent.print_response(
    "Tell me about revenue performance and top selling products in the region north_america and data_type sales",
    markdown=True,
)

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno lancedb openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/agentic_filtering.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/agentic_filtering.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Filtering
Source: https://docs.agno.com/examples/concepts/knowledge/filters/async-filtering



## Code

```python
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.DOCX
)

# Initialize LanceDB
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge base, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    name="Async Filtering",
    vector_db=vector_db,
)

asyncio.run(knowledge.add_contents_async(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ],
))


# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

# Option 1: Filters on the Agent
# Initialize the Agent with the knowledge base and filters
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

if __name__ == "__main__":
    # Query for Jordan Mitchell's experience and skills
    asyncio.run(
        agent.aprint_response(
            "Tell me about Jordan Mitchell's experience and skills",
            knowledge_filters={"user_id": "jordan_mitchell"},
            markdown=True,
        )
    )
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/async_filtering.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering
Source: https://docs.agno.com/examples/concepts/knowledge/filters/filtering



## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample sales documents and get their paths
downloaded_csv_paths = download_knowledge_filters_sample_data(
    num_files=4, file_extension=SampleDataFileExtension.CSV
)

# Initialize LanceDB
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Step 1: Initialize knowledge with documents and metadata
# -----------------------------------------------------------------------------
knowledge = Knowledge(
    name="CSV Knowledge Base",
    description="A knowledge base for CSV files",
    vector_db=vector_db,
)

# Load all documents into the vector database
knowledge.add_contents(
    [
        {
            "path": downloaded_csv_paths[0],
            "metadata": {
                "data_type": "sales",
                "quarter": "Q1",
                "year": 2024,
                "region": "north_america",
                "currency": "USD",
            },
        },
        {
            "path": downloaded_csv_paths[1],
            "metadata": {
                "data_type": "sales",
                "year": 2024,
                "region": "europe",
                "currency": "EUR",
            },
        },
        {
            "path": downloaded_csv_paths[2],
            "metadata": {
                "data_type": "survey",
                "survey_type": "customer_satisfaction",
                "year": 2024,
                "target_demographic": "mixed",
            },
        },
        {
            "path": downloaded_csv_paths[3],
            "metadata": {
                "data_type": "financial",
                "sector": "technology",
                "year": 2024,
                "report_type": "quarterly_earnings",
            },
        },
    ],
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------
na_sales = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

na_sales.print_response(
    "Revenue performance and top selling products",
    knowledge_filters={"region": "north_america", "data_type": "sales"},
    markdown=True,
)       

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/filtering.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/filtering.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on Load
Source: https://docs.agno.com/examples/concepts/knowledge/filters/filtering_on_load



## Code

```python
from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample sales files and get their paths
downloaded_csv_paths = download_knowledge_filters_sample_data(
    num_files=4, file_extension=SampleDataFileExtension.CSV
)

# Initialize LanceDB
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------
# When loading the knowledge base, we can attach metadata that will be used for filtering

# Initialize Knowledge
knowledge = Knowledge(
    vector_db=vector_db,
    max_results=5,
    contents_db=PostgresDb(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        knowledge_table="knowledge_contents",
    ),
)

knowledge.add_content(
    path=downloaded_csv_paths[0],
    metadata={
        "data_type": "sales",
        "quarter": "Q1",
        "year": 2024,
        "region": "north_america",
        "currency": "USD",
    },
)

knowledge.add_content(
    path=downloaded_csv_paths[1],
    metadata={
        "data_type": "sales",
        "year": 2024,
        "region": "europe",
        "currency": "EUR",
    },
)

knowledge.add_content(
    path=downloaded_csv_paths[2],
    metadata={
        "data_type": "survey",
        "survey_type": "customer_satisfaction",
        "year": 2024,
        "target_demographic": "mixed",
    },
)

knowledge.add_content(
    path=downloaded_csv_paths[3],
    metadata={
        "data_type": "financial",
        "sector": "technology",
        "year": 2024,
        "report_type": "quarterly_earnings",
    },
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    knowledge_filters={"region": "north_america", "data_type": "sales"},
)
agent.print_response(
    "Revenue performance and top selling products",
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/filtering_on_load.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/filtering_on_load.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering with Invalid Keys
Source: https://docs.agno.com/examples/concepts/knowledge/filters/filtering_with_invalid_keys



## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample sales documents and get their paths
downloaded_csv_paths = download_knowledge_filters_sample_data(
    num_files=4, file_extension=SampleDataFileExtension.CSV
)

# Initialize LanceDB
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Step 1: Initialize knowledge with documents and metadata
# -----------------------------------------------------------------------------
knowledge = Knowledge(
    name="CSV Knowledge Base",
    description="A knowledge base for CSV files",
    vector_db=vector_db,
)

# Load all documents into the vector database
knowledge.add_contents(
    [
        {
            "path": downloaded_csv_paths[0],
            "metadata": {
                "data_type": "sales",
                "quarter": "Q1",
                "year": 2024,
                "region": "north_america",
                "currency": "USD",
            },
        },
        {
            "path": downloaded_csv_paths[1],
            "metadata": {
                "data_type": "sales",
                "year": 2024,
                "region": "europe",
                "currency": "EUR",
            },
        },
        {
            "path": downloaded_csv_paths[2],
            "metadata": {
                "data_type": "survey",
                "survey_type": "customer_satisfaction",
                "year": 2024,
                "target_demographic": "mixed",
            },
        },
        {
            "path": downloaded_csv_paths[3],
            "metadata": {
                "data_type": "financial",
                "sector": "technology",
                "year": 2024,
                "report_type": "quarterly_earnings",
            },
        },
    ],
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------
na_sales = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

na_sales.print_response(
    "Revenue performance and top selling products",
    # Use "location" instead of "region" and we should receive a warning that the key is invalid
    knowledge_filters={"location": "north_america", "data_type": "sales"},
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/filtering_with_invalid_keys.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/filtering_with_invalid_keys.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on ChromaDB
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_chroma_db

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in ChromaDB.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.chroma import ChromaDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize ChromaDB
vector_db = ChromaDb(collection="recipes", path="tmp/chromadb", persistent_client=True)

# Step 1: Initialize knowledge with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    name="ChromaDB Knowledge Base",
    description="A knowledge base for ChromaDB",
    vector_db=vector_db,
)

# Load all documents into the vector database
knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)
# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno chromadb openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_chroma_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_chroma_db.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on LanceDB
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_lance_db

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in LanceDB.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize LanceDB
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge base, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    name="LanceDB Knowledge Base",
    description="A knowledge base for LanceDB",
    vector_db=vector_db,
)

knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ],
)
# Load all documents into the vector database

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno lancedb openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_lance_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_lance_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on MilvusDB
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_milvus_db

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in MilvusDB.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.milvus import Milvus

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize Milvus vector db
vector_db = Milvus(
    collection="recipes",
    uri="tmp/milvus.db",
)

# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge base, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    name="Milvus Knowledge Base",
    description="A knowledge base for Milvus",
    vector_db=vector_db,
)

knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)

# Load all documents into the vector database

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno pymilvus openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Milvus">
    ```bash
    docker run -d --name local-milvus -p 19530:19530 -p 19121:19121 -v milvus-data:/var/lib/milvus/data milvusdb/milvus:2.5.0
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_milvus_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_milvus_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on MongoDB
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_mongo_db

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in MongoDB.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.mongodb import MongoDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

mdb_connection_string = "mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority"

# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge base, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    name="MongoDB Knowledge Base",
    description="A knowledge base for MongoDB",
    vector_db=MongoDb(
        collection_name="filters",
        db_url=mdb_connection_string,
        search_index_name="filters",
    ),
)

# Load all documents into the vector database
knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno pymongo openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run MongoDB">
    ```bash
    docker run -d \
    --name local-mongo \
    -p 27017:27017 \
    -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
    -e MONGO_INITDB_ROOT_PASSWORD=secret \
    mongo
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_mongo_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_mongo_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on PgVector
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_pgvector

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in PgVector.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.pgvector import PgVector

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize PgVector
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

vector_db = PgVector(table_name="recipes", db_url=db_url)

# Step 1: Initialize knowledge with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    name="PgVector Knowledge Base",
    description="A knowledge base for PgVector",
    vector_db=vector_db,
)

knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_pgvector.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on Pinecone
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_pinecone

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in Pinecone.

## Code

```python
from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.pineconedb import PineconeDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize Pinecone
api_key = getenv("PINECONE_API_KEY")
index_name = "filtering-index"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
)


# Step 1: Initialize knowledge with documents and metadata
knowledge = Knowledge(
    name="Pinecone Knowledge Base",
    description="A knowledge base for Pinecone",
    vector_db=vector_db,
)

knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno pinecone pinecone-text openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export PINECONE_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_pinecone.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_pinecone.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on SurrealDB
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_surreal_db

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in SurrealDB.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.surrealdb import SurrealDb
from surrealdb import Surreal

# SurrealDB connection parameters
SURREALDB_URL = "ws://localhost:8000"
SURREALDB_USER = "root"
SURREALDB_PASSWORD = "root"
SURREALDB_NAMESPACE = "test"
SURREALDB_DATABASE = "test"

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Create a client
client = Surreal(url=SURREALDB_URL)
client.signin({"username": SURREALDB_USER, "password": SURREALDB_PASSWORD})
client.use(namespace=SURREALDB_NAMESPACE, database=SURREALDB_DATABASE)

vector_db = SurrealDb(
    client=client,
    collection="recipes",  # Collection name for storing documents
    efc=150,  # HNSW construction time/accuracy trade-off
    m=12,  # HNSW max number of connections per element
    search_ef=40,  # HNSW search time/accuracy trade-off
)


# Step 1: Initialize knowledge base with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge base, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

knowledge = Knowledge(
    vector_db=vector_db,
)

knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ],
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

# Option 1: Filters on the Agent
# Initialize the Agent with the knowledge base and filters
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno surrealdb openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run SurrealDB">
    ```bash
    docker run --rm --pull always -p 8000:8000 surrealdb/surrealdb:latest start --user root --pass root     
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_surrealdb.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_surrealdb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Filtering on Weaviate
Source: https://docs.agno.com/examples/concepts/knowledge/filters/vector-dbs/filtering_weaviate

Learn how to filter knowledge base searches using Pdf documents with user-specific metadata in Weaviate.

## Code

```python
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.weaviate import Distance, VectorIndex, Weaviate

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Step 1: Initialize knowledge with documents and metadata
# ------------------------------------------------------------------------------
# When initializing the knowledge, we can attach metadata that will be used for filtering
# This metadata can include user IDs, document types, dates, or any other attributes

vector_db = Weaviate(
    collection="recipes",
    vector_index=VectorIndex.HNSW,
    distance=Distance.COSINE,
    local=False,  # Set to False if using Weaviate Cloud and True if using local instance
)

knowledge = Knowledge(
    name="Weaviate Knowledge Base",
    description="A knowledge base for Weaviate",
    vector_db=vector_db,
)

knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)

# Step 2: Query the knowledge base with different filter combinations
# ------------------------------------------------------------------------------

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response(
    "Tell me about Jordan Mitchell's experience and skills",
    knowledge_filters={"user_id": "jordan_mitchell"},
    markdown=True,
)

```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno weaviate-client openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Setup Weaviate">
    <CodeGroup>
      ```bash Weaviate Cloud
      # 1. Create account at https://console.weaviate.cloud/
      # 2. Create a cluster and copy the "REST endpoint" and "Admin" API Key
      # 3. Set environment variables:
      export WCD_URL="your-cluster-url" 
      export WCD_API_KEY="your-api-key"
      # 4. Set local=False in the code
      ```

      ```bash Local Development
      # 1. Install Docker from https://docs.docker.com/get-docker/
      # 2. Run Weaviate locally:
      docker run -d \
          -p 8080:8080 \
          -p 50051:50051 \
          --name weaviate \
          cr.weaviate.io/semitechnologies/weaviate:1.28.4
      # 3. Set local=True in the code
      ```
    </CodeGroup>
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/filters/vector_dbs/filtering_weaviate.py
      ```

      ```bash Windows
      python cookbook/knowledge/filters/vector_dbs/filtering_weaviate.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with LanceDB
Source: https://docs.agno.com/examples/concepts/knowledge/rag/agentic-rag-lancedb



## Code

```python
rom agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy pypdf sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/agentic_rag_lancedb.py
      ```

      ```bash Windows
      python cookbook/agents/rag/agentic_rag_lancedb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with PgVector
Source: https://docs.agno.com/examples/concepts/knowledge/rag/agentic-rag-pgvector



## Code

```python
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/agentic_rag_pgvector.py
      ```

      ```bash Windows
      python cookbook/agents/rag/agentic_rag_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Reranking
Source: https://docs.agno.com/examples/concepts/knowledge/rag/agentic-rag-with-reranking



## Code

```python
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker import CohereReranker
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(
            id="text-embedding-3-small"
        ),
        reranker=CohereReranker(
            model="rerank-multilingual-v3.0"
        ),
    ),
)

knowledge.add_content(
    name="Agno Docs", url="https://docs.agno.com/introduction.md"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    markdown=True,
)

if __name__ == "__main__":
    # Load the knowledge base, comment after first run
    # agent.knowledge.load(recreate=True)
    agent.print_response("What are Agno's key features?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export COHERE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy pypdf sqlalchemy agno cohere
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/agentic_rag_with_reranking.py
      ```

      ```bash Windows
      python cookbook/agents/rag/agentic_rag_with_reranking.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# RAG with LanceDB and SQLite
Source: https://docs.agno.com/examples/concepts/knowledge/rag/rag-with-lance-db-and-sqlite



## Code

```python
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.ollama import OllamaEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.ollama import Ollama
from agno.vectordb.lancedb import LanceDb

# Define the database URL where the vector database will be stored
db_url = "/tmp/lancedb"

# Configure the language model
model = Ollama(id="llama3.1:8b")

# Create Ollama embedder
embedder = OllamaEmbedder(id="nomic-embed-text", dimensions=768)

# Create the vector database
vector_db = LanceDb(
    table_name="recipes",  # Table name in the vector database
    uri=db_url,  # Location to initiate/create the vector database
    embedder=embedder,  # Without using this, it will use OpenAIChat embeddings by default
)

knowledge = Knowledge(
    vector_db=vector_db,
)

knowledge.add_content(
    name="Recipes", url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)



db = SqliteDb(db_file="data.db")


agent = Agent(
    session_id="session_id", 
    user_id="user",  
    model=model,
    knowledge=knowledge,
    db=db,
)


agent.print_response(
    "What is the first step of making Gluai Buat Chi from the knowledge base?",
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the installation instructions at [Ollama's website](https://ollama.ai)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/rag_with_lance_db_and_sqlite.py
      ```

      ```bash Windows
      python cookbook/agents/rag/rag_with_lance_db_and_sqlite.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# RAG with Sentence Transformer
Source: https://docs.agno.com/examples/concepts/knowledge/rag/rag_sentence_transformer



## Code

```python
from agno.agent import Agent
from agno.knowledge.embedder.sentence_transformer import SentenceTransformerEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker import SentenceTransformerReranker
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector

search_results = [
    "Organic skincare for sensitive skin with aloe vera and chamomile.",
    "New makeup trends focus on bold colors and innovative techniques",
    "Bio-Hautpflege f√ºr empfindliche Haut mit Aloe Vera und Kamille",
    "Neue Make-up-Trends setzen auf kr√§ftige Farben und innovative Techniken",
    "Cuidado de la piel org√°nico para piel sensible con aloe vera y manzanilla",
    "Las nuevas tendencias de maquillaje se centran en colores vivos y t√©cnicas innovadoras",
    "ÈíàÂØπÊïèÊÑüËÇå‰∏ìÈó®ËÆæËÆ°ÁöÑÂ§©ÁÑ∂ÊúâÊú∫Êä§ËÇ§‰∫ßÂìÅ",
    "Êñ∞ÁöÑÂåñÂ¶ÜË∂ãÂäøÊ≥®ÈáçÈ≤úËâ≥ÁöÑÈ¢úËâ≤ÂíåÂàõÊñ∞ÁöÑÊäÄÂ∑ß",
    "ÊïèÊÑüËÇå„ÅÆ„Åü„ÇÅ„Å´ÁâπÂà•„Å´Ë®≠Ë®à„Åï„Çå„ÅüÂ§©ÁÑ∂ÊúâÊ©ü„Çπ„Ç≠„É≥„Ç±„Ç¢Ë£ΩÂìÅ",
    "Êñ∞„Åó„ÅÑ„É°„Ç§„ÇØ„ÅÆ„Éà„É¨„É≥„Éâ„ÅØÈÆÆ„ÇÑ„Åã„Å™Ëâ≤„Å®Èù©Êñ∞ÁöÑ„Å™ÊäÄË°ì„Å´ÁÑ¶ÁÇπ„ÇíÂΩì„Å¶„Å¶„ÅÑ„Åæ„Åô",
]

knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="sentence_transformer_rerank_docs",
        embedder=SentenceTransformerEmbedder(
            id="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        ),
    ),
    reranker=SentenceTransformerReranker(model="BAAI/bge-reranker-v2-m3"),
)

for result in search_results:
    knowledge.add_content(
        content=result,
        metadata={
            "source": "search_results",
        },
    )

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    instructions=[
        "Include sources in your response.",
        "Always search your knowledge before answering the question.",
    ],
    markdown=True,
)

if __name__ == "__main__":
    test_queries = [
        "What organic skincare products are good for sensitive skin?",
        "Tell me about makeup trends in different languages",
        "Compare skincare and makeup information across languages",
    ]

    for query in test_queries:
        agent.print_response(
            query,
            stream=True,
            show_full_reasoning=True,
        )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy psycopg pgvector agno sentence-transformers 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/rag_sentence_transformer.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Traditional RAG with LanceDB
Source: https://docs.agno.com/examples/concepts/knowledge/rag/traditional-rag-lancedb



## Code

```python
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    add_knowledge_to_context=True,
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy pypdf sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/traditional_rag_lancedb.py
      ```

      ```bash Windows
      python cookbook/agents/rag/traditional_rag_lancedb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Traditional RAG with PgVector
Source: https://docs.agno.com/examples/concepts/knowledge/rag/traditional-rag-pgvector



## Code

```python
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    # Enable RAG by adding context from the `knowledge` to the user prompt.
    add_knowledge_to_context=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy psycopg pgvector pypdf agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agents/rag/traditional_rag_pgvector.py
      ```

      ```bash Windows
      python cookbook/agents/rag/traditional_rag_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ArXiv Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/arxiv/arxiv-reader



The **ArXiv Reader** allows you to search and read academic papers from the ArXiv preprint repository, converting them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/arxiv_reader.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.arxiv_reader import ArxivReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with the ArXiv documents
knowledge = Knowledge(
    # Table name: ai.arxiv_documents
    vector_db=PgVector(
        table_name="arxiv_documents",
        db_url=db_url,
    ),
)
# Load the knowledge
knowledge.add_content(
    topics=["Generative AI", "Machine Learning"],
    reader=ArxivReader(),
)

# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

# Ask the agent about the knowledge
agent.print_response("What can you tell me about Generative AI?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U arxiv sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/arxiv_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/arxiv_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="arxiv-reader-reference.mdx" />


# ArXiv Reader Async
Source: https://docs.agno.com/examples/concepts/knowledge/readers/arxiv/arxiv-reader-async



The **ArXiv Reader** with asynchronous processing allows you to search and read academic papers from the ArXiv preprint repository with better performance for concurrent operations.

## Code

```python examples/concepts/knowledge/readers/arxiv_reader_async.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.arxiv_reader import ArxivReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Table name: ai.arxiv_documents
    vector_db=PgVector(
        table_name="arxiv_documents",
        db_url=db_url,
    ),
)

# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

def main():
    # Load the knowledge
    asyncio.run(
        knowledge.add_content_async(
            topics=["Generative AI", "Machine Learning"],
            reader=ArxivReader(),
        )
    )

    # Create and use the agent
    asyncio.run(
        agent.aprint_response(
            "What can you tell me about Generative AI?", markdown=True
        )
    )

if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U arxiv sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/arxiv_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/arxiv_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## ArXiv Reader Params

<Snippet file="arxiv-reader-reference.mdx" />


# CSV Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/csv/csv-reader



The **CSV Reader** processes local CSV files and converts them into documents that can be used with Agno's knowledge system.

## Code

```python examples/concepts/knowledge/readers/csv_reader.py
from pathlib import Path

from agno.knowledge.reader.csv_reader import CSVReader

reader = CSVReader()

csv_path = Path("tmp/test.csv")

try:
    print("Starting read...")
    documents = reader.read(csv_path)

    if documents:
        for doc in documents:
            print(doc.name)
            # print(doc.content)
            print(f"Content length: {len(doc.content)}")
            print("-" * 80)
    else:
        print("No documents were returned")

except Exception as e:
    print(f"Error type: {type(e)}")
    print(f"Error occurred: {str(e)}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pandas agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/csv_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/csv_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="csv-reader-reference.mdx" />


# CSV Reader Async
Source: https://docs.agno.com/examples/concepts/knowledge/readers/csv/csv-reader-async



The **CSV Reader** with asynchronous processing allows you to handle CSV files and integrate them with knowledge bases efficiently.

## Code

```python examples/concepts/knowledge/readers/csv_reader_async.py
import asyncio
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="csv_documents",
        db_url=db_url,
    ),
    max_results=5,  # Number of results to return on search
)

# Initialize the Agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

if __name__ == "__main__":
    # Comment out after first run
    asyncio.run(knowledge.add_content_async(path=Path("data/csv")))

    # Create and use the agent
    asyncio.run(agent.aprint_response("What is the csv file about", markdown=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pandas sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/csv_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/csv_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="csv-reader-reference.mdx" />


# CSV URL Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/csv/csv-url-reader



The **CSV URL Reader** processes CSV files directly from URLs, allowing you to create knowledge bases from remote CSV data sources.

## Code

```python examples/concepts/knowledge/readers/csv_reader_url_async.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    # Table name: ai.csv_documents
    vector_db=PgVector(
        table_name="csv_documents",
        db_url=db_url,
    ),
)

# Initialize the Agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

if __name__ == "__main__":
    # Comment out after first run
    asyncio.run(
        knowledge.add_content_async(
            url="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv"
        )
    )

    # Create and use the agent
    asyncio.run(
        agent.aprint_response("What genre of movies are present here?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pandas requests sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/csv_reader_url_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/csv_reader_url_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="csv-url-reader-reference.mdx" />


# Firecrawl Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/firecrawl/firecrawl-reader



The **Firecrawl Reader** uses the Firecrawl API to scrape and crawl web content, converting it into documents for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/firecrawl_reader.py
import os

from agno.knowledge.reader.firecrawl_reader import FirecrawlReader

api_key = os.getenv("FIRECRAWL_API_KEY")

reader = FirecrawlReader(
    api_key=api_key,
    mode="scrape",
    chunk=True,
    # for crawling
    # params={
    #     'limit': 5,
    #     'scrapeOptions': {'formats': ['markdown']}
    # }
    # for scraping
    params={"formats": ["markdown"]},
)

try:
    print("Starting scrape...")
    documents = reader.read("https://github.com/agno-agi/agno")

    if documents:
        for doc in documents:
            print(doc.name)
            print(doc.content)
            print(f"Content length: {len(doc.content)}")
            print("-" * 80)
    else:
        print("No documents were returned")

except Exception as e:
    print(f"Error type: {type(e)}")
    print(f"Error occurred: {str(e)}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U firecrawl-py agno
    ```
  </Step>

  <Step title="Set API Key">
    ```bash
    export FIRECRAWL_API_KEY="your-firecrawl-api-key"
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/firecrawl_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/firecrawl_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="firecrawl-reader-reference.mdx" />


# Firecrawl Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/firecrawl/firecrawl-reader-async



The **Firecrawl Reader** with asynchronous processing uses the Firecrawl API to scrape and crawl web content efficiently, converting it into documents for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/firecrawl_reader_async.py
import os
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.firecrawl_reader import FirecrawlReader
from agno.vectordb.pgvector import PgVector

api_key = os.getenv("FIRECRAWL_API_KEY")
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="firecrawl_documents",
        db_url=db_url,
    ),
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

async def main():
    # Add Firecrawl content to knowledge base
    await knowledge.add_content_async(
        url="https://github.com/agno-agi/agno",
        reader=FirecrawlReader(
            api_key=api_key,
            mode="scrape",
            chunk=True,
            params={"formats": ["markdown"]},
        ),
    )

    # Query the knowledge base
    await agent.aprint_response(
        "What is the main purpose of this repository?",
        markdown=True,
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U firecrawl-py sqlalchemy psycopg pgvector agno
    ```
  </Step>

  <Step title="Set API Key">
    ```bash
    export FIRECRAWL_API_KEY="your-firecrawl-api-key"
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/firecrawl_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/firecrawl_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="firecrawl-reader-reference.mdx" />


# JSON Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/json/json-reader



The **JSON Reader** processes JSON files and converts them into documents that can be used with Agno's knowledge system.

## Code

```python examples/concepts/knowledge/readers/json_reader.py
import json
from pathlib import Path

from agno.knowledge.reader.json_reader import JSONReader

reader = JSONReader()

json_path = Path("tmp/test.json")
test_data = {"key": "value"}
json_path.write_text(json.dumps(test_data))

try:
    print("Starting read...")
    documents = reader.read(json_path)

    if documents:
        for doc in documents:
            print(doc.name)
            print(doc.content)
            print(f"Content length: {len(doc.content)}")
            print("-" * 80)
    else:
        print("No documents were returned")

except Exception as e:
    print(f"Error type: {type(e)}")
    print(f"Error occurred: {str(e)}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/json_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/json_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="json-reader-reference.mdx" />


# JSON Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/json/json-reader-async



The **JSON Reader** with asynchronous processing allows you to handle JSON files efficiently and integrate them with knowledge bases.

## Code

```python examples/concepts/knowledge/readers/json_reader_async.py
import json
import asyncio
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.json_reader import JSONReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create test JSON data
json_path = Path("tmp/test.json")
json_path.parent.mkdir(exist_ok=True)
test_data = {
    "users": [
        {"id": 1, "name": "John Doe", "role": "Developer"},
        {"id": 2, "name": "Jane Smith", "role": "Designer"}
    ],
    "project": "Knowledge Base System"
}
json_path.write_text(json.dumps(test_data, indent=2))

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="json_documents",
        db_url=db_url,
    ),
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

async def main():
    # Add JSON content to knowledge base
    await knowledge.add_content_async(
        path=json_path,
        reader=JSONReader(),
    )

    # Query the knowledge base
    await agent.aprint_response(
        "What information is available about the users?",
        markdown=True
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/json_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/json_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="json-reader-reference.mdx" />


# Markdown Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/markdown/markdown-reader



The **Markdown Reader** processes Markdown files synchronously and converts them into documents that can be used with Agno's knowledge system.

## Code

```python examples/concepts/knowledge/readers/markdown_reader_sync.py
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.markdown_reader import MarkdownReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="markdown_documents",
        db_url=db_url,
    ),
)

# Add Markdown content to knowledge base
knowledge.add_content(
    path=Path("README.md"),
    reader=MarkdownReader(),
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

# Query the knowledge base
agent.print_response(
    "What can you tell me about this project?",
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U markdown sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/markdown_reader_sync.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/markdown_reader_sync.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Markdown Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/markdown/markdown-reader-async



The **Markdown Reader** with asynchronous processing allows you to handle Markdown files efficiently and integrate them with knowledge bases.

## Code

```python examples/concepts/knowledge/readers/markdown_reader_async.py
import asyncio
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="markdown_documents",
        db_url=db_url,
    ),
    max_results=5,  # Number of results to return on search
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            path=Path("README.md"),
        )
    )

    asyncio.run(
        agent.aprint_response(
            "What can you tell me about Agno?",
            markdown=True,
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U markdown sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/markdown_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/markdown_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PDF Password Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/pdf/pdf-password-reader



The **PDF Password Reader** handles password-protected PDF files, allowing you to process secure documents and convert them into searchable knowledge bases.

## Code

```python examples/concepts/knowledge/readers/pdf_reader_password.py
from agno.agent import Agent
from agno.knowledge.content import ContentAuth
from agno.knowledge.knowledge import Knowledge
from agno.utils.media import download_file
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
download_file(
    "https://agno-public.s3.us-east-1.amazonaws.com/recipes/ThaiRecipes_protected.pdf",
    "ThaiRecipes_protected.pdf",
)

# Create a knowledge base with simplified password handling
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="pdf_documents_password",
        db_url=db_url,
    ),
)

knowledge.add_content(
    path="ThaiRecipes_protected.pdf",
    auth=ContentAuth(password="ThaiRecipes"),
)

# Create an agent with the knowledge base
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("Give me the recipe for pad thai")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pypdf sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/pdf_reader_password.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/pdf_reader_password.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="pdf-reader-reference.mdx" />


# PDF Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/pdf/pdf-reader



The **PDF Reader** processes PDF files synchronously and converts them into documents that can be used with Agno's knowledge system.

## Code

```python examples/concepts/knowledge/readers/pdf_reader_sync.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with PDF documents
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url=db_url,
    )
)

# Add PDF content synchronously
knowledge.add_content(
    path="cookbook/knowledge/testing_resources/cv_1.pdf",
    reader=PDFReader(),
)

# Create an agent with the knowledge base
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

# Query the knowledge base
agent.print_response(
    "What skills does an applicant require to apply for the Software Engineer position?",
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pypdf sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/pdf_reader_sync.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/pdf_reader_sync.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="pdf-reader-reference.mdx" />


# PDF Reader Async
Source: https://docs.agno.com/examples/concepts/knowledge/readers/pdf/pdf-reader-async



The **PDF Reader** with asynchronous processing allows you to handle PDF files efficiently and integrate them with knowledge bases.

## Code

```python examples/concepts/knowledge/readers/pdf_reader_async.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with the PDFs from the data/pdfs directory
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url=db_url,
    )
)

# Create an agent with the knowledge base
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            path="cookbook/knowledge/testing_resources/cv_1.pdf",
        )
    )
    # Create and use the agent
    asyncio.run(
        agent.aprint_response(
            "What skills does an applicant require to apply for the Software Engineer position?",
            markdown=True,
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pypdf sqlalchemy psycopg pgvector agno openai  
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/pdf_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/pdf_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="pdf-reader-reference.mdx" />


# PDF URL Password Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/pdf/pdf-url-password-reader



The **PDF URL Password Reader** processes password-protected PDF files directly from URLs, allowing you to handle secure remote documents.

## Code

```python examples/concepts/knowledge/readers/pdf_reader_url_password.py
from agno.agent import Agent
from agno.knowledge.content import ContentAuth
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with simplified password handling
knowledge = Knowledge(
    vector_db=PgVector(
        table_name="pdf_documents_password",
        db_url=db_url,
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.us-east-1.amazonaws.com/recipes/ThaiRecipes_protected.pdf",
    auth=ContentAuth(password="ThaiRecipes"),
)

# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

agent.print_response("Give me the recipe for pad thai")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pypdf requests sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/pdf_reader_url_password.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/pdf_reader_url_password.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="pdf-reader-reference.mdx" />


# Web Search Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/web-search/web-search-reader



The **Web Search Reader** searches and reads web search results, converting them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/web_search_reader.py
from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.web_search_reader import WebSearchReader
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(id="web-search-db", db_url=db_url)

vector_db = PgVector(
    db_url=db_url,
    table_name="web_search_documents",
)
knowledge = Knowledge(
    name="Web Search Documents",
    contents_db=db,
    vector_db=vector_db,
)


# Load knowledge from web search
knowledge.add_content(
    topics=["agno"],
    reader=WebSearchReader(
        max_results=3,
        search_engine="duckduckgo",
        chunk=True,
    ),
)

# Create an agent with the knowledge
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

# Ask the agent about the knowledge
agent.print_response(
    "What are the latest AI trends according to the search results?", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U requests beautifulsoup4 agno openai
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/web_search_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/web_search_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="web-search-reader-reference.mdx" />


# Web Search Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/web-search/web-search-reader-async



The **Web Search Reader** searches and reads web search results, converting them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/web_search_reader_async.py
import asyncio

from agno.agent import Agent
from agno.db.postgres.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.web_search_reader import WebSearchReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(id="web-search-db", db_url=db_url)

vector_db = PgVector(
    db_url=db_url,
    table_name="web_search_documents",
)
knowledge = Knowledge(
    name="Web Search Documents",
    contents_db=db,
    vector_db=vector_db,
)


# Initialize the Agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)


if __name__ == "__main__":
    # Comment out after first run
    asyncio.run(
        knowledge.add_content_async(
            topics=["web3 latest trends 2025"],
            reader=WebSearchReader(
                max_results=3,
                search_engine="duckduckgo",
                chunk=True,
            ),
        )
    )

    # Create and use the agent
    asyncio.run(
        agent.aprint_response(
            "What are the latest AI trends according to the search results?",
            markdown=True,
        )
    )

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U requests beautifulsoup4 agno openai
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/web_search_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/web_search_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="web-search-reader-reference.mdx" />


# Website Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/website/website-reader



The **Website Reader** crawls and processes entire websites, following links to create comprehensive knowledge bases from web content.

## Code

```python examples/concepts/knowledge/readers/web_reader.py
from agno.knowledge.reader.website_reader import WebsiteReader

reader = WebsiteReader(max_depth=3, max_links=10)

try:
    print("Starting read...")
    documents = reader.read("https://docs.agno.com/introduction")
    if documents:
        for doc in documents:
            print(doc.name)
            print(doc.content)
            print(f"Content length: {len(doc.content)}")
            print("-" * 80)
    else:
        print("No documents were returned")

except Exception as e:
    print(f"Error type: {type(e)}")
    print(f"Error occurred: {str(e)}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U requests beautifulsoup4 agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/web_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/web_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="website-reader-reference.mdx" />


# Website Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/website/website-reader-async



The **Website Reader** with asynchronous processing crawls and processes entire websites efficiently, following links to create comprehensive knowledge bases from web content.

## Code

```python examples/concepts/knowledge/readers/website_reader_async.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.website_reader import WebsiteReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="website_documents",
        db_url=db_url,
    ),
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

async def main():
    # Crawl and add website content to knowledge base
    await knowledge.add_content_async(
        url="https://docs.agno.com/introduction",
        reader=WebsiteReader(max_depth=2, max_links=20),
    )

    # Query the knowledge base
    await agent.aprint_response(
        "What are the main features of Agno?",
        markdown=True,
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U requests beautifulsoup4 sqlalchemy psycopg pgvector agno openai    
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/website_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/website_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="website-reader-reference.mdx" />


# Wikipedia Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/wikipedia/wikipedia-reader



The **Wikipedia Reader** allows you to search and read Wikipedia articles synchronously, converting them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/wikipedia_reader_sync.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.wikipedia_reader import WikipediaReader
from agno.vectordb.pgvector import PgVector

# Create Knowledge Instance
knowledge = Knowledge(
    name="Wikipedia Knowledge Base",
    description="Knowledge base from Wikipedia articles",
    vector_db=PgVector(
        table_name="wikipedia_vectors", 
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

# Add topics from Wikipedia synchronously
knowledge.add_content(
    metadata={"source": "wikipedia", "type": "encyclopedia"},
    topics=["Manchester United", "Artificial Intelligence"],
    reader=WikipediaReader(),
)

# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

# Query the knowledge base
agent.print_response(
    "What can you tell me about Manchester United?",
    markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U wikipedia sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/wikipedia_reader_sync.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/wikipedia_reader_sync.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="wikipedia-reader-reference.mdx" />


# Wikipedia Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/wikipedia/wikipedia-reader-async



The **Wikipedia Reader** with asynchronous processing allows you to search and read Wikipedia articles efficiently, converting them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/wikipedia_reader_async.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.arxiv_reader import ArxivReader
from agno.knowledge.reader.wikipedia_reader import WikipediaReader
from agno.vectordb.pgvector import PgVector

# Create Knowledge Instance
knowledge = Knowledge(
    name="Multi-Source Knowledge Base",
    description="Knowledge base combining Wikipedia and ArXiv content",
    vector_db=PgVector(
        table_name="multi_vectors", 
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

async def main():
    # Add topics from Wikipedia
    await knowledge.add_content_async(
        metadata={"source": "wikipedia", "type": "encyclopedia"},
        topics=["Manchester United", "Machine Learning"],
        reader=WikipediaReader(),
    )

    # Add topics from ArXiv
    await knowledge.add_content_async(
        metadata={"source": "arxiv", "type": "academic"},
        topics=["Carbon Dioxide", "Neural Networks"],
        reader=ArxivReader(),
    )

    # Create an agent with the knowledge
    agent = Agent(
        knowledge=knowledge,
        search_knowledge=True,
    )

    # Query the knowledge base
    await agent.aprint_response(
        "What can you tell me about Machine Learning from both general and academic sources?",
        markdown=True
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U wikipedia arxiv sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/wikipedia_reader_async.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/wikipedia_reader_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="wikipedia-reader-reference.mdx" />


# YouTube Reader
Source: https://docs.agno.com/examples/concepts/knowledge/readers/youtube/youtube-reader



The **YouTube Reader** allows you to extract transcripts from YouTube videos synchronously and convert them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/youtube_reader_sync.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.youtube_reader import YouTubeReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create Knowledge Instance
knowledge = Knowledge(
    name="YouTube Knowledge Base",
    description="Knowledge base from YouTube video transcripts",
    vector_db=PgVector(
        table_name="youtube_vectors", 
        db_url=db_url
    ),
)

# Add YouTube video content synchronously
knowledge.add_content(
    metadata={"source": "youtube", "type": "educational"},
    urls=[
        "https://www.youtube.com/watch?v=dQw4w9WgXcQ",  # Replace with actual educational video
        "https://www.youtube.com/watch?v=example123"   # Replace with actual video URL
    ],
    reader=YouTubeReader(),
)

# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

# Query the knowledge base
agent.print_response(
    "What are the main topics discussed in the videos?",
    markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U youtube-transcript-api pytube sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/youtube_reader_sync.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/youtube_reader_sync.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="youtube-reader-reference.mdx" />


# YouTube Reader (Async)
Source: https://docs.agno.com/examples/concepts/knowledge/readers/youtube/youtube-reader-async



The **YouTube Reader** allows you to extract transcripts from YouTube videos and convert them into vector embeddings for your knowledge base.

## Code

```python examples/concepts/knowledge/readers/youtube_reader.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.youtube_reader import YouTubeReader
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create Knowledge Instance
knowledge = Knowledge(
    name="YouTube Knowledge Base",
    description="Knowledge base from YouTube video transcripts",
    vector_db=PgVector(
        table_name="youtube_vectors", 
        db_url=db_url
    ),
)

# Create an agent with the knowledge
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

async def main():
    # Add YouTube video content
    await knowledge.add_content_async(
        metadata={"source": "youtube", "type": "educational"},
        urls=[
            "https://www.youtube.com/watch?v=dQw4w9WgXcQ",  # Replace with actual educational video
            "https://www.youtube.com/watch?v=example123"   # Replace with actual video URL
        ],
        reader=YouTubeReader(),
    )

    # Query the knowledge base
    await agent.aprint_response(
        "What are the main topics discussed in the videos?",
        markdown=True
    )

if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U youtube-transcript-api pytube sqlalchemy psycopg pgvector agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python examples/concepts/knowledge/readers/youtube_reader.py
      ```

      ```bash Windows
      python examples/concepts/knowledge/readers/youtube_reader.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="youtube-reader-reference.mdx" />


# GCS Content
Source: https://docs.agno.com/examples/concepts/knowledge/remote-content/gcs-content



This example shows how to add content from a Google Cloud Storage (GCS) bucket to your knowledge base. This allows you to process documents stored in Google Cloud without downloading them locally.

## Code

```python gcs.py
"""This cookbook shows how to add content from a GCS bucket to the knowledge base.
1. Run: `python cookbook/agent_concepts/knowledge/12_from_gcs.py` to run the cookbook
"""

import asyncio

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.remote_content.remote_content import GCSContent
from agno.vectordb.pgvector import PgVector

contents_db = PostgresDb(
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    knowledge_table="knowledge_contents",
)

# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    contents_db=contents_db,
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

# Add from GCS
asyncio.run(
    knowledge.add_content_async(
        name="GCS PDF",
        remote_content=GCSContent(
            bucket_name="thai-recepies", blob_name="ThaiRecipes.pdf"
        ),
        metadata={"remote_content": "GCS"},
    )
)


agent = Agent(
    name="My Agent",
    description="Agno 2.0 Agent Implementation",
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

agent.print_response(
    "What is the best way to make a Thai curry?",
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector google-cloud-storage
    ```
  </Step>

  <Step title="Configure Google Cloud credentials">
    Set up your GCS credentials using one of these methods:

    * Service Account Key: Set `GOOGLE_APPLICATION_CREDENTIALS` environment variable
    * gcloud CLI: `gcloud auth application-default login`
    * Workload Identity (if running on Google Cloud)
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/07_from_gcs.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/07_from_gcs.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="gcs-remote-content-params.mdx" />


# S3 Content
Source: https://docs.agno.com/examples/concepts/knowledge/remote-content/s3-content



This example shows how to add content from an Amazon S3 bucket to your knowledge base. This allows you to process documents stored in cloud storage without downloading them locally.

## Code

```python s3.py  
import asyncio
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.remote_content.remote_content import S3Content
from agno.vectordb.pgvector import PgVector

contents_db = PostgresDb(
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    knowledge_table="knowledge_contents",
)

# Create Knowledge Instance
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation",
    contents_db=contents_db,
    vector_db=PgVector(
        table_name="vectors", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"
    ),
)

# Add from S3 bucket
asyncio.run(
    knowledge.add_content_async(
        name="S3 PDF",
        remote_content=S3Content(
            bucket_name="agno-public", key="recipes/ThaiRecipes.pdf"
        ),
        metadata={"remote_content": "S3"},
    )
)

agent = Agent(
    name="My Agent",
    description="Agno 2.0 Agent Implementation",
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

agent.print_response(
    "What is the best way to make a Thai curry?",
    markdown=True,
)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector boto3
    ```
  </Step>

  <Step title="Configure AWS credentials">
    Set up your AWS credentials using one of these methods:

    * AWS CLI: `aws configure`
    * Environment variables: `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`
    * IAM roles (if running on AWS infrastructure)
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/basic_operations/06_from_s3.py
      ```

      ```bash Windows
      python cookbook/knowledge/basic_operations/06_from_s3.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Params

<Snippet file="s3-remote-content-params.mdx" />


# Hybrid Search
Source: https://docs.agno.com/examples/concepts/knowledge/search_type/hybrid-search



## Code

```python hybrid_search.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Load knowledge base using hybrid search
hybrid_db = PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.hybrid)
knowledge = Knowledge(
    name="Hybrid Search Knowledge Base",
    vector_db=hybrid_db,
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

# Run a hybrid search query
results = hybrid_db.search("chicken coconut soup", limit=5)
print("Hybrid Search Results:", results)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/search_type/hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/search_type/hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Keyword Search
Source: https://docs.agno.com/examples/concepts/knowledge/search_type/keyword-search



## Code

```python keyword_search.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Load knowledge base using keyword search
keyword_db = PgVector(
    table_name="recipes", db_url=db_url, search_type=SearchType.keyword
)
knowledge = Knowledge(
    name="Keyword Search Knowledge Base",
    vector_db=keyword_db,
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

# Run a keyword-based query
results = keyword_db.search("chicken coconut soup", limit=5)
print("Keyword Search Results:", results)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/search_type/keyword_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/search_type/keyword_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Vector Search
Source: https://docs.agno.com/examples/concepts/knowledge/search_type/vector-search



## Code

```python vector_search.py
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Load knowledge base using vector search
vector_db = PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.vector)
knowledge = Knowledge(
    name="Vector Search Knowledge Base",
    vector_db=vector_db,
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

# Run a vector-based query
results = vector_db.search("chicken coconut soup", limit=5)
print("Vector Search Results:", results)
```

## Usage

<Steps>
  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Snippet file="run-pgvector-step.mdx" />

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/search_type/vector_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/search_type/vector_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Memory
Source: https://docs.agno.com/examples/concepts/memory/01-agent-with-memory



This example shows you how to use persistent memory with an Agent.

After each run, user memories are created/updated.

To enable this, set `enable_user_memories=True` in the Agent config.

## Code

```python cookbook/memory/01_agent_with_memory.py
from uuid import uuid4

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

db.clear_memories()

session_id = str(uuid4())
john_doe_id = "john_doe@example.com"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    enable_user_memories=True,
)

agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
    stream=True,
    user_id=john_doe_id,
    session_id=session_id,
)

agent.print_response(
    "What are my hobbies?", stream=True, user_id=john_doe_id, session_id=session_id
)

memories = agent.get_user_memories(user_id=john_doe_id)
print("John Doe's memories:")
pprint(memories)

agent.print_response(
    "Ok i dont like hiking anymore, i like to play soccer instead.",
    stream=True,
    user_id=john_doe_id,
    session_id=session_id,
)

# You can also get the user memories from the agent
memories = agent.get_user_memories(user_id=john_doe_id)
print("John Doe's memories:")
pprint(memories)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/01_agent_with_memory.py
      ```

      ```bash Windows
      python cookbook/memory/01_agent_with_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic Memory
Source: https://docs.agno.com/examples/concepts/memory/02-agentic-memory



This example shows you how to use persistent memory with an Agent.

During each run the Agent can create/update/delete user memories.

To enable this, set `enable_agentic_memory=True` in the Agent config.

## Code

```python cookbook/memory/02_agentic_memory.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)


john_doe_id = "john_doe@example.com"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    enable_agentic_memory=True,
)

agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
    stream=True,
    user_id=john_doe_id,
)

agent.print_response("What are my hobbies?", stream=True, user_id=john_doe_id)

memories = agent.get_user_memories(user_id=john_doe_id)
print("Memories about John Doe:")
pprint(memories)


agent.print_response(
    "Remove all existing memories of me.",
    stream=True,
    user_id=john_doe_id,
)

memories = agent.get_user_memories(user_id=john_doe_id)
print("Memories about John Doe:")
pprint(memories)

agent.print_response(
    "My name is John Doe and I like to paint.", stream=True, user_id=john_doe_id
)

memories = agent.get_user_memories(user_id=john_doe_id)
print("Memories about John Doe:")
pprint(memories)


agent.print_response(
    "I don't paint anymore, i draw instead.", stream=True, user_id=john_doe_id
)

memories = agent.get_user_memories(user_id=john_doe_id)

print("Memories about John Doe:")
pprint(memories)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/02_agentic_memory.py
      ```

      ```bash Windows
      python cookbook/memory/02_agentic_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Share Memory between Agents
Source: https://docs.agno.com/examples/concepts/memory/03-agents-share-memory



This example demonstrates how to share memory between Agents.

This means that memories created by one Agent, will be available to the other Agents.

## Code

```python cookbook/memory/03_agents_share_memory.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

john_doe_id = "john_doe@example.com"

chat_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You are a helpful assistant that can chat with users",
    db=db,
    enable_user_memories=True,
)

chat_agent.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
    stream=True,
    user_id=john_doe_id,
)

chat_agent.print_response("What are my hobbies?", stream=True, user_id=john_doe_id)


research_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You are a research assistant that can help users with their research questions",
    tools=[DuckDuckGoTools(cache_results=True)],
    db=db,
    enable_user_memories=True,
)

research_agent.print_response(
    "I love asking questions about quantum computing. What is the latest news on quantum computing?",
    stream=True,
    user_id=john_doe_id,
)

memories = research_agent.get_user_memories(user_id=john_doe_id)
print("Memories about John Doe:")
pprint(memories)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno rich
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/03_agents_share_memory.py
      ```

      ```bash Windows
      python cookbook/memory/03_agents_share_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Custom Memory Manager
Source: https://docs.agno.com/examples/concepts/memory/04-custom-memory-manager



This example shows how you can configure the Memory Manager.

We also set custom system prompts for the memory manager. You can either override the entire system prompt or add additional instructions which is added to the end of the system prompt.

## Code

```python cookbook/memory/04_custom_memory_manager.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

# You can also override the entire `system_message` for the memory manager
memory_manager = MemoryManager(
    model=OpenAIChat(id="gpt-5-mini"),
    additional_instructions="""
    IMPORTANT: Don't store any memories about the user's name. Just say "The User" instead of referencing the user's name.
    """,
    db=db,
)

john_doe_id = "john_doe@example.com"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    memory_manager=memory_manager,
    enable_user_memories=True,
    user_id=john_doe_id,
)

agent.print_response(
    "My name is John Doe and I like to swim and play soccer.", stream=True
)

agent.print_response("I dont like to swim", stream=True)


memories = agent.get_user_memories(user_id=john_doe_id)

print("John Doe's memories:")
pprint(memories)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/04_custom_memory_manager.py
      ```

      ```bash Windows
      python cookbook/memory/04_custom_memory_manager.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Multi-user, Multi-session Chat
Source: https://docs.agno.com/examples/concepts/memory/05-multi-user-multi-session-chat



This example demonstrates how to run a multi-user, multi-session chat.

## Code

```python cookbook/memory/05_agent_with_memory.py
"""
In this example, we have 3 users and 4 sessions.

User 1 has 2 sessions.
User 2 has 1 session.
User 3 has 1 session.
"""

import asyncio

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

user_1_id = "user_1@example.com"
user_2_id = "user_2@example.com"
user_3_id = "user_3@example.com"

user_1_session_1_id = "user_1_session_1"
user_1_session_2_id = "user_1_session_2"
user_2_session_1_id = "user_2_session_1"
user_3_session_1_id = "user_3_session_1"

chat_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    enable_user_memories=True,
)


async def run_chat_agent():
    await chat_agent.aprint_response(
        "My name is Mark Gonzales and I like anime and video games.",
        user_id=user_1_id,
        session_id=user_1_session_1_id,
    )
    await chat_agent.aprint_response(
        "I also enjoy reading manga and playing video games.",
        user_id=user_1_id,
        session_id=user_1_session_1_id,
    )

    # Chat with user 1 - Session 2
    await chat_agent.aprint_response(
        "I'm going to the movies tonight.",
        user_id=user_1_id,
        session_id=user_1_session_2_id,
    )

    # Chat with user 2
    await chat_agent.aprint_response(
        "Hi my name is John Doe.", user_id=user_2_id, session_id=user_2_session_1_id
    )
    await chat_agent.aprint_response(
        "I'm planning to hike this weekend.",
        user_id=user_2_id,
        session_id=user_2_session_1_id,
    )

    # Chat with user 3
    await chat_agent.aprint_response(
        "Hi my name is Jane Smith.", user_id=user_3_id, session_id=user_3_session_1_id
    )
    await chat_agent.aprint_response(
        "I'm going to the gym tomorrow.",
        user_id=user_3_id,
        session_id=user_3_session_1_id,
    )

    # Continue the conversation with user 1
    # The agent should take into account all memories of user 1.
    await chat_agent.aprint_response(
        "What do you suggest I do this weekend?",
        user_id=user_1_id,
        session_id=user_1_session_1_id,
    )


if __name__ == "__main__":
    # Chat with user 1 - Session 1
    asyncio.run(run_chat_agent())

    user_1_memories = chat_agent.get_user_memories(user_id=user_1_id)
    print("User 1's memories:")
    assert user_1_memories is not None
    for i, m in enumerate(user_1_memories):
        print(f"{i}: {m.memory}")

    user_2_memories = chat_agent.get_user_memories(user_id=user_2_id)
    print("User 2's memories:")
    assert user_2_memories is not None
    for i, m in enumerate(user_2_memories):
        print(f"{i}: {m.memory}")

    user_3_memories = chat_agent.get_user_memories(user_id=user_3_id)
    print("User 3's memories:")
    assert user_3_memories is not None
    for i, m in enumerate(user_3_memories):
        print(f"{i}: {m.memory}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/05_multi_user_multi_session_chat.py
      ```

      ```bash Windows
      python cookbook/memory/05_multi_user_multi_session_chat.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Multi-User, Multi-Session Chat Concurrently
Source: https://docs.agno.com/examples/concepts/memory/06-multi-user-multi-session-chat-concurrent



This example shows how to run a multi-user, multi-session chat concurrently.

## Code

```python cookbook/memory/06_multi_user_multi_session_chat_concurrent.py
"""
In this example, we have 3 users and 4 sessions.

User 1 has 2 sessions.
User 2 has 1 session.
User 3 has 1 session.
"""
import asyncio

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

user_1_id = "user_1@example.com"
user_2_id = "user_2@example.com"
user_3_id = "user_3@example.com"

user_1_session_1_id = "user_1_session_1"
user_1_session_2_id = "user_1_session_2"
user_2_session_1_id = "user_2_session_1"
user_3_session_1_id = "user_3_session_1"

chat_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    enable_user_memories=True,
)


async def user_1_conversation():
    """Handle conversation with user 1 across multiple sessions"""
    # User 1 - Session 1
    await chat_agent.arun(
        "My name is Mark Gonzales and I like anime and video games.",
        user_id=user_1_id,
        session_id=user_1_session_1_id,
    )
    await chat_agent.arun(
        "I also enjoy reading manga and playing video games.",
        user_id=user_1_id,
        session_id=user_1_session_1_id,
    )

    # User 1 - Session 2
    await chat_agent.arun(
        "I'm going to the movies tonight.",
        user_id=user_1_id,
        session_id=user_1_session_2_id,
    )

    # Continue the conversation in session 1
    await chat_agent.arun(
        "What do you suggest I do this weekend?",
        user_id=user_1_id,
        session_id=user_1_session_1_id,
    )

    print("User 1 Done")


async def user_2_conversation():
    """Handle conversation with user 2"""
    await chat_agent.arun(
        "Hi my name is John Doe.", user_id=user_2_id, session_id=user_2_session_1_id
    )
    await chat_agent.arun(
        "I'm planning to hike this weekend.",
        user_id=user_2_id,
        session_id=user_2_session_1_id,
    )
    print("User 2 Done")


async def user_3_conversation():
    """Handle conversation with user 3"""
    await chat_agent.arun(
        "Hi my name is Jane Smith.", user_id=user_3_id, session_id=user_3_session_1_id
    )
    await chat_agent.arun(
        "I'm going to the gym tomorrow.",
        user_id=user_3_id,
        session_id=user_3_session_1_id,
    )
    print("User 3 Done")


async def run_concurrent_chat_agent():
    """Run all user conversations concurrently"""
    await asyncio.gather(
        user_1_conversation(), user_2_conversation(), user_3_conversation()
    )


if __name__ == "__main__":
    # Run all conversations concurrently
    asyncio.run(run_concurrent_chat_agent())

    user_1_memories = chat_agent.get_user_memories(user_id=user_1_id)
    print("User 1's memories:")
    assert user_1_memories is not None
    for i, m in enumerate(user_1_memories):
        print(f"{i}: {m.memory}")

    user_2_memories = chat_agent.get_user_memories(user_id=user_2_id)
    print("User 2's memories:")
    assert user_2_memories is not None
    for i, m in enumerate(user_2_memories):
        print(f"{i}: {m.memory}")

    user_3_memories = chat_agent.get_user_memories(user_id=user_3_id)
    print("User 3's memories:")
    assert user_3_memories is not None
    for i, m in enumerate(user_3_memories):
        print(f"{i}: {m.memory}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/06_multi_user_multi_session_chat_concurrent.py
      ```

      ```bash Windows
      python cookbook/memory/06_multi_user_multi_session_chat_concurrent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Share Memory and History between Agents
Source: https://docs.agno.com/examples/concepts/memory/07-share-memory-and-history-between-agents



This example shows how to share memory and history between agents.

You can set `add_history_to_context=True` to add the history to the context of the agent.

You can set `enable_user_memories=True` to enable user memory generation at the end of each run.

## Code

```python cookbook/memory/07_share_memory_and_history_between_agents.py
from uuid import uuid4

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat

db = SqliteDb(db_file="tmp/agent_sessions.db")

session_id = str(uuid4())
user_id = "john_doe@example.com"

agent_1 = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are really friendly and helpful.",
    db=db,
    add_history_to_context=True,
    enable_user_memories=True,
)

agent_2 = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are really grumpy and mean.",
    db=db,
    add_history_to_context=True,
    enable_user_memories=True,
)

agent_1.print_response(
    "Hi! My name is John Doe.", session_id=session_id, user_id=user_id
)

agent_2.print_response("What is my name?", session_id=session_id, user_id=user_id)

agent_2.print_response(
    "I like to hike in the mountains on weekends.",
    session_id=session_id,
    user_id=user_id,
)

agent_1.print_response("What are my hobbies?", session_id=session_id, user_id=user_id)

agent_1.print_response(
    "What have we been discussing? Give me bullet points.",
    session_id=session_id,
    user_id=user_id,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/07_share_memory_and_history_between_agents.py
      ```

      ```bash Windows
      python cookbook/memory/07_share_memory_and_history_between_agents.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory with MongoDB
Source: https://docs.agno.com/examples/concepts/memory/db/mem-mongodb-memory



## Code

```python cookbook/memory/db/mem-mongodb-memory.py
from agno.agent import Agent
from agno.db.mongo import MongoDb

# Setup MongoDb
db_url = "mongodb://localhost:27017"

db = MongoDb(db_url=db_url)

agent = Agent(
    db=db,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")
agent.print_response("What's do I do in weekends?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai pymongo
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac/Linux
      python cookbook/memory/db/mem-mongodb-memory.py
      ```

      ```bash Windows
      python cookbook/memory/db/mem-mongodb-memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory with PostgreSQL
Source: https://docs.agno.com/examples/concepts/memory/db/mem-postgres-memory



## Code

```python cookbook/memory/db/mem-postgres-memory.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb

# Setup Postgres
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    db=db,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")
agent.print_response("What's do I do in weekends?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai sqlalchemy 'psycopg[binary]'
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac/Linux
      python cookbook/memory/db/mem-postgres-memory.py
      ```

      ```bash Windows
      python cookbook/memory/db/mem-postgres-memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory with Redis
Source: https://docs.agno.com/examples/concepts/memory/db/mem-redis-memory



## Code

```python cookbook/memory/db/mem-redis-memory.py
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.redis import RedisDb

# Setup Redis
# Initialize Redis db (use the right db_url for your setup)
db = RedisDb(db_url="redis://localhost:6379")

# Create agent with Redis db
agent = Agent(
    db=db,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")
agent.print_response("What's do I do in weekends?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai redis
    ```
  </Step>

  <Step title="Run Redis">
    ```bash
    docker run --name my-redis -p 6379:6379 -d redis
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac/Linux
      python cookbook/memory/db/mem-redis-memory.py
      ```

      ```bash Windows
      python cookbook/memory/db/mem-redis-memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory with SQLite
Source: https://docs.agno.com/examples/concepts/memory/db/mem-sqlite-memory



## Code

```python cookbook/memory/db/mem-sqlite-memory.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

# Setup the SQLite database
db = SqliteDb(db_file="tmp/data.db")

# Setup a basic agent with the SQLite database
agent = Agent(
    db=db,
    enable_user_memories=True,
)

agent.print_response("My name is John Doe and I like to play basketball on the weekends.")
agent.print_response("What's do I do in weekends?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac/Linux
      python cookbook/memory/db/mem-sqlite-memory.py
      ```

      ```bash Windows
      python cookbook/memory/db/mem-sqlite-memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Standalone Memory
Source: https://docs.agno.com/examples/concepts/memory/memory_manager/01-standalone-memory



## Code

```python cookbook/memory/memory_manager/01_standalone_memory.py
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager, UserMemory
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

memory = MemoryManager(db=PostgresDb(db_url=db_url))

# Add a memory for the default user
memory.add_user_memory(
    memory=UserMemory(memory="The user's name is John Doe", topics=["name"]),
)
print("Memories:")
pprint(memory.get_user_memories())

# Add memories for Jane Doe
jane_doe_id = "jane_doe@example.com"
print(f"\nUser: {jane_doe_id}")
memory_id_1 = memory.add_user_memory(
    memory=UserMemory(memory="The user's name is Jane Doe", topics=["name"]),
    user_id=jane_doe_id,
)
memory_id_2 = memory.add_user_memory(
    memory=UserMemory(memory="She likes to play tennis", topics=["hobbies"]),
    user_id=jane_doe_id,
)
memories = memory.get_user_memories(user_id=jane_doe_id)
print("Memories:")
pprint(memories)

# Delete a memory
print("\nDeleting memory")
assert memory_id_2 is not None
memory.delete_user_memory(user_id=jane_doe_id, memory_id=memory_id_2)
print("Memory deleted\n")
memories = memory.get_user_memories(user_id=jane_doe_id)
print("Memories:")
pprint(memories)

# Replace a memory
print("\nReplacing memory")
assert memory_id_1 is not None
memory.replace_user_memory(
    memory_id=memory_id_1,
    memory=UserMemory(memory="The user's name is Jane Mary Doe", topics=["name"]),
    user_id=jane_doe_id,
)
print("Memory replaced")
memories = memory.get_user_memories(user_id=jane_doe_id)
print("Memories:")
pprint(memories)
```

## Usage

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/memory_manager/01_standalone_memory.py
      ```

      ```bash Windows
      python cookbook/memory/memory_manager/01_standalone_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory Creation
Source: https://docs.agno.com/examples/concepts/memory/memory_manager/02-memory-creation



Create user memories with an Agent by providing a either text or a list of messages.

## Code

```python cookbook/memory/memory_manager/02_memory_creation.py
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager, UserMemory
from agno.models.message import Message
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

memory_db = PostgresDb(db_url=db_url)

memory = MemoryManager(model=OpenAIChat(id="gpt-5-mini"), db=memory_db)

john_doe_id = "john_doe@example.com"
memory.add_user_memory(
    memory=UserMemory(
        memory="""
I enjoy hiking in the mountains on weekends,
reading science fiction novels before bed,
cooking new recipes from different cultures,
playing chess with friends,
and attending live music concerts whenever possible.
Photography has become a recent passion of mine, especially capturing landscapes and street scenes.
I also like to meditate in the mornings and practice yoga to stay centered.
"""
    ),
    user_id=john_doe_id,
)


memories = memory.get_user_memories(user_id=john_doe_id)
print("John Doe's memories:")
pprint(memories)

jane_doe_id = "jane_doe@example.com"
# Send a history of messages and add memories
memory.create_user_memories(
    messages=[
        Message(role="user", content="My name is Jane Doe"),
        Message(role="assistant", content="That is great!"),
        Message(role="user", content="I like to play chess"),
        Message(role="assistant", content="That is great!"),
    ],
    user_id=jane_doe_id,
)

memories = memory.get_user_memories(user_id=jane_doe_id)
print("Jane Doe's memories:")
pprint(memories)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/memory_manager/02_memory_creation.py
      ```

      ```bash Windows
      python cookbook/memory/memory_manager/02_memory_creation.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Custom Memory Instructions
Source: https://docs.agno.com/examples/concepts/memory/memory_manager/03-custom-memory-instructions



Create user memories with an Agent by providing a either text or a list of messages.

## Code

```python cookbook/memory/memory_manager/03_custom_memory_instructions.py
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager
from agno.models.anthropic.claude import Claude
from agno.models.message import Message
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

memory_db = PostgresDb(db_url=db_url)

memory = MemoryManager(
    model=OpenAIChat(id="gpt-5-mini"),
    memory_capture_instructions="""\
                    Memories should only include details about the user's academic interests.
                    Only include which subjects they are interested in.
                    Ignore names, hobbies, and personal interests.
                    """,
    db=memory_db,
)

john_doe_id = "john_doe@example.com"

memory.create_user_memories(
    message="""\
My name is John Doe.

I enjoy hiking in the mountains on weekends,
reading science fiction novels before bed,
cooking new recipes from different cultures,
playing chess with friends.

I am interested to learn about the history of the universe and other astronomical topics.
""",
    user_id=john_doe_id,
)


memories = memory.get_user_memories(user_id=john_doe_id)
print("John Doe's memories:")
pprint(memories)


# Use default memory manager
memory = MemoryManager(model=Claude(id="claude-3-5-sonnet-latest"), db=memory_db)
jane_doe_id = "jane_doe@example.com"

# Send a history of messages and add memories
memory.create_user_memories(
    messages=[
        Message(role="user", content="Hi, how are you?"),
        Message(role="assistant", content="I'm good, thank you!"),
        Message(role="user", content="What are you capable of?"),
        Message(
            role="assistant",
            content="I can help you with your homework and answer questions about the universe.",
        ),
        Message(role="user", content="My name is Jane Doe"),
        Message(role="user", content="I like to play chess"),
        Message(
            role="user",
            content="Actually, forget that I like to play chess. I more enjoy playing table top games like dungeons and dragons",
        ),
        Message(
            role="user",
            content="I'm also interested in learning about the history of the universe and other astronomical topics.",
        ),
        Message(role="assistant", content="That is great!"),
        Message(
            role="user",
            content="I am really interested in physics. Tell me about quantum mechanics?",
        ),
    ],
    user_id=jane_doe_id,
)

memories = memory.get_user_memories(user_id=jane_doe_id)
print("Jane Doe's memories:")
pprint(memories)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/memory_manager/03_custom_memory_instructions.py
      ```

      ```bash Windows
      python cookbook/memory/memory_manager/03_custom_memory_instructions.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory Search
Source: https://docs.agno.com/examples/concepts/memory/memory_manager/04-memory-search



How to search for user memories using different retrieval methods.

* `last_n`: Retrieves the last n memories
* `first_n`: Retrieves the first n memories
* `semantic`: Retrieves memories using semantic search

## Code

```python cookbook/memory/memory_manager/04_memory_search.py
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager, UserMemory
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

memory_db = PostgresDb(db_url=db_url)

memory = MemoryManager(model=OpenAIChat(id="gpt-5-mini"), db=memory_db)

john_doe_id = "john_doe@example.com"
memory.add_user_memory(
    memory=UserMemory(memory="The user enjoys hiking in the mountains on weekends"),
    user_id=john_doe_id,
)
memory.add_user_memory(
    memory=UserMemory(
        memory="The user enjoys reading science fiction novels before bed"
    ),
    user_id=john_doe_id,
)
print("John Doe's memories:")
pprint(memory.get_user_memories(user_id=john_doe_id))

memories = memory.search_user_memories(
    user_id=john_doe_id, limit=1, retrieval_method="last_n"
)
print("\nJohn Doe's last_n memories:")
pprint(memories)

memories = memory.search_user_memories(
    user_id=john_doe_id, limit=1, retrieval_method="first_n"
)
print("\nJohn Doe's first_n memories:")
pprint(memories)

memories = memory.search_user_memories(
    user_id=john_doe_id,
    query="What does the user like to do on weekends?",
    retrieval_method="agentic",
)
print("\nJohn Doe's memories similar to the query (agentic):")
pprint(memories)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/memory/memory_manager/04_memory_search.py
      ```

      ```bash Windows
      python cookbook/memory/memory_manager/04_memory_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input Output
Source: https://docs.agno.com/examples/concepts/multimodal/audio-input-output



## Code

```python
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)

run_result = agent.run(
    "What's in these recording?",
    audio=[Audio(content=wav_data, format="wav")],
)

if run_result.response_audio is not None:
    write_audio_to_file(
        audio=run_result.response_audio.content, filename="tmp/result.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_input_output.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_input_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Multi-turn Audio Agent
Source: https://docs.agno.com/examples/concepts/multimodal/audio-multi-turn



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    debug_mode=True,
    add_history_to_context=True,
)

response_1 = agent.run("Is a golden retriever a good family dog?")
if response_1.response_audio is not None:
    write_audio_to_file(
        audio=response_1.response_audio.content, filename="tmp/answer_1.wav"
    )

response_2 = agent.run("Why do you say they are loyal?")
if response_2.response_audio is not None:
    write_audio_to_file(
        audio=response_2.response_audio.content, filename="tmp/answer_2.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_multi_turn.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_multi_turn.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Sentiment Analysis Agent
Source: https://docs.agno.com/examples/concepts/multimodal/audio-sentiment-analysis



## Code

```python
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

response = requests.get(url)
audio_content = response.content


agent.print_response(
    "Give a sentiment analysis of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install google-genai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_sentiment_analysis.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_sentiment_analysis.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Streaming Agent
Source: https://docs.agno.com/examples/concepts/multimodal/audio-streaming



## Code

```python
import base64
import wave
from typing import Iterator

from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat

# Audio Configuration
SAMPLE_RATE = 24000  # Hz (24kHz)
CHANNELS = 1  # Mono (Change to 2 if Stereo)
SAMPLE_WIDTH = 2  # Bytes (16 bits)

# Provide the agent with the audio file and audio configuration and get result as text + audio
agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={
            "voice": "alloy",
            "format": "pcm16",
        },  # Only pcm16 is supported with streaming
    ),
)
output_stream: Iterator[RunOutputEvent] = agent.run(
    "Tell me a 10 second story", stream=True
)

filename = "tmp/response_stream.wav"

# Open the file once in append-binary mode
with wave.open(str(filename), "wb") as wav_file:
    wav_file.setnchannels(CHANNELS)
    wav_file.setsampwidth(SAMPLE_WIDTH)
    wav_file.setframerate(SAMPLE_RATE)

    # Iterate over generated audio
    for response in output_stream:
        response_audio = response.response_audio  # type: ignore
        if response_audio:
            if response_audio.transcript:
                print(response_audio.transcript, end="", flush=True)
            if response_audio.content:
                try:
                    pcm_bytes = base64.b64decode(response_audio.content)
                    wav_file.writeframes(pcm_bytes)
                except Exception as e:
                    print(f"Error decoding audio: {e}")
print()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_streaming.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_streaming.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio to text Agent
Source: https://docs.agno.com/examples/concepts/multimodal/audio-to-text



## Code

```python
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"

response = requests.get(url)
audio_content = response.content


agent.print_response(
    "Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install google-genai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_to_text.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_to_text.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Blog to Podcast Agent
Source: https://docs.agno.com/examples/concepts/multimodal/blog-to-podcast



## Code

```python
import os
from uuid import uuid4
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.eleven_labs import ElevenLabsTools
from agno.tools.firecrawl import FirecrawlTools
from agno.agent import Agent, RunOutput
from agno.utils.audio import write_audio_to_file
from agno.utils.log import logger


url = "https://www.bcg.com/capabilities/artificial-intelligence/ai-agents"

blog_to_podcast_agent = Agent(
    name="Blog to Podcast Agent",
    id="blog_to_podcast_agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ElevenLabsTools(
            voice_id="JBFqnCBsd6RMkjVDRZzb",
            model_id="eleven_multilingual_v2",
            target_directory="audio_generations",
        ),
        FirecrawlTools(),
    ],
    description="You are an AI agent that can generate audio using the ElevenLabs API.",
    instructions=[
        "When the user provides a blog URL:",
        "1. Use FirecrawlTools to scrape the blog content",
        "2. Create a concise summary of the blog content that is NO MORE than 2000 characters long", 
        "3. The summary should capture the main points while being engaging and conversational",
        "4. Use the ElevenLabsTools to convert the summary to audio",
        "You don't need to find the appropriate voice first, I already specified the voice to user",
        "Ensure the summary is within the 2000 character limit to avoid ElevenLabs API limits",
    ],
    markdown=True,
    debug_mode=True,
)

podcast: RunOutput = blog_to_podcast_agent.run(
    f"Convert the blog content to a podcast: {url}"
)

save_dir = "audio_generations"

if podcast.audio is not None and len(podcast.audio) > 0:
    try:
        os.makedirs(save_dir, exist_ok=True)
        filename = f"{save_dir}/sample_podcast{uuid4()}.wav"
        write_audio_to_file(
            audio=podcast.audio[0].content,
            filename=filename
        )
        print(f"Audio saved successfully to: {filename}")
    except Exception as e:
        print(f"Error saving audio file: {e}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export ELEVEN_LABS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai elevenlabs firecrawl-py agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/blog_to_podcast.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/blog_to_podcast.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Images with Intermediate Steps
Source: https://docs.agno.com/examples/concepts/multimodal/generate-image



## Code

```python
from typing import Iterator

from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools
from agno.utils.common import dataclass_to_dict
from rich.pretty import pprint

image_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DalleTools()],
    description="You are an AI agent that can create images using DALL-E.",
    instructions=[
        "When the user asks you to create an image, use the DALL-E tool to create an image.",
        "The DALL-E tool will return an image URL.",
        "Return the image URL in your response in the following format: `![image description](image URL)`",
    ],
    markdown=True,
)

run_stream: Iterator[RunOutputEvent] = image_agent.run(
    "Create an image of a yellow siamese cat",
    stream=True,
    stream_intermediate_steps=True,
)
for chunk in run_stream:
    pprint(dataclass_to_dict(chunk, exclude={"messages"}))
    print("---" * 20)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai rich agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_image_with_intermediate_steps.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_image_with_intermediate_steps.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Music using Models Lab
Source: https://docs.agno.com/examples/concepts/multimodal/generate-music-agent



## Code

```python
import os
from uuid import uuid4

import requests
from agno.agent import Agent, RunOutput
from agno.models.openai import OpenAIChat
from agno.tools.models_labs import FileType, ModelsLabTools
from agno.utils.log import logger

agent = Agent(
    name="ModelsLab Music Agent",
    id="ml_music_agent",
    model=OpenAIChat(id="gpt-5-mini"),
        tools=[ModelsLabTools(wait_for_completion=True, file_type=FileType.MP3)],
    description="You are an AI agent that can generate music using the ModelsLabs API.",
    instructions=[
        "When generating music, use the `generate_media` tool with detailed prompts that specify:",
        "- The genre and style of music (e.g., classical, jazz, electronic)",
        "- The instruments and sounds to include",
        "- The tempo, mood and emotional qualities",
        "- The structure (intro, verses, chorus, bridge, etc.)",
        "Create rich, descriptive prompts that capture the desired musical elements.",
        "Focus on generating high-quality, complete instrumental pieces.",
    ],
    markdown=True,
    debug_mode=True,
)

music: RunOutput = agent.run("Generate a 30 second classical music piece")

save_dir = "audio_generations"

if music.audio is not None and len(music.audio) > 0:
    url = music.audio[0].url
    response = requests.get(url)
    os.makedirs(save_dir, exist_ok=True)
    filename = f"{save_dir}/sample_music{uuid4()}.wav"
    with open(filename, "wb") as f:
        f.write(response.content)
    logger.info(f"Music saved to {filename}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export MODELS_LAB_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_music_agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_music_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Video using Models Lab
Source: https://docs.agno.com/examples/concepts/multimodal/generate-video-models-lab



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models_labs import ModelsLabTools

video_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ModelsLabTools()],
    description="You are an AI agent that can generate videos using the ModelsLabs API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "The video will be displayed in the UI automatically below your response, so you don't need to show the video URL in your response.",
        "Politely and courteously let the user know that the video has been generated and will be displayed below as soon as its ready.",
    ],
    markdown=True,
    debug_mode=True,
    )

video_agent.print_response("Generate a video of a cat playing with a ball")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export MODELS_LAB_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_video_using_models_lab.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_video_using_models_lab.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Video using Replicate
Source: https://docs.agno.com/examples/concepts/multimodal/generate-video-replicate



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.replicate import ReplicateTools

video_agent = Agent(
    name="Video Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ReplicateTools(
            model="tencent/hunyuan-video:847dfa8b01e739637fc76f480ede0c1d76408e1d694b830b5dfb8e547bf98405"
        )
    ],
    description="You are an AI agent that can generate videos using the Replicate API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    )

video_agent.print_response("Generate a video of a horse in the dessert.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export REPLICATE_API_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai replicate agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_video_using_replicate.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_video_using_replicate.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Audio Agent
Source: https://docs.agno.com/examples/concepts/multimodal/image-to-audio



## Code

```python
from pathlib import Path

from agno.agent import Agent, RunOutput
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from rich import print
from rich.text import Text

image_agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

image_path = Path(__file__).parent.joinpath("sample.jpg")
image_story: RunOutput = image_agent.run(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
formatted_text = Text.from_markup(
    f":sparkles: [bold magenta]Story:[/bold magenta] {image_story.content} :sparkles:"
)
print(formatted_text)

audio_agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
)

audio_story: RunOutput = audio_agent.run(
    f"Narrate the story with flair: {image_story.content}"
)
if audio_story.response_audio is not None:
    write_audio_to_file(
        audio=audio_story.response_audio.content, filename="tmp/sample_story.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai rich agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/image_to_audio.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/image_to_audio.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Image Agent
Source: https://docs.agno.com/examples/concepts/multimodal/image-to-image



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    id="image-to-image",
    name="Image to Image Agent",
    tools=[FalTools()],
    markdown=True,
    debug_mode=True,
        instructions=[
        "You have to use the `image_to_image` tool to generate the image.",
        "You are an AI agent that can generate images using the Fal AI API.",
        "You will be given a prompt and an image URL.",
        "You have to return the image URL as provided, don't convert it to markdown or anything else.",
    ],
)

agent.print_response(
    "a cat dressed as a wizard with a background of a mystic forest. Make it look like 'https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png'",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export FAL_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai fal agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/image_to_image_agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/image_to_image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Text Agent
Source: https://docs.agno.com/examples/concepts/multimodal/image-to-text



## Code

```python
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    id="image-to-text",
    name="Image to Text Agent",
    markdown=True,
    debug_mode=True,
        instructions=[
        "You are an AI agent that can generate text descriptions based on an image.",
        "You have to return a text response describing the image.",
    ],
)
image_path = Path(__file__).parent.joinpath("sample.jpg")
agent.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/image_to_text_agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/image_to_text_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Caption Agent
Source: https://docs.agno.com/examples/concepts/multimodal/video-caption



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.moviepy_video import MoviePyVideoTools
from agno.tools.openai import OpenAITools

video_tools = MoviePyVideoTools(
    process_video=True, generate_captions=True, embed_captions=True
)

openai_tools = OpenAITools()

video_caption_agent = Agent(
    name="Video Caption Generator Agent",
    model=OpenAIChat(
        id="gpt-5-mini",
    ),
    tools=[video_tools, openai_tools],
    description="You are an AI agent that can generate and embed captions for videos.",
    instructions=[
        "When a user provides a video, process it to generate captions.",
        "Use the video processing tools in this sequence:",
        "1. Extract audio from the video using extract_audio",
        "2. Transcribe the audio using transcribe_audio",
        "3. Generate SRT captions using create_srt",
        "4. Embed captions into the video using embed_captions",
    ],
    markdown=True,
)

video_caption_agent.print_response(
    "Generate captions for {video with location} and embed them in the video"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai moviepy ffmpeg agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/video_caption_agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/video_caption_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video to Shorts Agent
Source: https://docs.agno.com/examples/concepts/multimodal/video-to-shorts



## Code

```python
import subprocess
import time
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini
from agno.utils.log import logger
from google.generativeai import get_file, upload_file

video_path = Path(__file__).parent.joinpath("sample.mp4")
output_dir = Path("tmp/shorts")

agent = Agent(
    name="Video2Shorts",
    description="Process videos and generate engaging shorts.",
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
    debug_mode=True,
    instructions=[
        "Analyze the provided video directly‚Äîdo NOT reference or analyze any external sources or YouTube videos.",
        "Identify engaging moments that meet the specified criteria for short-form content.",
        """Provide your analysis in a **table format** with these columns:
   - Start Time | End Time | Description | Importance Score""",
        "Ensure all timestamps use MM:SS format and importance scores range from 1-10. ",
        "Focus only on segments between 15 and 60 seconds long.",
        "Base your analysis solely on the provided video content.",
        "Deliver actionable insights to improve the identified segments for short-form optimization.",
    ],
)

# Upload and process video
video_file = upload_file(video_path)
while video_file.state.name == "PROCESSING":
    time.sleep(2)
    video_file = get_file(video_file.name)

# Multimodal Query for Video Analysis
query = """
You are an expert in video content creation, specializing in crafting engaging short-form content for platforms like YouTube Shorts and Instagram Reels. Your task is to analyze the provided video and identify segments that maximize viewer engagement.

For each video, you'll:

1. Identify key moments that will capture viewers' attention, focusing on:
   - High-energy sequences
   - Emotional peaks
   - Surprising or unexpected moments
   - Strong visual and audio elements
   - Clear narrative segments with compelling storytelling

2. Extract segments that work best for short-form content, considering:
   - Optimal length (strictly 15‚Äì60 seconds)
   - Natural start and end points that ensure smooth transitions
   - Engaging pacing that maintains viewer attention
   - Audio-visual harmony for an immersive experience
   - Vertical format compatibility and adjustments if necessary

3. Provide a detailed analysis of each segment, including:
   - Precise timestamps (Start Time | End Time in MM:SS format)
   - A clear description of why the segment would be engaging
   - Suggestions on how to enhance the segment for short-form content
   - An importance score (1-10) based on engagement potential

Your goal is to identify moments that are visually compelling, emotionally engaging, and perfectly optimized for short-form platforms.
"""

# Generate Video Analysis
response = agent.run(query, videos=[Video(content=video_file)])

# Create output directory
output_dir = Path(output_dir)
output_dir.mkdir(parents=True, exist_ok=True)

# Extract and cut video segments
def extract_segments(response_text):
    import re

    segments_pattern = r"\|\s*(\d+:\d+)\s*\|\s*(\d+:\d+)\s*\|\s*(.*?)\s*\|\s*(\d+)\s*\|"
    segments: list[dict] = []

    for match in re.finditer(segments_pattern, str(response_text)):
        start_time = match.group(1)
        end_time = match.group(2)
        description = match.group(3)
        score = int(match.group(4))

        start_seconds = sum(x * int(t) for x, t in zip([60, 1], start_time.split(":")))
        end_seconds = sum(x * int(t) for x, t in zip([60, 1], end_time.split(":")))
        duration = end_seconds - start_seconds

        if 15 <= duration <= 60 and score > 7:
            output_path = output_dir / f"short_{len(segments) + 1}.mp4"

            command = [
                "ffmpeg",
                "-ss",
                str(start_seconds),
                "-i",
                video_path,
                "-t",
                str(duration),
                "-vf",
                "scale=1080:1920,setsar=1:1",
                "-c:v",
                "libx264",
                "-c:a",
                "aac",
                "-y",
                str(output_path),
            ]

            try:
                subprocess.run(command, check=True)
                segments.append(
                    {"path": output_path, "description": description, "score": score}
                )
            except subprocess.CalledProcessError:
                print(f"Failed to process segment: {start_time} - {end_time}")

    return segments

logger.debug(f"{response.content}")

# Process segments
shorts = extract_segments(response.content)

# Print results
print("\n--- Generated Shorts ---")
for short in shorts:
    print(f"Short at {short['path']}")
    print(f"Description: {short['description']}")
    print(f"Engagement Score: {short['score']}/10\n")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U opencv-python google-generativeai sqlalchemy ffmpeg-python agno
    ```
  </Step>

  <Step title="Install ffmpeg">
    <CodeGroup>
      ```bash Mac
      brew install ffmpeg
      ```

      ```bash Windows
      # Install ffmpeg using chocolatey or download from https://ffmpeg.org/download.html
      choco install ffmpeg
      ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/video_to_shorts.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/video_to_shorts.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Reasoning Agent
Source: https://docs.agno.com/examples/concepts/reasoning/agents/basic-cot



This example demonstrates how to configure a basic Reasoning Agent, using the `reasoning=True` flag.

## Code

```python cookbook/reasoning/agents/analyse_treaty_of_versailles.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "Analyze the key factors that led to the signing of the Treaty of Versailles in 1919. "
    "Discuss the political, economic, and social impacts of the treaty on Germany and how it "
    "contributed to the onset of World War II. Provide a nuanced assessment that includes "
    "multiple historical perspectives."
)

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True, # The Agent will be able to reason.
    markdown=True,
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/agents/analyse_treaty_of_versailles.py
      ```

      ```bash Windows
      python cookbook/reasoning/agents/analyse_treaty_of_versailles.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Capture Reasoning Content
Source: https://docs.agno.com/examples/concepts/reasoning/agents/capture-reasoning-content-cot



This example demonstrates how to access and print the `reasoning_content` when using a Reasoning Agent (with `reasoning=True`) or setting a specific `reasoning_model`.

## Code

```python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

print("\n=== Example 1: Using reasoning=True (default COT) ===\n")

# Create agent with reasoning=True (default model COT)
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True,
    markdown=True,
)

# Run the agent (non-streaming)
print("Running with reasoning=True (non-streaming)...")
response = agent.run("What is the sum of the first 10 natural numbers?")

# Print the reasoning_content
print("\n--- reasoning_content from response ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print("‚úÖ reasoning_content FOUND in non-streaming response")
    print(f"   Length: {len(response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (non-streaming) ===")
    preview = response.reasoning_content[:1000]
    if len(response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in non-streaming response")


print("\n\n=== Example 2: Using a custom reasoning_model ===\n")

# Create agent with a specific reasoning_model
agent_with_reasoning_model = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning_model=OpenAIChat(id="gpt-5-mini"),  # Should default to manual COT
    markdown=True,
)

# Run the agent (non-streaming)
print("Running with reasoning_model specified (non-streaming)...")
response = agent_with_reasoning_model.run(
    "What is the sum of the first 10 natural numbers?"
)

# Print the reasoning_content
print("\n--- reasoning_content from response ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print("‚úÖ reasoning_content FOUND in non-streaming response")
    print(f"   Length: {len(response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (non-streaming) ===")
    preview = response.reasoning_content[:1000]
    if len(response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in non-streaming response")


print("\n\n=== Example 3: Processing stream with reasoning=True ===\n")

# Create a fresh agent for streaming
streaming_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning=True,
    markdown=True,
)

# Process streaming responses and look for the final RunOutput
print("Running with reasoning=True (streaming)...")
final_response = None
for event in streaming_agent.run(
    "What is the value of 5! (factorial)?",
    stream=True,
    stream_intermediate_steps=True,
):
    # Print content as it streams (optional)
    if hasattr(event, "content") and event.content:
        print(event.content, end="", flush=True)

    # The final event in the stream should be a RunOutput object
    if hasattr(event, "reasoning_content"):
        final_response = event

print("\n\n--- reasoning_content from final stream event ---")
if (
    final_response
    and hasattr(final_response, "reasoning_content")
    and final_response.reasoning_content
):
    print("‚úÖ reasoning_content FOUND in final stream event")
    print(f"   Length: {len(final_response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (streaming) ===")
    preview = final_response.reasoning_content[:1000]
    if len(final_response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in final stream event")


print("\n\n=== Example 4: Processing stream with reasoning_model ===\n")

# Create a fresh agent with reasoning_model for streaming
streaming_agent_with_model = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning_model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
)

# Process streaming responses and look for the final RunOutput
print("Running with reasoning_model specified (streaming)...")
final_response_with_model = None
for event in streaming_agent_with_model.run(
    "What is the value of 7! (factorial)?",
    stream=True,
    stream_intermediate_steps=True,
):
    # Print content as it streams (optional)
    if hasattr(event, "content") and event.content:
        print(event.content, end="", flush=True)

    # The final event in the stream should be a RunOutput object
    if hasattr(event, "reasoning_content"):
        final_response_with_model = event

print("\n\n--- reasoning_content from final stream event (reasoning_model) ---")
if (
    final_response_with_model
    and hasattr(final_response_with_model, "reasoning_content")
    and final_response_with_model.reasoning_content
):
    print("‚úÖ reasoning_content FOUND in final stream event")
    print(f"   Length: {len(final_response_with_model.reasoning_content)} characters")
    print("\n=== reasoning_content preview (streaming with reasoning_model) ===")
    preview = final_response_with_model.reasoning_content[:1000]
    if len(final_response_with_model.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in final stream event")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
      ```

      ```bash Windows
      python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Non-Reasoning Model Agent
Source: https://docs.agno.com/examples/concepts/reasoning/agents/non-reasoning-model



This example demonstrates how to use a non-reasoning model as a reasoning model.

For reasoning, we recommend using a Reasoning Agent (with `reasoning=True`), or to use an appropriate reasoning model with `reasoning_model=`.

## Code

```python cookbook/reasoning/agents/default_chain_of_thought.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning_model=OpenAIChat(
        id="gpt-5-mini", # This model will be used for reasoning, although it is not a native reasoning model.
        max_tokens=1200,
    ),
    markdown=True,
)
reasoning_agent.print_response(
    "Give me steps to write a python script for fibonacci series",
    stream=True,
    show_full_reasoning=True,
)

# It uses the default model of the Agent
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini", max_tokens=1200),
    reasoning=True,
    markdown=True,
)
reasoning_agent.print_response(
    "Give me steps to write a python script for fibonacci series",
    stream=True,
    show_full_reasoning=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/agents/default_chain_of_thought.py
      ```

      ```bash Windows
      python cookbook/reasoning/agents/default_chain_of_thought.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure AI Foundry
Source: https://docs.agno.com/examples/concepts/reasoning/models/azure-ai-foundary/azure-ai-foundary



## Code

```python cookbook/reasoning/models/azure_ai_foundry/reasoning_model_deepseek.py
import os

from agno.agent import Agent
from agno.models.azure import AzureAIFoundry

agent = Agent(
    model=AzureAIFoundry(id="gpt-5-mini"),
    reasoning_model=AzureAIFoundry(
        id="DeepSeek-R1",
        azure_endpoint=os.getenv("AZURE_ENDPOINT"),
        api_key=os.getenv("AZURE_API_KEY"),
    ),
)

agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/azure_ai_foundry/reasoning_model_deepseek.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/azure_ai_foundry/reasoning_model_deepseek.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure OpenAI o1
Source: https://docs.agno.com/examples/concepts/reasoning/models/azure-openai/o1



## Code

```python cookbook/reasoning/models/azure_openai/o1.py
from agno.agent import Agent
from agno.models.azure.openai_chat import AzureOpenAI

agent = Agent(model=AzureOpenAI(id="o1"))
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/azure_openai/o1.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/azure_openai/o1.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure OpenAI o3
Source: https://docs.agno.com/examples/concepts/reasoning/models/azure-openai/o3-tools



## Code

```python ccookbook/reasoning/models/azure_openai/o3_mini_with_tools.py
from agno.agent import Agent
from agno.models.azure.openai_chat import AzureOpenAI
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=AzureOpenAI(id="o3"),
    tools=[
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        )
    ],
    instructions="Use tables to display data.",
        markdown=True,
)
agent.print_response("Write a report comparing NVDA to TSLA", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python ccookbook/reasoning/models/azure_openai/o3_mini_with_tools.py
      ```

      ```bash Windows
      python ccookbook/reasoning/models/azure_openai/o3_mini_with_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure OpenAI GPT 4.1
Source: https://docs.agno.com/examples/concepts/reasoning/models/azure-openai/reasoning-model-gpt4-1



## Code

```python cookbook/reasoning/models/azure_openai/reasoning_model_gpt_4_1.py
from agno.agent import Agent
from agno.models.azure.openai_chat import AzureOpenAI

agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"), reasoning_model=AzureOpenAI(id="gpt-4.1")
)
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/azure_openai/reasoning_model_gpt_4_1.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/azure_openai/reasoning_model_gpt_4_1.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DeepSeek Reasoner
Source: https://docs.agno.com/examples/concepts/reasoning/models/deepseek/trolley-problem



## Code

```python cookbook/reasoning/models/deepseek/trolley_problem.py
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.models.openai import OpenAIChat

task = (
    "You are a philosopher tasked with analyzing the classic 'Trolley Problem'. In this scenario, a runaway trolley "
    "is barreling down the tracks towards five people who are tied up and unable to move. You are standing next to "
    "a large stranger on a footbridge above the tracks. The only way to save the five people is to push this stranger "
    "off the bridge onto the tracks below. This will kill the stranger, but save the five people on the tracks. "
    "Should you push the stranger to save the five people? Provide a well-reasoned answer considering utilitarian, "
    "deontological, and virtue ethics frameworks. "
    "Include a simple ASCII art diagram to illustrate the scenario."
)

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    reasoning_model=DeepSeek(id="deepseek-reasoner"),
    markdown=True,
)
reasoning_agent.print_response(task, stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/deepseek/trolley_problem.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/deepseek/trolley_problem.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Groq DeepSeek R1
Source: https://docs.agno.com/examples/concepts/reasoning/models/groq/groq-basic



## Code

```python cookbook/reasoning/models/groq/9_11_or_9_9.py
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(
    model=Groq(
        id="deepseek-r1-distill-llama-70b", temperature=0.6, max_tokens=1024, top_p=0.95
    ),
    markdown=True,
)
agent.print_response("9.11 and 9.9 -- which is bigger?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/groq/9_11_or_9_9.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/groq/9_11_or_9_9.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Groq Claude + DeepSeek R1
Source: https://docs.agno.com/examples/concepts/reasoning/models/groq/groq-plus-claude



## Code

```python cookbook/reasoning/models/groq/deepseek_plus_claude.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.groq import Groq

deepseek_plus_claude = Agent(
    model=Claude(id="claude-3-7-sonnet-20250219"),
    reasoning_model=Groq(
        id="deepseek-r1-distill-llama-70b", temperature=0.6, max_tokens=1024, top_p=0.95
    ),
)
deepseek_plus_claude.print_response("9.11 and 9.9 -- which is bigger?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/groq/deepseek_plus_claude.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/groq/deepseek_plus_claude.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Ollama DeepSeek R1
Source: https://docs.agno.com/examples/concepts/reasoning/models/ollama/ollama-basic



## Code

```python cookbook/reasoning/models/ollama/reasoning_model_deepseek.py
from agno.agent import Agent
from agno.models.ollama.chat import Ollama

agent = Agent(
    model=Ollama(id="llama3.2:latest"),
    reasoning_model=Ollama(id="deepseek-r1:14b", max_tokens=4096),
)
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2:latest
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/ollama/reasoning_model_deepseek.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/ollama/reasoning_model_deepseek.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI o1 pro
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/o1-pro



## Code

```python cookbook/reasoning/models/openai/o1_pro.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="o1-pro"))
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/o1_pro.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/o1_pro.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI gpt-5-mini
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/o3-mini



## Code

```python cookbook/reasoning/models/openai/o3_mini.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))
agent.print_response("Write a report comparing NVDA to TSLA", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/o3_mini.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/o3_mini.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI gpt-5-mini with Tools
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/o3-mini-tools



## Code

```python cookbook/reasoning/models/openai/o3_mini_with_tools.py
"""Run `pip install openai ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(search=True)],
    instructions="Use tables to display data.",
    markdown=True,
)

agent.print_response("Write a report comparing NVDA to TSLA", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/o3_mini_with_tools.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/o3_mini_with_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI o4-mini
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/o4-mini



## Code

```python cookbook/reasoning/models/openai/o4_mini.py
from agno.agent import Agent
from agno.models.openai.responses import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="o4-mini"))

agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/o4_mini.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/o4_mini.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI gpt-5-mini with reasoning effort
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/reasoning-effort



## Code

```python cookbook/reasoning/models/openai/reasoning_effort.py
"""Run `pip install openai ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini", reasoning_effort="high"),
    tools=[DuckDuckGoTools(search=True)],
    instructions="Use tables to display data.",
    markdown=True,
)

agent.print_response("Write a report comparing NVDA to TSLA", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/reasoning_effort.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/reasoning_effort.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI GPT-4.1
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/reasoning-model-gpt-4-1



## Code

```python cookbook/reasoning/models/openai/reasoning_model_gpt_4_1.py
from agno.agent import Agent
from agno.models.openai.responses import OpenAIResponses

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    reasoning_model=OpenAIResponses(id="gpt-4.1"),
)
agent.print_response(
    "Solve the trolley problem. Evaluate multiple ethical frameworks. "
    "Include an ASCII diagram of your solution.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/reasoning_model_gpt_4_1.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/reasoning_model_gpt_4_1.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI o4-mini with reasoning summary
Source: https://docs.agno.com/examples/concepts/reasoning/models/openai/reasoning-summary



## Code

```python cookbook/reasoning/models/openai/reasoning_summary.py
"""Run `pip install openai ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the reasoning Agent
agent = Agent(
    model=OpenAIResponses(
        id="o4-mini",
        reasoning_summary="auto",  # Requesting a reasoning summary
    ),
    tools=[DuckDuckGoTools(search=True)],
    instructions="Use tables to display the analysis",
    markdown=True,
)

agent.print_response(
    "Write a brief report comparing NVDA to TSLA",
    stream=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/reasoning/models/openai/reasoning_summary.py
      ```

      ```bash Windows
        python cookbook/reasoning/models/openai/reasoning_summary.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# xAI Grok 3 Mini
Source: https://docs.agno.com/examples/concepts/reasoning/models/xai/reasoning-effort



## Code

```python cookbook/reasoning/models/xai/reasoning_effort.py
from agno.agent import Agent
from agno.models.xai import xAI
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=xAI(id="grok-3-mini-fast", reasoning_effort="high"),
    tools=[
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        )
    ],
    instructions="Use tables to display data.",
        markdown=True,
)
agent.print_response("Write a report comparing NVDA to TSLA", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/xai/reasoning_effort.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/xai/reasoning_effort.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Finance Team Chain of Thought
Source: https://docs.agno.com/examples/concepts/reasoning/teams/finance_team_chain_of_thought



## Code

```python cookbook/reasoning/teams/finance_team_chain_of_thought.py
import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    add_datetime_to_context=True,
)

finance_agent = Agent(
    name="Finance Agent",
    role="Handle financial data requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(search=True)],
    instructions=[
        "You are a financial data specialist. Provide concise and accurate data.",
        "Use tables to display stock prices, fundamentals (P/E, Market Cap), and recommendations.",
        "Clearly state the company name and ticker symbol.",
        "Briefly summarize recent company-specific news if available.",
        "Focus on delivering the requested financial data points clearly.",
    ],
    add_datetime_to_context=True,
)

team_leader = Team(
    name="Reasoning Finance Team Leader",
    members=[
        web_agent,
        finance_agent,
    ],
    instructions=[
        "Only output the final answer, no other text.",
        "Use tables to display data",
    ],
    markdown=True,
    reasoning=True,
    show_members_responses=True,
)


async def run_team(task: str):
    await team_leader.aprint_response(
        task,
        stream=True,
        stream_intermediate_steps=True,
        show_full_reasoning=True,
    )


if __name__ == "__main__":
    asyncio.run(
        run_team(
            dedent("""\
    Analyze the impact of recent US tariffs on market performance across these key sectors:
    - Steel & Aluminum: (X, NUE, AA)
    - Technology Hardware: (AAPL, DELL, HPQ)
    - Agricultural Products: (ADM, BG, INGR)
    - Automotive: (F, GM, TSLA)

    For each sector:
    1. Compare stock performance before and after tariff implementation
    2. Identify supply chain disruptions and cost impact percentages
    3. Analyze companies' strategic responses (reshoring, price adjustments, supplier diversification)
    4. Assess analyst outlook changes directly attributed to tariff policies
    """)
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/teams/finance_team_chain_of_thought.py
      ```

      ```bash Windows
      python cookbook/reasoning/teams/finance_team_chain_of_thought.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Team with Knowledge Tools
Source: https://docs.agno.com/examples/concepts/reasoning/teams/knowledge-tool-team



This is a team reasoning example with knowledge tools.

<Tip>
  Enabling the reasoning option on the team leader helps optimize delegation and enhances multi-agent collaboration by selectively invoking deeper reasoning when required.
</Tip>

## Code

```python cookbook/reasoning/teams/knowledge_tool_team.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.knowledge import KnowledgeTools
from agno.vectordb.lancedb import LanceDb, SearchType

agno_docs = Knowledge(
    # Use LanceDB as the vector database and store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
    ),
)
# Add content to the knowledge
agno_docs.add_content(url="https://www.paulgraham.com/read.html")

knowledge_tools = KnowledgeTools(
    knowledge=agno_docs,
    think=True,
    search=True,
    analyze=True,
    add_few_shot=True,
)

web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    add_datetime_to_context=True,
)

finance_agent = Agent(
    name="Finance Agent",
    role="Handle financial data requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(search=True)],
    add_datetime_to_context=True,
)

team_leader = Team(
    name="Reasoning Finance Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[
        web_agent,
        finance_agent,
    ],
    tools=[knowledge_tools],
    instructions=[
        "Only output the final answer, no other text.",
        "Use tables to display data",
    ],
    markdown=True,
    show_members_responses=True,
    add_datetime_to_context=True,
)


def run_team(task: str):
    team_leader.print_response(
        task,
        stream=True,
        stream_intermediate_steps=True,
        show_full_reasoning=True,
    )


if __name__ == "__main__":
    run_team("What does Paul Graham talk about the need to read in this essay?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/teams/knowledge_tool_team.py
      ```

      ```bash Windows
      python cookbook/reasoning/teams/knowledge_tool_team.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Team with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/teams/reasoning-finance-team



This is a multi-agent team reasoning example with reasoning tools.

<Tip>
  Enabling the reasoning option on the team leader helps optimize delegation and enhances multi-agent collaboration by selectively invoking deeper reasoning when required.
</Tip>

## Code

```python cookbook/reasoning/teams/reasoning_finance_team.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    add_datetime_to_context=True,
)

finance_agent = Agent(
    name="Finance Agent",
    role="Handle financial data requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(search=True)],
    instructions=[
        "You are a financial data specialist. Provide concise and accurate data.",
        "Use tables to display stock prices, fundamentals (P/E, Market Cap), and recommendations.",
        "Clearly state the company name and ticker symbol.",
        "Briefly summarize recent company-specific news if available.",
        "Focus on delivering the requested financial data points clearly.",
    ],
    add_datetime_to_context=True,
)

team_leader = Team(
    name="Reasoning Finance Team Leader",
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[
        web_agent,
        finance_agent,
    ],
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Only output the final answer, no other text.",
        "Use tables to display data",
    ],
    markdown=True,
    show_members_responses=True,
    add_datetime_to_context=True,
)


def run_team(task: str):
    team_leader.print_response(
        task,
        stream=True,
        stream_intermediate_steps=True,
        show_full_reasoning=True,
    )


if __name__ == "__main__":
    run_team(
        dedent("""\
    Analyze the impact of recent US tariffs on market performance across these key sectors:
    - Steel & Aluminum: (X, NUE, AA)
    - Technology Hardware: (AAPL, DELL, HPQ)
    - Agricultural Products: (ADM, BG, INGR)
    - Automotive: (F, GM, TSLA)

    For each sector:
    1. Compare stock performance before and after tariff implementation
    2. Identify supply chain disruptions and cost impact percentages
    3. Analyze companies' strategic responses (reshoring, price adjustments, supplier diversification)
    4. Assess analyst outlook changes directly attributed to tariff policies
    """)
    )

    # run_team(dedent("""\
    # Assess the impact of recent semiconductor export controls on:
    # - US chip designers (Nvidia, AMD, Intel)
    # - Asian manufacturers (TSMC, Samsung)
    # - Equipment makers (ASML, Applied Materials)
    # Include effects on R&D investments, supply chain restructuring, and market share shifts."""))

    # run_team(dedent("""\
    # Compare the retail sector's response to consumer goods tariffs:
    # - Major retailers (Walmart, Target, Amazon)
    # - Consumer brands (Nike, Apple, Hasbro)
    # - Discount retailers (Dollar General, Five Below)
    # Include pricing strategy changes, inventory management, and consumer behavior impacts."""))

    # run_team(dedent("""\
    # Analyze the semiconductor market performance focusing on:
    # - NVIDIA (NVDA)
    # - AMD (AMD)
    # - Intel (INTC)
    # - Taiwan Semiconductor (TSM)
    # Compare their market positions, growth metrics, and future outlook."""))

    # run_team(dedent("""\
    # Evaluate the automotive industry's current state:
    # - Tesla (TSLA)
    # - Ford (F)
    # - General Motors (GM)
    # - Toyota (TM)
    # Include EV transition progress and traditional auto metrics."""))

    # run_team(dedent("""\
    # Compare the financial metrics of Apple (AAPL) and Google (GOOGL):
    # - Market Cap
    # - P/E Ratio
    # - Revenue Growth
    # - Profit Margin"""))

    # run_team(dedent("""\
    # Analyze the impact of recent Chinese solar panel tariffs on:
    # - US solar manufacturers (First Solar, SunPower)
    # - Chinese exporters (JinkoSolar, Trina Solar)
    # - US installation companies (Sunrun, SunPower)
    # Include effects on pricing, supply chains, and installation rates."""))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai anthropic agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/teams/reasoning_finance_team.py
      ```

      ```bash Windows
      python cookbook/reasoning/teams/reasoning_finance_team.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure OpenAI with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/azure-openai-reasoning-tools



This example shows how to use `ReasoningTools` with an Azure OpenAI model.

## Code

```python cookbook/reasoning/tools/azure_openai_reasoning_tools.py
from agno.agent import Agent
from agno.models.azure.openai_chat import AzureOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    tools=[
        DuckDuckGoTools(),
        ReasoningTools(
            think=True,
            analyze=True,
            add_instructions=True,
            add_few_shot=True,
        ),
    ],
    instructions="Use tables where possible. Think about the problem step by step.",
    markdown=True,
)

reasoning_agent.print_response(
    "Write a report comparing NVDA to TSLA.",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai anthropic agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/azure_openai_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/azure_openai_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Capture Reasoning Content with Knowledge Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/capture-reasoning-content-knowledge-tools



## Code

```python cookbook/reasoning/tools/capture_reasoning_content_knowledge_tools.py
import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.tools.knowledge import KnowledgeTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge containing information from a URL
print("Setting up URL knowledge...")
agno_docs = Knowledge(
    # Use LanceDB as the vector database
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="cookbook_knowledge_tools",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Add content to the knowledge
asyncio.run(agno_docs.add_content_async(url="https://www.paulgraham.com/read.html"))
print("Knowledge ready.")


print("\n=== Example 1: Using KnowledgeTools in non-streaming mode ===\n")

# Create agent with KnowledgeTools
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        KnowledgeTools(
            knowledge=agno_docs,
            think=True,
            search=True,
            analyze=True,
            add_instructions=True,
        )
    ],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†
        Use the knowledge tools to organize your thoughts, search for information,
        and analyze results step-by-step.
        \
    """),
    markdown=True,
)

# Run the agent (non-streaming) using agent.run() to get the response
print("Running with KnowledgeTools (non-streaming)...")
response = agent.run(
    "What does Paul Graham explain here with respect to need to read?", stream=False
)

# Check reasoning_content from the response
print("\n--- reasoning_content from response ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print("‚úÖ reasoning_content FOUND in non-streaming response")
    print(f"   Length: {len(response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (non-streaming) ===")
    preview = response.reasoning_content[:1000]
    if len(response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in non-streaming response")


print("\n\n=== Example 2: Using KnowledgeTools in streaming mode ===\n")

# Create a fresh agent for streaming
streaming_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        KnowledgeTools(
            knowledge=agno_docs,
            think=True,
            search=True,
            analyze=True,
            add_instructions=True,
        )
    ],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†
        Use the knowledge tools to organize your thoughts, search for information,
        and analyze results step-by-step.
        \
    """),
    markdown=True,
)

# Process streaming responses and look for the final RunOutput
print("Running with KnowledgeTools (streaming)...")
final_response = None
for event in streaming_agent.run(
    "What does Paul Graham explain here with respect to need to read?",
    stream=True,
    stream_intermediate_steps=True,
):
    # Print content as it streams (optional)
    if hasattr(event, "content") and event.content:
        print(event.content, end="", flush=True)

    # The final event in the stream should be a RunOutput object
    if hasattr(event, "reasoning_content"):
        final_response = event

print("\n\n--- reasoning_content from final stream event ---")
if (
    final_response
    and hasattr(final_response, "reasoning_content")
    and final_response.reasoning_content
):
    print("‚úÖ reasoning_content FOUND in final stream event")
    print(f"   Length: {len(final_response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (streaming) ===")
    preview = final_response.reasoning_content[:1000]
    if len(final_response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in final stream event")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai anthropic agno lancedb
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/capture_reasoning_content_knowledge_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/capture_reasoning_content_knowledge_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Capture Reasoning Content with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/capture-reasoning-content-reasoning-tools



## Code

```python cookbook/reasoning/tools/capture_reasoning_content_reasoning_tools.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools

"""Test function to verify reasoning_content is populated in RunOutput."""
print("\n=== Testing reasoning_content generation ===\n")

# Create an agent with ReasoningTools
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ReasoningTools(add_instructions=True)],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†
        Use step-by-step reasoning to solve the problem.
        \
    """),
)

# Test 1: Non-streaming mode
print("Running with stream=False...")
response = agent.run("What is the sum of the first 10 natural numbers?", stream=False)

# Check reasoning_content
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print("‚úÖ reasoning_content FOUND in non-streaming response")
    print(f"   Length: {len(response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (non-streaming) ===")
    preview = response.reasoning_content[:1000]
    if len(response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in non-streaming response")

# Process streaming responses to find the final one
print("\n\n=== Test 2: Processing stream to find final response ===\n")

# Create another fresh agent
streaming_agent_alt = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ReasoningTools(add_instructions=True)],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†
        Use step-by-step reasoning to solve the problem.
        \
    """),
)

# Process streaming responses and look for the final RunOutput
final_response = None
for event in streaming_agent_alt.run(
    "What is the value of 3! (factorial)?",
    stream=True,
    stream_intermediate_steps=True,
):
    # The final event in the stream should be a RunOutput object
    if hasattr(event, "reasoning_content"):
        final_response = event

print("--- Checking reasoning_content from final stream event ---")
if (
    final_response
    and hasattr(final_response, "reasoning_content")
    and final_response.reasoning_content
):
    print("‚úÖ reasoning_content FOUND in final stream event")
    print(f"   Length: {len(final_response.reasoning_content)} characters")
    print("\n=== reasoning_content preview (final stream event) ===")
    preview = final_response.reasoning_content[:1000]
    if len(final_response.reasoning_content) > 1000:
        preview += "..."
    print(preview)
else:
    print("‚ùå reasoning_content NOT FOUND in final stream event")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai anthropic agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/capture_reasoning_content_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/capture_reasoning_content_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cerebras Llama with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/cerebras-llama-reasoning-tools



## Code

```python cookbook/reasoning/tools/cerebras_llama_reasoning_tools.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.cerebras import Cerebras
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=Cerebras(id="llama-3.3-70b"),
    tools=[ReasoningTools(add_instructions=True)],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†

        Your approach to problems:
        1. First, break down complex questions into component parts
        2. Clearly state your assumptions
        3. Develop a structured reasoning path
        4. Consider multiple perspectives
        5. Evaluate evidence and counter-arguments
        6. Draw well-justified conclusions

        When solving problems:
        - Use explicit step-by-step reasoning
        - Identify key variables and constraints
        - Explore alternative scenarios
        - Highlight areas of uncertainty
        - Explain your thought process clearly
        - Consider both short and long-term implications
        - Evaluate trade-offs explicitly

        For quantitative problems:
        - Show your calculations
        - Explain the significance of numbers
        - Consider confidence intervals when appropriate
        - Identify source data reliability

        For qualitative reasoning:
        - Assess how different factors interact
        - Consider psychological and social dynamics
        - Evaluate practical constraints
        - Address value considerations
        \
    """),
    add_datetime_to_context=True,
    stream_intermediate_steps=True,
    markdown=True,
)

# Example usage with a complex reasoning problem
reasoning_agent.print_response(
    "Solve this logic puzzle: A man has to take a fox, a chicken, and a sack of grain across a river. "
    "The boat is only big enough for the man and one item. If left unattended together, the fox will "
    "eat the chicken, and the chicken will eat the grain. How can the man get everything across safely?",
    stream=True,
)

# # Economic analysis example
# reasoning_agent.print_response(
#     "Is it better to rent or buy a home given current interest rates, inflation, and market trends? "
#     "Consider both financial and lifestyle factors in your analysis.",
#     stream=True
# )

# # Strategic decision-making example
# reasoning_agent.print_response(
#     "A startup has $500,000 in funding and needs to decide between spending it on marketing or "
#     "product development. They want to maximize growth and user acquisition within 12 months. "
#     "What factors should they consider and how should they analyze this decision?",
#     stream=True
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CERERAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cerebras-cloud-sdk agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/cerebras_llama_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/cerebras_llama_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Claude with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/claude-reasoning-tools



This example shows how to use `ReasoningTools` with a Claude model.

## Code

```python cookbook/reasoning/tools/claude_reasoning_tools.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[
        ReasoningTools(add_instructions=True),
        DuckDuckGoTools(search=True),
    ],
    instructions="Use tables to display data.",
    markdown=True,
)

# Semiconductor market analysis example
reasoning_agent.print_response(
    """\
    Analyze the semiconductor market performance focusing on:
    - NVIDIA (NVDA)
    - AMD (AMD)
    - Intel (INTC)
    - Taiwan Semiconductor (TSM)
    Compare their market positions, growth metrics, and future outlook.""",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/claude_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/claude_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Gemini with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/gemini-reasoning-tools



## Code

```python cookbook/reasoning/tools/gemini_reasoning_tools.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.reasoning import ReasoningTools
from agno.tools.duckduckgo import DuckDuckGoTools

reasoning_agent = Agent(
    model=Gemini(id="gemini-2.5-pro-preview-03-25"),
    tools=[
        ReasoningTools(
            think=True,
            analyze=True,
            add_instructions=True,
        ),
        DuckDuckGoTools(),
    ],
    instructions="Use tables where possible",
    stream_intermediate_steps=True,
        markdown=True,
    debug_mode=True,
)
reasoning_agent.print_response(
    "Write a report comparing NVDA to TSLA.", show_full_reasoning=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/gemini_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/gemini_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Groq Llama Finance Agent
Source: https://docs.agno.com/examples/concepts/reasoning/tools/groq-llama-finance-agent



This example shows how to use `ReasoningTools` with a Groq Llama model.

## Code

```python cookbook/reasoning/tools/groq_llama_finance_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

thinking_llama = Agent(
    model=Groq(id="meta-llama/llama-4-scout-17b-16e-instruct"),
    tools=[
        ReasoningTools(),
        DuckDuckGoTools(),
    ],
    instructions=dedent("""\
    ## General Instructions
    - Always start by using the think tool to map out the steps needed to complete the task.
    - After receiving tool results, use the think tool as a scratchpad to validate the results for correctness
    - Before responding to the user, use the think tool to jot down final thoughts and ideas.
    - Present final outputs in well-organized tables whenever possible.

    ## Using the think tool
    At every step, use the think tool as a scratchpad to:
    - Restate the object in your own words to ensure full comprehension.
    - List the  specific rules that apply to the current request
    - Check if all required information is collected and is valid
    - Verify that the planned action completes the task\
    """),
    markdown=True,
)
thinking_llama.print_response("Write a report comparing NVDA to TSLA", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/groq_llama_finance_agent.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/groq_llama_finance_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning Agent with Knowledge Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/knowledge-tools



## Code

```python cookbook/reasoning/tools/knowledge_tools.py
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.tools.knowledge import KnowledgeTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge containing information from a URL
agno_docs = Knowledge(
    # Use LanceDB as the vector database and store embeddings in the `agno_docs` table
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Add content to the knowledge
agno_docs.add_content(url="https://docs.agno.com/llms-full.txt")

knowledge_tools = KnowledgeTools(
    knowledge=agno_docs,
    think=True,
    search=True,
    analyze=True,
    add_few_shot=True,
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[knowledge_tools],
    markdown=True,
)

if __name__ == "__main__":
    agent.print_response(
        "How do I build a team of agents in agno?",
        markdown=True,
        stream=True,
        stream_tools=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/knowledge_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/knowledge_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Ollama with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/ollama-reasoning-tools



This example shows how to use `ReasoningTools` with an Ollama model.

## Code

```python cookbook/reasoning/tools/ollama_reasoning_tools.py
from agno.agent import Agent
from agno.models.ollama.chat import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=Ollama(id="llama3.2:latest"),
    tools=[
        ReasoningTools(
            think=True,
            analyze=True,
            add_instructions=True,
            add_few_shot=True,
        ),
        DuckDuckGoTools(),
    ],
    instructions="Use tables where possible",
    markdown=True,
)
reasoning_agent.print_response(
    "Write a report comparing NVDA to TSLA",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/ollama_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/ollama_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/openai-reasoning-tools



This example shows how to use `ReasoningTools` with an OpenAI model.

## Code

```python cookbook/reasoning/tools/openai_reasoning_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ReasoningTools(
            think=True,
            analyze=True,
            add_instructions=True,
            add_few_shot=True,
        ),
        DuckDuckGoTools(),
    ],
    instructions="Use tables where possible",
    markdown=True,
)
reasoning_agent.print_response(
    "Write a report comparing NVDA to TSLA",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/openai_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/openai_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/reasoning-tools



This example shows how to setup a basic Reasoning Agent with `ReasoningTools`.

## Code

```python cookbook/reasoning/tools/reasoning_tools.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ReasoningTools(add_instructions=True)],
    instructions=dedent("""\
        You are an expert problem-solving assistant with strong analytical skills! üß†

        Your approach to problems:
        1. First, break down complex questions into component parts
        2. Clearly state your assumptions
        3. Develop a structured reasoning path
        4. Consider multiple perspectives
        5. Evaluate evidence and counter-arguments
        6. Draw well-justified conclusions

        When solving problems:
        - Use explicit step-by-step reasoning
        - Identify key variables and constraints
        - Explore alternative scenarios
        - Highlight areas of uncertainty
        - Explain your thought process clearly
        - Consider both short and long-term implications
        - Evaluate trade-offs explicitly

        For quantitative problems:
        - Show your calculations
        - Explain the significance of numbers
        - Consider confidence intervals when appropriate
        - Identify source data reliability

        For qualitative reasoning:
        - Assess how different factors interact
        - Consider psychological and social dynamics
        - Evaluate practical constraints
        - Address value considerations
        \
    """),
    add_datetime_to_context=True,
    stream_intermediate_steps=True,
    markdown=True,
)

# Example usage with a complex reasoning problem
reasoning_agent.print_response(
    "Solve this logic puzzle: A man has to take a fox, a chicken, and a sack of grain across a river. "
    "The boat is only big enough for the man and one item. If left unattended together, the fox will "
    "eat the chicken, and the chicken will eat the grain. How can the man get everything across safely?",
    stream=True,
)

# # Economic analysis example
# reasoning_agent.print_response(
#     "Is it better to rent or buy a home given current interest rates, inflation, and market trends? "
#     "Consider both financial and lifestyle factors in your analysis.",
#     stream=True
# )

# # Strategic decision-making example
# reasoning_agent.print_response(
#     "A startup has $500,000 in funding and needs to decide between spending it on marketing or "
#     "product development. They want to maximize growth and user acquisition within 12 months. "
#     "What factors should they consider and how should they analyze this decision?",
#     stream=True
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Vercel with Reasoning Tools
Source: https://docs.agno.com/examples/concepts/reasoning/tools/vercel-reasoning-tools



This example shows how to use `ReasoningTools` with a Vercel model.

## Code

```python cookbook/reasoning/tools/vercel_reasoning_tools.py
from agno.agent import Agent
from agno.models.vercel import v0
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools

reasoning_agent = Agent(
    model=v0(id="v0-1.0-md"),
    tools=[
        ReasoningTools(add_instructions=True, add_few_shot=True),
        DuckDuckGoTools(),
    ],
    instructions=[
        "Use tables to display data",
        "Only output the report, no other text",
    ],
    markdown=True,
)

reasoning_agent.print_response(
    "Write a report on TSLA",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export V0_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Example">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/tools/vercel_reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/reasoning/tools/vercel_reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Coordinated Team
Source: https://docs.agno.com/examples/concepts/teams/async/async_coordination_team



This example demonstrates a coordinated team of AI agents working together asynchronously to research topics across different platforms.

## Code

```python cookbook/examples/teams/async/02_async_coordinate.py
import asyncio
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.tools.newspaper4k import Newspaper4kTools
from pydantic import BaseModel, Field


class Article(BaseModel):
    title: str = Field(..., description="The title of the article")
    summary: str = Field(..., description="A summary of the article")
    reference_links: List[str] = Field(
        ..., description="A list of reference links to the article"
    )


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)

article_reader = Agent(
    name="Article Reader",
    role="Reads articles from URLs.",
    tools=[Newspaper4kTools()],
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat(id="o3"),
    members=[hn_researcher, web_searcher, article_reader],
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the article reader to read the links for the stories to get more information.",
        "Important: you must provide the article reader with the links to read.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    add_member_tools_to_context=False,
    markdown=True,
    show_members_responses=True,
)


async def main():
    """Main async function demonstrating coordinated team mode."""
    await hn_team.aprint_response(
        input="Write an article about the top 2 stories on hackernews"
    )


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs newspaper4k lxml_html_clean
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/async/02_async_coordinate.py
    ```
  </Step>
</Steps>


# Async Collaborative Team
Source: https://docs.agno.com/examples/concepts/teams/async/async_delegate_to_all_members



This example demonstrates a collaborative team of AI agents working together asynchronously to research topics across different platforms.

## Code

```python cookbook/examples/teams/async/01_async_collaborate.py
"""
This example demonstrates a collaborative team of AI agents working together to research topics across different platforms.

The team consists of two specialized agents:
1. Reddit Researcher - Uses DuckDuckGo to find and analyze relevant Reddit posts
2. HackerNews Researcher - Uses HackerNews API to find and analyze relevant HackerNews posts

The agents work in "collaborate" mode, meaning they:
- Both are given the same task at the same time
- Work towards reaching consensus through discussion
- Are coordinated by a team leader that guides the discussion

The team leader moderates the discussion and determines when consensus is reached.

This setup is useful for:
- Getting diverse perspectives from different online communities
- Cross-referencing information across platforms
- Having agents collaborate to form more comprehensive analysis
- Reaching balanced conclusions through structured discussion

"""

import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools

reddit_researcher = Agent(
    name="Reddit Researcher",
    role="Research a topic on Reddit",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    add_name_to_context=True,
    instructions=dedent("""
    You are a Reddit researcher.
    You will be given a topic to research on Reddit.
    You will need to find the most relevant posts on Reddit.
    """),
)

hackernews_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Research a topic on HackerNews.",
    tools=[HackerNewsTools()],
    add_name_to_context=True,
    instructions=dedent("""
    You are a HackerNews researcher.
    You will be given a topic to research on HackerNews.
    You will need to find the most relevant posts on HackerNews.
    """),
)


agent_team = Team(
    name="Discussion Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[
        reddit_researcher,
        hackernews_researcher,
    ],
    instructions=[
        "You are a discussion master.",
        "You have to stop the discussion when you think the team has reached a consensus.",
    ],
    delegate_task_to_all_members=True,
    markdown=True,
    show_members_responses=True,
)


async def main():
    """Main async function demonstrating collaborative team mode."""
    await agent_team.aprint_response(
        input="Start the discussion on the topic: 'What is the best way to learn to code?'",
        # stream=True,
        # stream_intermediate_steps=True,
    )


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/async/01_async_collaborate.py
    ```
  </Step>
</Steps>


# Async Multi-Language Team
Source: https://docs.agno.com/examples/concepts/teams/async/async_respond_directly



This example demonstrates an asynchronous route team of AI agents working together to answer questions in different languages. The team consists of six specialized language agents (English, Japanese, Chinese, Spanish, French, and German) with a team leader that routes user questions to the appropriate language agent based on the input language.

## Code

```python cookbook/examples/teams/async/03_async_route.py
"""
This example demonstrates a route team of AI agents working together to answer questions in different languages.

The team consists of six specialized agents:
1. English Agent - Can only answer in English
2. Japanese Agent - Can only answer in Japanese
3. Chinese Agent - Can only answer in Chinese
4. Spanish Agent - Can only answer in Spanish
5. French Agent - Can only answer in French
6. German Agent - Can only answer in German

The team leader routes the user's question to the appropriate language agent. It can only forward the question and cannot answer itself.
"""

import asyncio

from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.deepseek import DeepSeek
from agno.models.openai import OpenAIChat
from agno.team.team import Team

english_agent = Agent(
    name="English Agent",
    role="You only answer in English",
    model=OpenAIChat(id="gpt-5-mini"),
)
japanese_agent = Agent(
    name="Japanese Agent",
    role="You only answer in Japanese",
    model=DeepSeek(id="deepseek-chat"),
)
chinese_agent = Agent(
    name="Chinese Agent",
    role="You only answer in Chinese",
    model=DeepSeek(id="deepseek-chat"),
)
spanish_agent = Agent(
    name="Spanish Agent",
    role="You can only answer in Spanish",
    model=OpenAIChat(id="gpt-5-mini"),
)
french_agent = Agent(
    name="French Agent",
    role="You can only answer in French",
    model=OpenAIChat(id="gpt-5-mini"),
)
german_agent = Agent(
    name="German Agent",
    role="You can only answer in German",
    model=Claude("claude-3-5-sonnet-20241022"),
)

multi_language_team = Team(
    name="Multi Language Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[
        english_agent,
        spanish_agent,
        japanese_agent,
        french_agent,
        german_agent,
        chinese_agent,
    ],
    markdown=True,
    respond_directly=True,
    instructions=[
        "You are a language router that directs questions to the appropriate language agent.",
        "If the user asks in a language whose agent is not a team member, respond in English with:",
        "'I can only answer in the following languages: English, Spanish, Japanese, French and German. Please ask your question in one of these languages.'",
        "Always check the language of the user's input before routing to an agent.",
        "For unsupported languages like Italian, respond in English with the above message.",
    ],
    show_members_responses=True,
)


async def main():
    """Main async function demonstrating team routing mode."""
    # Ask "How are you?" in all supported languages
    # await multi_language_team.aprint_response(
    #     "How are you?", stream=True  # English
    # )

    # await multi_language_team.aprint_response(
    #     "‰Ω†Â•ΩÂêóÔºü", stream=True  # Chinese
    # )

    # await multi_language_team.aprint_response(
    #     "„ÅäÂÖÉÊ∞ó„Åß„Åô„Åã?", stream=True  # Japanese
    # )

    await multi_language_team.aprint_response(input="Comment allez-vous?")

    # await multi_language_team.aprint_response(
    #     "Wie geht es Ihnen?", stream=True  # German
    # )

    # await multi_language_team.aprint_response(
    #     "Come stai?", stream=True  # Italian
    # )


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno anthropic openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export DEEPSEEK_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/async/03_async_route.py
    ```
  </Step>
</Steps>


# Few-Shot Learning with Customer Support Team
Source: https://docs.agno.com/examples/concepts/teams/basic/few_shot_learning



This example demonstrates few-shot learning by providing example conversations to teach a customer support team proper response patterns. The team learns from provided examples to handle different types of customer issues with appropriate escalation and communication patterns.

## Code

```python cookbook/examples/teams/basic/few_shot_learning.py
"""
This example shows a straightforward use case of additional_input
to teach a customer support team proper response patterns.
"""

from agno.agent import Agent
from agno.models.message import Message
from agno.models.openai import OpenAIChat
from agno.team import Team

# Few-shot examples showing good support patterns
support_examples = [
    # Example 1: Simple issue resolution
    Message(role="user", content="I forgot my password and can't log in"),
    Message(
        role="assistant",
        content="""
    I'll help you reset your password right away.
    
    **Transferring to Support Specialist**: Please assist this customer with password reset:
    - Guide them through the password reset process
    - Verify their identity if needed  
    - Ensure they can successfully log in
    - Provide tips for creating a secure password
    
    Expected outcome: Customer successfully logs in with new password.
    """.strip(),
    ),
    # Example 2: Escalation pattern
    Message(
        role="user",
        content="I've been charged twice for the same order and your chat bot couldn't help!",
    ),
    Message(
        role="assistant",
        content="""
        I sincerely apologize for the billing issue and the frustration with our chat system.

        **Transferring to Escalation Manager**: Priority billing issue requiring immediate attention:
        - Customer charged twice for same order
        - Previous automated support was unsuccessful
        - Customer is understandably frustrated
        - Needs immediate resolution and possible compensation

        Expected outcome: Billing corrected, customer satisfaction restored, and follow-up to prevent recurrence.
        """.strip(),
    ),
    # Example 3: Proactive support
    Message(role="user", content="Your app keeps crashing when I try to upload photos"),
    Message(
        role="assistant",
        content="""
    I'm sorry you're experiencing crashes with photo uploads. Let me get this resolved for you. 

    **Transferring to Support Specialist**: Technical issue with photo upload feature:
    - App crashes during photo upload process
    - Need to troubleshoot device compatibility and app version
    - Provide workaround solutions if available
    - Escalate to technical team if it's a known bug    

    Expected outcome: Upload feature working properly or clear timeline for fix provided.
        """.strip(),
    ),
]

if __name__ == "__main__":
    # Support Agent
    support_agent = Agent(
        name="Support Specialist",
        role="Handle customer inquiries",
        model=OpenAIChat(id="gpt-5-mini"),
        instructions=[
            "You are a helpful customer support specialist.",
            "Always be polite, professional, and solution-oriented.",
        ],
    )

    # Escalation Agent
    escalation_agent = Agent(
        name="Escalation Manager",
        role="Handle complex issues",
        model=OpenAIChat(id="gpt-5-mini"),
        instructions=[
            "You handle escalated customer issues that require management attention.",
            "Focus on customer satisfaction and finding solutions.",
        ],
    )

    # Create team with few-shot learning
    team = Team(
        name="Customer Support Team",
        members=[support_agent, escalation_agent],
        model=OpenAIChat(id="gpt-5-mini"),
        add_name_to_context=True,
        additional_input=support_examples,  # üÜï Teaching examples
        instructions=[
            "You coordinate customer support with excellence and empathy.",
            "Follow established patterns for proper issue resolution.",
            "Always prioritize customer satisfaction and clear communication.",
        ],
        debug_mode=True,
        markdown=True,
    )

    scenarios = [
        "I can't find my order confirmation email",
        "The product I received is damaged",
        "I want to cancel my subscription but the website won't let me",
    ]

    for i, scenario in enumerate(scenarios, 1):
        print(f"üìû Scenario {i}: {scenario}")
        print("-" * 50)
        team.print_response(scenario)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/few_shot_learning.py
    ```
  </Step>
</Steps>


# Input as Dictionary
Source: https://docs.agno.com/examples/concepts/teams/basic/input_as_dict



This example shows how to pass input to a team as a dictionary format, useful for multimodal inputs or structured data.

## Code

```python cookbook/examples/teams/basic/input_as_dict.py
from agno.agent import Agent
from agno.team import Team

# Create a research team
team = Team(
    members=[
        Agent(
            name="Sarah",
            role="Data Researcher",
            instructions="Focus on gathering and analyzing data",
        ),
        Agent(
            name="Mike",
            role="Technical Writer",
            instructions="Create clear, concise summaries",
        ),
    ],
    stream=True,
    markdown=True,
)

team.print_response(
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {
                "type": "image_url",
                "image_url": {
                    "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                },
            },
        ],
    },
    stream=True,
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/input_as_dict.py
    ```
  </Step>
</Steps>


# Team Input as Image List
Source: https://docs.agno.com/examples/concepts/teams/basic/input_as_list



This example demonstrates how to pass input to a team as a list containing both text and images. The team processes multimodal input including text descriptions and image URLs for analysis.

## Code

```python cookbook/examples/teams/basic/input_as_list.py
from agno.agent import Agent
from agno.team import Team

team = Team(
    members=[
        Agent(
            name="Sarah",
            role="Data Researcher",
            instructions="Focus on gathering and analyzing data",
        ),
        Agent(
            name="Mike",
            role="Technical Writer",
            instructions="Create clear, concise summaries",
        ),
    ],
)

team.print_response(
    [
        {"type": "text", "text": "What's in this image?"},
        {
            "type": "image_url",
            "image_url": {
                "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
            },
        },
    ],
    stream=True,
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/input_as_list.py
    ```
  </Step>
</Steps>


# Team Input as Messages List
Source: https://docs.agno.com/examples/concepts/teams/basic/input_as_messages_list



This example demonstrates how to provide input to a team as a list of Message objects, creating a conversation context with multiple user and assistant messages for more complex interactions.

## Code

```python cookbook/examples/teams/basic/input_as_messages_list.py
from agno.agent import Agent
from agno.models.message import Message
from agno.team import Team

# Create a research team
research_team = Team(
    name="Research Team",
    members=[
        Agent(
            name="Sarah",
            role="Data Researcher",
            instructions="Focus on gathering and analyzing data",
        ),
        Agent(
            name="Mike",
            role="Technical Writer",
            instructions="Create clear, concise summaries",
        ),
    ],
    stream=True,
    markdown=True,
)

research_team.print_response(
    [
        Message(
            role="user",
            content="I'm preparing a presentation for my company about renewable energy adoption.",
        ),
        Message(
            role="assistant",
            content="I'd be happy to help with your renewable energy presentation. What specific aspects would you like me to focus on?",
        ),
        Message(
            role="user",
            content="Could you research the latest solar panel efficiency improvements in 2024?",
        ),
        Message(
            role="user",
            content="Also, please summarize the key findings in bullet points for my slides.",
        ),
    ],
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/input_as_messages_list.py
    ```
  </Step>
</Steps>


# Capturing Team Responses as Variables
Source: https://docs.agno.com/examples/concepts/teams/basic/response_as_variable



This example demonstrates how to capture team responses as variables and validate them using Pydantic models. It shows a routing team that analyzes stocks and company news, with structured responses for different types of queries.

## Code

```python cookbook/examples/teams/basic/response_as_variable.py
"""
This example demonstrates how to capture team responses as variables.

Shows how to get structured responses from teams and validate them using
Pydantic models for different types of queries.
"""

from typing import Iterator  # noqa
from pydantic import BaseModel
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.utils.pprint import pprint_run_response
from agno.tools.exa import ExaTools

class StockAnalysis(BaseModel):
    """Stock analysis data structure."""

    symbol: str
    company_name: str
    analysis: str


class CompanyAnalysis(BaseModel):
    """Company analysis data structure."""

    company_name: str
    analysis: str


# Stock price analysis agent
stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    output_schema=StockAnalysis,
    role="Searches for stock price and analyst information",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
    instructions=[
        "Provide detailed stock analysis with price information",
        "Include analyst recommendations when available",
    ],
)

# Company news and information agent
company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches for company news and information",
    output_schema=CompanyAnalysis,
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
    instructions=[
        "Focus on company news and business information",
        "Provide comprehensive analysis of company developments",
    ],
)

# Create routing team
team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    respond_directly=True,
    markdown=True,
    show_members_responses=True,
    instructions=[
        "Route stock price questions to the Stock Searcher",
        "Route company news and info questions to the Company Info Searcher",
    ],
)

# Example 1: Get stock price analysis as a variable
print("=" * 50)
print("STOCK PRICE ANALYSIS")
print("=" * 50)

stock_response = team.run("What is the current stock price of NVDA?")
assert isinstance(stock_response.content, StockAnalysis)
print(f"Response type: {type(stock_response.content)}")
print(f"Symbol: {stock_response.content.symbol}")
print(f"Company: {stock_response.content.company_name}")
print(f"Analysis: {stock_response.content.analysis}")
pprint_run_response(stock_response)

# Example 2: Get company news analysis as a variable
print("\n" + "=" * 50)
print("COMPANY NEWS ANALYSIS")
print("=" * 50)

news_response = team.run("What is in the news about NVDA?")
assert isinstance(news_response.content, CompanyAnalysis)
print(f"Response type: {type(news_response.content)}")
print(f"Company: {news_response.content.company_name}")
print(f"Analysis: {news_response.content.analysis}")
pprint_run_response(news_response)

# Example 3: Process multiple responses
print("\n" + "=" * 50)
print("BATCH PROCESSING")
print("=" * 50)

companies = ["AAPL", "GOOGL", "MSFT"]
responses = []

for company in companies:
    response = team.run(f"Analyze {company} stock")
    responses.append(response)
    print(f"Processed {company}: {type(response.content).__name__}")

print(f"Total responses processed: {len(responses)}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai exa
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/response_as_variable.py
    ```
  </Step>
</Steps>


# Interactive CLI Writing Team
Source: https://docs.agno.com/examples/concepts/teams/basic/run_as_cli



This example demonstrates how to create an interactive CLI application with a collaborative writing team. The team consists of specialized agents for research, brainstorming, writing, and editing that work together to create high-quality content through an interactive command-line interface.

## Code

```python cookbook/examples/teams/basic/run_as_cli.py
"""‚úçÔ∏è Interactive Writing Team - CLI App Example

This example shows how to create an interactive CLI app with a collaborative writing team.

Run `pip install openai agno ddgs` to install dependencies.
"""

from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

research_agent = Agent(
    name="Research Specialist",
    role="Information Research and Fact Verification",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=dedent("""\
        You are an expert research specialist! 
        
        Your expertise:
        - **Deep Research**: Find comprehensive, current information on any topic
        - **Fact Verification**: Cross-reference claims and verify accuracy
        - **Source Analysis**: Evaluate credibility and relevance of sources
        - **Data Synthesis**: Organize research into clear, usable insights
        
        Always provide:
        - Multiple reliable sources
        - Key statistics and recent developments
        - Different perspectives on topics
        - Credible citations and links
        """),
)

brainstorm_agent = Agent(
    name="Creative Brainstormer",
    role="Idea Generation and Creative Concepts",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are a creative brainstorming expert! 
        
        Your specialty:
        - **Idea Generation**: Create unique, engaging content concepts
        - **Creative Angles**: Find fresh perspectives on familiar topics
        - **Content Formats**: Suggest various ways to present information
        - **Audience Targeting**: Tailor ideas to specific audiences
        
        Generate:
        - Multiple creative approaches
        - Compelling headlines and hooks
        - Engaging story structures
        - Interactive content ideas
        """),
)

writer_agent = Agent(
    name="Content Writer",
    role="Content Creation and Storytelling",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are a skilled content writer! 
        
        Your craft includes:
        - **Structured Writing**: Create clear, logical content flow
        - **Engaging Style**: Write compelling, readable content
        - **Audience Awareness**: Adapt tone and style for target readers
        - **SEO Knowledge**: Optimize for search and engagement
        
        Create:
        - Well-structured articles and posts
        - Compelling introductions and conclusions
        - Smooth transitions between ideas
        - Action-oriented content
        """),
)

editor_agent = Agent(
    name="Editor",
    role="Content Editing and Quality Assurance",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are a meticulous editor! 
        
        Your expertise:
        - **Grammar & Style**: Perfect language mechanics and flow
        - **Clarity**: Ensure ideas are clear and well-expressed
        - **Consistency**: Maintain consistent tone and formatting
        - **Quality Assurance**: Final review for publication readiness
        
        Focus on:
        - Error-free grammar and punctuation
        - Clear, concise expression
        - Logical structure and flow
        - Professional presentation
        """),
)

writing_team = Team(
    name="Writing Team",
    members=[research_agent, brainstorm_agent, writer_agent, editor_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are a collaborative writing team that excels at creating high-quality content!
        
        Team Process:
        1. **Research Phase**: Gather comprehensive, current information
        2. **Creative Phase**: Brainstorm unique angles and approaches  
        3. **Writing Phase**: Create structured, engaging content
        4. **Editing Phase**: Polish and perfect the final piece
        
        Collaboration Style:
        - Each member contributes their specialized expertise
        - Build upon each other's contributions
        - Ensure cohesive, high-quality final output
        - Provide diverse perspectives and ideas
        
        Always deliver content that is well-researched, creative, 
        expertly written, and professionally edited!
        """),
    show_members_responses=True,
    markdown=True,
)

if __name__ == "__main__":
    print("üí° Tell us about your writing project and watch the team collaborate!")
    print("‚úèÔ∏è Type 'exit', 'quit', or 'bye' to end our session.\n")

    writing_team.cli_app(
        input="Hello! We're excited to work on your writing project. What would you like us to help you create today? Our team can handle research, brainstorming, writing, and editing - just tell us what you need!",
        user="Client",
        emoji="üë•",
        stream=True,
    )

    ###########################################################################
    # ASYNC CLI APP
    ###########################################################################
    # import asyncio

    # asyncio.run(writing_team.acli_app(
    #     input="Hello! We're excited to work on your writing project. What would you like us to help you create today? Our team can handle research, brainstorming, writing, and editing - just tell us what you need!",
    #     user="Client",
    #     emoji="üë•",
    #     stream=True,
    # ))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/run_as_cli.py
    ```
  </Step>
</Steps>


# Team Run Cancellation
Source: https://docs.agno.com/examples/concepts/teams/basic/team_cancel_a_run



This example demonstrates how to cancel a running team execution by starting a team run in a separate thread and cancelling it from another thread. It shows proper handling of cancelled responses and thread management.

## Code

```python cookbook/examples/teams/basic/team_cancel_a_run.py
"""
Example demonstrating how to cancel a running team execution.

This example shows how to:
1. Start a team run in a separate thread
2. Cancel the run from another thread
3. Handle the cancelled response
"""

import threading
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent
from agno.run.base import RunStatus
from agno.run.team import TeamRunEvent
from agno.team import Team


def long_running_task(team: Team, run_id_container: dict):
    """
    Simulate a long-running team task that can be cancelled.

    Args:
        team: The team to run
        run_id_container: Dictionary to store the run_id for cancellation

    Returns:
        Dictionary with run results and status
    """
    try:
        # Start the team run - this simulates a long task
        final_response = None
        content_pieces = []

        for chunk in team.run(
            "Write a very long story about a dragon who learns to code. "
            "Make it at least 2000 words with detailed descriptions and dialogue. "
            "Take your time and be very thorough.",
            stream=True,
        ):
            if "run_id" not in run_id_container and chunk.run_id:
                print(f"üöÄ Team run started: {chunk.run_id}")
                run_id_container["run_id"] = chunk.run_id

            if chunk.event in [TeamRunEvent.run_content, RunEvent.run_content]:
                print(chunk.content, end="", flush=True)
                content_pieces.append(chunk.content)
            elif chunk.event == RunEvent.run_cancelled:
                print(f"\nüö´ Member run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif chunk.event == TeamRunEvent.run_cancelled:
                print(f"\nüö´ Team run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif hasattr(chunk, "status") and chunk.status == RunStatus.completed:
                final_response = chunk

        # If we get here, the run completed successfully
        if final_response:
            run_id_container["result"] = {
                "status": final_response.status.value
                if final_response.status
                else "completed",
                "run_id": final_response.run_id,
                "cancelled": final_response.status == RunStatus.cancelled,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }
        else:
            run_id_container["result"] = {
                "status": "unknown",
                "run_id": run_id_container.get("run_id"),
                "cancelled": False,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }

    except Exception as e:
        print(f"\n‚ùå Exception in run: {str(e)}")
        run_id_container["result"] = {
            "status": "error",
            "error": str(e),
            "run_id": run_id_container.get("run_id"),
            "cancelled": True,
            "content": "Error occurred",
        }


def cancel_after_delay(team: Team, run_id_container: dict, delay_seconds: int = 3):
    """
    Cancel the team run after a specified delay.

    Args:
        team: The team whose run should be cancelled
        run_id_container: Dictionary containing the run_id to cancel
        delay_seconds: How long to wait before cancelling
    """
    print(f"‚è∞ Will cancel team run in {delay_seconds} seconds...")
    time.sleep(delay_seconds)

    run_id = run_id_container.get("run_id")
    if run_id:
        print(f"üö´ Cancelling team run: {run_id}")
        success = team.cancel_run(run_id)
        if success:
            print(f"‚úÖ Team run {run_id} marked for cancellation")
        else:
            print(
                f"‚ùå Failed to cancel team run {run_id} (may not exist or already completed)"
            )
    else:
        print("‚ö†Ô∏è  No run_id found to cancel")


def main():
    """Main function demonstrating team run cancellation."""

    # Create team members
    storyteller_agent = Agent(
        name="StorytellerAgent",
        model=OpenAIChat(id="gpt-5-mini"),
        description="An agent that writes creative stories",
    )

    editor_agent = Agent(
        name="EditorAgent",
        model=OpenAIChat(id="gpt-5-mini"),
        description="An agent that reviews and improves stories",
    )

    # Initialize the team with agents
    team = Team(
        name="Storytelling Team",
        members=[storyteller_agent, editor_agent],
        model=OpenAIChat(id="gpt-5-mini"),  # Team leader model
        description="A team that collaborates to write detailed stories",
    )

    print("üöÄ Starting team run cancellation example...")
    print("=" * 50)

    # Container to share run_id between threads
    run_id_container = {}

    # Start the team run in a separate thread
    team_thread = threading.Thread(
        target=lambda: long_running_task(team, run_id_container), name="TeamRunThread"
    )

    # Start the cancellation thread
    cancel_thread = threading.Thread(
        target=cancel_after_delay,
        args=(team, run_id_container, 8),  # Cancel after 8 seconds
        name="CancelThread",
    )

    # Start both threads
    print("üèÉ Starting team run thread...")
    team_thread.start()

    print("üèÉ Starting cancellation thread...")
    cancel_thread.start()

    # Wait for both threads to complete
    print("‚åõ Waiting for threads to complete...")
    team_thread.join()
    cancel_thread.join()

    # Print the results
    print("\n" + "=" * 50)
    print("üìä RESULTS:")
    print("=" * 50)

    result = run_id_container.get("result")
    if result:
        print(f"Status: {result['status']}")
        print(f"Run ID: {result['run_id']}")
        print(f"Was Cancelled: {result['cancelled']}")

        if result.get("error"):
            print(f"Error: {result['error']}")
        else:
            print(f"Content Preview: {result['content']}")

        if result["cancelled"]:
            print("\n‚úÖ SUCCESS: Team run was successfully cancelled!")
        else:
            print("\n‚ö†Ô∏è  WARNING: Team run completed before cancellation")
    else:
        print("‚ùå No result obtained - check if cancellation happened during streaming")

    print("\nüèÅ Team cancellation example completed!")


if __name__ == "__main__":
    # Run the main example
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/team_cancel_a_run.py
    ```
  </Step>
</Steps>


# Team with Exponential Backoff
Source: https://docs.agno.com/examples/concepts/teams/basic/team_exponential_backoff



This example demonstrates how to configure a team with exponential backoff retry logic. When agents encounter errors or rate limits, the team will automatically retry with increasing delays between attempts.

## Code

```python cookbook/examples/teams/basic/team_exponential_backoff.py
from agno.agent import Agent
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

# Create a research team
team = Team(
    members=[
        Agent(
            name="Sarah",
            role="Data Researcher",
            tools=[DuckDuckGoTools()],
            instructions="Focus on gathering and analyzing data",
        ),
        Agent(
            name="Mike",
            role="Technical Writer",
            instructions="Create clear, concise summaries",
        ),
    ],
    retries=3,
    exponential_backoff=True,
)

team.print_response(
    "Search for latest news about the latest AI models",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/basic/team_exponential_backoff.py
    ```
  </Step>
</Steps>


# Access Dependencies in Team Tool
Source: https://docs.agno.com/examples/concepts/teams/dependencies/access_dependencies_in_tool

How to access dependencies passed to a team in a tool

This example demonstrates how team tools can access dependencies passed to the team, allowing tools to utilize dynamic context like team metrics and current time information while team members collaborate with shared data sources.

## Code

```python cookbook/examples/teams/dependencies/access_dependencies_in_tool.py
from typing import Dict, Any, Optional
from datetime import datetime

from agno.agent import Agent
from agno.team import Team
from agno.models.openai import OpenAIChat


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }

def analyze_team_performance(team_id: str, dependencies: Optional[Dict[str, Any]] = None) -> str:
    """
    Analyze team performance using available data sources.
    
    This tool analyzes team metrics and provides insights.
    Call this tool with the team_id you want to analyze.
    
    Args:
        team_id: The team ID to analyze (e.g., 'engineering_team', 'sales_team')
        dependencies: Available data sources (automatically provided)
    
    Returns:
        Detailed team performance analysis and insights
    """
    if not dependencies:
        return "No data sources available for analysis."
    
    print(f"--> Team tool received data sources: {list(dependencies.keys())}")
    
    results = [f"=== TEAM PERFORMANCE ANALYSIS FOR {team_id.upper()} ==="]
    
    # Use team metrics data if available
    if "team_metrics" in dependencies:
        metrics_data = dependencies["team_metrics"]
        results.append(f"Team Metrics: {metrics_data}")
        
        # Add analysis based on the metrics
        if metrics_data.get("productivity_score"):
            score = metrics_data["productivity_score"]
            if score >= 8:
                results.append(f"Performance Analysis: Excellent performance with {score}/10 productivity score")
            elif score >= 6:
                results.append(f"Performance Analysis: Good performance with {score}/10 productivity score")
            else:
                results.append(f"Performance Analysis: Needs improvement with {score}/10 productivity score")
    
    # Use current context data if available
    if "current_context" in dependencies:
        context_data = dependencies["current_context"]
        results.append(f"Current Context: {context_data}")
        results.append(f"Time-based Analysis: Team analysis performed on {context_data['day_of_week']} at {context_data['current_time']}")

    print(f"--> Team tool returned results: {results}")
    
    return "\n\n".join(results)

# Create team members
data_analyst = Agent(
    model=OpenAIChat(id="gpt-4o"),
    name="Data Analyst",
    description="Specialist in analyzing team metrics and performance data",
    instructions=[
        "You are a data analysis expert focusing on team performance metrics.",
        "Interpret quantitative data and identify trends.",
        "Provide data-driven insights and recommendations.",
    ],
)

team_lead = Agent(
    model=OpenAIChat(id="gpt-4o"),
    name="Team Lead", 
    description="Experienced team leader who provides strategic insights",
    instructions=[
        "You are an experienced team leader and management expert.",
        "Focus on leadership insights and team dynamics.",
        "Provide strategic recommendations for team improvement.",
        "Collaborate with the data analyst to get comprehensive insights.",
    ],
)

# Create a team with the analysis tool
performance_team = Team(
    model=OpenAIChat(id="gpt-4o"),
    members=[data_analyst, team_lead],
    tools=[analyze_team_performance],
    name="Team Performance Analysis Team",
    description="A team specialized in analyzing team performance using integrated data sources.",
    instructions=[
        "You are a team performance analysis unit with access to team metrics and analysis tools.",
        "When asked to analyze any team, use the analyze_team_performance tool first.",
        "This tool has access to team metrics and current context through integrated data sources.",
        "Data Analyst: Focus on the quantitative metrics and trends.",
        "Team Lead: Provide strategic insights and management recommendations.",
        "Work together to provide comprehensive team performance insights.",
    ],
)

print("=== Team Tool Dependencies Access Example ===\n")

response = performance_team.run(
    input="Please analyze the 'engineering_team' performance and provide comprehensive insights about their productivity and recommendations for improvement.",
    dependencies={
        "team_metrics": {
            "team_name": "Engineering Team Alpha",
            "team_size": 8,
            "productivity_score": 7.5,
            "sprint_velocity": 85,
            "bug_resolution_rate": 92,
            "code_review_turnaround": "2.3 days",
            "areas": ["Backend Development", "Frontend Development", "DevOps"],
        },
        "current_context": get_current_context,
    },
    session_id="test_team_tool_dependencies",
)

print(f"\nTeam Response: {response.content}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the team">
    ```bash
    python cookbook/examples/teams/dependencies/access_dependencies_in_tool.py
    ```
  </Step>
</Steps>


# Adding Dependencies to Team Run
Source: https://docs.agno.com/examples/concepts/teams/dependencies/add_dependencies_run



This example demonstrates how to add dependencies to a specific team run. Dependencies are functions that provide contextual information (like user profiles and current context) that get passed to the team during execution for personalized responses.

## Code

```python cookbook/examples/teams/dependencies/add_dependencies_on_run.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team


def get_user_profile(user_id: str = "john_doe") -> dict:
    """Get user profile information that can be referenced in responses."""
    profiles = {
        "john_doe": {
            "name": "John Doe",
            "preferences": {
                "communication_style": "professional",
                "topics_of_interest": ["AI/ML", "Software Engineering", "Finance"],
                "experience_level": "senior",
            },
            "location": "San Francisco, CA",
            "role": "Senior Software Engineer",
        }
    }

    return profiles.get(user_id, {"name": "Unknown User"})


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    from datetime import datetime

    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }


profile_agent = Agent(
    name="ProfileAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze user profiles and provide personalized recommendations.",
)

context_agent = Agent(
    name="ContextAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze current context and timing to provide relevant insights.",
)

team = Team(
    name="PersonalizationTeam",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[profile_agent, context_agent],
    markdown=True,
)

response = team.run(
    "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
    dependencies={
        "user_profile": get_user_profile,
        "current_context": get_current_context,
    },
    add_dependencies_to_context=True,
)

print(response.content)

# ------------------------------------------------------------
# ASYNC EXAMPLE
# ------------------------------------------------------------
# async def test_async():
#     async_response = await team.arun(
#         "Based on my profile, what should I focus on this week? Include specific recommendations.",
#         dependencies={
#             "user_profile": get_user_profile,
#             "current_context": get_current_context,
#         },
#         add_dependencies_to_context=True,
#         debug_mode=True,
#     )
#
#     print("\n=== Async Run Response ===")
#     print(async_response.content)

# # Run the async test
# import asyncio
# asyncio.run(test_async())

# ------------------------------------------------------------
# PRINT RESPONSE
# ------------------------------------------------------------
# team.print_response(
#     "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
#     dependencies={
#         "user_profile": get_user_profile,
#         "current_context": get_current_context,
#     },
#     add_dependencies_to_context=True,
#     debug_mode=True,
# )

# print(response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/dependencies/add_dependencies_on_run.py
    ```
  </Step>
</Steps>


# Adding Dependencies to Team Context
Source: https://docs.agno.com/examples/concepts/teams/dependencies/add_dependencies_to_context



This example demonstrates how to add dependencies directly to the team context. Unlike adding dependencies per run, this approach makes the dependency functions available to all team runs by default, providing consistent access to contextual information across all interactions.

## Code

```python cookbook/examples/teams/dependencies/add_dependencies_to_context.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team


def get_user_profile(user_id: str = "john_doe") -> dict:
    """Get user profile information that can be referenced in responses."""
    profiles = {
        "john_doe": {
            "name": "John Doe",
            "preferences": {
                "communication_style": "professional",
                "topics_of_interest": ["AI/ML", "Software Engineering", "Finance"],
                "experience_level": "senior",
            },
            "location": "San Francisco, CA",
            "role": "Senior Software Engineer",
        }
    }

    return profiles.get(user_id, {"name": "Unknown User"})


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    from datetime import datetime

    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }


profile_agent = Agent(
    name="ProfileAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze user profiles and provide personalized recommendations.",
)

context_agent = Agent(
    name="ContextAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze current context and timing to provide relevant insights.",
)

team = Team(
    name="PersonalizationTeam",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[profile_agent, context_agent],
    dependencies={
        "user_profile": get_user_profile,
        "current_context": get_current_context,
    },
    add_dependencies_to_context=True,
    debug_mode=True,
    markdown=True,
)

response = team.run(
    "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
)

print(response.content)

# ------------------------------------------------------------
# ASYNC EXAMPLE
# ------------------------------------------------------------
# async def test_async():
#     async_response = await team.arun(
#         "Based on my profile, what should I focus on this week? Include specific recommendations.",
#     )
#
#     print("\n=== Async Run Response ===")
#     print(async_response.content)

# # Run the async test
# import asyncio
# asyncio.run(test_async())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/dependencies/add_dependencies_to_context.py
    ```
  </Step>
</Steps>


# Using Reference Dependencies in Team Instructions
Source: https://docs.agno.com/examples/concepts/teams/dependencies/reference_dependencies



This example demonstrates how to use reference dependencies by defining them in the team constructor and referencing them directly in team instructions. This approach allows dependencies to be automatically injected into the team's context and referenced using template variables in instructions.

## Code

```python cookbook/examples/teams/dependencies/reference_dependencies.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team


def get_user_profile(user_id: str = "john_doe") -> dict:
    """Get user profile information that can be referenced in responses."""
    profiles = {
        "john_doe": {
            "name": "John Doe",
            "preferences": {
                "communication_style": "professional",
                "topics_of_interest": ["AI/ML", "Software Engineering", "Finance"],
                "experience_level": "senior",
            },
            "location": "San Francisco, CA",
            "role": "Senior Software Engineer",
        }
    }

    return profiles.get(user_id, {"name": "Unknown User"})


def get_current_context() -> dict:
    """Get current contextual information like time, weather, etc."""
    from datetime import datetime

    return {
        "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "PST",
        "day_of_week": datetime.now().strftime("%A"),
    }


profile_agent = Agent(
    name="ProfileAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze user profiles and provide personalized recommendations.",
)

context_agent = Agent(
    name="ContextAnalyst",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You analyze current context and timing to provide relevant insights.",
)

team = Team(
    name="PersonalizationTeam",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[profile_agent, context_agent],
    dependencies={
        "user_profile": get_user_profile,
        "current_context": get_current_context,
    },
    instructions=[
        "You are a personalization team that provides personalized recommendations based on the user's profile and context.",
        "Here is the user profile: {user_profile}",
        "Here is the current context: {current_context}",
    ],
    debug_mode=True,
    markdown=True,
)

response = team.run(
    "Please provide me with a personalized summary of today's priorities based on my profile and interests.",
)

print(response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/dependencies/reference_dependencies.py
    ```
  </Step>
</Steps>


# Distributed RAG with LanceDB
Source: https://docs.agno.com/examples/concepts/teams/distributed_rag/distributed_rag_lancedb



This example demonstrates how multiple specialized agents coordinate to provide comprehensive RAG responses using distributed knowledge bases and specialized retrieval strategies with LanceDB. The team includes primary retrieval, context expansion, answer synthesis, and quality validation.

## Code

```python cookbook/examples/teams/distributed_rag/02_distributed_rag_lancedb.py
"""
This example demonstrates how multiple specialized agents coordinate to provide
comprehensive RAG responses using distributed knowledge bases and specialized
retrieval strategies with LanceDB.

Team Composition:
- Primary Retriever: Handles primary document retrieval from main knowledge base
- Context Expander: Expands context by finding related information
- Answer Synthesizer: Synthesizes retrieved information into comprehensive answers
- Quality Validator: Validates answer quality and suggests improvements

Setup:
1. Run: `pip install openai lancedb tantivy pypdf sqlalchemy agno`
2. Run this script to see distributed RAG in action
"""

import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.vectordb.lancedb import LanceDb, SearchType

# Primary knowledge base for main retrieval
primary_knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="recipes_primary",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Secondary knowledge base for context expansion
context_knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="recipes_context",
        uri="tmp/lancedb",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Primary Retriever Agent - Specialized in main document retrieval
primary_retriever = Agent(
    name="Primary Retriever",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Retrieve primary documents and core information from knowledge base",
    knowledge=primary_knowledge,
    search_knowledge=True,
    instructions=[
        "Search the knowledge base for directly relevant information to the user's query.",
        "Focus on retrieving the most relevant and specific documents first.",
        "Provide detailed information with proper context.",
        "Ensure accuracy and completeness of retrieved information.",
    ],
    markdown=True,
)

# Context Expander Agent - Specialized in expanding context
context_expander = Agent(
    name="Context Expander",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Expand context by finding related and supplementary information",
    knowledge=context_knowledge,
    search_knowledge=True,
    instructions=[
        "Find related information that complements the primary retrieval.",
        "Look for background context, related topics, and supplementary details.",
        "Search for information that helps understand the broader context.",
        "Identify connections between different pieces of information.",
    ],
    markdown=True,
)

# Answer Synthesizer Agent - Specialized in synthesis
answer_synthesizer = Agent(
    name="Answer Synthesizer",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Synthesize retrieved information into comprehensive answers",
    instructions=[
        "Combine information from the Primary Retriever and Context Expander.",
        "Create a comprehensive, well-structured response.",
        "Ensure logical flow and coherence in the final answer.",
        "Include relevant details while maintaining clarity.",
        "Organize information in a user-friendly format.",
    ],
    markdown=True,
)

# Quality Validator Agent - Specialized in validation
quality_validator = Agent(
    name="Quality Validator",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Validate answer quality and suggest improvements",
    instructions=[
        "Review the synthesized answer for accuracy and completeness.",
        "Check if the answer fully addresses the user's query.",
        "Identify any gaps or areas that need clarification.",
        "Suggest improvements or additional information if needed.",
        "Ensure the response meets high quality standards.",
    ],
    markdown=True,
)

# Create distributed RAG team
distributed_rag_team = Team(
    name="Distributed RAG Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[
        primary_retriever,
        context_expander,
        answer_synthesizer,
        quality_validator,
    ],
    instructions=[
        "Work together to provide comprehensive, high-quality RAG responses.",
        "Primary Retriever: First retrieve core relevant information.",
        "Context Expander: Then expand with related context and background.",
        "Answer Synthesizer: Synthesize all information into a comprehensive answer.",
        "Quality Validator: Finally validate and suggest any improvements.",
        "Ensure all responses are accurate, complete, and well-structured.",
    ],
    show_members_responses=True,
    markdown=True,
)


async def async_distributed_rag_demo():
    """Demonstrate async distributed RAG processing."""
    print("üìö Async Distributed RAG with LanceDB Demo")
    print("=" * 50)

    query = "How do I make chicken and galangal in coconut milk soup? Include cooking tips and variations."

    # Add content to knowledge bases
    await primary_knowledge.add_contents_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    await context_knowledge.add_contents_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    # # Run async distributed RAG
    # await distributed_rag_team.aprint_response(
    #     query, stream=True, stream_intermediate_steps=True
    # )
    await distributed_rag_team.aprint_response(input=query)


def sync_distributed_rag_demo():
    """Demonstrate sync distributed RAG processing."""
    print("üìö Distributed RAG with LanceDB Demo")
    print("=" * 40)

    query = "How do I make chicken and galangal in coconut milk soup? Include cooking tips and variations."

    # Add content to knowledge bases
    primary_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    context_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    # Run distributed RAG
    distributed_rag_team.print_response(input=query)


def multi_course_meal_demo():
    """Demonstrate distributed RAG for complex multi-part queries."""
    print("üçΩÔ∏è Multi-Course Meal Planning with Distributed RAG")
    print("=" * 55)

    query = """Hi, I want to make a 3 course Thai meal. Can you recommend some recipes? 
    I'd like to start with a soup, then a thai curry for the main course and finish with a dessert.
    Please include cooking techniques and any special tips."""

    # Add content to knowledge bases
    primary_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    context_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    distributed_rag_team.print_response(input=query)


if __name__ == "__main__":
    # Choose which demo to run
    asyncio.run(async_distributed_rag_demo())

    # multi_course_meal_demo()

    # sync_distributed_rag_demo()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai lancedb tantivy pypdf sqlalchemy
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/distributed_rag/02_distributed_rag_lancedb.py
    ```
  </Step>
</Steps>


# Distributed RAG with PgVector
Source: https://docs.agno.com/examples/concepts/teams/distributed_rag/distributed_rag_pgvector



This example demonstrates how multiple specialized agents coordinate to provide comprehensive RAG responses using distributed PostgreSQL vector databases with pgvector for scalable, production-ready retrieval. The team includes vector retrieval, hybrid search, data validation, and response composition specialists.

## Code

```python cookbook/examples/teams/distributed_rag/01_distributed_rag_pgvector.py
"""
This example demonstrates how multiple specialized agents coordinate to provide
comprehensive RAG responses using distributed PostgreSQL vector databases with
pgvector for scalable, production-ready retrieval.

Team Composition:
- Vector Retriever: Specialized in vector similarity search using pgvector
- Hybrid Searcher: Combines vector and text search for comprehensive results
- Data Validator: Validates retrieved data quality and relevance
- Response Composer: Composes final responses with proper source attribution

Setup:
1. Run: `./cookbook/run_pgvector.sh` to start a postgres container with pgvector
2. Run: `pip install openai sqlalchemy 'psycopg[binary]' pgvector agno`
3. Run this script to see distributed PgVector RAG in action
"""

import asyncio  # noqa: F401

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.vectordb.pgvector import PgVector, SearchType

# Database connection URL
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Vector-focused knowledge base for similarity search
vector_knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes_vector",
        db_url=db_url,
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Hybrid knowledge base for comprehensive search
hybrid_knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes_hybrid",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Vector Retriever Agent - Specialized in vector similarity search
vector_retriever = Agent(
    name="Vector Retriever",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Retrieve information using vector similarity search in PostgreSQL",
    knowledge=vector_knowledge,
    search_knowledge=True,
    instructions=[
        "Use vector similarity search to find semantically related content.",
        "Focus on finding information that matches the semantic meaning of queries.",
        "Leverage pgvector's efficient similarity search capabilities.",
        "Retrieve content that has high semantic relevance to the user's query.",
    ],
    markdown=True,
)

# Hybrid Searcher Agent - Specialized in hybrid search
hybrid_searcher = Agent(
    name="Hybrid Searcher",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Perform hybrid search combining vector and text search",
    knowledge=hybrid_knowledge,
    search_knowledge=True,
    instructions=[
        "Combine vector similarity and text search for comprehensive results.",
        "Find information that matches both semantic and lexical criteria.",
        "Use PostgreSQL's hybrid search capabilities for best coverage.",
        "Ensure retrieval of both conceptually and textually relevant content.",
    ],
    markdown=True,
)

# Data Validator Agent - Specialized in data quality validation
data_validator = Agent(
    name="Data Validator",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Validate retrieved data quality and relevance",
    instructions=[
        "Assess the quality and relevance of retrieved information.",
        "Check for consistency across different search results.",
        "Identify the most reliable and accurate information.",
        "Filter out any irrelevant or low-quality content.",
        "Ensure data integrity and relevance to the user's query.",
    ],
    markdown=True,
)

# Response Composer Agent - Specialized in response composition
response_composer = Agent(
    name="Response Composer",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Compose comprehensive responses with proper source attribution",
    instructions=[
        "Combine validated information from all team members.",
        "Create well-structured, comprehensive responses.",
        "Include proper source attribution and data provenance.",
        "Ensure clarity and coherence in the final response.",
        "Format responses for optimal user experience.",
    ],
    markdown=True,
)

# Create distributed PgVector RAG team
distributed_pgvector_team = Team(
    name="Distributed PgVector RAG Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[vector_retriever, hybrid_searcher, data_validator, response_composer],
    instructions=[
        "Work together to provide comprehensive RAG responses using PostgreSQL pgvector.",
        "Vector Retriever: First perform vector similarity search.",
        "Hybrid Searcher: Then perform hybrid search for comprehensive coverage.",
        "Data Validator: Validate and filter the retrieved information quality.",
        "Response Composer: Compose the final response with proper attribution.",
        "Leverage PostgreSQL's scalability and pgvector's performance.",
        "Ensure enterprise-grade reliability and accuracy.",
    ],
    show_members_responses=True,
    markdown=True,
)


async def async_pgvector_rag_demo():
    """Demonstrate async distributed PgVector RAG processing."""
    print("üêò Async Distributed PgVector RAG Demo")
    print("=" * 40)

    query = "How do I make chicken and galangal in coconut milk soup? What are the key ingredients and techniques?"

    try:
        # Add content to knowledge bases
        await vector_knowledge.add_contents_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
        await hybrid_knowledge.add_contents_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
        # Run async distributed PgVector RAG
        await distributed_pgvector_team.aprint_response(input=query)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("üí° Make sure PostgreSQL with pgvector is running!")
        print("   Run: ./cookbook/run_pgvector.sh")


def sync_pgvector_rag_demo():
    """Demonstrate sync distributed PgVector RAG processing."""
    print("üêò Distributed PgVector RAG Demo")
    print("=" * 35)

    query = "How do I make chicken and galangal in coconut milk soup? What are the key ingredients and techniques?"

    try:
        # Add content to knowledge bases
        vector_knowledge.add_contents(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
        hybrid_knowledge.add_contents(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
        # Run distributed PgVector RAG
        distributed_pgvector_team.print_response(input=query)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("üí° Make sure PostgreSQL with pgvector is running!")
        print("   Run: ./cookbook/run_pgvector.sh")


def complex_query_demo():
    """Demonstrate distributed RAG for complex culinary queries."""
    print("üë®‚Äçüç≥ Complex Culinary Query with Distributed PgVector RAG")
    print("=" * 60)

    query = """I'm planning a Thai dinner party for 8 people. Can you help me plan a complete menu?
    I need appetizers, main courses, and desserts. Please include:
    - Preparation timeline
    - Shopping list
    - Cooking techniques for each dish
    - Any dietary considerations or alternatives"""

    try:
        # Add content to knowledge bases
        vector_knowledge.add_contents(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
        hybrid_knowledge.add_contents(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )

        distributed_pgvector_team.print_response(input=query)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("üí° Make sure PostgreSQL with pgvector is running!")
        print("   Run: ./cookbook/run_pgvector.sh")


if __name__ == "__main__":
    # Choose which demo to run

    # asyncio.run(async_pgvector_rag_demo())

    # complex_query_demo()

    sync_pgvector_rag_demo()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up PostgreSQL with pgvector">
    ```bash
    ./cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Install required libraries">
    ```bash
    pip install agno openai sqlalchemy 'psycopg[binary]' pgvector
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/distributed_rag/01_distributed_rag_pgvector.py
    ```
  </Step>
</Steps>


# Distributed RAG with Advanced Reranking
Source: https://docs.agno.com/examples/concepts/teams/distributed_rag/distributed_rag_with_reranking



This example demonstrates how multiple specialized agents coordinate to provide comprehensive RAG responses using advanced reranking strategies for optimal information retrieval and synthesis. The team includes initial retrieval, reranking optimization, context analysis, and final synthesis.

## Code

```python cookbook/examples/teams/distributed_rag/03_distributed_rag_with_reranking.py
"""
This example demonstrates how multiple specialized agents coordinate to provide
comprehensive RAG responses using advanced reranking strategies for optimal
information retrieval and synthesis.

Team Composition:
- Initial Retriever: Performs broad initial retrieval from knowledge base
- Reranking Specialist: Applies advanced reranking for result optimization
- Context Analyzer: Analyzes context and relevance of reranked results
- Final Synthesizer: Synthesizes reranked results into optimal responses

Setup:
1. Run: `pip install openai lancedb tantivy pypdf sqlalchemy agno`
2. Run this script to see advanced reranking RAG in action
"""

import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker import CohereReranker
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.utils.print_response.team import aprint_response, print_response
from agno.vectordb.lancedb import LanceDb, SearchType

# Knowledge base with advanced reranking
reranked_knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="recipes_reranked",
        uri="tmp/lancedb",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

# Secondary knowledge base for cross-validation
validation_knowledge = Knowledge(
    vector_db=LanceDb(
        table_name="recipes_validation",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Initial Retriever Agent - Specialized in broad initial retrieval
initial_retriever = Agent(
    name="Initial Retriever",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Perform broad initial retrieval to gather candidate information",
    knowledge=reranked_knowledge,
    search_knowledge=True,
    instructions=[
        "Perform comprehensive initial retrieval from the knowledge base.",
        "Cast a wide net to gather all potentially relevant information.",
        "Focus on recall rather than precision in this initial phase.",
        "Retrieve diverse content that might be relevant to the query.",
    ],
    markdown=True,
)

# Reranking Specialist Agent - Specialized in result optimization
reranking_specialist = Agent(
    name="Reranking Specialist",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Apply advanced reranking to optimize retrieval results",
    knowledge=reranked_knowledge,
    search_knowledge=True,
    instructions=[
        "Apply advanced reranking techniques to optimize result relevance.",
        "Focus on precision and ranking quality over quantity.",
        "Use the Cohere reranker to identify the most relevant content.",
        "Prioritize results that best match the user's specific needs.",
    ],
    markdown=True,
)

# Context Analyzer Agent - Specialized in context analysis
context_analyzer = Agent(
    name="Context Analyzer",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Analyze context and relevance of reranked results",
    knowledge=validation_knowledge,
    search_knowledge=True,
    instructions=[
        "Analyze the context and relevance of reranked results.",
        "Cross-validate information against the validation knowledge base.",
        "Assess the quality and accuracy of retrieved content.",
        "Identify the most contextually appropriate information.",
    ],
    markdown=True,
)

# Final Synthesizer Agent - Specialized in optimal synthesis
final_synthesizer = Agent(
    name="Final Synthesizer",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Synthesize reranked results into optimal comprehensive responses",
    instructions=[
        "Synthesize information from all team members into optimal responses.",
        "Leverage the reranked and analyzed results for maximum quality.",
        "Create responses that demonstrate the benefits of advanced reranking.",
        "Ensure optimal information organization and presentation.",
        "Include confidence levels and source quality indicators.",
    ],
    markdown=True,
)

# Create distributed reranking RAG team
distributed_reranking_team = Team(
    name="Distributed Reranking RAG Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[
        initial_retriever,
        reranking_specialist,
        context_analyzer,
        final_synthesizer,
    ],
    instructions=[
        "Work together to provide optimal RAG responses using advanced reranking.",
        "Initial Retriever: First perform broad comprehensive retrieval.",
        "Reranking Specialist: Apply advanced reranking for result optimization.",
        "Context Analyzer: Analyze and validate the reranked results.",
        "Final Synthesizer: Create optimal responses from reranked information.",
        "Leverage advanced reranking for superior result quality.",
        "Demonstrate the benefits of specialized reranking in team coordination.",
    ],
    show_members_responses=True,
    markdown=True,
)


async def async_reranking_rag_demo():
    """Demonstrate async distributed reranking RAG processing."""
    print("üéØ Async Distributed Reranking RAG Demo")
    print("=" * 45)

    query = "What's the best way to prepare authentic Tom Kha Gai? I want traditional methods and modern variations."

    # Add content to knowledge bases
    await reranked_knowledge.add_contents_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    await validation_knowledge.add_contents_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    # Run async distributed reranking RAG
    await aprint_response(input=query, team=distributed_reranking_team)


def sync_reranking_rag_demo():
    """Demonstrate sync distributed reranking RAG processing."""
    print("üéØ Distributed Reranking RAG Demo")
    print("=" * 35)

    query = "What's the best way to prepare authentic Tom Kha Gai? I want traditional methods and modern variations."

    # Add content to knowledge bases
    reranked_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    validation_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    # Run distributed reranking RAG
    print_response(distributed_reranking_team, query)


def advanced_culinary_demo():
    """Demonstrate advanced reranking for complex culinary queries."""
    print("üë®‚Äçüç≥ Advanced Culinary Analysis with Reranking RAG")
    print("=" * 55)

    query = """I want to understand the science behind Thai curry pastes. Can you explain:
    - Traditional preparation methods vs modern techniques
    - How different ingredients affect flavor profiles
    - Regional variations and their historical origins
    - Best practices for storage and usage
    - How to adapt recipes for different dietary needs"""

    # Add content to knowledge bases
    reranked_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    validation_knowledge.add_contents(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )

    print_response(distributed_reranking_team, query)


if __name__ == "__main__":
    # Choose which demo to run
    asyncio.run(async_reranking_rag_demo())

    # advanced_culinary_demo()

    # sync_reranking_rag_demo()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai lancedb tantivy pypdf sqlalchemy cohere
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export COHERE_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/distributed_rag/03_distributed_rag_with_reranking.py
    ```
  </Step>
</Steps>


# Custom Events
Source: https://docs.agno.com/examples/concepts/teams/events/custom_events

Learn how to yield custom events from your own tools.

### Complete Example

```python
import asyncio
from dataclasses import dataclass
from typing import Optional

from agno.agent import Agent
from agno.team import Team
from agno.models.openai import OpenAIChat
from agno.run.team import CustomEvent
from agno.tools import tool


# Our custom event, extending the CustomEvent class
@dataclass
class CustomerProfileEvent(CustomEvent):
    """CustomEvent for customer profile."""

    customer_name: Optional[str] = None
    customer_email: Optional[str] = None
    customer_phone: Optional[str] = None


# Our custom tool
@tool()
async def get_customer_profile():
    """
    Get the customer profile for the customer with ID 123.
    """
    yield CustomerProfileEvent(
        customer_name="John Doe",
        customer_email="john.doe@example.com",
        customer_phone="1234567890",
    )


agent = Agent(
    name="Customer Support Agent",
    role="Support agent that handles customer requests.",
    model=OpenAIChat(id="gpt-4o"),
)

# Setup the Team with our custom tool.
team = Team(
    members=[agent],
    tools=[get_customer_profile],
    model=OpenAIChat(id="gpt-4o"),
    instructions="You are a team that handles customer requests.",
)


async def run_team():
    # Running the Team: The team should call our custom tool and yield the custom event
    async for event in team.arun(
        "Hello, can you get me the customer profile for customer with ID 123?",
        stream=True,
    ):
        if isinstance(event, CustomEvent):
            print(f"‚úÖ Custom event emitted: {event}")


asyncio.run(run_team())
```


# Team with Agentic Knowledge Filters
Source: https://docs.agno.com/examples/concepts/teams/knowledge/team_with_agentic_knowledge_filters



This example demonstrates how to use agentic knowledge filters with teams. Unlike predefined filters, agentic knowledge filters allow the AI to dynamically determine which documents to search based on the query context, providing more intelligent and context-aware document retrieval.

## Code

```python cookbook/examples/teams/knowledge/03_team_with_agentic_knowledge_filters.py
"""
This example demonstrates how to use agentic knowledge filters with teams.

Agentic knowledge filters allow the AI to dynamically determine which documents
to search based on the query context, rather than using predefined filters.
"""

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize LanceDB vector database
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Create knowledge base
knowledge = Knowledge(
    vector_db=vector_db,
)

# Add documents with metadata for agentic filtering
knowledge.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ]
)

# Create knowledge search agent with filter awareness
web_agent = Agent(
    name="Knowledge Search Agent",
    role="Handle knowledge search",
    knowledge=knowledge,
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=["Always take into account filters"],
)

# Create team with agentic knowledge filters enabled
team_with_knowledge = Team(
    name="Team with Knowledge",
    members=[
        web_agent
    ],  # If you omit the member, the leader will search the knowledge base itself.
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    show_members_responses=True,
    markdown=True,
    enable_agentic_knowledge_filters=True,  # Allow AI to determine filters
)

# Test agentic knowledge filtering
team_with_knowledge.print_response(
    "Tell me about Jordan Mitchell's work and experience with user_id as jordan_mitchell"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/knowledge/03_team_with_agentic_knowledge_filters.py
    ```
  </Step>
</Steps>


# Team with Knowledge Base
Source: https://docs.agno.com/examples/concepts/teams/knowledge/team_with_knowledge



This example demonstrates how to create a team with knowledge base integration. The team has access to a knowledge base with Agno documentation and can combine this knowledge with web search capabilities.

## Code

```python cookbook/examples/teams/knowledge/01_team_with_knowledge.py
"""
This example demonstrates how to create a team with knowledge base integration.

The team has access to a knowledge base with Agno documentation and can combine
this knowledge with web search capabilities.
"""

from pathlib import Path

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Setup paths for knowledge storage
cwd = Path(__file__).parent
tmp_dir = cwd.joinpath("tmp")
tmp_dir.mkdir(parents=True, exist_ok=True)

# Initialize knowledge base with vector database
agno_docs_knowledge = Knowledge(
    vector_db=LanceDb(
        uri=str(tmp_dir.joinpath("lancedb")),
        table_name="agno_docs",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Add content to knowledge base
agno_docs_knowledge.add_content(url="https://docs.agno.com/llms-full.txt")

# Create web search agent for supplementary information
web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
)

# Create team with knowledge base integration
team_with_knowledge = Team(
    name="Team with Knowledge",
    members=[web_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=agno_docs_knowledge,
    show_members_responses=True,
    markdown=True,
)

if __name__ == "__main__":
    team_with_knowledge.print_response("Tell me about the Agno framework", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/knowledge/01_team_with_knowledge.py
    ```
  </Step>
</Steps>


# Team with Knowledge Filters
Source: https://docs.agno.com/examples/concepts/teams/knowledge/team_with_knowledge_filters



This example demonstrates how to use knowledge filters with teams to restrict knowledge searches to specific documents or metadata criteria, enabling personalized and contextual responses based on predefined filter conditions.

## Code

```python cookbook/examples/teams/knowledge/02_team_with_knowledge_filters.py
"""
This example demonstrates how to use knowledge filters with teams.

Knowledge filters allow you to restrict knowledge searches to specific documents
or metadata criteria, enabling personalized and contextual responses.
"""

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.utils.media import (
    SampleDataFileExtension,
    download_knowledge_filters_sample_data,
)
from agno.vectordb.lancedb import LanceDb

# Download all sample CVs and get their paths
downloaded_cv_paths = download_knowledge_filters_sample_data(
    num_files=5, file_extension=SampleDataFileExtension.PDF
)

# Initialize LanceDB vector database
# By default, it stores data in /tmp/lancedb
vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",  # You can change this path to store data elsewhere
)

# Create knowledge base
knowledge_base = Knowledge(
    vector_db=vector_db,
)

# Add documents with metadata for filtering
knowledge_base.add_contents(
    [
        {
            "path": downloaded_cv_paths[0],
            "metadata": {
                "user_id": "jordan_mitchell",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[1],
            "metadata": {
                "user_id": "taylor_brooks",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[2],
            "metadata": {
                "user_id": "morgan_lee",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[3],
            "metadata": {
                "user_id": "casey_jordan",
                "document_type": "cv",
                "year": 2025,
            },
        },
        {
            "path": downloaded_cv_paths[4],
            "metadata": {
                "user_id": "alex_rivera",
                "document_type": "cv",
                "year": 2025,
            },
        },
    ],
    reader=PDFReader(chunk=True),
)

# Create knowledge search agent
web_agent = Agent(
    name="Knowledge Search Agent",
    role="Handle knowledge search",
    knowledge=knowledge_base,
    model=OpenAIChat(id="gpt-5-mini"),
)

# Create team with knowledge filters
team_with_knowledge = Team(
    name="Team with Knowledge",
    members=[
        web_agent
    ],  # If you omit the member, the leader will search the knowledge base itself.
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge_base,
    show_members_responses=True,
    markdown=True,
    knowledge_filters={
        "user_id": "jordan_mitchell"
    },  # Filter to specific user's documents
)

# Test knowledge filtering
team_with_knowledge.print_response(
    "Tell me about Jordan Mitchell's work and experience"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai lancedb
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/knowledge/02_team_with_knowledge_filters.py
    ```
  </Step>
</Steps>


# Team with Agentic Memory
Source: https://docs.agno.com/examples/concepts/teams/memory/team_with_agentic_memory



This example demonstrates how to use agentic memory with a team. Unlike simple memory storage, agentic memory allows the AI to actively create, update, and delete user memories during each run based on the conversation context, providing intelligent memory management.

## Code

```python cookbook/examples/teams/memory/02_team_with_agentic_memory.py
"""
This example shows you how to use persistent memory with an Agent.

During each run the Agent can create/update/delete user memories.

To enable this, set `enable_agentic_memory=True` in the Agent config.
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager  # noqa: F401
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

john_doe_id = "john_doe@example.com"

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    enable_agentic_memory=True,
)

team.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
    stream=True,
    user_id=john_doe_id,
)

team.print_response("What are my hobbies?", stream=True, user_id=john_doe_id)

# More examples:
# agent.print_response(
#     "Remove all existing memories of me.",
#     stream=True,
#     user_id=john_doe_id,
# )

# agent.print_response(
#     "My name is John Doe and I like to paint.", stream=True, user_id=john_doe_id
# )

# agent.print_response(
#     "I don't pain anymore, i draw instead.", stream=True, user_id=john_doe_id
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up PostgreSQL database">
    ```bash
    ./cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Install required libraries">
    ```bash
    pip install agno openai 'psycopg[binary]' sqlalchemy
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/memory/02_team_with_agentic_memory.py
    ```
  </Step>
</Steps>


# Team with Memory Manager
Source: https://docs.agno.com/examples/concepts/teams/memory/team_with_memory_manager



This example demonstrates how to use persistent memory with a team. After each run, user memories are created and updated, allowing the team to remember information about users across sessions and provide personalized experiences.

## Code

```python cookbook/examples/teams/memory/01_team_with_memory_manager.py
"""
This example shows you how to use persistent memory with an Agent.

After each run, user memories are created/updated.

To enable this, set `enable_user_memories=True` in the Agent config.
"""

from uuid import uuid4

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.memory import MemoryManager  # noqa: F401
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

session_id = str(uuid4())
john_doe_id = "john_doe@example.com"

# 1. Create memories by setting `enable_user_memories=True` in the Agent
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)
team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    enable_user_memories=True,
)

team.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
    stream=True,
    user_id=john_doe_id,
    session_id=session_id,
)

team.print_response(
    "What are my hobbies?", stream=True, user_id=john_doe_id, session_id=session_id
)

# 2. Set a custom MemoryManager on the agent
# memory_manager = MemoryManager(model=OpenAIChat(id="gpt-5-mini"))

# memory_manager.clear()

# agent = Agent(
#     model=OpenAIChat(id="gpt-5-mini"),
#     memory_manager=memory_manager,
# )

# team = Team(
#     model=OpenAIChat(id="gpt-5-mini"),
#     members=[agent],
#     db=db,
#     enable_user_memories=True,
# )

# team.print_response(
#     "My name is John Doe and I like to hike in the mountains on weekends.",
#     stream=True,
#     user_id=john_doe_id,
#     session_id=session_id,
# )

# # You can also get the user memories from the agent
# memories = agent.get_user_memories(user_id=john_doe_id)
# print("John Doe's memories:")
# pprint(memories)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up PostgreSQL database">
    ```bash
    ./cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Install required libraries">
    ```bash
    pip install agno openai psycopg sqlalchemy
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/memory/01_team_with_memory_manager.py
    ```
  </Step>
</Steps>


# Team Metrics Analysis
Source: https://docs.agno.com/examples/concepts/teams/metrics/team_metrics



This example demonstrates how to access and analyze comprehensive team metrics including message-level metrics, session metrics, and member-specific performance data.

## Code

```python cookbook/examples/teams/metrics/01_team_metrics.py
"""
This example demonstrates how to access and analyze team metrics.

Shows how to retrieve detailed metrics for team execution, including
message-level metrics, session metrics, and member-specific metrics.

Prerequisites:
1. Run: cookbook/run_pgvector.sh (to start PostgreSQL)
2. Ensure PostgreSQL is running on localhost:5532
"""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.exa import ExaTools
from agno.utils.pprint import pprint_run_response
from rich.pretty import pprint

# Database configuration for metrics storage
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url, session_table="team_metrics_sessions")

# Create stock research agent
stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Create team with metrics tracking enabled
team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher],
    db=db,  # Database required for session metrics
    session_id="team_metrics_demo",
    markdown=True,
    show_members_responses=True,
    store_member_responses=True,
)

# Run the team and capture metrics
run_output = team.run("What is the stock price of NVDA")
pprint_run_response(run_output, markdown=True)

# Analyze team leader message metrics
print("=" * 50)
print("TEAM LEADER MESSAGE METRICS")
print("=" * 50)

if run_output.messages:
    for message in run_output.messages:
        if message.role == "assistant":
            if message.content:
                print(f"üìù Message: {message.content[:100]}...")
            elif message.tool_calls:
                print(f"üîß Tool calls: {message.tool_calls}")

            print("-" * 30, "Metrics", "-" * 30)
            pprint(message.metrics)
            print("-" * 70)

# Analyze aggregated team metrics
print("=" * 50)
print("AGGREGATED TEAM METRICS")
print("=" * 50)
pprint(run_output.metrics)

# Analyze session-level metrics
print("=" * 50)
print("SESSION METRICS")
print("=" * 50)
pprint(team.get_session_metrics(session_id="team_metrics_demo"))

# Analyze individual member metrics
print("=" * 50)
print("TEAM MEMBER MESSAGE METRICS")
print("=" * 50)

if run_output.member_responses:
    for member_response in run_output.member_responses:
        if member_response.messages:
            for message in member_response.messages:
                if message.role == "assistant":
                    if message.content:
                        print(f"üìù Member Message: {message.content[:100]}...")
                    elif message.tool_calls:
                        print(f"üîß Member Tool calls: {message.tool_calls}")

                    print("-" * 20, "Member Metrics", "-" * 20)
                    pprint(message.metrics)
                    print("-" * 60)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py rich
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/metrics/01_team_metrics.py
    ```
  </Step>
</Steps>


# Audio Sentiment Analysis Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/audio_sentiment_analysis



This example demonstrates how a team can collaborate to perform sentiment analysis on audio conversations using transcription and sentiment analysis agents working together.

## Code

```python cookbook/examples/teams/multimodal/audio_sentiment_analysis.py
import requests
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.media import Audio
from agno.models.google import Gemini
from agno.team import Team

transcription_agent = Agent(
    name="Audio Transcriber",
    role="Transcribe audio conversations accurately",
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Transcribe audio with speaker identification",
        "Maintain conversation structure and flow",
    ],
)

sentiment_analyst = Agent(
    name="Sentiment Analyst",
    role="Analyze emotional tone and sentiment in conversations",
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Analyze sentiment for each speaker separately",
        "Identify emotional patterns and conversation dynamics",
        "Provide detailed sentiment insights",
    ],
)

# Create a team for collaborative audio sentiment analysis
sentiment_team = Team(
    name="Audio Sentiment Team",
    members=[transcription_agent, sentiment_analyst],
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Analyze audio sentiment with conversation memory.",
        "Audio Transcriber: First transcribe audio with speaker identification.",
        "Sentiment Analyst: Analyze emotional tone and conversation dynamics.",
    ],
    add_history_to_context=True,
    markdown=True,
    db=SqliteDb(
        session_table="audio_sentiment_team_sessions",
        db_file="tmp/audio_sentiment_team.db",
    ),
)

url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

response = requests.get(url)
audio_content = response.content

sentiment_team.print_response(
    "Give a sentiment analysis of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)

sentiment_team.print_response(
    "What else can you tell me about this audio conversation?",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno requests google-generativeai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export GOOGLE_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/audio_sentiment_analysis.py
    ```
  </Step>
</Steps>


# Audio to Text Transcription Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/audio_to_text



This example demonstrates how a team can collaborate to transcribe audio content and analyze the transcribed text for insights and themes.

## Code

```python cookbook/examples/teams/multimodal/audio_to_text.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini
from agno.team import Team

transcription_specialist = Agent(
    name="Transcription Specialist",
    role="Convert audio to accurate text transcriptions",
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Transcribe audio with high accuracy",
        "Identify speakers clearly as Speaker A, Speaker B, etc.",
        "Maintain conversation flow and context",
    ],
)

content_analyzer = Agent(
    name="Content Analyzer",
    role="Analyze transcribed content for insights",
    model=Gemini(id="gemini-2.0-flash-exp"),
    instructions=[
        "Analyze transcription for key themes and insights",
        "Provide summaries and extract important information",
    ],
)

# Create a team for collaborative audio-to-text processing
audio_team = Team(
    name="Audio Analysis Team",
    model=Gemini(id="gemini-2.0-flash-exp"),
    members=[transcription_specialist, content_analyzer],
    instructions=[
        "Work together to transcribe and analyze audio content.",
        "Transcription Specialist: First convert audio to accurate text with speaker identification.",
        "Content Analyzer: Analyze transcription for insights and key themes.",
    ],
    markdown=True,
)

url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"

response = requests.get(url)
audio_content = response.content

audio_team.print_response(
    "Give a transcript of this audio conversation. Use speaker A, speaker B to identify speakers.",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno requests google-generativeai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export GOOGLE_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/audio_to_text.py
    ```
  </Step>
</Steps>


# Collaborative Image Generation Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/generate_image_with_team



This example demonstrates how a team can collaborate to generate high-quality images using a prompt engineer to optimize prompts and an image creator to generate images with DALL-E.

## Code

```python cookbook/examples/teams/multimodal/generate_image_with_team.py
from typing import Iterator

from agno.agent import Agent, RunOutputEvent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.dalle import DalleTools
from agno.utils.common import dataclass_to_dict
from rich.pretty import pprint

image_generator = Agent(
    name="Image Creator",
    role="Generate images using DALL-E",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DalleTools()],
    instructions=[
        "Use the DALL-E tool to create high-quality images",
        "Return image URLs in markdown format: `![description](URL)`",
    ],
)

prompt_engineer = Agent(
    name="Prompt Engineer",
    role="Optimize and enhance image generation prompts",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Enhance user prompts for better image generation results",
        "Consider artistic style, composition, and technical details",
    ],
)

# Create a team for collaborative image generation
image_team = Team(
    name="Image Generation Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[prompt_engineer, image_generator],
    instructions=[
        "Generate high-quality images from user prompts.",
        "Prompt Engineer: First enhance and optimize the user's prompt.",
        "Image Creator: Generate images using the enhanced prompt with DALL-E.",
    ],
    markdown=True,
)

run_stream: Iterator[RunOutputEvent] = image_team.run(
    "Create an image of a yellow siamese cat",
    stream=True,
    stream_intermediate_steps=True,
)
for chunk in run_stream:
    pprint(dataclass_to_dict(chunk, exclude={"messages"}))
    print("---" * 20)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno rich
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/generate_image_with_team.py
    ```
  </Step>
</Steps>


# AI Image Transformation Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/image_to_image_transformation



This example demonstrates how a team can collaborate to transform images using a style advisor to recommend transformations and an image transformer to apply AI-powered changes.

## Code

```python cookbook/examples/teams/multimodal/image_to_image_transformation.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.fal import FalTools

style_advisor = Agent(
    name="Style Advisor",
    role="Analyze and recommend artistic styles and transformations",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Analyze the input image and transformation request",
        "Provide style recommendations and enhancement suggestions",
        "Consider artistic elements like composition, lighting, and mood",
    ],
)

image_transformer = Agent(
    name="Image Transformer",
    role="Transform images using AI tools",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[FalTools()],
    instructions=[
        "Use the `image_to_image` tool to generate transformed images",
        "Apply the recommended styles and transformations",
        "Return the image URL as provided without markdown conversion",
    ],
)

# Create a team for collaborative image transformation
transformation_team = Team(
    name="Image Transformation Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[style_advisor, image_transformer],
    instructions=[
        "Transform images with artistic style and precision.",
        "Style Advisor: First analyze transformation requirements and recommend styles.",
        "Image Transformer: Apply transformations using AI tools with style guidance.",
    ],
    markdown=True,
)

transformation_team.print_response(
    "a cat dressed as a wizard with a background of a mystic forest. Make it look like 'https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png'",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export FAL_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/image_to_image_transformation.py
    ```
  </Step>
</Steps>


# Image to Structured Movie Script Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/image_to_structured_output



This example demonstrates how a team can collaborate to analyze images and create structured movie scripts using Pydantic models for consistent output format.

## Code

```python cookbook/examples/teams/multimodal/image_to_structured_output.py
from typing import List

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.team import Team
from pydantic import BaseModel, Field
from rich.pretty import pprint


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


image_analyst = Agent(
    name="Image Analyst",
    role="Analyze visual content and extract key elements",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Analyze images for visual elements, setting, and characters",
        "Focus on details that can inspire creative content",
    ],
)

script_writer = Agent(
    name="Script Writer",
    role="Create structured movie scripts from visual inspiration",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Transform visual analysis into compelling movie concepts",
        "Follow the structured output format precisely",
    ],
)

# Create a team for collaborative structured output generation
movie_team = Team(
    name="Movie Script Team",
    members=[image_analyst, script_writer],
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Create structured movie scripts from visual content.",
        "Image Analyst: First analyze the image for visual elements and context.",
        "Script Writer: Transform analysis into structured movie concepts.",
        "Ensure all output follows the MovieScript schema precisely.",
    ],
    output_schema=MovieScript,
)

response = movie_team.run(
    "Write a movie about this image",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

for event in response:
    pprint(event.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno pydantic rich
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/image_to_structured_output.py
    ```
  </Step>
</Steps>


# Image to Fiction Story Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/image_to_text



This example demonstrates how a team can collaborate to analyze images and create engaging fiction stories using an image analyst and creative writer.

## Code

```python cookbook/examples/teams/multimodal/image_to_text.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.team import Team

image_analyzer = Agent(
    name="Image Analyst",
    role="Analyze and describe images in detail",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Analyze images carefully and provide detailed descriptions",
        "Focus on visual elements, composition, and key details",
    ],
)

creative_writer = Agent(
    name="Creative Writer",
    role="Create engaging stories and narratives",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Transform image descriptions into compelling fiction stories",
        "Use vivid language and creative storytelling techniques",
    ],
)

# Create a team for collaborative image-to-text processing
image_team = Team(
    name="Image Story Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[image_analyzer, creative_writer],
    instructions=[
        "Work together to create compelling fiction stories from images.",
        "Image Analyst: First analyze the image for visual details and context.",
        "Creative Writer: Transform the analysis into engaging fiction narratives.",
        "Ensure the story captures the essence and mood of the image.",
    ],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")
image_team.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Add sample image">
    ```bash
    # Add a sample.jpg image file in the same directory as the script
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/image_to_text.py
    ```
  </Step>
</Steps>


# Video Caption Generation Team
Source: https://docs.agno.com/examples/concepts/teams/multimodal/video_caption_generation



This example demonstrates how a team can collaborate to process videos and generate captions by extracting audio, transcribing it, and embedding captions back into the video.

## Code

```python cookbook/examples/teams/multimodal/video_caption_generation.py
"""Please install dependencies using:
pip install openai moviepy ffmpeg
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.moviepy_video import MoviePyVideoTools
from agno.tools.openai import OpenAITools

video_processor = Agent(
    name="Video Processor",
    role="Handle video processing and audio extraction",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[MoviePyVideoTools(process_video=True, generate_captions=True)],
    instructions=[
        "Extract audio from videos for processing",
        "Handle video file operations efficiently",
    ],
)

caption_generator = Agent(
    name="Caption Generator",
    role="Generate and embed captions in videos",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[MoviePyVideoTools(embed_captions=True), OpenAITools()],
    instructions=[
        "Transcribe audio to create accurate captions",
        "Generate SRT format captions with proper timing",
        "Embed captions seamlessly into videos",
    ],
)

# Create a team for collaborative video caption generation
caption_team = Team(
    name="Video Caption Team",
    members=[video_processor, caption_generator],
    model=OpenAIChat(id="gpt-5-mini"),
    description="Team that generates and embeds captions for videos",
    instructions=[
        "Process videos to generate captions in this sequence:",
        "1. Extract audio from the video using extract_audio",
        "2. Transcribe the audio using transcribe_audio",
        "3. Generate SRT captions using create_srt",
        "4. Embed captions into the video using embed_captions",
    ],
    markdown=True,
)

caption_team.print_response(
    "Generate captions for {video with location} and embed them in the video"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno moviepy ffmpeg-python
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/multimodal/video_caption_generation.py
    ```
  </Step>
</Steps>


# Async Multi-Purpose Reasoning Team
Source: https://docs.agno.com/examples/concepts/teams/reasoning/async_multi_purpose_reasoning_team



This example demonstrates an asynchronous multi-purpose reasoning team that uses reasoning tools to analyze questions and delegate to appropriate specialist agents asynchronously, showcasing coordination and intelligent task routing.

## Code

```python cookbook/examples/teams/reasoning/02_async_multi_purpose_reasoning_team.py
"""
This example demonstrates an async multi-purpose reasoning team.

The team uses reasoning tools to analyze questions and delegate to appropriate
specialist agents asynchronously, showcasing coordination and intelligent task routing.
"""

import asyncio
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.calculator import CalculatorTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.e2b import E2BTools
from agno.tools.knowledge import KnowledgeTools
from agno.tools.pubmed import PubmedTools
from agno.tools.reasoning import ReasoningTools
from agno.tools.exa import ExaTools
from agno.vectordb.lancedb.lance_db import LanceDb
from agno.vectordb.search import SearchType

cwd = Path(__file__).parent.resolve()

# Web search agent
web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=Claude(id="claude-3-5-sonnet-latest"),
    tools=[DuckDuckGoTools(cache_results=True)],
    instructions=["Always include sources"],
)

# Financial data agent
finance_agent = Agent(
    name="Finance Agent",
    model=Claude(id="claude-3-5-sonnet-latest"),
    role="Get financial data",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
    instructions=[
        "You are a finance agent that can get financial data about stocks, companies, and the economy.",
        "Always use real-time data when possible.",
    ],
)

# Medical research agent
medical_agent = Agent(
    name="Medical Agent",
    model=Claude(id="claude-3-5-sonnet-latest"),
    role="Medical researcher",
    tools=[PubmedTools()],
    instructions=[
        "You are a medical agent that can answer questions about medical topics.",
        "Always search for recent medical literature and evidence.",
    ],
)

# Calculator agent
calculator_agent = Agent(
    name="Calculator Agent",
    model=Claude(id="claude-3-5-sonnet-latest"),
    role="Perform mathematical calculations",
    tools=[
        CalculatorTools()
    ],
    instructions=[
        "Perform accurate mathematical calculations.",
        "Show your work step by step.",
    ],
)

# Agno documentation knowledge base
agno_assist_knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_assist_knowledge",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Agno framework assistant
agno_assist = Agent(
    name="Agno Assist",
    role="Help with Agno framework questions and code",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Search your knowledge before answering. Help write working Agno code.",
    tools=[
        KnowledgeTools(
            knowledge=agno_assist_knowledge, add_instructions=True, add_few_shot=True
        ),
    ],
    add_history_to_context=True,
    add_datetime_to_context=True,
)

# Code execution agent
code_agent = Agent(
    name="Code Agent",
    model=Claude(id="claude-3-5-sonnet-latest"),
    role="Execute and test code",
    tools=[E2BTools()],
    instructions=[
        "Execute code safely in the sandbox environment.",
        "Test code thoroughly before providing results.",
        "Provide clear explanations of code execution.",
    ],
)

# Create multi-purpose reasoning team
agent_team = Team(
    name="Multi-Purpose Agent Team",
    model=Claude(id="claude-3-5-sonnet-latest"),
    tools=[ReasoningTools()],  # Enable reasoning capabilities
    members=[
        web_agent,
        finance_agent,
        medical_agent,
        calculator_agent,
        agno_assist,
        code_agent,
    ],
    instructions=[
        "You are a team of agents that can answer a variety of questions.",
        "Use reasoning tools to analyze questions before delegating.",
        "You can answer directly or forward to appropriate specialist agents.",
        "For complex questions, reason about the best approach first.",
        "If the user is just being conversational, respond directly without tools.",
    ],
    markdown=True,
    show_members_responses=True,
    share_member_interactions=True,
)


async def main():
    """Main async function to demonstrate different team capabilities."""

    # Add Agno documentation content
    await agno_assist_knowledge.add_contents_async(url="https://docs.agno.com/llms-full.txt")

    # Example interactions:

    # 1. General capability query
    await agent_team.aprint_response(input="Hi! What are you capable of doing?")

    # 2. Technical code question
    # await agent_team.aprint_response(dedent("""
    #     Create a minimal Agno Agent that searches Hacker News for articles.
    #     Test it locally and save it as './python/hacker_news_agent.py'.
    #     Use real Agno documentation, don't mock anything.
    # """), stream=True)

    # 3. Financial research
    # await agent_team.aprint_response(dedent("""
    #     What should I be investing in right now?
    #     Research current market trends and write a detailed report
    #     suitable for a financial advisor.
    # """), stream=True)

    # 4. Medical analysis (using external medical history file)
    # txt_path = Path(__file__).parent.resolve() / "medical_history.txt"
    # if txt_path.exists():
    #     loaded_txt = open(txt_path, "r").read()
    #     await agent_team.aprint_response(
    #         f"Analyze this medical information and suggest a likely diagnosis:\n{loaded_txt}",
    #         stream=True,
    #     )


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno lancedb exa_py ddgs pubmed-parser e2b
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export E2B_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/reasoning/02_async_multi_purpose_reasoning_team.py
    ```
  </Step>
</Steps>


# Multi-Purpose Reasoning Team
Source: https://docs.agno.com/examples/concepts/teams/reasoning/reasoning_multi_purpose_team



This example demonstrates a comprehensive team of specialist agents that uses reasoning tools to analyze questions and intelligently delegate tasks to appropriate members including web search, finance, writing, medical research, and code execution agents.

## Code

```python cookbook/examples/teams/reasoning/01_reasoning_multi_purpose_team.py
"""
This example demonstrates a team of agents that can answer a variety of questions.

The team uses reasoning tools to reason about the questions and delegate to the appropriate agent.

The team consists of:
- A web agent that can search the web for information
- A finance agent that can get financial data
- A writer agent that can write content
- A calculator agent that can calculate
- A FastAPI assistant that can explain how to write FastAPI code
- A code execution agent that can execute code in a secure E2B sandbox
"""

import asyncio
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.calculator import CalculatorTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.file import FileTools
from agno.tools.github import GithubTools
from agno.tools.knowledge import KnowledgeTools
from agno.tools.pubmed import PubmedTools
from agno.tools.python import PythonTools
from agno.tools.reasoning import ReasoningTools
from agno.tools.exa import ExaTools
from agno.vectordb.lancedb import LanceDb
from agno.vectordb.search import SearchType

cwd = Path(__file__).parent.resolve()

# Agent that can search the web for information
web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=Claude(id="claude-3-5-sonnet-latest"),
    tools=[DuckDuckGoTools(cache_results=True)],
    instructions=["Always include sources"],
)

reddit_researcher = Agent(
    name="Reddit Researcher",
    role="Research a topic on Reddit",
    model=Claude(id="claude-3-5-sonnet-latest"),
    tools=[DuckDuckGoTools(cache_results=True)],
    add_name_to_context=True,
    instructions=dedent("""
    You are a Reddit researcher.
    You will be given a topic to research on Reddit.
    You will need to find the most relevant information on Reddit.
    """),
)

# Agent that can get financial data
finance_agent = Agent(
    name="Finance Agent",
    role="Get financial data",
    model=Claude(id="claude-3-5-sonnet-latest"),
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
    instructions=["Use tables to display data"],
)

# Writer agent that can write content
writer_agent = Agent(
    name="Write Agent",
    role="Write content",
    model=Claude(id="claude-3-5-sonnet-latest"),
    description="You are an AI agent that can write content.",
    instructions=[
        "You are a versatile writer who can create content on any topic.",
        "When given a topic, write engaging and informative content in the requested format and style.",
        "If you receive mathematical expressions or calculations from the calculator agent, convert them into clear written text.",
        "Ensure your writing is clear, accurate and tailored to the specific request.",
        "Maintain a natural, engaging tone while being factually precise.",
        "Write something that would be good enough to be published in a newspaper like the New York Times.",
    ],
)

# Writer agent that can write content
medical_agent = Agent(
    name="Medical Agent",
    role="Write content",
    model=Claude(id="claude-3-5-sonnet-latest"),
    description="You are an AI agent that can write content.",
    tools=[PubmedTools()],
    instructions=[
        "You are a medical agent that can answer questions about medical topics.",
    ],
)

# Calculator agent that can calculate
calculator_agent = Agent(
    name="Calculator Agent",
    model=Claude(id="claude-3-5-sonnet-latest"),
    role="Calculate",
    tools=[
        CalculatorTools()
    ],
)

agno_assist_knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_assist_knowledge",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

agno_assist = Agent(
    name="Agno Assist",
    role="You help answer questions about the Agno framework.",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Search your knowledge before answering the question. Help me to write working code for Agno Agents.",
    tools=[
        KnowledgeTools(
            knowledge=agno_assist_knowledge, add_instructions=True, add_few_shot=True
        ),
    ],
    add_history_to_context=True,
    add_datetime_to_context=True,
)

github_agent = Agent(
    name="Github Agent",
    role="Do analysis on Github repositories",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Use your tools to answer questions about the repo: agno-agi/agno",
        "Do not create any issues or pull requests unless explicitly asked to do so",
    ],
    tools=[
        GithubTools(
            list_issues=True,
            list_issue_comments=True,
            get_pull_request=True,
            get_issue=True,
            get_pull_request_comments=True,
        )
    ],
)

local_python_agent = Agent(
    name="Local Python Agent",
    role="Run Python code locally",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Use your tools to run Python code locally",
    ],
    tools=[
        FileTools(base_dir=cwd),
        PythonTools(
            base_dir=Path(cwd), list_files=True, run_files=True, uv_pip_install=True
        ),
    ],
)


agent_team = Team(
    name="Multi-Purpose Team",
    model=Claude(id="claude-3-7-sonnet-latest"),
    tools=[
        ReasoningTools(add_instructions=True, add_few_shot=True),
    ],
    members=[
        web_agent,
        finance_agent,
        writer_agent,
        calculator_agent,
        agno_assist,
        github_agent,
        local_python_agent,
    ],
    instructions=[
        "You are a team of agents that can answer a variety of questions.",
        "You can use your member agents to answer the questions.",
        "You can also answer directly, you don't HAVE to forward the question to a member agent.",
        "Reason about more complex questions before delegating to a member agent.",
        "If the user is only being conversational, don't use any tools, just answer directly.",
    ],
    markdown=True,
    show_members_responses=True,
    share_member_interactions=True,
)

if __name__ == "__main__":
    # Load the knowledge base
    asyncio.run(
        agno_assist_knowledge.add_contents_async(url="https://docs.agno.com/llms-full.txt")
    )

    # asyncio.run(agent_team.aprint_response("Hi! What are you capable of doing?"))

    # Python code execution
    # asyncio.run(agent_team.aprint_response(dedent("""What is the right way to implement an Agno Agent that searches Hacker News for good articles?
    #                                        Create a minimal example for me and test it locally to ensure it won't immediately crash.
    #                                        Make save the created code in a file called `./python/hacker_news_agent.py`.
    #                                        Don't mock anything. Use the real information from the Agno documentation."""), stream=True))

    # # Reddit research
    # asyncio.run(agent_team.aprint_response(dedent("""What should I be investing in right now?
    #                                        Find some popular subreddits and do some reseach of your own.
    #                                        Write a detailed report about your findings that could be given to a financial advisor."""), stream=True))

    # Github analysis
    # asyncio.run(agent_team.aprint_response(dedent("""List open pull requests in the agno-agi/agno repository.
    #                                        Find an issue that you think you can resolve and give me the issue number,
    #                                        your suggested solution and some code snippets."""), stream=True))

    # Medical research
    txt_path = Path(__file__).parent.resolve() / "medical_history.txt"
    loaded_txt = open(txt_path, "r", encoding="utf-8").read()
    agent_team.print_response(
        input=dedent(f"""I have a patient with the following medical information:\n {loaded_txt}
                         What is the most likely diagnosis?
                        """),
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno lancedb exa_py ddgs pubmed-parser
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export GITHUB_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Create medical history file">
    ```bash
    # Create medical_history.txt with sample medical data in the same directory
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/reasoning/01_reasoning_multi_purpose_team.py
    ```
  </Step>
</Steps>


# Coordinated Agentic RAG Team
Source: https://docs.agno.com/examples/concepts/teams/search_coordination/coordinated_agentic_rag



This example demonstrates how multiple specialized agents can coordinate to provide comprehensive RAG (Retrieval-Augmented Generation) responses by dividing search and analysis tasks across team members.

## Code

```python cookbook/examples/teams/search_coordination/01_coordinated_agentic_rag.py
"""
This example demonstrates how multiple specialized agents can coordinate to provide
comprehensive RAG (Retrieval-Augmented Generation) responses by dividing search
and analysis tasks across team members.

Team Composition:
- Knowledge Searcher: Searches knowledge base for relevant information
- Content Analyzer: Analyzes and synthesizes retrieved content
- Response Synthesizer: Creates final comprehensive response with sources

Setup:
1. Run: `pip install agno anthropic cohere lancedb tantivy sqlalchemy`
2. Export your ANTHROPIC_API_KEY and CO_API_KEY
3. Run this script to see coordinated RAG in action
"""

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker.cohere import CohereReranker
from agno.models.anthropic import Claude
from agno.team.team import Team
from agno.vectordb.lancedb import LanceDb, SearchType

# Shared knowledge base for the team
knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs_team",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

# Add documentation content
knowledge.add_contents(urls=["https://docs.agno.com/introduction/agents.md"])

# Knowledge Searcher Agent - Specialized in finding relevant information
knowledge_searcher = Agent(
    name="Knowledge Searcher",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Search and retrieve relevant information from the knowledge base",
    knowledge=knowledge,
    search_knowledge=True,
    instructions=[
        "You are responsible for searching the knowledge base thoroughly.",
        "Find all relevant information for the user's query.",
        "Provide detailed search results with context and sources.",
        "Focus on comprehensive information retrieval.",
    ],
    markdown=True,
)

# Content Analyzer Agent - Specialized in analyzing retrieved content
content_analyzer = Agent(
    name="Content Analyzer",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Analyze and extract key insights from retrieved content",
    instructions=[
        "Analyze the content provided by the Knowledge Searcher.",
        "Extract key concepts, relationships, and important details.",
        "Identify gaps or areas needing additional clarification.",
        "Organize information logically for synthesis.",
    ],
    markdown=True,
)

# Response Synthesizer Agent - Specialized in creating comprehensive responses
response_synthesizer = Agent(
    name="Response Synthesizer",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Create comprehensive final response with proper citations",
    instructions=[
        "Synthesize information from team members into a comprehensive response.",
        "Include proper source citations and references.",
        "Ensure accuracy and completeness of the final answer.",
        "Structure the response clearly with appropriate formatting.",
    ],
    markdown=True,
)

# Create coordinated RAG team
coordinated_rag_team = Team(
    name="Coordinated RAG Team",
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[knowledge_searcher, content_analyzer, response_synthesizer],
    instructions=[
        "Work together to provide comprehensive responses using the knowledge base.",
        "Knowledge Searcher: First search for relevant information thoroughly.",
        "Content Analyzer: Then analyze and organize the retrieved content.",
        "Response Synthesizer: Finally create a well-structured response with sources.",
        "Ensure all responses include proper citations and are factually accurate.",
    ],
    show_members_responses=True,
    markdown=True,
)


def main():
    """Run the coordinated agentic RAG team example."""
    print("ü§ñ Coordinated Agentic RAG Team Demo")
    print("=" * 50)

    # Example query that benefits from coordinated search and analysis
    query = "What are Agents and how do they work with tools and knowledge?"

    # Run the coordinated team
    coordinated_rag_team.print_response(
        query, stream=True, stream_intermediate_steps=True
    )


if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno cohere lancedb tantivy sqlalchemy
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export ANTHROPIC_API_KEY=****
    export CO_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/search_coordination/01_coordinated_agentic_rag.py
    ```
  </Step>
</Steps>


# Coordinated Reasoning RAG Team
Source: https://docs.agno.com/examples/concepts/teams/search_coordination/coordinated_reasoning_rag



This example demonstrates how multiple specialized agents coordinate to provide comprehensive RAG responses with distributed reasoning capabilities. Each agent has specific reasoning responsibilities to ensure thorough analysis.

## Code

```python cookbook/examples/teams/search_coordination/02_coordinated_reasoning_rag.py
"""
This example demonstrates how multiple specialized agents coordinate to provide
comprehensive RAG responses with distributed reasoning capabilities. Each agent
has specific reasoning responsibilities to ensure thorough analysis.

Team Composition:
- Information Gatherer: Searches knowledge base and gathers raw information
- Reasoning Analyst: Applies logical reasoning to analyze gathered information
- Evidence Evaluator: Evaluates evidence quality and identifies gaps
- Response Coordinator: Synthesizes everything into a final reasoned response

Setup:
1. Run: `pip install agno anthropic cohere lancedb tantivy sqlalchemy`
2. Export your ANTHROPIC_API_KEY and CO_API_KEY
3. Run this script to see coordinated reasoning RAG in action
"""

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker.cohere import CohereReranker
from agno.models.anthropic import Claude
from agno.team.team import Team
from agno.tools.reasoning import ReasoningTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Shared knowledge base for the reasoning team
knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs_reasoning_team",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=CohereReranker(model="rerank-v3.5"),
    ),
)

# Information Gatherer Agent - Specialized in comprehensive information retrieval
information_gatherer = Agent(
    name="Information Gatherer",
    model=Claude(id="claude-sonnet-4-20250514"),
    role="Gather comprehensive information from knowledge sources",
    knowledge=knowledge,
    search_knowledge=True,
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Search the knowledge base thoroughly for all relevant information.",
        "Use reasoning tools to plan your search strategy.",
        "Gather comprehensive context and supporting details.",
        "Document all sources and evidence found.",
    ],
    markdown=True,
)

# Reasoning Analyst Agent - Specialized in logical analysis
reasoning_analyst = Agent(
    name="Reasoning Analyst",
    model=Claude(id="claude-sonnet-4-20250514"),
    role="Apply logical reasoning to analyze gathered information",
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Analyze information using structured reasoning approaches.",
        "Identify logical connections and relationships.",
        "Apply deductive and inductive reasoning where appropriate.",
        "Break down complex topics into logical components.",
        "Use reasoning tools to structure your analysis.",
    ],
    markdown=True,
)

# Evidence Evaluator Agent - Specialized in evidence assessment
evidence_evaluator = Agent(
    name="Evidence Evaluator",
    model=Claude(id="claude-sonnet-4-20250514"),
    role="Evaluate evidence quality and identify information gaps",
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Evaluate the quality and reliability of gathered evidence.",
        "Identify gaps in information or reasoning.",
        "Assess the strength of logical connections.",
        "Highlight areas needing additional clarification.",
        "Use reasoning tools to structure your evaluation.",
    ],
    markdown=True,
)

# Response Coordinator Agent - Specialized in synthesis and coordination
response_coordinator = Agent(
    name="Response Coordinator",
    model=Claude(id="claude-sonnet-4-20250514"),
    role="Coordinate team findings into comprehensive reasoned response",
    tools=[ReasoningTools(add_instructions=True)],
    instructions=[
        "Synthesize all team member contributions into a coherent response.",
        "Ensure logical flow and consistency across the response.",
        "Include proper citations and evidence references.",
        "Present reasoning chains clearly and transparently.",
        "Use reasoning tools to structure the final response.",
    ],
    markdown=True,
)

# Create coordinated reasoning RAG team
coordinated_reasoning_team = Team(
    name="Coordinated Reasoning RAG Team",
    model=Claude(id="claude-sonnet-4-20250514"),
    members=[
        information_gatherer,
        reasoning_analyst,
        evidence_evaluator,
        response_coordinator,
    ],
    instructions=[
        "Work together to provide comprehensive, well-reasoned responses.",
        "Information Gatherer: First search and gather all relevant information.",
        "Reasoning Analyst: Then apply structured reasoning to analyze the information.",
        "Evidence Evaluator: Evaluate the evidence quality and identify any gaps.",
        "Response Coordinator: Finally synthesize everything into a clear, reasoned response.",
        "All agents should use reasoning tools to structure their contributions.",
        "Show your reasoning process transparently in responses.",
    ],
    show_members_responses=True,
    markdown=True,
)


async def async_reasoning_demo():
    """Demonstrate async coordinated reasoning RAG with streaming."""
    print("üß† Async Coordinated Reasoning RAG Team Demo")
    print("=" * 60)

    query = "What are Agents and how do they work with tools? Explain the reasoning behind their design."

    # Add documentation content
    await knowledge.add_contents_async(urls=["https://docs.agno.com/introduction/agents.md"])

    # Run async with streaming and reasoning
    await coordinated_reasoning_team.aprint_response(
        query, stream=True, stream_intermediate_steps=True, show_full_reasoning=True
    )


def sync_reasoning_demo():
    """Demonstrate sync coordinated reasoning RAG."""
    print("üß† Coordinated Reasoning RAG Team Demo")
    print("=" * 50)

    query = "What are Agents and how do they work with tools? Explain the reasoning behind their design."

    # Add documentation content
    knowledge.add_contents(urls=["https://docs.agno.com/introduction/agents.md"])

    # Run with detailed reasoning output
    coordinated_reasoning_team.print_response(
        query, stream=True, stream_intermediate_steps=True, show_full_reasoning=True
    )


if __name__ == "__main__":
    # Choose which demo to run
    # asyncio.run(async_reasoning_demo())

    sync_reasoning_demo()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno cohere lancedb tantivy sqlalchemy
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export ANTHROPIC_API_KEY=****
    export CO_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/search_coordination/02_coordinated_reasoning_rag.py
    ```
  </Step>
</Steps>


# Distributed Search with Infinity Reranker
Source: https://docs.agno.com/examples/concepts/teams/search_coordination/distributed_infinity_search



This example demonstrates how multiple agents coordinate to perform distributed search using Infinity reranker for high-performance ranking across team members.

## Code

```python cookbook/examples/teams/search_coordination/03_distributed_infinity_search.py
"""
This example demonstrates how multiple agents coordinate to perform distributed
search using Infinity reranker for high-performance ranking across team members.

Team Composition:
- Primary Searcher: Performs initial broad search with infinity reranking
- Secondary Searcher: Performs targeted search on specific topics
- Cross-Reference Validator: Validates information across different sources
- Result Synthesizer: Combines and ranks all results for final response

Setup:
1. Install dependencies: `pip install agno anthropic infinity-client lancedb`
2. Set up Infinity Server:
   \`\`\`bash
   pip install "infinity-emb[all]"
   infinity_emb v2 --model-id BAAI/bge-reranker-base --port 7997
   \`\`\`
3. Export ANTHROPIC_API_KEY
4. Run this script
"""

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reranker.infinity import InfinityReranker
from agno.models.anthropic import Claude
from agno.team.team import Team
from agno.vectordb.lancedb import LanceDb, SearchType

# Knowledge base with Infinity reranker for high performance
knowledge_primary = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs_primary",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=InfinityReranker(
            base_url="http://localhost:7997/rerank", model="BAAI/bge-reranker-base"
        ),
    ),
)

# Secondary knowledge base for targeted search
knowledge_secondary = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_docs_secondary",
        search_type=SearchType.hybrid,
        embedder=CohereEmbedder(id="embed-v4.0"),
        reranker=InfinityReranker(
            base_url="http://localhost:7997/rerank", model="BAAI/bge-reranker-base"
        ),
    ),
)

# Primary Searcher Agent - Broad search with infinity reranking
primary_searcher = Agent(
    name="Primary Searcher",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Perform comprehensive primary search with high-performance reranking",
    knowledge=knowledge_primary,
    search_knowledge=True,
    instructions=[
        "Conduct broad, comprehensive searches across the knowledge base.",
        "Use the infinity reranker to ensure high-quality result ranking.",
        "Focus on capturing the most relevant information first.",
        "Provide detailed context and multiple perspectives on topics.",
    ],
    markdown=True,
)

# Secondary Searcher Agent - Targeted and specialized search
secondary_searcher = Agent(
    name="Secondary Searcher",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Perform targeted searches on specific topics and edge cases",
    knowledge=knowledge_secondary,
    search_knowledge=True,
    instructions=[
        "Perform targeted searches on specific aspects of the query.",
        "Look for edge cases, technical details, and specialized information.",
        "Use infinity reranking to find the most precise matches.",
        "Focus on details that complement the primary search results.",
    ],
    markdown=True,
)

# Cross-Reference Validator Agent - Validates across sources
cross_reference_validator = Agent(
    name="Cross-Reference Validator",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Validate information consistency across different search results",
    instructions=[
        "Compare and validate information from both searchers.",
        "Identify consistencies and discrepancies in the results.",
        "Highlight areas where information aligns or conflicts.",
        "Assess the reliability of different information sources.",
    ],
    markdown=True,
)

# Result Synthesizer Agent - Combines and ranks all findings
result_synthesizer = Agent(
    name="Result Synthesizer",
    model=Claude(id="claude-3-7-sonnet-latest"),
    role="Synthesize and rank all search results into comprehensive response",
    instructions=[
        "Combine results from all team members into a unified response.",
        "Rank information based on relevance and reliability.",
        "Ensure comprehensive coverage of the query topic.",
        "Present results with clear source attribution and confidence levels.",
    ],
    markdown=True,
)

# Create distributed search team
distributed_search_team = Team(
    name="Distributed Search Team with Infinity Reranker",
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[
        primary_searcher,
        secondary_searcher,
        cross_reference_validator,
        result_synthesizer,
    ],
    instructions=[
        "Work together to provide comprehensive search results using distributed processing.",
        "Primary Searcher: Conduct broad comprehensive search first.",
        "Secondary Searcher: Perform targeted specialized search.",
        "Cross-Reference Validator: Validate consistency across all results.",
        "Result Synthesizer: Combine everything into a ranked, comprehensive response.",
        "Leverage the infinity reranker for high-performance result ranking.",
        "Ensure all results are properly attributed and ranked by relevance.",
    ],
    show_members_responses=True,
    markdown=True,
)


async def async_distributed_search():
    """Demonstrate async distributed search with infinity reranking."""
    print("‚ö° Async Distributed Search with Infinity Reranker Demo")
    print("=" * 65)

    query = "How do Agents work with tools and what are the performance considerations?"

    # Add content to both knowledge bases
    await knowledge_primary.add_contents_async(
        urls=["https://docs.agno.com/introduction/agents.md"]
    )
    await knowledge_secondary.add_contents_async(
        urls=["https://docs.agno.com/introduction/agents.md"]
    )

    # Run async distributed search
    await distributed_search_team.aprint_response(
        query, stream=True, stream_intermediate_steps=True
    )


def sync_distributed_search():
    """Demonstrate sync distributed search with infinity reranking."""
    print("‚ö° Distributed Search with Infinity Reranker Demo")
    print("=" * 55)

    query = "How do Agents work with tools and what are the performance considerations?"

    # Add content to both knowledge bases
    knowledge_primary.add_contents(
        urls=["https://docs.agno.com/introduction/agents.md"]
    )
    knowledge_secondary.add_contents(
        urls=["https://docs.agno.com/introduction/agents.md"]
    )

    # Run distributed search
    distributed_search_team.print_response(
        query, stream=True, stream_intermediate_steps=True
    )


if __name__ == "__main__":
    # Choose which demo to run

    try:
        # asyncio.run(async_distributed_search())

        sync_distributed_search()
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("\nüí° Make sure Infinity server is running:")
        print("   pip install 'infinity-emb[all]'")
        print("   infinity_emb v2 --model-id BAAI/bge-reranker-base --port 7997")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno cohere lancedb "infinity-emb[all]"
    ```
  </Step>

  <Step title="Set up Infinity server">
    ```bash
    infinity_emb v2 --model-id BAAI/bge-reranker-base --port 7997
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export ANTHROPIC_API_KEY=****
    export CO_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/search_coordination/03_distributed_infinity_search.py
    ```
  </Step>
</Steps>


# Session Caching for Performance
Source: https://docs.agno.com/examples/concepts/teams/session/cache_session



This example demonstrates how to enable session caching to store team sessions in memory for faster access and improved performance.

## Code

```python cookbook/examples/teams/session/08_cache_session.py
"""Example of how to cache the team session in memory for faster access."""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    name="Research Assistant",
)

# Setup the team
team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    session_id="team_session_cache",
    add_history_to_context=True,
    # Activate session caching. The session will be cached in memory for faster access.
    cache_session=True,
)

team.print_response("Tell me a new interesting fact about space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/08_cache_session.py
    ```
  </Step>
</Steps>


# Chat History Retrieval
Source: https://docs.agno.com/examples/concepts/teams/session/chat_history



This example demonstrates how to retrieve and display chat history from team sessions for conversation tracking and analysis.

## Code

```python cookbook/examples/teams/session/05_chat_history.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
)

team.print_response("Tell me a new interesting fact about space")
print(team.get_chat_history())

team.print_response("Tell me a new interesting fact about oceans")
print(team.get_chat_history())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/05_chat_history.py
    ```
  </Step>
</Steps>


# In-Memory Database Session
Source: https://docs.agno.com/examples/concepts/teams/session/in_memory_db



This example shows how to use an in-memory database with teams for storing sessions, user memories, etc. without setting up a persistent database - useful for development and testing.

## Code

```python cookbook/examples/teams/session/07_in_memory_db.py
"""This example shows how to use an in-memory database with teams.

With this you will be able to store team sessions, user memories, etc. without setting up a database.
Keep in mind that in production setups it is recommended to use a database.
"""

from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from rich.pretty import pprint

# Setup the in-memory database
db = InMemoryDb()

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    name="Research Assistant",
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    # Set add_history_to_context=true to add the previous chat history to the context sent to the Model.
    add_history_to_context=True,
    # Number of historical responses to add to the messages.
    num_history_runs=3,
    session_id="test_session",
)

# -*- Create a run
team.print_response("Share a 2 sentence horror story", stream=True)

# -*- Print the messages in the memory
print("\n" + "=" * 50)
print("CHAT HISTORY AFTER FIRST RUN")
print("=" * 50)
try:
    chat_history = team.get_chat_history(session_id="test_session")
    pprint([m.model_dump(include={"role", "content"}) for m in chat_history])
except Exception as e:
    print(f"Error getting chat history: {e}")
    print("This might be expected on first run with in-memory database")

# -*- Ask a follow up question that continues the conversation
team.print_response("What was my first message?", stream=True)

# -*- Print the messages in the memory
print("\n" + "=" * 50)
print("CHAT HISTORY AFTER SECOND RUN")
print("=" * 50)
try:
    chat_history = team.get_chat_history(session_id="test_session")
    pprint([m.model_dump(include={"role", "content"}) for m in chat_history])
except Exception as e:
    print(f"Error getting chat history: {e}")
    print("This indicates an issue with in-memory database session handling")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno rich
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/07_in_memory_db.py
    ```
  </Step>
</Steps>


# Persistent Session with Database
Source: https://docs.agno.com/examples/concepts/teams/session/persistent_session



This example demonstrates how to use persistent session storage with a PostgreSQL database to maintain team conversations across multiple runs.

## Code

```python cookbook/examples/teams/session/01_persistent_session.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
)

team.print_response("Tell me a new interesting fact about space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/01_persistent_session.py
    ```
  </Step>
</Steps>


# Persistent Session with History Context
Source: https://docs.agno.com/examples/concepts/teams/session/persistent_session_history



This example shows how to use the session history to store conversation history and add it to the context with configurable history limits.

## Code

```python cookbook/examples/teams/session/02_persistent_session_history.py
"""
This example shows how to use the session history to store the conversation history.
add_history_to_context flag is used to add the history to the messages.
num_history_runs is used to set the number of history runs to add to the messages.
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(model=OpenAIChat(id="gpt-5-mini"))

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    add_history_to_context=True,
    num_history_runs=2,
)

team.print_response("Tell me a new interesting fact about space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/02_persistent_session_history.py
    ```
  </Step>
</Steps>


# Session Name Management
Source: https://docs.agno.com/examples/concepts/teams/session/rename_session



This example demonstrates how to set custom session names or automatically generate meaningful names for better session organization and identification.

## Code

```python cookbook/examples/teams/session/06_rename_session.py
from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
)

team.print_response("Tell me a new interesting fact about space")
team.set_session_name(session_name="Interesting Space Facts")
print(team.get_session_name())

# Autogenerate session name
team.set_session_name(autogenerate=True)
print(team.get_session_name())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/06_rename_session.py
    ```
  </Step>
</Steps>


# Session Summary Management
Source: https://docs.agno.com/examples/concepts/teams/session/session_summary



This example shows how to use session summary to store and maintain conversation summaries for better context management over long conversations.

## Code

```python cookbook/examples/teams/session/03_session_summary.py
"""
This example shows how to use the session summary to store the conversation summary.
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.session.summary import SessionSummaryManager  # noqa: F401
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

# Method 1: Set enable_session_summaries to True

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    enable_session_summaries=True,
)

team.print_response("Hi my name is John and I live in New York")
team.print_response("I like to play basketball and hike in the mountains")

# Method 2: Set session_summary_manager

# session_summary_manager = SessionSummaryManager(model=OpenAIChat(id="gpt-5-mini"))

# agent = Agent(
#     model=OpenAIChat(id="gpt-5-mini"),
# )

# team = Team(
#     model=OpenAIChat(id="gpt-5-mini"),
#     members=[agent],
#     db=db,
#     session_summary_manager=session_summary_manager,
# )

# team.print_response("Hi my name is John and I live in New York")
# team.print_response("I like to play basketball and hike in the mountains")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/03_session_summary.py
    ```
  </Step>
</Steps>


# Session Summary with Context References
Source: https://docs.agno.com/examples/concepts/teams/session/session_summary_references



This example shows how to use the `add_session_summary_to_context` parameter to add session summaries to team context for maintaining conversation continuity.

## Code

```python cookbook/examples/teams/session/04_session_summary_references.py
"""
This example shows how to use the `add_session_summary_to_context` parameter in the Team config to
add session summaries to the Team context.

Start the postgres db locally on Docker by running: cookbook/scripts/run_pgvector.sh
"""

from agno.agent.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

db = PostgresDb(db_url=db_url, session_table="sessions")

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[agent],
    db=db,
    enable_session_summaries=True,
)

# This will create a new session summary
team.print_response(
    "My name is John Doe and I like to hike in the mountains on weekends.",
)

# You can use existing session summaries from session storage without creating or updating any new ones.
team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    session_id="session_summary",
    add_session_summary_to_context=True,
    members=[agent],
)

team.print_response("I also like to play basketball.")

# Alternatively, you can create a new session summary without adding the session summary to context.

# team = Team(
#     model=OpenAIChat(id="gpt-5-mini"),
#     db=db,
#     session_id="session_summary",
#     enable_session_summaries=True,
#     add_session_summary_to_context=False,
# )

# team.print_response("I also like to play basketball.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno psycopg2-binary
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Start PostgreSQL database">
    ```bash
    cookbook/run_pgvector.sh
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/session/04_session_summary_references.py
    ```
  </Step>
</Steps>


# Agentic Session State
Source: https://docs.agno.com/examples/concepts/teams/state/agentic_session_state



This example demonstrates how to enable agentic session state in teams and agents, allowing them to automatically manage and update their session state during interactions. The agents can modify the session state autonomously based on the conversation context.

## Code

```python cookbook/examples/teams/state/agentic_session_state.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team.team import Team

db = SqliteDb(db_file="tmp/agents.db")
shopping_agent = Agent(
    name="Shopping List Agent",
    role="Manage the shopping list",
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    add_session_state_to_context=True,  # Required so the agent is aware of the session state
    enable_agentic_state=True,
)

team = Team(
    members=[shopping_agent],
    session_state={"shopping_list": []},
    db=db,
    add_session_state_to_context=True,  # Required so the team is aware of the session state
    enable_agentic_state=True,
    description="You are a team that manages a shopping list and chores",
    show_members_responses=True,
)


team.print_response("Add milk, eggs, and bread to the shopping list")

team.print_response("I picked up the eggs, now what's on my list?")

print(f"Session state: {team.get_session_state()}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/state/agentic_session_state.py
    ```
  </Step>
</Steps>


# Change Session State on Run
Source: https://docs.agno.com/examples/concepts/teams/state/change_state_on_run



This example demonstrates how to set and manage session state for different users and sessions. It shows how session state can be passed during runs and persists across multiple interactions within the same session.

## Code

```python cookbook/examples/teams/state/change_state_on_run.py
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIChat
from agno.team import Team

team = Team(
    db=InMemoryDb(),
    model=OpenAIChat(id="gpt-5-mini"),
    members=[],
    instructions="Users name is {user_name} and age is {age}",
)

# Sets the session state for the session with the id "user_1_session_1"
team.print_response(
    "What is my name?",
    session_id="user_1_session_1",
    user_id="user_1",
    session_state={"user_name": "John", "age": 30},
)

# Will load the session state from the session with the id "user_1_session_1"
team.print_response("How old am I?", session_id="user_1_session_1", user_id="user_1")

# Sets the session state for the session with the id "user_2_session_1"
team.print_response(
    "What is my name?",
    session_id="user_2_session_1",
    user_id="user_2",
    session_state={"user_name": "Jane", "age": 25},
)

# Will load the session state from the session with the id "user_2_session_1"
team.print_response("How old am I?", session_id="user_2_session_1", user_id="user_2")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/state/change_state_on_run.py
    ```
  </Step>
</Steps>


# Session State in Instructions
Source: https://docs.agno.com/examples/concepts/teams/state/session_state_in_instructions



This example demonstrates how to use session state variables directly in team instructions using template syntax. The session state values are automatically injected into the instructions, making them available to the team during execution.

## Code

```python cookbook/examples/teams/state/session_state_in_instructions.py
from agno.team.team import Team

team = Team(
    members=[],
    # Initialize the session state with a variable
    session_state={"user_name": "John"},
    instructions="Users name is {user_name}",
    markdown=True,
)

team.print_response("What is my name?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/state/session_state_in_instructions.py
    ```
  </Step>
</Steps>


# Share Member Interactions
Source: https://docs.agno.com/examples/concepts/teams/state/share_member_interactions



This example demonstrates how to enable sharing of member interactions within a team. When `share_member_interactions` is set to True, team members can see and build upon each other's responses, creating a collaborative workflow.

## Code

```python cookbook/examples/teams/state/share_member_interactions.py
from agno.agent.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

db = SqliteDb(db_file="tmp/agents.db")

web_research_agent = Agent(
    name="Web Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="You are a web research agent that can answer questions from the web.",
)

report_agent = Agent(
    name="Report Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a report agent that can write a report from the web research.",
)

team = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    members=[web_research_agent, report_agent],
    share_member_interactions=True,
    instructions=[
        "You are a team of agents that can research the web and write a report.",
        "First, research the web for information about the topic.",
        "Then, use your report agent to write a report from the web research.",
    ],
    show_members_responses=True,
    debug_mode=True,
)

team.print_response("How are LEDs made?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/state/share_member_interactions.py
    ```
  </Step>
</Steps>


# Team with Nested Shared State
Source: https://docs.agno.com/examples/concepts/teams/state/team_with_nested_shared_state



This example demonstrates a hierarchical team structure with nested shared state management for complex multi-agent coordination in a shopping list and meal planning system.

## Code

```python cookbook/examples/teams/state/team_with_nested_shared_state.py
"""
This example demonstrates the nested Team functionality in a hierarchical team structure.
Each team and agent has a clearly defined role that guides their behavior and specialization:

Team Hierarchy & Roles:
‚îú‚îÄ‚îÄ Shopping List Team (Orchestrator)
‚îÇ   Role: "Orchestrate comprehensive shopping list management and meal planning"
‚îÇ   ‚îú‚îÄ‚îÄ Shopping Management Team (Operations Specialist)
‚îÇ   ‚îÇ   Role: "Execute precise shopping list operations through delegation"
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Shopping List Agent
‚îÇ   ‚îÇ       Role: "Maintain and modify the shopping list with precision and accuracy"
‚îÇ   ‚îî‚îÄ‚îÄ Meal Planning Team (Culinary Expert)
‚îÇ       Role: "Transform shopping list ingredients into creative meal suggestions"
‚îÇ       ‚îî‚îÄ‚îÄ Recipe Suggester Agent
‚îÇ           Role: "Create innovative and practical recipe suggestions"

"""

from agno.agent.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team

db = SqliteDb(db_file="tmp/example.db")


# Define tools to manage our shopping list
def add_item(session_state, item: str) -> str:
    """Add an item to the shopping list and return confirmation.

    Args:
        item (str): The item to add to the shopping list.
    """
    # Add the item if it's not already in the list
    if item.lower() not in [i.lower() for i in session_state["shopping_list"]]:
        session_state["shopping_list"].append(item)
        return f"Added '{item}' to the shopping list"
    else:
        return f"'{item}' is already in the shopping list"


def remove_item(session_state, item: str) -> str:
    """Remove an item from the shopping list by name.

    Args:
        item (str): The item to remove from the shopping list.
    """
    # Case-insensitive search
    for i, list_item in enumerate(session_state["shopping_list"]):
        if list_item.lower() == item.lower():
            session_state["shopping_list"].pop(i)
            return f"Removed '{list_item}' from the shopping list"

    return f"'{item}' was not found in the shopping list. Current shopping list: {session_state['shopping_list']}"


def remove_all_items(session_state) -> str:
    """Remove all items from the shopping list."""
    session_state["shopping_list"] = []
    return "All items removed from the shopping list"


shopping_list_agent = Agent(
    name="Shopping List Agent",
    role="Manage the shopping list",
    id="shopping_list_manager",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[add_item, remove_item, remove_all_items],
    instructions=[
        "Manage the shopping list by adding and removing items",
        "Always confirm when items are added or removed",
        "If the task is done, update the session state to log the changes & chores you've performed",
    ],
)


# Shopping management team - new layer for handling all shopping list modifications
shopping_mgmt_team = Team(
    name="Shopping Management Team",
    role="Execute shopping list operations",
    id="shopping_management",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[shopping_list_agent],
    instructions=[
        "Manage adding and removing items from the shopping list using the Shopping List Agent",
        "Forward requests to add or remove items to the Shopping List Agent",
    ],
)


def get_ingredients(session_state) -> str:
    """Retrieve ingredients from the shopping list to use for recipe suggestions."""
    shopping_list = session_state["shopping_list"]

    if not shopping_list:
        return "The shopping list is empty. Add some ingredients first to get recipe suggestions."

    # Just return the ingredients - the agent will create recipes
    return f"Available ingredients from shopping list: {', '.join(shopping_list)}"


recipe_agent = Agent(
    name="Recipe Suggester",
    id="recipe_suggester",
    role="Suggest recipes based on available ingredients",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[get_ingredients],
    instructions=[
        "First, use the get_ingredients tool to get the current ingredients from the shopping list",
        "After getting the ingredients, create detailed recipe suggestions based on those ingredients",
        "Create at least 3 different recipe ideas using the available ingredients",
        "For each recipe, include: name, ingredients needed (highlighting which ones are from the shopping list), and brief preparation steps",
        "Be creative but practical with recipe suggestions",
        "Consider common pantry items that people usually have available in addition to shopping list items",
        "Consider dietary preferences if mentioned by the user",
        "If no meal type is specified, suggest a variety of options (breakfast, lunch, dinner, snacks)",
    ],
)


def list_items(session_state) -> str:
    """List all items in the shopping list."""
    shopping_list = session_state["shopping_list"]

    if not shopping_list:
        return "The shopping list is empty."

    items_text = "\n".join([f"- {item}" for item in shopping_list])
    return f"Current shopping list:\n{items_text}"


# Create meal planning subteam
meal_planning_team = Team(
    name="Meal Planning Team",
    role="Plan meals based on shopping list items",
    id="meal_planning",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[recipe_agent],
    instructions=[
        "You are a meal planning team that suggests recipes based on shopping list items.",
        "IMPORTANT: When users ask 'What can I make with these ingredients?' or any recipe-related questions, IMMEDIATELY forward the EXACT SAME request to the recipe_agent WITHOUT asking for further information.",
        "DO NOT ask the user for ingredients - the recipe_agent will work with what's already in the shopping list.",
        "Your primary job is to forward recipe requests directly to the recipe_agent without modification.",
    ],
)


def add_chore(session_state, chore: str, priority: str = "medium") -> str:
    """Add a chore to the list with priority level.

    Args:
        chore (str): The chore to add to the list
        priority (str): Priority level of the chore (low, medium, high)

    Returns:
        str: Confirmation message
    """
    # Initialize chores list if it doesn't exist
    if "chores" not in session_state:
        session_state["chores"] = []

    # Validate priority
    valid_priorities = ["low", "medium", "high"]
    if priority.lower() not in valid_priorities:
        priority = "medium"  # Default to medium if invalid

    # Add the chore with timestamp and priority
    from datetime import datetime

    chore_entry = {
        "description": chore,
        "priority": priority.lower(),
        "added_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
    }

    session_state["chores"].append(chore_entry)

    return f"Added chore: '{chore}' with {priority} priority"


# Orchestrates the entire shopping and meal planning ecosystem
shopping_team = Team(
    id="shopping_list_team",
    name="Shopping List Team",
    role="Orchestrate shopping list management and meal planning",
    model=OpenAIChat(id="gpt-5-mini"),
    session_state={"shopping_list": [], "chores": []},
    tools=[list_items, add_chore],
    db=db,
    members=[
        shopping_mgmt_team,
        meal_planning_team,
    ],
    markdown=True,
    instructions=[
        "You are the orchestration layer for a comprehensive shopping and meal planning ecosystem",
        "If you need to add or remove items from the shopping list, forward the full request to the Shopping Management Team",
        "IMPORTANT: If the user asks about recipes or what they can make with ingredients, IMMEDIATELY forward the EXACT request to the meal_planning_team with NO additional questions",
        "Example: When user asks 'What can I make with these ingredients?', you should simply forward this exact request to meal_planning_team without asking for more information",
        "If you need to list the items in the shopping list, use the list_items tool",
        "If the user got something from the shopping list, it means it can be removed from the shopping list",
        "After each completed task, use the add_chore tool to log exactly what was done with high priority",
        "Provide a seamless experience by leveraging your specialized teams for their expertise",
    ],
    show_members_responses=True,
)

# =============================================================================
# DEMONSTRATION
# =============================================================================

# Example 1: Adding items (demonstrates role-based delegation)
print("Example 1: Adding Items to Shopping List")
print("-" * 50)
shopping_team.print_response(
    "Add milk, eggs, and bread to the shopping list", stream=True
)
print(f"Session state: {shopping_team.get_session_state()}")
print()

# Example 2: Item consumption and removal
print("Example 2: Item Consumption & Removal")
print("-" * 50)
shopping_team.print_response("I got bread from the store", stream=True)
print(f"Session state: {shopping_team.get_session_state()}")
print()

# Example 3: Adding more ingredients
print("Example 3: Adding Fresh Ingredients")
print("-" * 50)
shopping_team.print_response(
    "I need apples and oranges for my fruit salad", stream=True
)
print(f"Session state: {shopping_team.get_session_state()}")
print()

# Example 4: Listing current items
print("Example 4: Viewing Current Shopping List")
print("-" * 50)
shopping_team.print_response("What's on my shopping list right now?", stream=True)
print(f"Session state: {shopping_team.get_session_state()}")
print()

# Example 5: Recipe suggestions (demonstrates culinary expertise role)
print("Example 5: Recipe Suggestions from Culinary Team")
print("-" * 50)
shopping_team.print_response("What can I make with these ingredients?", stream=True)
print(f"Session state: {shopping_team.get_session_state()}")
print()

# Example 6: Complete list management
print("Example 6: Complete List Reset & Restart")
print("-" * 50)
shopping_team.print_response(
    "Clear everything from my list and start over with just bananas and yogurt",
    stream=True,
)
print(f"Shared Session state: {shopping_team.get_session_state()}")
print()

# Example 7: Quick recipe check with new ingredients
print("Example 7: Quick Recipe Check with New Ingredients")
print("-" * 50)
shopping_team.print_response("What healthy breakfast can I make now?", stream=True)
print()

print(f"Team Session State: {shopping_team.get_session_state()}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/state/team_with_nested_shared_state.py
    ```
  </Step>
</Steps>


# Async Team Events Monitoring
Source: https://docs.agno.com/examples/concepts/teams/streaming/async_team_events



This example demonstrates how to handle and monitor team events asynchronously, capturing various events during async team execution including tool calls, run states, and content generation.

## Code

```python cookbook/examples/teams/streaming/05_async_team_events.py
"""
This example demonstrates how to handle and monitor team events asynchronously.

Shows how to capture and respond to various events during async team execution,
including tool calls, run states, and content generation events.
"""

import asyncio
from uuid import uuid4

from agno.agent import RunEvent
from agno.agent.agent import Agent
from agno.models.anthropic.claude import Claude
from agno.models.openai import OpenAIChat
from agno.team.team import Team, TeamRunEvent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools

# Hacker News search agent
hacker_news_agent = Agent(
    id="hacker-news-agent",
    name="Hacker News Agent",
    role="Search Hacker News for information",
    tools=[HackerNewsTools()],
    instructions=[
        "Find articles about the company in the Hacker News",
    ],
)

# Web search agent
website_agent = Agent(
    id="website-agent",
    name="Website Agent",
    role="Search the website for information",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=[
        "Search the website for information",
    ],
)

# Generate unique IDs
user_id = str(uuid4())
id = str(uuid4())

# Create team with event monitoring
company_info_team = Team(
    name="Company Info Team",
    id=id,
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[
        hacker_news_agent,
        website_agent,
    ],
    markdown=True,
    instructions=[
        "You are a team that finds information about a company.",
        "First search the web and Hacker News for information about the company.",
        "If you can find the company's website URL, then scrape the homepage and the about page.",
    ],
    show_members_responses=True,
)


async def run_team_with_events(prompt: str):
    """
    Run the team and capture all events for monitoring and debugging.

    This function demonstrates how to handle different types of events:
    - Team-level events (run start/completion, tool calls)
    - Member-level events (agent tool calls)
    - Content generation events
    """
    content_started = False

    async for run_response_event in company_info_team.arun(
        prompt,
        stream=True,
        stream_intermediate_steps=True,
    ):
        # Handle team-level events
        if run_response_event.event in [
            TeamRunEvent.run_started,
            TeamRunEvent.run_completed,
        ]:
            print(f"\nüéØ TEAM EVENT: {run_response_event.event}")

        # Handle team tool call events
        if run_response_event.event in [TeamRunEvent.tool_call_started]:
            print(f"\nüîß TEAM TOOL STARTED: {run_response_event.tool.tool_name}")
            print(f"   Args: {run_response_event.tool.tool_args}")

        if run_response_event.event in [TeamRunEvent.tool_call_completed]:
            print(f"\n‚úÖ TEAM TOOL COMPLETED: {run_response_event.tool.tool_name}")
            print(f"   Result: {run_response_event.tool.result}")

        # Handle member-level events
        if run_response_event.event in [RunEvent.tool_call_started]:
            print(f"\nü§ñ MEMBER TOOL STARTED: {run_response_event.agent_id}")
            print(f"   Tool: {run_response_event.tool.tool_name}")
            print(f"   Args: {run_response_event.tool.tool_args}")

        if run_response_event.event in [RunEvent.tool_call_completed]:
            print(f"\n‚úÖ MEMBER TOOL COMPLETED: {run_response_event.agent_id}")
            print(f"   Tool: {run_response_event.tool.tool_name}")
            print(
                f"   Result: {run_response_event.tool.result[:100]}..."
            )  # Truncate for readability

        # Handle content generation
        if run_response_event.event in [TeamRunEvent.run_content]:
            if not content_started:
                print("\nüìù CONTENT:")
                content_started = True
            else:
                print(run_response_event.content, end="")


if __name__ == "__main__":
    asyncio.run(
        run_team_with_events(
            "Write me a full report on everything you can find about Agno, the company building AI agent infrastructure.",
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export ANTHROPIC_API_KEY=****
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/streaming/05_async_team_events.py
    ```
  </Step>
</Steps>


# Async Team Streaming
Source: https://docs.agno.com/examples/concepts/teams/streaming/async_team_streaming



This example demonstrates asynchronous streaming responses from a team using specialized agents with financial tools to provide real-time stock information with async streaming output.

## Code

```python cookbook/examples/teams/streaming/04_async_team_streaming.py
"""
This example demonstrates asynchronous streaming responses from a team.

The team uses specialized agents with financial tools to provide real-time
stock information with async streaming output.
"""

import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.exa import ExaTools
from agno.utils.pprint import apprint_run_response

# Stock price and analyst data agent
stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Company information agent
company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a company.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Create team with async streaming capabilities
team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    markdown=True,
    show_members_responses=True,
)


async def streaming_with_arun():
    """Demonstrate async streaming using arun() method."""
    await apprint_run_response(
        team.arun(input="What is the current stock price of NVDA?", stream=True)
    )


async def streaming_with_aprint_response():
    """Demonstrate async streaming using aprint_response() method."""
    await team.aprint_response("What is the current stock price of NVDA?", stream=True)


if __name__ == "__main__":
    asyncio.run(streaming_with_arun())

    # asyncio.run(streaming_with_aprint_response())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/streaming/04_async_team_streaming.py
    ```
  </Step>
</Steps>


# Team Events Monitoring
Source: https://docs.agno.com/examples/concepts/teams/streaming/events



This example demonstrates how to monitor and handle different types of events during team execution, including tool calls, run states, and content generation events.

## Code

```python cookbook/examples/teams/streaming/02_events.py
import asyncio
from uuid import uuid4

from agno.agent import RunEvent
from agno.agent.agent import Agent
from agno.models.anthropic.claude import Claude

# from agno.models.mistral.mistral import MistralChat
from agno.models.openai import OpenAIChat
from agno.team import Team, TeamRunEvent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools

wikipedia_agent = Agent(
    id="hacker-news-agent",
    name="Hacker News Agent",
    role="Search Hacker News for information",
    # model=MistralChat(id="mistral-large-latest"),
    tools=[HackerNewsTools()],
    instructions=[
        "Find articles about the company in the Hacker News",
    ],
)

website_agent = Agent(
    id="website-agent",
    name="Website Agent",
    role="Search the website for information",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=[
        "Search the website for information",
    ],
)

user_id = str(uuid4())
id = str(uuid4())

company_info_team = Team(
    name="Company Info Team",
    id=id,
    user_id=user_id,
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[
        wikipedia_agent,
        website_agent,
    ],
    markdown=True,
    instructions=[
        "You are a team that finds information about a company.",
        "First search the web and wikipedia for information about the company.",
        "If you can find the company's website URL, then scrape the homepage and the about page.",
    ],
    show_members_responses=True,
)


async def run_team_with_events(prompt: str):
    content_started = False
    async for run_output_event in company_info_team.arun(
        prompt,
        stream=True,
        stream_intermediate_steps=True,
    ):
        if run_output_event.event in [
            TeamRunEvent.run_started,
            TeamRunEvent.run_completed,
        ]:
            print(f"\nTEAM EVENT: {run_output_event.event}")

        if run_output_event.event in [TeamRunEvent.tool_call_started]:
            print(f"\nTEAM EVENT: {run_output_event.event}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TOOL CALL ARGS: {run_output_event.tool.tool_args}")

        if run_output_event.event in [TeamRunEvent.tool_call_completed]:
            print(f"\nTEAM EVENT: {run_output_event.event}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TOOL CALL RESULT: {run_output_event.tool.result}")

        # Member events
        if run_output_event.event in [RunEvent.tool_call_started]:
            print(f"\nMEMBER EVENT: {run_output_event.event}")
            print(f"AGENT ID: {run_output_event.agent_id}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TOOL CALL ARGS: {run_output_event.tool.tool_args}")

        if run_output_event.event in [RunEvent.tool_call_completed]:
            print(f"\nMEMBER EVENT: {run_output_event.event}")
            print(f"AGENT ID: {run_output_event.agent_id}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TOOL CALL RESULT: {run_output_event.tool.result}")

        if run_output_event.event in [TeamRunEvent.run_content]:
            if not content_started:
                print("CONTENT")
                content_started = True
            else:
                print(run_output_event.content, end="")


if __name__ == "__main__":
    asyncio.run(
        run_team_with_events(
            "Write me a full report on everything you can find about Agno, the company building AI agent infrastructure.",
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export ANTHROPIC_API_KEY=****
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/streaming/02_events.py
    ```
  </Step>
</Steps>


# Route Mode Team Events
Source: https://docs.agno.com/examples/concepts/teams/streaming/route_mode_events



This example demonstrates event handling in route mode teams, showing how to capture team and member events separately with detailed tool call information.

## Code

```python cookbook/examples/teams/streaming/03_route_mode_events.py
import asyncio

from agno.agent import RunEvent
from agno.agent.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team, TeamRunEvent
from agno.tools.exa import ExaTools

stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    markdown=True,
    # If you want to disable the member events, set this to False (default is True)
    # stream_member_events=False
)


async def run_team_with_events(prompt: str):
    content_started = False
    member_content_started = False
    async for run_output_event in team.arun(
        prompt,
        stream=True,
        stream_intermediate_steps=True,
    ):
        if run_output_event.event in [
            TeamRunEvent.run_started,
            TeamRunEvent.run_completed,
        ]:
            print(f"\nTEAM EVENT: {run_output_event.event}")
        if run_output_event.event in [
            RunEvent.run_started,
            RunEvent.run_completed,
        ]:
            print(f"\nMEMBER RUN EVENT: {run_output_event.event}")

        if run_output_event.event in [TeamRunEvent.tool_call_started]:
            print(f"\nTEAM EVENT: {run_output_event.event}")
            print(f"TEAM TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TEAM TOOL CALL ARGS: {run_output_event.tool.tool_args}")

        if run_output_event.event in [TeamRunEvent.tool_call_completed]:
            print(f"\nTEAM EVENT: {run_output_event.event}")
            print(f"TEAM TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TEAM TOOL CALL RESULT: {run_output_event.tool.result}")

        # Member events
        if run_output_event.event in [RunEvent.tool_call_started]:
            print(f"\nMEMBER EVENT: {run_output_event.event}")
            print(f"TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"TOOL CALL ARGS: {run_output_event.tool.tool_args}")

        if run_output_event.event in [RunEvent.tool_call_completed]:
            print(f"\nMEMBER EVENT: {run_output_event.event}")
            print(f"MEMBER TOOL CALL: {run_output_event.tool.tool_name}")
            print(f"MEMBER TOOL CALL RESULT: {run_output_event.tool.result}")

        if run_output_event.event in [TeamRunEvent.run_content]:
            if not content_started:
                print("TEAM CONTENT:")
                content_started = True
            print(run_output_event.content, end="")

        if run_output_event.event in [RunEvent.run_content]:
            if not member_content_started:
                print("MEMBER CONTENT:")
                member_content_started = True
            print(run_output_event.content, end="")


if __name__ == "__main__":
    asyncio.run(
        run_team_with_events(
            "What is the current stock price of NVDA?",
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/streaming/03_route_mode_events.py
    ```
  </Step>
</Steps>


# Team Streaming Responses
Source: https://docs.agno.com/examples/concepts/teams/streaming/team_streaming



This example demonstrates streaming responses from a team using specialized agents with financial tools to provide real-time stock information with streaming output.

## Code

```python cookbook/examples/teams/streaming/01_team_streaming.py
"""
This example demonstrates streaming responses from a team.

The team uses specialized agents with financial tools to provide real-time
stock information with streaming output.
"""

from typing import Iterator  # noqa
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.exa import ExaTools

# Stock price and analyst data agent
stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Company information agent
company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Create team with streaming capabilities
team = Team(
    name="Stock Research Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    markdown=True,
    show_members_responses=True,
)

# Test streaming response
team.print_response(
    "What is the current stock price of NVDA?",
    stream=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/streaming/01_team_streaming.py
    ```
  </Step>
</Steps>


# Async Structured Output Streaming
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/async_structured_output_streaming



This example demonstrates async structured output streaming from a team using Pydantic models to ensure structured responses while streaming, providing both real-time output and validated data structures asynchronously.

## Code

```python cookbook/examples/teams/structured_input_output/05_async_structured_output_streaming.py
"""
This example demonstrates async structured output streaming from a team.

The team uses Pydantic models to ensure structured responses while streaming,
providing both real-time output and validated data structures asynchronously.
"""

import asyncio
from typing import Iterator  # noqa

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.exa import ExaTools
from agno.utils.pprint import apprint_run_response
from pydantic import BaseModel


class StockAnalysis(BaseModel):
    """Stock analysis data structure."""

    symbol: str
    company_name: str
    analysis: str


class CompanyAnalysis(BaseModel):
    """Company analysis data structure."""

    company_name: str
    analysis: str


class StockReport(BaseModel):
    """Final stock report data structure."""

    symbol: str
    company_name: str
    analysis: str


# Stock price and analyst data agent with structured output
stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    output_schema=StockAnalysis,
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Company information agent with structured output
company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    output_schema=CompanyAnalysis,
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
)

# Create team with structured output streaming
team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    output_schema=StockReport,
    markdown=True,
    show_members_responses=True,
)


async def test_structured_streaming():
    """Test async structured output streaming."""
    # Run with streaming and consume the async generator to get the final response
    async_stream = team.arun(
        "Give me a stock report for NVDA", stream=True, stream_intermediate_steps=True
    )

    # Consume the async streaming events and get the final response
    run_response = None
    async for event_or_response in async_stream:
        # The last item in the stream is the final TeamRunOutput
        run_response = event_or_response

    assert isinstance(run_response.content, StockReport)
    print(f"‚úÖ Stock Symbol: {run_response.content.symbol}")
    print(f"‚úÖ Company Name: {run_response.content.company_name}")


async def test_structured_streaming_with_arun():
    """Test async structured output streaming using arun() method."""
    await apprint_run_response(
        team.arun(
            input="Give me a stock report for AAPL",
            stream=True,
            stream_intermediate_steps=True,
        )
    )


if __name__ == "__main__":
    asyncio.run(test_structured_streaming())

    asyncio.run(test_structured_streaming_with_arun())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py pydantic
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/05_async_structured_output_streaming.py
    ```
  </Step>
</Steps>


# Team Input Schema Validation
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/input_schema_on_team



This example demonstrates how to use input\_schema with teams for automatic input validation and structured data handling, allowing automatic validation and conversion of dictionary inputs into Pydantic models.

## Code

```python cookbook/examples/teams/structured_input_output/06_input_schema_on_team.py
"""
This example demonstrates how to use input_schema with teams for automatic
input validation and structured data handling.

The input_schema feature allows teams to automatically validate and convert
dictionary inputs into Pydantic models, ensuring type safety and data validation.
"""

from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel, Field


class ResearchProject(BaseModel):
    """Structured research project with validation requirements."""

    project_name: str = Field(description="Name of the research project")
    research_topics: List[str] = Field(
        description="List of topics to research", min_items=1
    )
    target_audience: str = Field(description="Intended audience for the research")
    depth_level: str = Field(
        description="Research depth level", pattern="^(basic|intermediate|advanced)$"
    )
    max_sources: int = Field(
        description="Maximum number of sources to use", ge=3, le=20, default=10
    )
    include_recent_only: bool = Field(
        description="Whether to focus only on recent sources", default=True
    )


# Create research agents
hackernews_agent = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Research trending topics and discussions on HackerNews",
    instructions=[
        "Search for relevant discussions and articles",
        "Focus on high-quality posts with good engagement",
        "Extract key insights and technical details",
    ],
)

web_researcher = Agent(
    name="Web Researcher",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Conduct comprehensive web research",
    instructions=[
        "Search for authoritative sources and documentation",
        "Find recent articles and blog posts",
        "Gather diverse perspectives on the topics",
    ],
)

# Create team with input_schema for automatic validation
research_team = Team(
    name="Research Team with Input Validation",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[hackernews_agent, web_researcher],
    input_schema=ResearchProject,
    instructions=[
        "Conduct thorough research based on the validated input",
        "Coordinate between team members to avoid duplicate work",
        "Ensure research depth matches the specified level",
        "Respect the maximum sources limit",
        "Focus on recent sources if requested",
    ],
)

print("=== Example 1: Valid Dictionary Input (will be auto-validated) ===")
# Pass a dictionary - it will be automatically validated against ResearchProject schema
research_team.print_response(
    input={
        "project_name": "AI Framework Comparison 2024",
        "research_topics": ["LangChain", "CrewAI", "AutoGen", "Agno"],
        "target_audience": "AI Engineers and Developers",
        "depth_level": "intermediate",
        "max_sources": 15,
        "include_recent_only": True,
    }
)

print("\n=== Example 2: Pydantic Model Input (direct pass-through) ===")
# Pass a Pydantic model directly - no additional validation needed
research_request = ResearchProject(
    project_name="Blockchain Development Tools",
    research_topics=["Ethereum", "Solana", "Web3 Libraries"],
    target_audience="Blockchain Developers",
    depth_level="advanced",
    max_sources=12,
    include_recent_only=False,
)

research_team.print_response(input=research_request)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno pydantic ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/06_input_schema_on_team.py
    ```
  </Step>
</Steps>


# Pydantic Models as Team Input
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/pydantic_model_as_input



This example demonstrates how to use Pydantic models as input to teams, showing how structured data can be passed as messages for more precise and validated input handling.

## Code

```python cookbook/examples/teams/structured_input_output/01_pydantic_model_as_input.py
"""
This example demonstrates how to use Pydantic models as input to teams.

Shows how structured data can be passed as messages to teams for more
precise and validated input handling.
"""

from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.hackernews import HackerNewsTools
from pydantic import BaseModel, Field


class ResearchTopic(BaseModel):
    """Structured research topic with specific requirements."""

    topic: str = Field(description="The main research topic")
    focus_areas: List[str] = Field(description="Specific areas to focus on")
    target_audience: str = Field(description="Who this research is for")
    sources_required: int = Field(description="Number of sources needed", default=5)


# Create specialized Hacker News research agent
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
    instructions=[
        "Search Hacker News for relevant articles and discussions",
        "Extract key insights and summarize findings",
        "Focus on high-quality, well-discussed posts",
    ],
)

# Create collaborative research team
team = Team(
    name="Hackernews Research Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[hackernews_agent],
    determine_input_for_members=False,
    instructions=[
        "Conduct thorough research based on the structured input",
        "Address all focus areas mentioned in the research topic",
        "Tailor the research to the specified target audience",
        "Provide the requested number of sources",
    ],
    show_members_responses=True,
)

# Use Pydantic model as structured input
research_request = ResearchTopic(
    topic="AI Agent Frameworks",
    focus_areas=["AI Agents", "Framework Design", "Developer Tools", "Open Source"],
    target_audience="Software Developers and AI Engineers",
    sources_required=7,
)

# Execute research with structured input
team.print_response(input=research_request)

# Alternative example with different topic
alternative_research = ResearchTopic(
    topic="Distributed Systems",
    focus_areas=["Microservices", "Event-Driven Architecture", "Scalability"],
    target_audience="Backend Engineers",
    sources_required=5,
)

team.print_response(input=alternative_research)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno pydantic
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/01_pydantic_model_as_input.py
    ```
  </Step>
</Steps>


# Pydantic Models as Team Output
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/pydantic_model_output



This example demonstrates how to use Pydantic models as output from teams, showing how structured data can be returned as responses for more precise and validated output handling.

## Code

```python cookbook/examples/teams/structured_input_output/00_pydantic_model_output.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.pprint import pprint_run_response
from pydantic import BaseModel


class StockAnalysis(BaseModel):
    symbol: str
    company_name: str
    analysis: str


class CompanyAnalysis(BaseModel):
    company_name: str
    analysis: str


stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    output_schema=StockAnalysis,
    role="Searches for information on stocks and provides price analysis.",
    tools=[DuckDuckGoTools()],
)

company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches for information about companies and recent news.",
    output_schema=CompanyAnalysis,
    tools=[DuckDuckGoTools()],
)


class StockReport(BaseModel):
    symbol: str
    company_name: str
    analysis: str


team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    output_schema=StockReport,
    markdown=True,
)

# This should route to the stock_searcher
response = team.run("What is the current stock price of NVDA?")
assert isinstance(response.content, StockReport)
pprint_run_response(response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/00_pydantic_model_output.py
    ```
  </Step>
</Steps>


# Structured Output Streaming
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/structured_output_streaming



This example demonstrates streaming structured output from a team, using Pydantic models to ensure validated data structures while providing real-time streaming responses.

## Code

```python cookbook/examples/teams/structured_input_output/04_structured_output_streaming.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.exa import ExaTools
from pydantic import BaseModel


class StockAnalysis(BaseModel):
    symbol: str
    company_name: str
    analysis: str


stock_searcher = Agent(
    name="Stock Searcher",
    model=OpenAIChat("gpt-5-mini"),
    output_schema=StockAnalysis,
    role="Searches the web for information on a stock.",
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            highlights=False,
            show_results=True,
        )
    ],
)


class CompanyAnalysis(BaseModel):
    company_name: str
    analysis: str


company_info_agent = Agent(
    name="Company Info Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a stock.",
    output_schema=CompanyAnalysis,
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            text=False,
            highlights=False,
            show_results=True,
        )
    ],
)


class StockReport(BaseModel):
    symbol: str
    company_name: str
    analysis: str


team = Team(
    name="Stock Research Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[stock_searcher, company_info_agent],
    output_schema=StockReport,
    markdown=True,
    show_members_responses=True,
)

# Run with streaming and consume the generator to get the final response
stream_generator = team.run(
    "Give me a stock report for NVDA",
    stream=True,
    stream_intermediate_steps=True,
)

# Consume the streaming events and get the final response
run_response = None
for event_or_response in stream_generator:
    # The last item in the stream is the final TeamRunOutput
    run_response = event_or_response

assert isinstance(run_response.content, StockReport)
print(
    f"‚úÖ Response content is correctly typed as StockReport: {type(run_response.content)}"
)
print(f"‚úÖ Stock Symbol: {run_response.content.symbol}")
print(f"‚úÖ Company Name: {run_response.content.company_name}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py pydantic
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/04_structured_output_streaming.py
    ```
  </Step>
</Steps>


# Team with Output Model
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/team_with_output_model



This example shows how to use the output\_model parameter to specify the model that should be used to generate the final response from a team.

## Code

```python cookbook/examples/teams/structured_input_output/03_team_with_output_model.py
"""
This example shows how to use the output_model parameter to specify the model that should be used to generate the final response.
"""

from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

itinerary_planner = Agent(
    name="Itinerary Planner",
    model=Claude(id="claude-sonnet-4-20250514"),
    description="You help people plan amazing vacations. Use the tools at your disposal to find latest information about the destination.",
    tools=[DuckDuckGoTools()],
)

travel_expert = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[itinerary_planner],
    output_model=OpenAIChat(id="gpt-5-mini"),
)

travel_expert.print_response("Plan a summer vacation in Paris", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/03_team_with_output_model.py
    ```
  </Step>
</Steps>


# Team with Parser Model
Source: https://docs.agno.com/examples/concepts/teams/structured_input_output/team_with_parser_model



This example demonstrates using a parser model with teams to generate structured output, creating detailed national park adventure guides with validated Pydantic schemas.

## Code

```python cookbook/examples/teams/structured_input_output/02_team_with_parser_model.py
import random
from typing import Iterator, List  # noqa

from agno.agent import Agent, RunOutput, RunOutputEvent  # noqa
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team import Team
from pydantic import BaseModel, Field
from rich.pretty import pprint


class NationalParkAdventure(BaseModel):
    park_name: str = Field(..., description="Name of the national park")
    best_season: str = Field(
        ...,
        description="Optimal time of year to visit this park (e.g., 'Late spring to early fall')",
    )
    signature_attractions: List[str] = Field(
        ...,
        description="Must-see landmarks, viewpoints, or natural features in the park",
    )
    recommended_trails: List[str] = Field(
        ...,
        description="Top hiking trails with difficulty levels (e.g., 'Angel's Landing - Strenuous')",
    )
    wildlife_encounters: List[str] = Field(
        ..., description="Animals visitors are likely to spot, with viewing tips"
    )
    photography_spots: List[str] = Field(
        ...,
        description="Best locations for capturing stunning photos, including sunrise/sunset spots",
    )
    camping_options: List[str] = Field(
        ..., description="Available camping areas, from primitive to RV-friendly sites"
    )
    safety_warnings: List[str] = Field(
        ..., description="Important safety considerations specific to this park"
    )
    hidden_gems: List[str] = Field(
        ..., description="Lesser-known spots or experiences that most visitors miss"
    )
    difficulty_rating: int = Field(
        ...,
        ge=1,
        le=5,
        description="Overall park difficulty for average visitor (1=easy, 5=very challenging)",
    )
    estimated_days: int = Field(
        ...,
        ge=1,
        le=14,
        description="Recommended number of days to properly explore the park",
    )
    special_permits_needed: List[str] = Field(
        default=[],
        description="Any special permits or reservations required for certain activities",
    )


itinerary_planner = Agent(
    name="Itinerary Planner",
    model=Claude(id="claude-sonnet-4-20250514"),
    description="You help people plan amazing national park adventures and provide detailed park guides.",
)

weather_expert = Agent(
    name="Weather Expert",
    model=Claude(id="claude-sonnet-4-20250514"),
    description="You are a weather expert and can provide detailed weather information for a given location.",
)

national_park_expert = Team(
    model=OpenAIChat(id="gpt-5-mini"),
    members=[itinerary_planner, weather_expert],
    output_schema=NationalParkAdventure,
    parser_model=OpenAIChat(id="gpt-5-mini"),
)

# Get the response in a variable
national_parks = [
    "Yellowstone National Park",
    "Yosemite National Park",
    "Grand Canyon National Park",
    "Zion National Park",
    "Grand Teton National Park",
    "Rocky Mountain National Park",
    "Acadia National Park",
    "Mount Rainier National Park",
    "Great Smoky Mountains National Park",
    "Rocky National Park",
]
# Get the response in a variable
run: RunOutput = national_park_expert.run(
    f"What is the best season to visit {national_parks[random.randint(0, len(national_parks) - 1)]}? Please provide a detailed one week itinerary for a visit to the park."
)
pprint(run.content)

# Stream the response
# run_events: Iterator[RunOutputEvent] = national_park_expert.run(f"What is the best season to visit {national_parks[random.randint(0, len(national_parks) - 1)]}? Please provide a detailed one week itinerary for a visit to the park.", stream=True)
# for event in run_events:
#     pprint(event)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno pydantic rich
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/structured_input_output/02_team_with_parser_model.py
    ```
  </Step>
</Steps>


# Async Team with Tools
Source: https://docs.agno.com/examples/concepts/teams/tools/async_team_with_tools



This example demonstrates how to create an async team with various tools for information gathering using multiple agents with different tools (Wikipedia, DuckDuckGo, AgentQL) to gather comprehensive information asynchronously.

## Code

```python cookbook/examples/teams/tools/03_async_team_with_tools.py
"""
This example demonstrates how to create an async team with various tools for information gathering.

The team uses multiple agents with different tools (Wikipedia, DuckDuckGo, AgentQL) to
gather comprehensive information about a company asynchronously.
"""

import asyncio
from uuid import uuid4

from agno.agent.agent import Agent
from agno.models.anthropic import Claude
from agno.models.mistral import MistralChat
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.agentql import AgentQLTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.wikipedia import WikipediaTools

# Wikipedia search agent
wikipedia_agent = Agent(
    name="Wikipedia Agent",
    role="Search wikipedia for information",
    model=MistralChat(id="mistral-large-latest"),
    tools=[WikipediaTools()],
    instructions=[
        "Find information about the company in the wikipedia",
    ],
)

# Web search agent
website_agent = Agent(
    name="Website Agent",
    role="Search the website for information",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=[
        "Search the website for information",
    ],
)

# Define custom AgentQL query for specific data extraction (see https://docs.agentql.com/concepts/query-language)
custom_query = """
{
    title
    text_content[]
}
"""

# Generate unique IDs
user_id = str(uuid4())
id = str(uuid4())

# Create the company information gathering team
company_info_team = Team(
    name="Company Info Team",
    id=id,
    model=Claude(id="claude-3-7-sonnet-latest"),
    tools=[AgentQLTools(agentql_query=custom_query)],
    members=[
        wikipedia_agent,
        website_agent,
    ],
    markdown=True,
    instructions=[
        "You are a team that finds information about a company.",
        "First search the web and wikipedia for information about the company.",
        "If you can find the company's website URL, then scrape the homepage and the about page.",
    ],
    show_members_responses=True,
)

if __name__ == "__main__":
    asyncio.run(
        company_info_team.aprint_response(
            "Write me a full report on everything you can find about Agno, the company building AI agent infrastructure.",
            stream=True,
            stream_intermediate_steps=True,
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno wikipedia ddgs agentql
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export MISTRAL_API_KEY=****
    export AGENTQL_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/tools/03_async_team_with_tools.py
    ```
  </Step>
</Steps>


# Team with Custom Tools
Source: https://docs.agno.com/examples/concepts/teams/tools/team_with_custom_tools



This example demonstrates how to create a team with custom tools, using custom tools alongside agent tools to answer questions from a knowledge base and fall back to web search when needed.

## Code

```python cookbook/examples/teams/tools/01_team_with_custom_tools.py
"""
This example demonstrates how to create a team with custom tools.

The team uses custom tools alongside agent tools to answer questions from a knowledge base
and fall back to web search when needed.
"""

from agno.agent import Agent
from agno.team.team import Team
from agno.tools import tool
from agno.tools.duckduckgo import DuckDuckGoTools


@tool()
def answer_from_known_questions(question: str) -> str:
    """Answer a question from a list of known questions

    Args:
        question: The question to answer

    Returns:
        The answer to the question
    """

    # FAQ knowledge base
    faq = {
        "What is the capital of France?": "Paris",
        "What is the capital of Germany?": "Berlin",
        "What is the capital of Italy?": "Rome",
        "What is the capital of Spain?": "Madrid",
        "What is the capital of Portugal?": "Lisbon",
        "What is the capital of Greece?": "Athens",
        "What is the capital of Turkey?": "Ankara",
    }

    # Check if question is in FAQ
    if question in faq:
        return f"From my knowledge base: {faq[question]}"
    else:
        return "I don't have that information in my knowledge base. Try asking the web search agent."


# Create web search agent for fallback
web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Create team with custom tool and agent members
team = Team(name="Q & A team", members=[web_agent], tools=[answer_from_known_questions])

# Test the team
team.print_response("What is the capital of France?", stream=True)

# Check if team has session state and display information
print("\nüìä Team Session Info:")
session = team.get_session()
print(f"   Session ID: {session.session_id}")
print(f"   Session State: {session.session_data['session_state']}")

# Show team capabilities
print("\nüîß Team Tools Available:")
for t in team.tools:
    print(f"   - {t.name}: {t.description}")

print("\nüë• Team Members:")
for member in team.members:
    print(f"   - {member.name}: {member.role}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/tools/01_team_with_custom_tools.py
    ```
  </Step>
</Steps>


# Team with Tool Hooks
Source: https://docs.agno.com/examples/concepts/teams/tools/team_with_tool_hooks



This example demonstrates how to use tool hooks with teams and agents for intercepting and monitoring tool function calls, providing logging, timing, and other observability features.

## Code

```python cookbook/examples/teams/tools/02_team_with_tool_hooks.py
"""
This example demonstrates how to use tool hooks with teams and agents.

Tool hooks allow you to intercept and monitor tool function calls, providing
logging, timing, and other observability features.
"""

import time
from typing import Any, Callable, Dict
from uuid import uuid4

from agno.agent.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reddit import RedditTools
from agno.utils.log import logger


def logger_hook(function_name: str, function_call: Callable, arguments: Dict[str, Any]):
    """
    Tool hook that logs function calls and measures execution time.

    Args:
        function_name: Name of the function being called
        function_call: The actual function to call
        arguments: Arguments passed to the function

    Returns:
        The result of the function call
    """
    if function_name == "delegate_task_to_member":
        member_id = arguments.get("member_id")
        logger.info(f"Delegating task to member {member_id}")

    # Start timer
    start_time = time.time()
    result = function_call(**arguments)
    # End timer
    end_time = time.time()
    duration = end_time - start_time
    logger.info(f"Function {function_name} took {duration:.2f} seconds to execute")
    return result


# Reddit search agent with tool hooks
reddit_agent = Agent(
    name="Reddit Agent",
    id="reddit-agent",
    role="Search reddit for information",
    tools=[RedditTools(cache_results=True)],
    instructions=[
        "Find information about the company on Reddit",
    ],
    tool_hooks=[logger_hook],
)

# Web search agent with tool hooks
website_agent = Agent(
    name="Website Agent",
    id="website-agent",
    role="Search the website for information",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(cache_results=True)],
    instructions=[
        "Search the website for information",
    ],
    tool_hooks=[logger_hook],
)

# Generate unique user ID
user_id = str(uuid4())

# Create team with tool hooks
company_info_team = Team(
    name="Company Info Team",
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[
        reddit_agent,
        website_agent,
    ],
    markdown=True,
    instructions=[
        "You are a team that finds information about a company.",
        "First search the web and wikipedia for information about the company.",
        "If you can find the company's website URL, then scrape the homepage and the about page.",
    ],
    show_members_responses=True,
    tool_hooks=[logger_hook],
)

if __name__ == "__main__":
    company_info_team.print_response(
        "Write me a full report on everything you can find about Agno, the company building AI agent infrastructure.",
        stream=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export REDDIT_CLIENT_ID=****
    export REDDIT_CLIENT_SECRET=****
    export REDDIT_USER_AGENT=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/tools/02_team_with_tool_hooks.py
    ```
  </Step>
</Steps>


# CSV Tools
Source: https://docs.agno.com/examples/concepts/tools/database/csv



## Code

```python cookbook/tools/csv_tools.py
from pathlib import Path

import httpx
from agno.agent import Agent
from agno.tools.csv_toolkit import CsvTools

url = "https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv"
response = httpx.get(url)

imdb_csv = Path(__file__).parent.joinpath("imdb.csv")
imdb_csv.parent.mkdir(parents=True, exist_ok=True)
imdb_csv.write_bytes(response.content)

agent = Agent(
    tools=[CsvTools(csvs=[imdb_csv])],
    markdown=True,
        instructions=[
        "First always get the list of files",
        "Then check the columns in the file",
        "Then run the query to answer the question",
    ],
)
agent.cli_app(stream=False)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U httpx openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/csv_tools.py
      ```

      ```bash Windows
      python cookbook/tools/csv_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DuckDB Tools
Source: https://docs.agno.com/examples/concepts/tools/database/duckdb



## Code

```python cookbook/tools/duckdb_tools.py
from agno.agent import Agent
from agno.tools.duckdb import DuckDbTools

agent = Agent(
    tools=[DuckDbTools()],
        instructions="Use this file for Movies data: https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
)
agent.print_response(
    "What is the average rating of movies?", markdown=True, stream=False
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckdb openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/duckdb_tools.py
      ```

      ```bash Windows
      python cookbook/tools/duckdb_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google BigQuery Tools
Source: https://docs.agno.com/examples/concepts/tools/database/google_bigquery



## Code

```python cookbook/tools/google_bigquery_tools.py
from agno.agent import Agent
from agno.tools.google_bigquery import GoogleBigQueryTools

agent = Agent(
    instructions=[
        "You are a data analyst assistant that helps with BigQuery operations",
        "Execute SQL queries to analyze large datasets",
        "Provide insights and summaries of query results",
    ],
    tools=[GoogleBigQueryTools(dataset="your_dataset_name")],
    markdown=True,
)

agent.print_response("List all tables in the dataset and describe the sales table")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your credentials">
    ```bash
    export GOOGLE_CLOUD_PROJECT=your-project-id
    export GOOGLE_CLOUD_LOCATION=US
    export GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-bigquery openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/google_bigquery_tools.py
      ```

      ```bash Windows
      python cookbook/tools/google_bigquery_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Neo4j Tools
Source: https://docs.agno.com/examples/concepts/tools/database/neo4j

Neo4jTools enables agents to interact with Neo4j graph databases for querying and managing graph data.

## Code

```python cookbook/tools/neo4j_tools.py
from agno.agent import Agent
from agno.tools.neo4j import Neo4jTools

agent = Agent(
    instructions=[
        "You are a graph database assistant that helps with Neo4j operations",
        "Execute Cypher queries to analyze graph data and relationships",
        "Provide insights about graph structure and patterns",
    ],
    tools=[Neo4jTools()],
    markdown=True,
)

agent.print_response("Show me the schema of the graph database and list all node labels")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your credentials">
    ```bash
    export NEO4J_URI=bolt://localhost:7687
    export NEO4J_USERNAME=neo4j
    export NEO4J_PASSWORD=your-password
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U neo4j openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/neo4j_tools.py
      ```

      ```bash Windows
      python cookbook/tools/neo4j_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# null
Source: https://docs.agno.com/examples/concepts/tools/database/pandas



Description:

Implemented an AI agent using the agno library with PandasTools for automated data analysis.

The agent loads a CSV file (data.csv) and performs analysis based on natural language instructions.

Enables interaction with data without manual Pandas coding, simplifying data exploration and insights extraction.

Includes setup instructions for environment variables and dependencies.

***

## title: Pandas Tools

## Code

```python cookbook/tools/pandas_tools.py
from agno.agent import Agent
from agno.tools.pandas import PandasTools

agent = Agent(
    tools=[PandasTools()],
        markdown=True,
)
agent.print_response("Load and analyze the dataset from data.csv")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U pandas openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/pandas_tools.py
      ```

      ```bash Windows
      python cookbook/tools/pandas_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Postgres Tools
Source: https://docs.agno.com/examples/concepts/tools/database/postgres



## Code

```python cookbook/tools/postgres_tools.py
from agno.agent import Agent
from agno.tools.postgres import PostgresTools

agent = Agent(
    tools=[PostgresTools(db_url="postgresql://user:pass@localhost:5432/db")],
        markdown=True,
)
agent.print_response("Show me all tables in the database")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your database URL">
    ```bash
    export DATABASE_URL=postgresql://user:pass@localhost:5432/db
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U psycopg2-binary sqlalchemy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/postgres_tools.py
      ```

      ```bash Windows
      python cookbook/tools/postgres_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SQL Tools
Source: https://docs.agno.com/examples/concepts/tools/database/sql



## Code

```python cookbook/tools/sql_tools.py
from agno.agent import Agent
from agno.tools.sql import SQLTools

agent = Agent(
    tools=[SQLTools(db_url="sqlite:///database.db")],
        markdown=True,
)
agent.print_response("Show me all tables in the database and their schemas")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/sql_tools.py
      ```

      ```bash Windows
      python cookbook/tools/sql_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Zep Memory Tools
Source: https://docs.agno.com/examples/concepts/tools/database/zep



## Code

```python cookbook/tools/zep_tools.py
import time
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.zep import ZepTools

# Initialize the ZepTools
zep_tools = ZepTools(user_id="agno", session_id="agno-session", add_instructions=True)

# Initialize the Agent
agent = Agent(
    model=OpenAIChat(),
    tools=[zep_tools],
    dependencies={"memory": zep_tools.get_zep_memory(memory_type="context")},
    add_dependencies_to_context=True,
)

# Interact with the Agent so that it can learn about the user
agent.print_response("My name is John Billings")
agent.print_response("I live in NYC")
agent.print_response("I'm going to a concert tomorrow")

# Allow the memories to sync with Zep database
time.sleep(10)

# Refresh the context
agent.context["memory"] = zep_tools.get_zep_memory(memory_type="context")

# Ask the Agent about the user
agent.print_response("What do you know about me?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export ZEP_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U zep-cloud openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/zep_tools.py
      ```

      ```bash Windows
      python cookbook/tools/zep_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Zep Async Memory Tools
Source: https://docs.agno.com/examples/concepts/tools/database/zep_async



## Code

```python cookbook/tools/zep_async_tools.py
import asyncio
import time
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.zep import ZepAsyncTools


async def main():
    # Initialize the ZepAsyncTools
    zep_tools = ZepAsyncTools(
        user_id="agno", session_id="agno-async-session", add_instructions=True
    )

    # Initialize the Agent
    agent = Agent(
        model=OpenAIChat(),
        tools=[zep_tools],
        dependencies={
            "memory": lambda: zep_tools.get_zep_memory(memory_type="context"),
        },
        add_dependencies_to_context=True,
    )

    # Interact with the Agent
    await agent.aprint_response("My name is John Billings")
    await agent.aprint_response("I live in NYC")
    await agent.aprint_response("I'm going to a concert tomorrow")

    # Allow the memories to sync with Zep database
    time.sleep(10)

    # Refresh the context
    agent.context["memory"] = await zep_tools.get_zep_memory(memory_type="context")

    # Ask the Agent about the user
    await agent.aprint_response("What do you know about me?")


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export ZEP_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U zep-cloud openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/zep_async_tools.py
      ```

      ```bash Windows
      python cookbook/tools/zep_async_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# File Generation Tools
Source: https://docs.agno.com/examples/concepts/tools/file-generation

This cookbook shows how to use the FileGenerationTool to generate various file types (JSON, CSV, PDF, TXT).

## Code

```python cookbook/tools/file_generation_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.file_generation import FileGenerationTools
from agno.db.sqlite import SqliteDb

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    db=SqliteDb(db_file="tmp/test.db"),
    tools=[FileGenerationTools(output_directory="tmp")],  
    description="You are a helpful assistant that can generate files in various formats.",
    instructions=[
        "When asked to create files, use the appropriate file generation tools.",
        "Always provide meaningful content and appropriate filenames.",
        "Explain what you've created and how it can be used.",
    ],
    markdown=True,
)

def process_file_generation_output(response, example_name: str):
    """Process and display the file generation output"""
    print(f"=== {example_name} ===")
    print(response.content)
    if response.files:
        for file in response.files:
            print(f"Generated file: {file.filename} ({file.size} bytes)")
            if file.url:
                print(f"File location: {file.url}")
    print()

if __name__ == "__main__":
    print("File Generation Tool Cookbook Examples")
    print("=" * 50)

    # JSON File Generation Example
    response = agent.run(
        "Create a JSON file containing information about 3 fictional employees with name, position, department, and salary."
    )
    process_file_generation_output(response, "JSON File Generation Example")

    # CSV File Generation Example
    response = agent.run(
        "Create a CSV file with sales data for the last 6 months. Include columns for month, product, units_sold, and revenue."
    )
    process_file_generation_output(response, "CSV File Generation Example")

    # PDF File Generation Example
    response = agent.run(
        "Create a PDF report about renewable energy trends in 2024. Include sections on solar, wind, and hydroelectric power."
    )
    process_file_generation_output(response, "PDF File Generation Example")

    # Text File Generation Example
    response = agent.run(
        "Create a text file with a list of best practices for remote work productivity."
    )
    process_file_generation_output(response, "Text File Generation Example")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno reportlab
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/file_generation_tools.py
      ```

      ```bash Windows
      python cookbook/tools/file_generation_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Calculator
Source: https://docs.agno.com/examples/concepts/tools/local/calculator



## Code

```python cookbook/tools/calculator_tools.py
from agno.agent import Agent
from agno.tools.calculator import CalculatorTools

agent = Agent(
    tools=[
        CalculatorTools()
    ],
        markdown=True,
)
agent.print_response("What is 10*5 then to the power of 2, do it step by step")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/calculator_tools.py
      ```

      ```bash Windows
      python cookbook/tools/calculator_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Docker Tools
Source: https://docs.agno.com/examples/concepts/tools/local/docker



## Code

```python cookbook/tools/docker_tools.py
import sys
from agno.agent import Agent

try:
    from agno.tools.docker import DockerTools

    docker_tools = DockerTools(
        enable_container_management=True,
        enable_image_management=True,
        enable_volume_management=True,
        enable_network_management=True,
    )

    # Create an agent with Docker tools
    docker_agent = Agent(
        name="Docker Agent",
        instructions=[
            "You are a Docker management assistant that can perform various Docker operations.",
            "You can manage containers, images, volumes, and networks.",
        ],
        tools=[docker_tools],
                markdown=True,
    )

    # Example: List running containers
    docker_agent.print_response("List all running Docker containers", stream=True)

    # Example: List all images
    docker_agent.print_response("List all Docker images on this system", stream=True)

    # Example: Pull an image
    docker_agent.print_response("Pull the latest nginx image", stream=True)

    # Example: Run a container
    docker_agent.print_response(
        "Run an nginx container named 'web-server' on port 8080", stream=True
    )

    # Example: Get container logs
    docker_agent.print_response("Get logs from the 'web-server' container", stream=True)

    # Example: List volumes
    docker_agent.print_response("List all Docker volumes", stream=True)

    # Example: Create a network
    docker_agent.print_response(
        "Create a new Docker network called 'test-network'", stream=True
    )

    # Example: Stop and remove container
    docker_agent.print_response(
        "Stop and remove the 'web-server' container", stream=True
    )

except ValueError as e:
    print(f"\n‚ùå Docker Tool Error: {e}")
    print("\nüîç Troubleshooting steps:")

    if sys.platform == "darwin":  # macOS
        print("1. Ensure Docker Desktop is running")
        print("2. Check Docker Desktop settings")
        print("3. Try running 'docker ps' in terminal to verify access")

    elif sys.platform == "linux":
        print("1. Check if Docker service is running:")
        print("   systemctl status docker")
        print("2. Make sure your user has permissions to access Docker:")
        print("   sudo usermod -aG docker $USER")

    elif sys.platform == "win32":
        print("1. Ensure Docker Desktop is running")
        print("2. Check Docker Desktop settings")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Docker">
    Install Docker Desktop (for macOS/Windows) or Docker Engine (for Linux) from [Docker's official website](https://www.docker.com/products/docker-desktop).
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U docker agno
    ```
  </Step>

  <Step title="Start Docker">
    Make sure Docker is running on your system:

    * **macOS/Windows**: Start Docker Desktop application
    * **Linux**: Run `sudo systemctl start docker`
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac/Linux
      python cookbook/tools/docker_tools.py
      ```

      ```bash Windows
      python cookbook\tools\docker_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# File Tools
Source: https://docs.agno.com/examples/concepts/tools/local/file



## Code

```python cookbook/tools/file_tools.py
from pathlib import Path

from agno.agent import Agent
from agno.tools.file import FileTools

agent = Agent(tools=[FileTools(Path("tmp/file"))])
agent.print_response(
    "What is the most advanced LLM currently? Save the answer to a file.", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/file_tools.py
      ```

      ```bash Windows
      python cookbook/tools/file_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Local File System Tools
Source: https://docs.agno.com/examples/concepts/tools/local/local_file_system



## Code

```python cookbook/tools/local_file_system_tools.py
from agno.agent import Agent
from agno.tools.local_file_system import LocalFileSystemTools

agent = Agent(
    instructions=[
        "You are a file management assistant that helps save content to local files",
        "Create files with appropriate names and extensions",
        "Organize files in the specified directory structure",
    ],
    tools=[LocalFileSystemTools(target_directory="./output")],
    markdown=True,
)

agent.print_response("Save this meeting summary to a file: 'Discussed Q4 goals and budget allocation'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/local_file_system_tools.py
      ```

      ```bash Windows
      python cookbook/tools/local_file_system_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Python Tools
Source: https://docs.agno.com/examples/concepts/tools/local/python



## Code

```python cookbook/tools/python_tools.py
from agno.agent import Agent
from agno.tools.python import PythonTools

agent = Agent(
    tools=[PythonTools()],
        markdown=True,
)
agent.print_response("Calculate the factorial of 5 using Python")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/python_tools.py
      ```

      ```bash Windows
      python cookbook/tools/python_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Shell Tools
Source: https://docs.agno.com/examples/concepts/tools/local/shell



## Code

```python cookbook/tools/shell_tools.py
from agno.agent import Agent
from agno.tools.shell import ShellTools

agent = Agent(
    tools=[ShellTools()],
        markdown=True,
)
agent.print_response("List all files in the current directory")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/shell_tools.py
      ```

      ```bash Windows
      python cookbook/tools/shell_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Sleep Tools
Source: https://docs.agno.com/examples/concepts/tools/local/sleep



## Code

```python cookbook/tools/sleep_tools.py
from agno.agent import Agent
from agno.tools.sleep import SleepTools

agent = Agent(
    tools=[SleepTools()],
        markdown=True,
)
agent.print_response("Wait for 5 seconds before continuing")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/sleep_tools.py
      ```

      ```bash Windows
      python cookbook/tools/sleep_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Airbnb MCP agent
Source: https://docs.agno.com/examples/concepts/tools/mcp/airbnb



Using the [Airbnb MCP server](https://github.com/openbnb-org/mcp-server-airbnb) to create an Agent that can search for Airbnb listings:

```python
"""üè† MCP Airbnb Agent - Search for Airbnb listings!

This example shows how to create an agent that uses MCP and Gemini 2.5 Pro to search for Airbnb listings.

Run: `pip install google-genai mcp agno` to install the dependencies
"""

import asyncio

from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.mcp import MCPTools
from agno.utils.pprint import apprint_run_response


async def run_agent(message: str) -> None:
    async with MCPTools(
        "npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt"
    ) as mcp_tools:
        agent = Agent(
            model=Gemini(id="gemini-2.5-pro-exp-03-25"),
            tools=[mcp_tools],
            markdown=True,
        )

        response_stream = await agent.arun(message, stream=True)
        await apprint_run_response(response_stream, markdown=True)


if __name__ == "__main__":
    asyncio.run(
        run_agent(
            "What listings are available in San Francisco for 2 people for 3 nights from 1 to 4 August 2025?"
        )
    )

```


# GitHub MCP agent
Source: https://docs.agno.com/examples/concepts/tools/mcp/github



Using the [GitHub MCP server](https://github.com/modelcontextprotocol/servers/tree/main/src/github) to create an Agent that can explore, analyze and provide insights about GitHub repositories:

```python
"""üêô MCP GitHub Agent - Your Personal GitHub Explorer!

This example shows how to create a GitHub agent that uses MCP to explore,
analyze, and provide insights about GitHub repositories. The agent leverages the Model
Context Protocol (MCP) to interact with GitHub, allowing it to answer questions
about issues, pull requests, repository details and more.

Example prompts to try:
- "List open issues in the repository"
- "Show me recent pull requests"
- "What are the repository statistics?"
- "Find issues labeled as bugs"
- "Show me contributor activity"

Run: `pip install agno mcp openai` to install the dependencies
Environment variables needed:
- Create a GitHub personal access token following these steps:
    - https://github.com/modelcontextprotocol/servers/tree/main/src/github#setup
- export GITHUB_TOKEN: Your GitHub personal access token
"""

import asyncio
import os
from textwrap import dedent

from agno.agent import Agent
from agno.tools.mcp import MCPTools
from mcp import StdioServerParameters


async def run_agent(message: str) -> None:
    """Run the GitHub agent with the given message."""

    # Initialize the MCP server
    server_params = StdioServerParameters(
        command="npx",
        args=["-y", "@modelcontextprotocol/server-github"],
    )

    # Create a client session to connect to the MCP server
    async with MCPTools(server_params=server_params) as mcp_tools:
        agent = Agent(
            tools=[mcp_tools],
            instructions=dedent("""\
                You are a GitHub assistant. Help users explore repositories and their activity.

                - Use headings to organize your responses
                - Be concise and focus on relevant information\
            """),
            markdown=True,
                    )

        # Run the agent
        await agent.aprint_response(message, stream=True)


# Example usage
if __name__ == "__main__":
    # Pull request example
    asyncio.run(
        run_agent(
            "Tell me about Agno. Github repo: https://github.com/agno-agi/agno. You can read the README for more information."
        )
    )


# More example prompts to explore:
"""
Issue queries:
1. "Find issues needing attention"
2. "Show me issues by label"
3. "What issues are being actively discussed?"
4. "Find related issues"
5. "Analyze issue resolution patterns"

Pull request queries:
1. "What PRs need review?"
2. "Show me recent merged PRs"
3. "Find PRs with conflicts"
4. "What features are being developed?"
5. "Analyze PR review patterns"

Repository queries:
1. "Show repository health metrics"
2. "What are the contribution guidelines?"
3. "Find documentation gaps"
4. "Analyze code quality trends"
5. "Show repository activity patterns"
"""
```


# Notion MCP agent
Source: https://docs.agno.com/examples/concepts/tools/mcp/notion



Using the [Notion MCP server](https://github.com/makenotion/notion-mcp-server) to create an Agent that can create, update and search for Notion pages:

```python
"""
Notion MCP Agent - Manages your documents

This example shows how to use the Agno MCP tools to interact with your Notion workspace.

1. Start by setting up a new internal integration in Notion: https://www.notion.so/profile/integrations
2. Export your new Notion key: `export NOTION_API_KEY=ntn_****`
3. Connect your relevant Notion pages to the integration. To do this, you'll need to visit that page, and click on the 3 dots, and select "Connect to integration".

Dependencies: pip install agno mcp openai

Usage:
  python cookbook/tools/mcp/notion_mcp_agent.py
"""

import asyncio
import json
import os
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from mcp import StdioServerParameters


async def run_agent():
    token = os.getenv("NOTION_API_KEY")
    if not token:
        raise ValueError(
            "Missing Notion API key: provide --NOTION_API_KEY or set NOTION_API_KEY environment variable"
        )

    command = "npx"
    args = ["-y", "@notionhq/notion-mcp-server"]
    env = {
        "OPENAPI_MCP_HEADERS": json.dumps(
            {"Authorization": f"Bearer {token}", "Notion-Version": "2022-06-28"}
        )
    }
    server_params = StdioServerParameters(command=command, args=args, env=env)

    async with MCPTools(server_params=server_params) as mcp_tools:
        agent = Agent(
            name="NotionDocsAgent",
            model=OpenAIChat(id="gpt-5-mini"),
            tools=[mcp_tools],
            description="Agent to query and modify Notion docs via MCP",
            instructions=dedent("""\
                You have access to Notion documents through MCP tools.
                - Use tools to read, search, or update pages.
                - Confirm with the user before making modifications.
            """),
            markdown=True,
                    )

        await agent.acli_app(
            message="You are a helpful assistant that can access Notion workspaces and pages.",
            stream=True,
            markdown=True,
            exit_on=["exit", "quit"],
        )


if __name__ == "__main__":
    asyncio.run(run_agent())
```


# Pipedream Auth
Source: https://docs.agno.com/examples/concepts/tools/mcp/pipedream_auth

This example shows how to add authorization when integrating Pipedream MCP servers with Agno Agents.

## Code

```python
"""
üîí Using Pipedream MCP servers with authentication

This is an example of how to use Pipedream MCP servers with authentication.
This is useful if your app is interfacing with the MCP servers in behalf of your users.

1. Get your access token. You can check how in Pipedream's docs: https://pipedream.com/docs/connect/mcp/developers/
2. Get the URL of the MCP server. It will look like this: https://remote.mcp.pipedream.net/<External user id>/<MCP app slug>
3. Set the environment variables:
    - MCP_SERVER_URL: The URL of the MCP server you previously got
    - MCP_ACCESS_TOKEN: The access token you previously got
    - PIPEDREAM_PROJECT_ID: The project id of the Pipedream project you want to use
    - PIPEDREAM_ENVIRONMENT: The environment of the Pipedream project you want to use
3. Install dependencies: pip install agno mcp-sdk
"""

import asyncio
from os import getenv

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools, StreamableHTTPClientParams
from agno.utils.log import log_exception

mcp_server_url = getenv("MCP_SERVER_URL")
mcp_access_token = getenv("MCP_ACCESS_TOKEN")
pipedream_project_id = getenv("PIPEDREAM_PROJECT_ID")
pipedream_environment = getenv("PIPEDREAM_ENVIRONMENT")


server_params = StreamableHTTPClientParams(
    url=mcp_server_url,
    headers={
        "Authorization": f"Bearer {mcp_access_token}",
        "x-pd-project-id": pipedream_project_id,
        "x-pd-environment": pipedream_environment,
    },
)


async def run_agent(task: str) -> None:
    try:
        async with MCPTools(
            server_params=server_params, transport="streamable-http", timeout_seconds=20
        ) as mcp:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp],
                markdown=True,
            )
            await agent.aprint_response(message=task, stream=True)
    except Exception as e:
        log_exception(f"Unexpected error: {e}")


if __name__ == "__main__":
    # The agent can read channels, users, messages, etc.
    asyncio.run(run_agent("Show me the latest message in the channel #general"))
```


# Pipedream Google Calendar
Source: https://docs.agno.com/examples/concepts/tools/mcp/pipedream_google_calendar

This example shows how to use the Google Calendar Pipedream MCP server with Agno Agents.

## Code

```python
"""
üóìÔ∏è Pipedream Google Calendar MCP

This example shows how to use Pipedream MCP servers (in this case the Google Calendar one) with Agno Agents.

1. Connect your Pipedream and Google Calendar accounts: https://mcp.pipedream.com/app/google-calendar
2. Get your Pipedream MCP server url: https://mcp.pipedream.com/app/google-calendar
3. Set the MCP_SERVER_URL environment variable to the MCP server url you got above
4. Install dependencies: pip install agno mcp-sdk
"""

import asyncio
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.utils.log import log_exception

mcp_server_url = os.getenv("MCP_SERVER_URL")


async def run_agent(task: str) -> None:
    try:
        async with MCPTools(
            url=mcp_server_url, transport="sse", timeout_seconds=20
        ) as mcp:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp],
                markdown=True,
            )
            await agent.aprint_response(
                message=task,
                stream=True,
            )
    except Exception as e:
        log_exception(f"Unexpected error: {e}")


if __name__ == "__main__":
    asyncio.run(
        run_agent("Tell me about all events I have in my calendar for tomorrow")
    )
```


# Pipedream LinkedIn
Source: https://docs.agno.com/examples/concepts/tools/mcp/pipedream_linkedin

This example shows how to use the LinkedIn Pipedream MCP server with Agno Agents.

## Code

```python
"""
üíª Pipedream LinkedIn MCP

This example shows how to use Pipedream MCP servers (in this case the LinkedIn one) with Agno Agents.

1. Connect your Pipedream and LinkedIn accounts: https://mcp.pipedream.com/app/linkedin
2. Get your Pipedream MCP server url: https://mcp.pipedream.com/app/linkedin
3. Set the MCP_SERVER_URL environment variable to the MCP server url you got above
4. Install dependencies: pip install agno mcp-sdk
"""

import asyncio
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.utils.log import log_exception

mcp_server_url = os.getenv("MCP_SERVER_URL")


async def run_agent(task: str) -> None:
    try:
        async with MCPTools(
            url=mcp_server_url, transport="sse", timeout_seconds=20
        ) as mcp:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp],
                markdown=True,
            )
            await agent.aprint_response(
                message=task,
                stream=True,
            )
    except Exception as e:
        log_exception(f"Unexpected error: {e}")


if __name__ == "__main__":
    asyncio.run(
        run_agent("Check the Pipedream organization on LinkedIn and tell me about it")
    )
```


# Pipedream Slack
Source: https://docs.agno.com/examples/concepts/tools/mcp/pipedream_slack

This example shows how to use the Slack Pipedream MCP server with Agno Agents.

## Code

```python
"""
üí¨ Pipedream Slack MCP

This example shows how to use Pipedream MCP servers (in this case the Slack one) with Agno Agents.

1. Connect your Pipedream and Slack accounts: https://mcp.pipedream.com/app/slack
2. Get your Pipedream MCP server url: https://mcp.pipedream.com/app/slack
3. Set the MCP_SERVER_URL environment variable to the MCP server url you got above
4. Install dependencies: pip install agno mcp-sdk

"""

import asyncio
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.utils.log import log_exception

mcp_server_url = os.getenv("MCP_SERVER_URL")


async def run_agent(task: str) -> None:
    try:
        async with MCPTools(
            url=mcp_server_url, transport="sse", timeout_seconds=20
        ) as mcp:
            agent = Agent(
                model=OpenAIChat(id="gpt-5-mini"),
                tools=[mcp],
                markdown=True,
            )
            await agent.aprint_response(
                message=task,
                stream=True,
            )
    except Exception as e:
        log_exception(f"Unexpected error: {e}")


if __name__ == "__main__":
    # The agent can read channels, users, messages, etc.
    asyncio.run(run_agent("Show me the latest message in the channel #general"))

    # Use your real Slack name for this one to work!
    asyncio.run(
        run_agent("Send a message to <YOUR_NAME> saying 'Hello, I'm your Agno Agent!'")
    )
```


# Stagehand MCP agent
Source: https://docs.agno.com/examples/concepts/tools/mcp/stagehand

A web scraping agent that uses the Stagehand MCP server to automate browser interactions and create a structured content digest from Hacker News.

## Key Features

* **Safe Navigation**: Proper initialization sequence prevents common browser automation errors
* **Structured Data Extraction**: Methodical approach to extracting and organizing web content
* **Flexible Output**: Creates well-structured digests with headlines, summaries, and insights

## Prerequisites

Before running this example, you'll need:

* **Browserbase Account**: Get API credentials from [Browserbase](https://browserbase.com)
* **OpenAI API Key**: Get an API Key from [OpenAI](https://platform.openai.com/settings/organization/api-keys)

## Setup Instructions

### 1. Clone and Build Stagehand MCP Server

```bash
git clone https://github.com/browserbase/mcp-server-browserbase

# Navigate to the stagehand directory
cd mcp-server-browserbase/stagehand

# Install dependencies and build
npm install
npm run build
```

### 2. Install Python Dependencies

```bash
pip install agno mcp openai
```

### 3. Set Environment Variables

```bash
export BROWSERBASE_API_KEY=your_browserbase_api_key
export BROWSERBASE_PROJECT_ID=your_browserbase_project_id
export OPENAI_API_KEY=your_openai_api_key
```

## Code Example

```python
import asyncio
from os import environ
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from mcp import StdioServerParameters


async def run_agent(message: str) -> None:
    server_params = StdioServerParameters(
        command="node",
        # Update this path to the location where you cloned the repository
        args=["mcp-server-browserbase/stagehand/dist/index.js"],
        env=environ.copy(),
    )

    async with MCPTools(server_params=server_params, timeout_seconds=60) as mcp_tools:
        agent = Agent(
            model=OpenAIChat(id="gpt-5-mini"),
            tools=[mcp_tools],
            instructions=dedent("""\
                You are a web scraping assistant that creates concise reader's digests from Hacker News.

                CRITICAL INITIALIZATION RULES - FOLLOW EXACTLY:
                1. NEVER use screenshot tool until AFTER successful navigation
                2. ALWAYS start with stagehand_navigate first
                3. Wait for navigation success message before any other actions
                4. If you see initialization errors, restart with navigation only
                5. Use stagehand_observe and stagehand_extract to explore pages safely

                Available tools and safe usage order:
                - stagehand_navigate: Use FIRST to initialize browser
                - stagehand_extract: Use to extract structured data from pages
                - stagehand_observe: Use to find elements and understand page structure
                - stagehand_act: Use to click links and navigate to comments
                - screenshot: Use ONLY after navigation succeeds and page loads

                Your goal is to create a comprehensive but concise digest that includes:
                - Top headlines with brief summaries
                - Key themes and trends
                - Notable comments and insights
                - Overall tech news landscape overview

                Be methodical, extract structured data, and provide valuable insights.
            """),
            markdown=True,
                    )
        await agent.aprint_response(message, stream=True)


if __name__ == "__main__":
    asyncio.run(
        run_agent(
            "Create a comprehensive Hacker News Reader's Digest from https://news.ycombinator.com"
        )
    )
```

## Available Tools

The Stagehand MCP server provides several tools for web automation:

| Tool                 | Purpose                                     | Usage Notes                            |
| -------------------- | ------------------------------------------- | -------------------------------------- |
| `stagehand_navigate` | Navigate to web pages                       | **Use first** for initialization       |
| `stagehand_extract`  | Extract structured data                     | Safe for content extraction            |
| `stagehand_observe`  | Find elements and understand page structure | Good for exploration                   |
| `stagehand_act`      | Interact with page elements                 | Click, type, scroll actions            |
| `screenshot`         | Take screenshots                            | **Use only after** navigation succeeds |


# Stripe MCP agent
Source: https://docs.agno.com/examples/concepts/tools/mcp/stripe



Using the [Stripe MCP server](https://github.com/stripe/agent-toolkit/tree/main/modelcontextprotocol) to create an Agent that can interact with the Stripe API:

```python
"""üíµ Stripe MCP Agent - Manage Your Stripe Operations

This example demonstrates how to create an Agno agent that interacts with the Stripe API via the Model Context Protocol (MCP). This agent can create and manage Stripe objects like customers, products, prices, and payment links using natural language commands.


Setup:
2. Install Python dependencies: `pip install agno mcp-sdk`
3. Set Environment Variable: export STRIPE_SECRET_KEY=***.

Stripe MCP Docs: https://github.com/stripe/agent-toolkit
"""

import asyncio
import os
from textwrap import dedent

from agno.agent import Agent
from agno.tools.mcp import MCPTools
from agno.utils.log import log_error, log_exception, log_info


async def run_agent(message: str) -> None:
    """
    Sets up the Stripe MCP server and initialize the Agno agent
    """
    # Verify Stripe API Key is available
    stripe_api_key = os.getenv("STRIPE_SECRET_KEY")
    if not stripe_api_key:
        log_error("STRIPE_SECRET_KEY environment variable not set.")
        return

    enabled_tools = "paymentLinks.create,products.create,prices.create,customers.create,customers.read"

    # handle different Operating Systems
    npx_command = "npx.cmd" if os.name == "nt" else "npx"

    try:
        # Initialize MCP toolkit with Stripe server
        async with MCPTools(
            command=f"{npx_command} -y @stripe/mcp --tools={enabled_tools} --api-key={stripe_api_key}"
        ) as mcp_toolkit:
            agent = Agent(
                name="StripeAgent",
                instructions=dedent("""\
                    You are an AI assistant specialized in managing Stripe operations.
                    You interact with the Stripe API using the available tools.

                    - Understand user requests to create or list Stripe objects (customers, products, prices, payment links).
                    - Clearly state the results of your actions, including IDs of created objects or lists retrieved.
                    - Ask for clarification if a request is ambiguous.
                    - Use markdown formatting, especially for links or code snippets.
                    - Execute the necessary steps sequentially if a request involves multiple actions (e.g., create product, then price, then link).
                """),
                tools=[mcp_toolkit],
                markdown=True,
                            )

            # Run the agent with the provided task
            log_info(f"Running agent with assignment: '{message}'")
            await agent.aprint_response(message, stream=True)

    except FileNotFoundError:
        error_msg = f"Error: '{npx_command}' command not found. Please ensure Node.js and npm/npx are installed and in your system's PATH."
        log_error(error_msg)
    except Exception as e:
        log_exception(f"An unexpected error occurred during agent execution: {e}")


if __name__ == "__main__":
    task = "Create a new Stripe product named 'iPhone'. Then create a price of $999.99 USD for it. Finally, create a payment link for that price."
    asyncio.run(run_agent(task))


# Example prompts:
"""
Customer Management:
- "Create a customer. Name: ACME Corp, Email: billing@acme.example.com"
- "List my customers."
- "Find customer by email 'jane.doe@example.com'" # Note: Requires 'customers.retrieve' or search capability

Product and Price Management:
- "Create a new product called 'Basic Plan'."
- "Create a recurring monthly price of $10 USD for product 'Basic Plan'."
- "Create a product 'Ebook Download' and a one-time price of $19.95 USD."
- "List all products." # Note: Requires 'products.list' capability
- "List all prices." # Note: Requires 'prices.list' capability

Payment Links:
- "Create a payment link for the $10 USD monthly 'Basic Plan' price."
- "Generate a payment link for the '$19.95 Ebook Download'."

Combined Tasks:
- "Create a product 'Pro Service', add a price $150 USD (one-time), and give me the payment link."
- "Register a new customer 'support@example.com' named 'Support Team'."
"""


```


# Supabase MCP agent
Source: https://docs.agno.com/examples/concepts/tools/mcp/supabase



Using the [Supabase MCP server](https://github.com/supabase-community/supabase-mcp) to create an Agent that can create projects, database schemas, edge functions, and more:

```python
"""üîë Supabase MCP Agent - Showcase Supabase MCP Capabilities

This example demonstrates how to use the Supabase MCP server to create projects, database schemas, edge functions, and more.

Setup:
1. Install Python dependencies: `pip install agno mcp-sdk`
2. Create a Supabase Access Token: https://supabase.com/dashboard/account/tokens and set it as the SUPABASE_ACCESS_TOKEN environment variable.
"""

import asyncio
import os
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from agno.tools.reasoning import ReasoningTools
from agno.utils.log import log_error, log_exception, log_info


async def run_agent(task: str) -> None:
    token = os.getenv("SUPABASE_ACCESS_TOKEN")
    if not token:
        log_error("SUPABASE_ACCESS_TOKEN environment variable not set.")
        return

    npx_cmd = "npx.cmd" if os.name == "nt" else "npx"

    try:
        async with MCPTools(
            f"{npx_cmd} -y @supabase/mcp-server-supabase@latest --access-token={token}"
        ) as mcp:
            instructions = dedent(f"""
                You are an expert Supabase MCP architect. Given the project description:
                {task}

                Automatically perform the following steps :
                1. Plan the entire database schema based on the project description.
                2. Call `list_organizations` and select the first organization in the response.
                3. Use `get_cost(type='project')` to estimate project creation cost and mention the cost in your response.
                4. Create a new Supabase project with `create_project`, passing the confirmed cost ID.
                5. Poll project status with `get_project` until the status is `ACTIVE_HEALTHY`.
                6. Analyze the project requirements and propose a complete, normalized SQL schema (tables,  columns, data types, indexes, constraints, triggers, and functions) as DDL statements.
                7. Apply the schema using `apply_migration`, naming the migration `initial_schema`.
                8. Validate the deployed schema via `list_tables` and `list_extensions`.
                8. Deploy a simple health-check edge function with `deploy_edge_function`.
                9. Retrieve and print the project URL (`get_project_url`) and anon key (`get_anon_key`).
            """)
            agent = Agent(
                model=OpenAIChat(id="o4-mini"),
                instructions=instructions,
                tools=[mcp, ReasoningTools(add_instructions=True)],
                markdown=True,
            )

            log_info(f"Running Supabase project agent for: {task}")
            await agent.aprint_response(
                message=task,
                stream=True,
                stream_intermediate_steps=True,
                show_full_reasoning=True,
            )
    except Exception as e:
        log_exception(f"Unexpected error: {e}")


if __name__ == "__main__":
    demo_description = (
        "Develop a cloud-based SaaS platform with AI-powered task suggestions, calendar syncing, predictive prioritization, "
        "team collaboration, and project analytics."
    )
    asyncio.run(run_agent(demo_description))


# Example prompts to try:
"""
A SaaS tool that helps businesses automate document processing using AI. Users can upload invoices, contracts, or PDFs and get structured data, smart summaries, and red flag alerts for compliance or anomalies. Ideal for legal teams, accountants, and enterprise back offices.

An AI-enhanced SaaS platform for streamlining the recruitment process. Features include automated candidate screening using NLP, AI interview scheduling, bias detection in job descriptions, and pipeline analytics. Designed for fast-growing startups and mid-sized HR teams.

An internal SaaS tool for HR departments to monitor employee wellbeing. Combines weekly mood check-ins, anonymous feedback, and AI-driven burnout detection models. Integrates with Slack and HR systems to support a healthier workplace culture.
"""


```


# Azure OpenAI Tools
Source: https://docs.agno.com/examples/concepts/tools/models/azure_openai



## Code

```python cookbook/tools/azure_openai_tools.py
from agno.agent import Agent
from agno.tools.models.azure_openai import AzureOpenAITools

agent = Agent(
    instructions=[
        "You are an AI image generation assistant using Azure OpenAI",
        "Generate high-quality images based on user descriptions",
        "Provide detailed descriptions of the generated images",
    ],
    tools=[AzureOpenAITools()],
    markdown=True,
)

agent.print_response("Generate an image of a sunset over mountains")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your credentials">
    ```bash
    export AZURE_OPENAI_API_KEY=your-azure-openai-api-key
    export AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
    export AZURE_OPENAI_IMAGE_DEPLOYMENT=your-dalle-deployment-name
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/azure_openai_tools.py
      ```

      ```bash Windows
      python cookbook/tools/azure_openai_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Morph Tools
Source: https://docs.agno.com/examples/concepts/tools/models/morph



## Code

```python cookbook/tools/morph_tools.py
from agno.agent import Agent
from agno.tools.models.morph import MorphTools

agent = Agent(
    instructions=[
        "You are a code editing assistant using Morph's advanced AI capabilities",
        "Help users modify, improve, and refactor their code intelligently",
        "Apply code changes efficiently while maintaining code quality",
    ],
    tools=[MorphTools()],
    markdown=True,
)

agent.print_response("Refactor this Python function to be more efficient and add type hints")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export MORPH_API_KEY=your-morph-api-key
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/morph_tools.py
      ```

      ```bash Windows
      python cookbook/tools/morph_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Nebius Tools
Source: https://docs.agno.com/examples/concepts/tools/models/nebius



## Code

```python cookbook/tools/nebius_tools.py
from agno.agent import Agent
from agno.tools.models.nebius import NebiusTools

agent = Agent(
    instructions=[
        "You are an AI image generation assistant using Nebius AI Studio",
        "Create high-quality images based on user descriptions",
        "Provide detailed information about the generated images",
    ],
    tools=[NebiusTools()],
    markdown=True,
)

agent.print_response("Generate an image of a futuristic city with flying cars at sunset")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export NEBIUS_API_KEY=your-nebius-api-key
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/nebius_tools.py
      ```

      ```bash Windows
      python cookbook/tools/nebius_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Meeting Summary Agent
Source: https://docs.agno.com/examples/concepts/tools/models/openai/meeting-summarizer

Multi-modal Agno agent that transcribes meeting recordings, extracts key insights, generates visual summaries, and creates audio summaries using OpenAI tools.

This example demonstrates a multi-modal meeting summarizer and visualizer agent that uses OpenAITools and ReasoningTools to transcribe a meeting recording, extract key insights, generate a visual summary, and synthesize an audio summary.

## Code

```python ref/meeting_summarizer_agent.py
"""Example: Meeting Summarizer & Visualizer Agent

This script uses OpenAITools (transcribe_audio, generate_image, generate_speech)
to process a meeting recording, summarize it, visualize it, and create an audio summary.

Requires: pip install openai agno
"""

import base64
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.openai import OpenAITools
from agno.tools.reasoning import ReasoningTools
from agno.utils.media import download_file, save_base64_data

input_audio_url: str = (
    "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/sample_audio.mp3"
)

local_audio_path = Path("tmp/meeting_recording.mp3")
print(f"Downloading file to local path: {local_audio_path}")
download_file(input_audio_url, local_audio_path)

meeting_agent: Agent = Agent(
    model=Gemini(id="gemini-2.0-flash"),
    tools=[OpenAITools(), ReasoningTools()],
    description=dedent("""\
        You are an efficient Meeting Assistant AI.
        Your purpose is to process audio recordings of meetings, extract key information,
        create a visual representation, and provide an audio summary.
    """),
    instructions=dedent("""\
        Follow these steps precisely:
        1. Receive the path to an audio file.
        2. Use the `transcribe_audio` tool to get the text transcription.
        3. Analyze the transcription and write a concise summary highlighting key discussion points, decisions, and action items.
        4. Based *only* on the summary created in step 3, generating important meeting points. This should be a essentially an overview of the summary's content properly ordered and formatted in the form of meeting minutes.
        5. Convert the meeting minutes into an audio summary using the `generate_speech` tool.
    """),
    markdown=True,
)

response = meeting_agent.run(
    f"Please process the meeting recording located at '{local_audio_path}'"
)
if response.audio:
    base64_audio = base64.b64encode(response.audio[0].content).decode("utf-8")
    save_base64_data(base64_audio, Path("tmp/meeting_summary.mp3"))
    print(f"Meeting summary saved to: {Path('tmp/meeting_summary.mp3')}")
```

## Usage

<Steps>
  <Step title="Install dependencies">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the example">
    ```bash
    python ref/meeting_summarizer_agent.py
    ```
  </Step>
</Steps>

By default, the audio summary will be saved to `tmp/meeting_summary.mp3`.


# Recipe RAG Image Agent
Source: https://docs.agno.com/examples/concepts/tools/models/openai/rag-recipe-image



This example demonstrates a multi-modal RAG agent that uses Groq and OpenAITools to search a PDF recipe knowledge base and generate a step-by-step visual guide for recipes.

## Code

```python ref/recipe_rag_image.py
"""Example: Multi-Modal RAG & Image Agent

An agent that uses Llama 4 for multi-modal RAG and OpenAITools to create a visual, step-by-step image manual for a recipe.

Run: `pip install openai agno groq cohere` to install the dependencies
"""

from pathlib import Path

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.tools.openai import OpenAITools
from agno.utils.media import download_image
from agno.vectordb.pgvector import PgVector

knowledge_base = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="embed_vision_documents",
        embedder=CohereEmbedder(
            id="embed-v4.0",
        ),
    ),
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    name="EmbedVisionRAGAgent",
    model=Groq(id="meta-llama/llama-4-scout-17b-16e-instruct"),
    tools=[OpenAITools()],
    knowledge=knowledge_base,
    instructions=[
        "You are a specialized recipe assistant.",
        "When asked for a recipe:",
        "1. Search the knowledge base to retrieve the relevant recipe details.",
        "2. Analyze the retrieved recipe steps carefully.",
        "3. Use the `generate_image` tool to create a visual, step-by-step image manual for the recipe.",
        "4. Present the recipe text clearly and mention that you have generated an accompanying image manual. Add instructions while generating the image.",
    ],
    markdown=True,
    debug_mode=True,
)

response = agent.print_response(
    "What is the recipe for a Thai curry?",
)
if response.images:
    download_image(response.images[0].url, Path("tmp/recipe_image.png"))
```

## Usage

<Steps>
  <Step title="Install dependencies">
    ```bash
    pip install openai agno groq cohere
    ```
  </Step>

  <Step title="Run the example">
    ```bash
    python ref/recipe_rag_image.py
    ```
  </Step>
</Steps>

By default, the generated image will be saved to `tmp/recipe_image.png`.


# Airflow Tools
Source: https://docs.agno.com/examples/concepts/tools/others/airflow



## Code

```python cookbook/tools/airflow_tools.py
from agno.agent import Agent
from agno.tools.airflow import AirflowTools

agent = Agent(
    tools=[AirflowTools(dags_dir="tmp/dags", enable_save_dag=True, enable_read_dag=True)],
        markdown=True,
)

dag_content = """
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# Using 'schedule' instead of deprecated 'schedule_interval'
with DAG(
    'example_dag',
    default_args=default_args,
    description='A simple example DAG',
    schedule='@daily',  # Changed from schedule_interval
    catchup=False
) as dag:

    def print_hello():
        print("Hello from Airflow!")
        return "Hello task completed"

    task = PythonOperator(
        task_id='hello_task',
        python_callable=print_hello,
        dag=dag,
    )
"""

agent.run(f"Save this DAG file as 'example_dag.py': {dag_content}")
agent.print_response("Read the contents of 'example_dag.py'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U apache-airflow openai agno
    ```
  </Step>

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/airflow_tools.py
      ```

      ```bash Windows
      python cookbook/tools/airflow_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Apify Tools
Source: https://docs.agno.com/examples/concepts/tools/others/apify



## Code

```python cookbook/tools/apify_tools.py
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(tools=[ApifyTools()])
agent.print_response("Tell me about https://docs.agno.com/introduction", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export APIFY_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U apify-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/apify_tools.py
      ```

      ```bash Windows
      python cookbook/tools/apify_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# AWS Lambda Tools
Source: https://docs.agno.com/examples/concepts/tools/others/aws_lambda



## Code

```python cookbook/tools/aws_lambda_tools.py
from agno.agent import Agent
from agno.tools.aws_lambda import AWSLambdaTools

agent = Agent(
    tools=[AWSLambdaTools(region_name="us-east-1")],
    name="AWS Lambda Agent",
    )

agent.print_response("List all Lambda functions in our AWS account", markdown=True)
agent.print_response(
    "Invoke the 'hello-world' Lambda function with an empty payload", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=xxx
    export AWS_SECRET_ACCESS_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/aws_lambda_tools.py
      ```

      ```bash Windows
      python cookbook/tools/aws_lambda_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# AWS SES Tools
Source: https://docs.agno.com/examples/concepts/tools/others/aws_ses



## Code

```python cookbook/tools/aws_ses_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.aws_ses import AWSSESTool
from agno.tools.duckduckgo import DuckDuckGoTools

# Configure email settings
sender_email = "verified-sender@example.com"  # Your verified SES email
sender_name = "AI Research Updates"
region_name = "us-east-1"

# Create an agent that can research and send personalized email updates
agent = Agent(
    name="Research Newsletter Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    description="""You are an AI research specialist who creates and sends
    personalized email newsletters about the latest developments in artificial
    intelligence and technology.""",
    instructions=[
        """When given a prompt:,
        1. Extract the recipient's email address carefully. Look for the
        complete email in format 'user@domain.com'.,
        2. Research the latest AI developments using DuckDuckGo,
        3. Compose a concise, engaging email with:
           - A compelling subject line,
           - 3-4 key developments or news items,
           - Brief explanations of why they matter,
           - Links to sources,
        4. Format the content in a clean, readable way,
        5. Send the email using AWS SES. IMPORTANT: The receiver_email parameter
        must be the COMPLETE email address including the @ symbol and domain.""",
    ],
    tools=[
        AWSSESTool(
            sender_email=sender_email,
            sender_name=sender_name,
            region_name=region_name
        ),
        DuckDuckGoTools(),
    ],
    markdown=True,
    )

agent.print_response(
    "Research AI developments in healthcare from the past week with a focus on practical applications in clinical settings. Send the summary via email to johndoe@example.com"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  {" "}

  <Step title="Set up AWS SES">
    ### Verify your email/domain: **For testing:** 1. Go to \[AWS SES

    Console]\([https://console.aws.amazon.com/ses/home](https://console.aws.amazon.com/ses/home)) > Verified Identities >
    Create Identity 2. Choose "Email Address" verification 3. Click verification
    link sent to your email **For production:** 1. Choose "Domain" and follow DNS
    verification steps 2. Add DKIM and SPF records to your domain's DNS **Note:**
    In sandbox mode, both sender and recipient emails must be verified.
  </Step>

  {" "}

  <Step title="Configure AWS credentials">
    ### Create IAM user: 1. Go to IAM Console > Users > Add User 2. Enable

    "Programmatic access" 3. Attach 'AmazonSESFullAccess' policy ### Set
    credentials (choose one method): **Method 1 - Using AWS CLI:** `bash aws
      configure ` **Method 2 - Environment variables:** `bash export
      AWS_ACCESS_KEY_ID=xxx export AWS_SECRET_ACCESS_KEY=xxx export
      AWS_DEFAULT_REGION=us-east-1 export OPENAI_API_KEY=xxx `
  </Step>

  {" "}

  <Step title="Install libraries">
    `bash pip install -U boto3 openai ddgs agno `
  </Step>

  {" "}

  <Step title="Run Agent">
    `bash python cookbook/tools/aws_ses_tools.py `
  </Step>

  <Step title="Troubleshooting">
    If emails aren't sending, check:

    * Both sender and recipient are verified (in sandbox mode)
    * AWS credentials are correctly configured
    * You're within sending limits
    * Your IAM user has correct SES permissions
    * Use SES Console's 'Send Test Email' feature to verify setup
  </Step>
</Steps>


# Bitbucket Tools
Source: https://docs.agno.com/examples/concepts/tools/others/bitbucket



## Code

```python cookbook/tools/bitbucket_tools.py
from agno.agent import Agent
from agno.tools.bitbucket import BitbucketTools

agent = Agent(
    instructions=[
        "Use your tools to answer questions about the Bitbucket repository",
        "Do not create any issues or pull requests unless explicitly asked to do so",
    ],
    tools=[BitbucketTools(
        workspace="your-workspace",
        repo_slug="your-repository"
    )],
    markdown=True,
)

agent.print_response("List all open pull requests in the repository")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Bitbucket credentials">
    ```bash
    export BITBUCKET_USERNAME=your-username
    export BITBUCKET_PASSWORD=your-app-password
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/bitbucket_tools.py
      ```

      ```bash Windows
      python cookbook/tools/bitbucket_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Brandfetch Tools
Source: https://docs.agno.com/examples/concepts/tools/others/brandfetch



## Code

```python cookbook/tools/brandfetch_tools.py
from agno.agent import Agent
from agno.tools.brandfetch import BrandfetchTools

agent = Agent(
    instructions=[
        "You are a brand research assistant that helps find brand information",
        "Use Brandfetch to retrieve logos, colors, and other brand assets",
        "Provide comprehensive brand information when requested",
    ],
    tools=[BrandfetchTools()],
    markdown=True,
)

agent.print_response("Find brand information for Apple Inc.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export BRANDFETCH_API_KEY=your-brandfetch-api-key
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U httpx openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/brandfetch_tools.py
      ```

      ```bash Windows
      python cookbook/tools/brandfetch_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cal.com Tools
Source: https://docs.agno.com/examples/concepts/tools/others/calcom



## Code

```python cookbook/tools/calcom_tools.py
from datetime import datetime

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.calcom import CalComTools

agent = Agent(
    name="Calendar Assistant",
    instructions=[
        f"You're scheduing assistant. Today is {datetime.now()}.",
        "You can help users by:",
        "    - Finding available time slots",
        "    - Creating new bookings",
        "    - Managing existing bookings (view, reschedule, cancel)",
        "    - Getting booking details",
        "    - IMPORTANT: In case of rescheduling or cancelling booking, call the get_upcoming_bookings function to get the booking uid. check available slots before making a booking for given time",
        "Always confirm important details before making bookings or changes.",
    ],
    model=OpenAIChat(id="gpt-4"),
    tools=[CalComTools(user_timezone="America/New_York")],
        markdown=True,
)

agent.print_response("What are my bookings for tomorrow?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export CALCOM_API_KEY=xxx
    export CALCOM_EVENT_TYPE_ID=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests pytz openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/calcom_tools.py
      ```

      ```bash Windows
      python cookbook/tools/calcom_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ClickUp Tools
Source: https://docs.agno.com/examples/concepts/tools/others/clickup



## Code

```python cookbook/tools/clickup_tools.py
from agno.agent import Agent
from agno.tools.clickup import ClickUpTools

agent = Agent(
    instructions=[
        "You are a ClickUp project management assistant",
        "Help users manage their tasks, projects, and workspaces",
        "Create, update, and organize tasks efficiently",
    ],
    tools=[ClickUpTools()],
    markdown=True,
)

agent.print_response("Create a new task called 'Review documentation' and list all current tasks")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export CLICKUP_API_KEY=your-clickup-api-key
    export MASTER_SPACE_ID=your-space-id
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/clickup_tools.py
      ```

      ```bash Windows
      python cookbook/tools/clickup_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Composio Tools
Source: https://docs.agno.com/examples/concepts/tools/others/composio



## Code

```python cookbook/tools/composio_tools.py
from agno.agent import Agent
from composio_agno import Action, ComposioToolSet

toolset = ComposioToolSet()
composio_tools = toolset.get_tools(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)

agent = Agent(tools=composio_tools)
agent.print_response("Can you star agno-agi/agno repo?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export COMPOSIO_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U composio-agno openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/composio_tools.py
      ```

      ```bash Windows
      python cookbook/tools/composio_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confluence Tools
Source: https://docs.agno.com/examples/concepts/tools/others/confluence



## Code

```python cookbook/tools/confluence_tools.py
from agno.agent import Agent
from agno.tools.confluence import ConfluenceTools

agent = Agent(
    name="Confluence agent",
    tools=[ConfluenceTools()],
        markdown=True,
)

agent.print_response("How many spaces are there and what are their names?")
agent.print_response(
    "What is the content present in page 'Large language model in LLM space'"
)
agent.print_response("Can you extract all the page names from 'LLM' space")
agent.print_response("Can you create a new page named 'TESTING' in 'LLM' space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API credentials">
    ```bash
    export CONFLUENCE_API_TOKEN=xxx
    export CONFLUENCE_SITE_URL=xxx
    export CONFLUENCE_USERNAME=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U atlassian-python-api openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/confluence_tools.py
      ```

      ```bash Windows
      python cookbook/tools/confluence_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Custom API Tools
Source: https://docs.agno.com/examples/concepts/tools/others/custom_api



## Code

```python cookbook/tools/custom_api_tools.py
from agno.agent import Agent
from agno.tools.api import CustomApiTools

agent = Agent(
    tools=[CustomApiTools(base_url="https://dog.ceo/api")],
    markdown=True,
)

agent.print_response(
    'Make API calls to the following two different endpoints: /breeds/image/random and /breeds/list/all to get a random dog image and list of dog breeds respectively. Use GET method for both calls.'
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/custom_api_tools.py
      ```

      ```bash Windows
      python cookbook/tools/custom_api_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DALL-E Tools
Source: https://docs.agno.com/examples/concepts/tools/others/dalle



## Code

```python cookbook/tools/dalle_tools.py
from pathlib import Path

from agno.agent import Agent
from agno.tools.dalle import DalleTools
from agno.utils.media import download_image

agent = Agent(tools=[DalleTools()], name="DALL-E Image Generator")

agent.print_response(
    "Generate an image of a futuristic city with flying cars and tall skyscrapers",
    markdown=True,
)

custom_dalle = DalleTools(
    model="dall-e-3", size="1792x1024", quality="hd", style="natural"
)

agent_custom = Agent(
    tools=[custom_dalle],
    name="Custom DALL-E Generator",
    )

response = agent_custom.run(
    "Create a panoramic nature scene showing a peaceful mountain lake at sunset",
    markdown=True,
)
if response.images:
    download_image(
        url=response.images[0].url,
        save_path=Path(__file__).parent.joinpath("tmp/nature.jpg"),
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx  # Required for DALL-E image generation
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/dalle_tools.py
      ```

      ```bash Windows
      python cookbook/tools/dalle_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Daytona Code Execution
Source: https://docs.agno.com/examples/concepts/tools/others/daytona

Learn to use Agno's Daytona integration to run your Agent-generated code in a secure sandbox.

## Code

```python cookbook/tools/daytona_tools.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.daytona import DaytonaTools

daytona_tools = DaytonaTools()

# Setup an Agent focused on coding tasks, with access to the Daytona tools
agent = Agent(
    name="Coding Agent with Daytona tools",
    id="coding-agent",
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[daytona_tools],
    markdown=True,
        instructions=[
        "You are an expert at writing and validating Python code. You have access to a remote, secure Daytona sandbox.",
        "Your primary purpose is to:",
        "1. Write clear, efficient Python code based on user requests",
        "2. Execute and verify the code in the Daytona sandbox",
        "3. Share the complete code with the user, as this is the main use case",
        "4. Provide thorough explanations of how the code works",
        "You can use the run_python_code tool to run Python code in the Daytona sandbox.",
        "Guidelines:",
        "- ALWAYS share the complete code with the user, properly formatted in code blocks",
        "- Verify code functionality by executing it in the sandbox before sharing",
        "- Iterate and debug code as needed to ensure it works correctly",
        "- Use pandas, matplotlib, and other Python libraries for data analysis when appropriate",
        "- Create proper visualizations when requested and add them as image artifacts to show inline",
        "- Handle file uploads and downloads properly",
        "- Explain your approach and the code's functionality in detail",
        "- Format responses with both code and explanations for maximum clarity",
        "- Handle errors gracefully and explain any issues encountered",
    ],
)


agent.print_response(
    "Write Python code to generate the first 10 Fibonacci numbers and calculate their sum and average"
)
```


# Desi Vocal Tools
Source: https://docs.agno.com/examples/concepts/tools/others/desi_vocal



## Code

```python cookbook/tools/desi_vocal_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.desi_vocal import DesiVocalTools

audio_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DesiVocalTools()],
    description="You are an AI agent that can generate audio using the DesiVocal API.",
    instructions=[
        "When the user asks you to generate audio, use the `text_to_speech` tool to generate the audio.",
        "You'll generate the appropriate prompt to send to the tool to generate audio.",
        "You don't need to find the appropriate voice first, I already specified the voice to user.",
        "Return the audio file name in your response. Don't convert it to markdown.",
        "Generate the text prompt we send in hindi language",
    ],
    markdown=True,
    debug_mode=True,
    )

audio_agent.print_response(
    "Generate a very small audio of history of french revolution"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DESI_VOCAL_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/desi_vocal_tools.py
      ```

      ```bash Windows
      python cookbook/tools/desi_vocal_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# E2B Code Execution
Source: https://docs.agno.com/examples/concepts/tools/others/e2b

Learn to use Agno's E2B integration to run your Agent-generated code in a secure sandbox.

## Code

```python cookbook/tools/e2b_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.e2b import E2BTools

e2b_tools = E2BTools(
    timeout=600,  # 10 minutes timeout (in seconds)
)

agent = Agent(
    name="Code Execution Sandbox",
    id="e2b-sandbox",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[e2b_tools],
    markdown=True,
        instructions=[
        "You are an expert at writing and validating Python code using a secure E2B sandbox environment.",
        "Your primary purpose is to:",
        "1. Write clear, efficient Python code based on user requests",
        "2. Execute and verify the code in the E2B sandbox",
        "3. Share the complete code with the user, as this is the main use case",
        "4. Provide thorough explanations of how the code works",
    ],
)

# Example: Generate Fibonacci numbers
agent.print_response(
    "Write Python code to generate the first 10 Fibonacci numbers and calculate their sum and average"
)

# Example: Data visualization
agent.print_response(
    "Write a Python script that creates a sample dataset of sales by region and visualize it with matplotlib"
)

# Example: Run a web server
agent.print_response(
    "Create a simple FastAPI web server that displays 'Hello from E2B Sandbox!' and run it to get a public URL"
)

# Example: Sandbox management
agent.print_response("What's the current status of our sandbox and how much time is left before timeout?")

# Example: File operations
agent.print_response("Create a text file with the current date and time, then read it back")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Create an E2B account">
    Create an account at [E2B](https://e2b.dev/) and get your API key from the dashboard.
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install e2b_code_interpreter
    ```
  </Step>

  <Step title="Set your API Key">
    <CodeGroup>
      ```bash Mac/Linux
      export E2B_API_KEY=your_api_key_here
      ```

      ```bash Windows (Command Prompt)
      set E2B_API_KEY=your_api_key_here
      ```

      ```bash Windows (PowerShell)
      $env:E2B_API_KEY="your_api_key_here"
      ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac/Linux
      python cookbook/tools/e2b_tools.py
      ```

      ```bash Windows
      python cookbook\tools\e2b_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# EVM Tools
Source: https://docs.agno.com/examples/concepts/tools/others/evm



## Code

```python cookbook/tools/evm_tools.py
from agno.agent import Agent
from agno.tools.evm import EvmTools

agent = Agent(
    instructions=[
        "You are a blockchain assistant that helps with Ethereum transactions",
        "Help users send transactions and interact with smart contracts",
        "Always verify transaction details before executing",
    ],
    tools=[EvmTools()],
    markdown=True,
)

agent.print_response("Check my account balance and estimate gas for sending 0.01 ETH")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your credentials">
    ```bash
    export EVM_PRIVATE_KEY=your-private-key
    export EVM_RPC_URL=https://your-rpc-endpoint.com
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U web3 openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/evm_tools.py
      ```

      ```bash Windows
      python cookbook/tools/evm_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Fal Tools
Source: https://docs.agno.com/examples/concepts/tools/others/fal



## Code

```python cookbook/tools/fal_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

fal_agent = Agent(
    name="Fal Video Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[FalTools("fal-ai/hunyuan-video")],
    description="You are an AI agent that can generate videos using the Fal API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    )

fal_agent.print_response("Generate video of balloon in the ocean")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export FAL_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U fal openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/fal_tools.py
      ```

      ```bash Windows
      python cookbook/tools/fal_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Financial Datasets Tools
Source: https://docs.agno.com/examples/concepts/tools/others/financial_datasets



## Code

```python cookbook/tools/financial_datasets_tools.py
from agno.agent import Agent
from agno.tools.financial_datasets import FinancialDatasetsTools

agent = Agent(
    name="Financial Data Agent",
    tools=[
        FinancialDatasetsTools(),  # For accessing financial data
    ],
    description="You are a financial data specialist that helps analyze financial information for stocks and cryptocurrencies.",
    instructions=[
        "When given a financial query:",
        "1. Use appropriate Financial Datasets methods based on the query type",
        "2. Format financial data clearly and highlight key metrics",
        "3. For financial statements, compare important metrics with previous periods when relevant",
        "4. Calculate growth rates and trends when appropriate",
        "5. Handle errors gracefully and provide meaningful feedback",
    ],
    markdown=True,
    )

# Example 1: Financial Statements
print("\n=== Income Statement Example ===")
agent.print_response(
    "Get the most recent income statement for AAPL and highlight key metrics",
    stream=True,
)

# Example 2: Balance Sheet Analysis
print("\n=== Balance Sheet Analysis Example ===")
agent.print_response(
    "Analyze the balance sheets for MSFT over the last 3 years. Focus on debt-to-equity ratio and cash position.",
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API credentials">
    ```bash
    export FINANCIAL_DATASETS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/tools/financial_datasets_tools.py
      ```

      ```bash Windows
        python cookbook/tools/financial_datasets_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Giphy Tools
Source: https://docs.agno.com/examples/concepts/tools/others/giphy



## Code

```python cookbook/tools/giphy_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.giphy import GiphyTools

gif_agent = Agent(
    name="Gif Generator Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GiphyTools(limit=5)],
    description="You are an AI agent that can generate gifs using Giphy.",
    instructions=[
        "When the user asks you to create a gif, come up with the appropriate Giphy query and use the `search_gifs` tool to find the appropriate gif.",
    ],
    debug_mode=True,
    )

gif_agent.print_response("I want a gif to send to a friend for their birthday.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GIPHY_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U giphy_client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/giphy_tools.py
      ```

      ```bash Windows
      python cookbook/tools/giphy_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# GitHub Tools
Source: https://docs.agno.com/examples/concepts/tools/others/github



## Code

```python cookbook/tools/github_tools.py
from agno.agent import Agent
from agno.tools.github import GithubTools

agent = Agent(
    instructions=[
        "Use your tools to answer questions about the repo: agno-agi/agno",
        "Do not create any issues or pull requests unless explicitly asked to do so",
    ],
    tools=[GithubTools()],
    )
agent.print_response("List open pull requests", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your GitHub token">
    ```bash
    export GITHUB_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U PyGithub openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/github_tools.py
      ```

      ```bash Windows
      python cookbook/tools/github_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google Calendar Tools
Source: https://docs.agno.com/examples/concepts/tools/others/google_calendar



## Code

```python cookbook/tools/google_calendar_tools.py
from agno.agent import Agent
from agno.tools.googlecalendar import GoogleCalendarTools

agent = Agent(
    tools=[GoogleCalendarTools()],
        markdown=True,
)

agent.print_response("What events do I have today?")
agent.print_response("Schedule a meeting with John tomorrow at 2pm")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set up Google Calendar credentials">
    ```bash
    export GOOGLE_CALENDAR_CREDENTIALS=path/to/credentials.json
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-auth-oauthlib google-auth-httplib2 google-api-python-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/google_calendar_tools.py
      ```

      ```bash Windows
      python cookbook/tools/google_calendar_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google Maps Tools
Source: https://docs.agno.com/examples/concepts/tools/others/google_maps



## Code

```python cookbook/tools/google_maps_tools.py
from agno.agent import Agent
from agno.tools.google_maps import GoogleMapTools
from agno.tools.crawl4ai import Crawl4aiTools  # Optional: for enriching place data

agent = Agent(
    name="Maps API Demo Agent",
    tools=[
        GoogleMapTools(),
        Crawl4aiTools(max_length=5000),  # Optional: for scraping business websites
    ],
    description="Location and business information specialist for mapping and location-based queries.",
    markdown=True,
    )

# Example 1: Business Search
print("\n=== Business Search Example ===")
agent.print_response(
    "Find me highly rated Indian restaurants in Phoenix, AZ with their contact details",
    markdown=True,
    stream=True,
)

# Example 2: Directions
print("\n=== Directions Example ===")
agent.print_response(
    """Get driving directions from 'Phoenix Sky Harbor Airport' to 'Desert Botanical Garden', 
    avoiding highways if possible""",
    markdown=True,
    stream=True,
)

# Example 3: Address Validation and Geocoding
print("\n=== Address Validation and Geocoding Example ===")
agent.print_response(
    """Please validate and geocode this address: 
    '1600 Amphitheatre Parkway, Mountain View, CA'""",
    markdown=True,
    stream=True,
)

# Example 4: Distance Matrix
print("\n=== Distance Matrix Example ===")
agent.print_response(
    """Calculate the travel time and distance between these locations in Phoenix:
    Origins: ['Phoenix Sky Harbor Airport', 'Downtown Phoenix']
    Destinations: ['Desert Botanical Garden', 'Phoenix Zoo']""",
    markdown=True,
    stream=True,
)

# Example 5: Location Analysis
print("\n=== Location Analysis Example ===")
agent.print_response(
    """Analyze this location in Phoenix:
    Address: '2301 N Central Ave, Phoenix, AZ 85004'
    Please provide:
    1. Exact coordinates
    2. Nearby landmarks
    3. Elevation data
    4. Local timezone""",
    markdown=True,
    stream=True,
)

# Example 6: Multi-mode Transit Comparison
print("\n=== Transit Options Example ===")
agent.print_response(
    """Compare different travel modes from 'Phoenix Convention Center' to 'Phoenix Art Museum':
    1. Driving
    2. Walking
    3. Transit (if available)
    Include estimated time and distance for each option.""",
    markdown=True,
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export GOOGLE_MAPS_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```

    Get your API key from the [Google Cloud Console](https://console.cloud.google.com/projectselector2/google/maps-apis/credentials)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai googlemaps agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/google_maps_tools.py
      ```

      ```bash Windows
      python cookbook/tools/google_maps_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Jira Tools
Source: https://docs.agno.com/examples/concepts/tools/others/jira



## Code

```python cookbook/tools/jira_tools.py
from agno.agent import Agent
from agno.tools.jira import JiraTools

agent = Agent(
    tools=[JiraTools()],
        markdown=True,
)

agent.print_response("List all open issues in project 'DEMO'")
agent.print_response("Create a new task in project 'DEMO' with high priority")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Jira credentials">
    ```bash
    export JIRA_API_TOKEN=xxx
    export JIRA_SERVER_URL=xxx
    export JIRA_EMAIL=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U jira openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/jira_tools.py
      ```

      ```bash Windows
      python cookbook/tools/jira_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Knowledge Tools
Source: https://docs.agno.com/examples/concepts/tools/others/knowledge



## Code

```python cookbook/tools/knowledge_tools.py
from agno.agent import Agent
from agno.tools.knowledge import KnowledgeTools
from agno.knowledge import Knowledge

# Initialize knowledge base
knowledge = Knowledge()
knowledge.load_documents("./docs/")

agent = Agent(
    instructions=[
        "You are a knowledge assistant that helps find and analyze information",
        "Search through the knowledge base to answer questions",
        "Provide detailed analysis and reasoning about the information found",
    ],
    tools=[KnowledgeTools(knowledge=knowledge)],
    markdown=True,
)

agent.print_response("What are the best practices for API design?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/knowledge_tools.py
      ```

      ```bash Windows
      python cookbook/tools/knowledge_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Linear Tools
Source: https://docs.agno.com/examples/concepts/tools/others/linear



## Code

```python cookbook/tools/linear_tools.py
from agno.agent import Agent
from agno.tools.linear import LinearTools

agent = Agent(
    tools=[LinearTools()],
        markdown=True,
)

agent.print_response("Show me all active issues")
agent.print_response("Create a new high priority task for the engineering team")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Linear API key">
    ```bash
    export LINEAR_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U linear-sdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/linear_tools.py
      ```

      ```bash Windows
      python cookbook/tools/linear_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Luma Labs Tools
Source: https://docs.agno.com/examples/concepts/tools/others/lumalabs



## Code

```python cookbook/tools/lumalabs_tools.py
from agno.agent import Agent
from agno.tools.lumalabs import LumaLabsTools

agent = Agent(
    tools=[LumaLabsTools()],
        markdown=True,
)
agent.print_response("Generate a 3D model of a futuristic city")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LUMALABS_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/lumalabs_tools.py
      ```

      ```bash Windows
      python cookbook/tools/lumalabs_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Mem0 Tools
Source: https://docs.agno.com/examples/concepts/tools/others/mem0



## Code

```python cookbook/tools/mem0_tools.py
from agno.agent import Agent
from agno.tools.mem0 import Mem0Tools

agent = Agent(
    instructions=[
        "You are a memory-enhanced assistant that can remember information across conversations",
        "Store important information about users and their preferences",
        "Retrieve relevant memories to provide personalized responses",
    ],
    tools=[Mem0Tools(user_id="user_123")],
    markdown=True,
)

agent.print_response("Remember that I prefer vegetarian meals and I'm allergic to nuts")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export MEM0_API_KEY=your-mem0-api-key
    export MEM0_ORG_ID=your-organization-id
    export MEM0_PROJECT_ID=your-project-id
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mem0ai openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/mem0_tools.py
      ```

      ```bash Windows
      python cookbook/tools/mem0_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memori Tools
Source: https://docs.agno.com/examples/concepts/tools/others/memori



## Code

```python cookbook/tools/memori_tools.py
from agno.agent import Agent
from agno.tools.memori import MemoriTools

agent = Agent(
    instructions=[
        "You are a memory-enhanced assistant with persistent conversation history",
        "Remember important information about users and their preferences",
        "Use stored memories to provide personalized and contextual responses",
    ],
    tools=[MemoriTools(
        database_url="sqlite:///memori.db",
        user_id="user_123"
    )],
    markdown=True,
)

agent.print_response("Remember that I prefer vegetarian recipes and I'm learning to cook Italian cuisine")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U memorisdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/memori_tools.py
      ```

      ```bash Windows
      python cookbook/tools/memori_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MLX Transcribe Tools
Source: https://docs.agno.com/examples/concepts/tools/others/mlx_transcribe



## Code

```python cookbook/tools/mlx_transcribe_tools.py
from agno.agent import Agent
from agno.tools.mlx_transcribe import MLXTranscribeTools

agent = Agent(
    tools=[MLXTranscribeTools()],
        markdown=True,
)
agent.print_response("Transcribe this audio file: path/to/audio.mp3")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mlx-transcribe openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/mlx_transcribe_tools.py
      ```

      ```bash Windows
      python cookbook/tools/mlx_transcribe_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Models Labs Tools
Source: https://docs.agno.com/examples/concepts/tools/others/models_labs



## Code

```python cookbook/tools/models_labs_tools.py
from agno.agent import Agent
from agno.tools.models_labs import ModelsLabsTools

agent = Agent(
    tools=[ModelsLabsTools()],
        markdown=True,
)
agent.print_response("Generate an image of a sunset over mountains")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MODELS_LABS_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/models_labs_tools.py
      ```

      ```bash Windows
      python cookbook/tools/models_labs_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenBB Tools
Source: https://docs.agno.com/examples/concepts/tools/others/openbb



## Code

```python cookbook/tools/openbb_tools.py
from agno.agent import Agent
from agno.tools.openbb import OpenBBTools

agent = Agent(
    tools=[OpenBBTools()],
        markdown=True,
)
agent.print_response("Get the latest stock price for AAPL")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENBB_PAT=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openbb openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/openbb_tools.py
      ```

      ```bash Windows
      python cookbook/tools/openbb_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenCV Tools
Source: https://docs.agno.com/examples/concepts/tools/others/opencv



## Code

```python cookbook/tools/opencv_tools.py
from agno.agent import Agent
from agno.tools.opencv import OpenCVTools

agent = Agent(
    instructions=[
        "You are a computer vision assistant that can capture images and videos",
        "Use the webcam to take photos or record videos as requested",
        "Provide clear feedback about capture operations",
    ],
    tools=[OpenCVTools()],
    markdown=True,
)

agent.print_response("Take a photo using the webcam")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U opencv-python openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/opencv_tools.py
      ```

      ```bash Windows
      python cookbook/tools/opencv_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning Tools
Source: https://docs.agno.com/examples/concepts/tools/others/reasoning



## Code

```python cookbook/tools/reasoning_tools.py
from agno.agent import Agent
from agno.tools.reasoning import ReasoningTools

agent = Agent(
    instructions=[
        "You are a logical reasoning assistant that breaks down complex problems",
        "Use step-by-step thinking to analyze situations thoroughly",
        "Apply structured reasoning to reach well-founded conclusions",
    ],
    tools=[ReasoningTools()],
    markdown=True,
)

agent.print_response("Analyze the pros and cons of remote work for software developers")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/reasoning_tools.py
      ```

      ```bash Windows
      python cookbook/tools/reasoning_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Replicate Tools
Source: https://docs.agno.com/examples/concepts/tools/others/replicate



## Code

```python cookbook/tools/replicate_tools.py
from agno.agent import Agent
from agno.tools.replicate import ReplicateTools

agent = Agent(
    tools=[ReplicateTools()],
        markdown=True,
)
agent.print_response("Generate an image of a cyberpunk city")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API token">
    ```bash
    export REPLICATE_API_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U replicate openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/replicate_tools.py
      ```

      ```bash Windows
      python cookbook/tools/replicate_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Resend Tools
Source: https://docs.agno.com/examples/concepts/tools/others/resend



## Code

```python cookbook/tools/resend_tools.py
from agno.agent import Agent
from agno.tools.resend import ResendTools

agent = Agent(
    tools=[ResendTools()],
        markdown=True,
)
agent.print_response("Send an email to test@example.com with the subject 'Test Email'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export RESEND_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U resend openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/resend_tools.py
      ```

      ```bash Windows
      python cookbook/tools/resend_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Todoist Tools
Source: https://docs.agno.com/examples/concepts/tools/others/todoist



## Code

```python cookbook/tools/todoist_tools.py
"""
Example showing how to use the Todoist Tools with Agno

Requirements:
- Sign up/login to Todoist and get a Todoist API Token (get from https://app.todoist.com/app/settings/integrations/developer)
- pip install todoist-api-python

Usage:
- Set the following environment variables:
    export TODOIST_API_TOKEN="your_api_token"

- Or provide them when creating the TodoistTools instance
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.todoist import TodoistTools

todoist_agent = Agent(
    name="Todoist Agent",
    role="Manage your todoist tasks",
    instructions=[
        "When given a task, create a todoist task for it.",
        "When given a list of tasks, create a todoist task for each one.",
        "When given a task to update, update the todoist task.",
        "When given a task to delete, delete the todoist task.",
        "When given a task to get, get the todoist task.",
    ],
    id="todoist-agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[TodoistTools()],
    markdown=True,
    debug_mode=True,
    )

# Example 1: Create a task
print("\n=== Create a task ===")
todoist_agent.print_response("Create a todoist task to buy groceries tomorrow at 10am")


# Example 2: Delete a task
print("\n=== Delete a task ===")
todoist_agent.print_response(
    "Delete the todoist task to buy groceries tomorrow at 10am"
)


# Example 3: Get all tasks
print("\n=== Get all tasks ===")
todoist_agent.print_response("Get all the todoist tasks")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API Token">
    ```bash
    export TODOIST_API_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U todoist-api-python openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/todoist_tools.py
      ```

      ```bash Windows
      python cookbook/tools/todoist_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# User Control Flow Tools
Source: https://docs.agno.com/examples/concepts/tools/others/user_control_flow



## Code

```python cookbook/tools/user_control_flow_tools.py
from agno.agent import Agent
from agno.tools.user_control_flow import UserControlFlowTools

agent = Agent(
    instructions=[
        "You are an interactive assistant that can ask users for input when needed",
        "Use user input requests to gather specific information or clarify requirements",
        "Always explain why you need the user input and how it will be used",
    ],
    tools=[UserControlFlowTools()],
    markdown=True,
)

agent.print_response("Help me create a personalized workout plan")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/user_control_flow_tools.py
      ```

      ```bash Windows
      python cookbook/tools/user_control_flow_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Visualization Tools
Source: https://docs.agno.com/examples/concepts/tools/others/visualization



## Code

```python cookbook/tools/visualization_tools.py
from agno.agent import Agent
from agno.tools.visualization import VisualizationTools

agent = Agent(
    instructions=[
        "You are a data visualization assistant that creates charts and plots",
        "Generate clear, informative visualizations based on user data",
        "Save charts to files and provide insights about the data",
    ],
    tools=[VisualizationTools(output_dir="charts")],
    markdown=True,
)

agent.print_response("Create a bar chart showing sales by quarter: Q1=100, Q2=150, Q3=120, Q4=180")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U matplotlib openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/visualization_tools.py
      ```

      ```bash Windows
      python cookbook/tools/visualization_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Web Tools
Source: https://docs.agno.com/examples/concepts/tools/others/webtools



## Code

```python cookbook/tools/webtools.py
from agno.agent import Agent
from agno.tools.webtools import WebTools

agent = Agent(
    instructions=[
        "You are a web utility assistant that helps with URL operations",
        "Expand shortened URLs to show their final destinations",
        "Help users understand where links lead before visiting them",
    ],
    tools=[WebTools()],
    markdown=True,
)

agent.print_response("Expand this shortened URL: https://bit.ly/3example")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U httpx openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/webtools.py
      ```

      ```bash Windows
      python cookbook/tools/webtools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# YFinance Tools
Source: https://docs.agno.com/examples/concepts/tools/others/yfinance



## Code

```python cookbook/tools/yfinance_tools.py
from agno.agent import Agent
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    tools=[YFinanceTools()],
        markdown=True,
)
agent.print_response("Get the current stock price and recent history for AAPL")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U yfinance openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/yfinance_tools.py
      ```

      ```bash Windows
      python cookbook/tools/yfinance_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# YouTube Tools
Source: https://docs.agno.com/examples/concepts/tools/others/youtube



## Code

```python cookbook/tools/youtube_tools.py
from agno.agent import Agent
from agno.tools.youtube import YouTubeTools

agent = Agent(
    tools=[YouTubeTools()],
        markdown=True,
)
agent.print_response("Search for recent videos about artificial intelligence")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export YOUTUBE_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-api-python-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/youtube_tools.py
      ```

      ```bash Windows
      python cookbook/tools/youtube_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Zendesk Tools
Source: https://docs.agno.com/examples/concepts/tools/others/zendesk



## Code

```python cookbook/tools/zendesk_tools.py
from agno.agent import Agent
from agno.tools.zendesk import ZendeskTools

agent = Agent(
    tools=[ZendeskTools()],
        markdown=True,
)
agent.print_response("Show me all open tickets")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your Zendesk credentials">
    ```bash
    export ZENDESK_EMAIL=xxx
    export ZENDESK_TOKEN=xxx
    export ZENDESK_SUBDOMAIN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U zenpy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/zendesk_tools.py
      ```

      ```bash Windows
      python cookbook/tools/zendesk_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ArXiv Tools
Source: https://docs.agno.com/examples/concepts/tools/search/arxiv



## Code

```python cookbook/tools/arxiv_tools.py
from agno.agent import Agent
from agno.tools.arxiv_toolkit import ArxivTools

agent = Agent(tools=[ArxivTools()])
agent.print_response("Search arxiv for 'language models'", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U arxiv openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/arxiv_tools.py
      ```

      ```bash Windows
      python cookbook/tools/arxiv_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Baidu Search Tools
Source: https://docs.agno.com/examples/concepts/tools/search/baidusearch



## Code

```python cookbook/tools/baidusearch_tools.py
from agno.agent import Agent
from agno.tools.baidusearch import BaiduSearchTools

agent = Agent(
    tools=[BaiduSearchTools()],
    description="You are a search agent that helps users find the most relevant information using Baidu.",
    instructions=[
        "Given a topic by the user, respond with the 3 most relevant search results about that topic.",
        "Search for 5 results and select the top 3 unique items.",
        "Search in both English and Chinese.",
    ],
    )
agent.print_response("What are the latest advancements in AI?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/baidusearch_tools.py
      ```

      ```bash Windows
      python cookbook/tools/baidusearch_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Brave Search Tools
Source: https://docs.agno.com/examples/concepts/tools/search/bravesearch



## Code

```python cookbook/tools/bravesearch_tools.py
from agno.agent import Agent
from agno.tools.bravesearch import BraveSearchTools

agent = Agent(
    tools=[BraveSearchTools()],
    description="You are a news agent that helps users find the latest news.",
    instructions=[
        "Given a topic by the user, respond with 4 latest news items about that topic."
    ],
    )
agent.print_response("AI Agents", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API credentials">
    ```bash
    export BRAVE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U brave-search openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/bravesearch_tools.py
      ```

      ```bash Windows
      python cookbook/tools/bravesearch_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Crawl4ai Tools
Source: https://docs.agno.com/examples/concepts/tools/search/crawl4ai



## Code

```python cookbook/tools/crawl4ai_tools.py
from agno.agent import Agent
from agno.tools.crawl4ai import Crawl4aiTools

agent = Agent(tools=[Crawl4aiTools(max_length=None)])
agent.print_response("Tell me about https://github.com/agno-agi/agno.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U crawl4ai openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/crawl4ai_tools.py
      ```

      ```bash Windows
      python cookbook/tools/crawl4ai_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DuckDuckGo Search
Source: https://docs.agno.com/examples/concepts/tools/search/duckduckgo



## Code

```python cookbook/tools/duckduckgo_tools.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(tools=[DuckDuckGoTools()])
agent.print_response("Whats happening in France?", markdown=True)

# We will search DDG but limit the site to Politifact
agent = Agent(
    tools=[DuckDuckGoTools(modifier="site:politifact.com")]
)
agent.print_response(
    "Is Taylor Swift promoting energy-saving devices with Elon Musk?", markdown=False
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/duckduckgo_tools.py
      ```

      ```bash Windows
      python cookbook/tools/duckduckgo_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Exa Tools
Source: https://docs.agno.com/examples/concepts/tools/search/exa



## Code

```python cookbook/tools/exa_tools.py
from agno.agent import Agent
from agno.tools.exa import ExaTools

agent = Agent(
    tools=[ExaTools(include_domains=["cnbc.com", "reuters.com", "bloomberg.com"], show_results=True)],
    )
agent.print_response("Search for AAPL news", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export EXA_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U exa-py openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/exa_tools.py
      ```

      ```bash Windows
      python cookbook/tools/exa_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google Search Tools
Source: https://docs.agno.com/examples/concepts/tools/search/google_search



## Code

```python cookbook/tools/googlesearch_tools.py
from agno.agent import Agent
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    tools=[GoogleSearchTools()],
        markdown=True,
)
agent.print_response("What are the latest developments in AI?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API credentials">
    ```bash
    export GOOGLE_CSE_ID=xxx
    export GOOGLE_API_KEY=xxx
    export OPENAI_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-api-python-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/googlesearch_tools.py
      ```

      ```bash Windows
      python cookbook/tools/googlesearch_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Hacker News Tools
Source: https://docs.agno.com/examples/concepts/tools/search/hackernews



## Code

```python cookbook/tools/hackernews_tools.py
from agno.agent import Agent
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    tools=[HackerNewsTools()],
        markdown=True,
)
agent.print_response("What are the top stories on Hacker News right now?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/hackernews_tools.py
      ```

      ```bash Windows
      python cookbook/tools/hackernews_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Linkup Tools
Source: https://docs.agno.com/examples/concepts/tools/search/linkup



## Code

```python cookbook/tools/linkup_tools.py
from agno.agent import Agent
from agno.tools.linkup import LinkupTools

agent = Agent(
    instructions=[
        "You are a web search assistant that provides comprehensive search results",
        "Use Linkup to find detailed and relevant information from the web",
        "Provide structured search results with source attribution",
    ],
    tools=[LinkupTools()],
    markdown=True,
)

agent.print_response("Search for the latest developments in quantum computing")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export LINKUP_API_KEY=your-linkup-api-key
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U linkup-sdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/linkup_tools.py
      ```

      ```bash Windows
      python cookbook/tools/linkup_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PubMed Tools
Source: https://docs.agno.com/examples/concepts/tools/search/pubmed



## Code

```python cookbook/tools/pubmed_tools.py
from agno.agent import Agent
from agno.tools.pubmed import PubMedTools

agent = Agent(
    tools=[PubMedTools()],
        markdown=True,
)
agent.print_response("Find recent research papers about COVID-19 vaccines")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U biopython openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/pubmed_tools.py
      ```

      ```bash Windows
      python cookbook/tools/pubmed_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SearxNG Tools
Source: https://docs.agno.com/examples/concepts/tools/search/searxng



## Code

```python cookbook/tools/searxng_tools.py
from agno.agent import Agent
from agno.tools.searxng import SearxNGTools

agent = Agent(
    tools=[SearxNGTools(instance_url="https://your-searxng-instance.com")],
        markdown=True,
)
agent.print_response("Search for recent news about artificial intelligence")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U searxng-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/searxng_tools.py
      ```

      ```bash Windows
      python cookbook/tools/searxng_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SerpAPI Tools
Source: https://docs.agno.com/examples/concepts/tools/search/serpapi



## Code

```python cookbook/tools/serpapi_tools.py
from agno.agent import Agent
from agno.tools.serpapi import SerpAPITools

agent = Agent(
    tools=[SerpAPITools()],
        markdown=True,
)
agent.print_response("What are the top search results for 'machine learning'?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export SERPAPI_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-search-results openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/serpapi_tools.py
      ```

      ```bash Windows
      python cookbook/tools/serpapi_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tavily Tools
Source: https://docs.agno.com/examples/concepts/tools/search/tavily



## Code

```python cookbook/tools/tavily_tools.py
from agno.agent import Agent
from agno.tools.tavily import TavilyTools

agent = Agent(
    tools=[TavilyTools()],
        markdown=True,
)
agent.print_response("Search for recent breakthroughs in quantum computing")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export TAVILY_API_KEY=xxx
    export OPENAI_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai tavily-python agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/tavily_tools.py
      ```

      ```bash Windows
      python cookbook/tools/tavily_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Valyu Tools
Source: https://docs.agno.com/examples/concepts/tools/search/valyu



## Code

```python cookbook/tools/valyu_tools.py
from agno.agent import Agent
from agno.tools.valyu import ValyuTools

agent = Agent(
    instructions=[
        "You are a research assistant that helps find academic papers and web content",
        "Use Valyu to search for high-quality, relevant information",
        "Provide detailed analysis of search results with relevance scores",
    ],
    tools=[ValyuTools()],
    markdown=True,
)

agent.print_response("Find recent research papers about machine learning in healthcare")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export VALYU_API_KEY=your-valyu-api-key
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U valyu openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/valyu_tools.py
      ```

      ```bash Windows
      python cookbook/tools/valyu_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Wikipedia Tools
Source: https://docs.agno.com/examples/concepts/tools/search/wikipedia



## Code

```python cookbook/tools/wikipedia_tools.py
from agno.agent import Agent
from agno.tools.wikipedia import WikipediaTools

agent = Agent(
    tools=[WikipediaTools()],
        markdown=True,
)
agent.print_response("Search Wikipedia for information about artificial intelligence")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U wikipedia openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/wikipedia_tools.py
      ```

      ```bash Windows
      python cookbook/tools/wikipedia_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Discord Tools
Source: https://docs.agno.com/examples/concepts/tools/social/discord



## Code

```python cookbook/tools/discord_tools.py
from agno.agent import Agent
from agno.tools.discord import DiscordTools

discord_agent = Agent(
    name="Discord Agent",
    instructions=[
        "You are a Discord bot that can perform various operations.",
        "You can send messages, read message history, manage channels, and delete messages.",
    ],
    tools=[
        DiscordTools(
            bot_token="YOUR_DISCORD_BOT_TOKEN",
            enable_send_message=True,
            enable_get_channel_messages=True,
            enable_get_channel_info=True,
            enable_list_channels=True,
            enable_delete_message=True,
        )
    ],
    markdown=True,
)

channel_id = "YOUR_CHANNEL_ID"
server_id = "YOUR_SERVER_ID"

discord_agent.print_response(
    f"Send a message 'Hello from Agno!' to channel {channel_id}", stream=True
)

discord_agent.print_response(f"Get information about channel {channel_id}", stream=True)

discord_agent.print_response(f"List all channels in server {server_id}", stream=True)

discord_agent.print_response(
    f"Get the last 5 messages from channel {channel_id}", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Discord token">
    ```bash
    export DISCORD_BOT_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U discord.py openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/discord_tools.py
      ```

      ```bash Windows
      python cookbook/tools/discord_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Email Tools
Source: https://docs.agno.com/examples/concepts/tools/social/email



## Code

```python cookbook/tools/email_tools.py
from agno.agent import Agent
from agno.tools.email import EmailTools

receiver_email = "<receiver_email>"
sender_email = "<sender_email>"
sender_name = "<sender_name>"
sender_passkey = "<sender_passkey>"

agent = Agent(
    tools=[
        EmailTools(
            receiver_email=receiver_email,
            sender_email=sender_email,
            sender_name=sender_name,
            sender_passkey=sender_passkey,
        )
    ]
)
agent.print_response("Send an email to <receiver_email>.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your email credentials">
    ```bash
    export SENDER_EMAIL=xxx
    export SENDER_PASSKEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/email_tools.py
      ```

      ```bash Windows
      python cookbook/tools/email_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reddit Tools
Source: https://docs.agno.com/examples/concepts/tools/social/reddit



## Code

```python cookbook/tools/reddit_tools.py
from agno.agent import Agent
from agno.tools.reddit import RedditTools

agent = Agent(
    instructions=[
        "You are a Reddit content analyst that helps explore and understand Reddit data",
        "Browse subreddits, analyze posts, and provide insights about discussions",
        "Respect Reddit's community guidelines and rate limits",
    ],
    tools=[RedditTools()],
    markdown=True,
)

agent.print_response("Show me the top posts from r/technology today")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your credentials">
    ```bash
    export REDDIT_CLIENT_ID=your-reddit-client-id
    export REDDIT_CLIENT_SECRET=your-reddit-client-secret
    export REDDIT_USER_AGENT=YourApp/1.0
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U praw openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/reddit_tools.py
      ```

      ```bash Windows
      python cookbook/tools/reddit_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Slack Tools
Source: https://docs.agno.com/examples/concepts/tools/social/slack



## Code

```python cookbook/tools/slack_tools.py
from agno.agent import Agent
from agno.tools.slack import SlackTools

agent = Agent(
    tools=[SlackTools()],
        markdown=True,
)
agent.print_response("Send a message to #general channel saying 'Hello from Agno!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your Slack token">
    ```bash
    export SLACK_BOT_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U slack-sdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/slack_tools.py
      ```

      ```bash Windows
      python cookbook/tools/slack_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Twilio Tools
Source: https://docs.agno.com/examples/concepts/tools/social/twilio



## Code

```python cookbook/tools/twilio_tools.py
from agno.agent import Agent
from agno.tools.twilio import TwilioTools

agent = Agent(
    tools=[TwilioTools()],
        markdown=True,
)
agent.print_response("Send an SMS to +1234567890 saying 'Hello from Agno!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your Twilio credentials">
    ```bash
    export TWILIO_ACCOUNT_SID=xxx
    export TWILIO_AUTH_TOKEN=xxx
    export TWILIO_FROM_NUMBER=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U twilio openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/twilio_tools.py
      ```

      ```bash Windows
      python cookbook/tools/twilio_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Webex Tools
Source: https://docs.agno.com/examples/concepts/tools/social/webex



## Code

```python cookbook/tools/webex_tools.py
from agno.agent import Agent
from agno.tools.webex import WebexTools

agent = Agent(
    name="Webex Assistant",
    tools=[WebexTools()],
    description="You are a Webex assistant that can send messages and manage spaces.",
    instructions=[
        "You can help users by:",
        "- Listing available Webex spaces",
        "- Sending messages to spaces",
        "Always confirm the space exists before sending messages.",
    ],
        markdown=True,
)

# List all spaces in Webex
agent.print_response("List all spaces on our Webex", markdown=True)

# Send a message to a Space in Webex
agent.print_response(
    "Send a funny ice-breaking message to the webex Welcome space", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up Webex Bot">
    1. Go to [Webex Developer Portal](https://developer.webex.com/)
    2. Create a Bot:
       * Navigate to My Webex Apps ‚Üí Create a Bot
       * Fill in the bot details and click Add Bot
    3. Get your access token:
       * Copy the token shown after bot creation
       * Or regenerate via My Webex Apps ‚Üí Edit Bot
  </Step>

  <Step title="Set your API keys">
    ```bash
    export WEBEX_ACCESS_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U webexpythonsdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/webex_tools.py
      ```

      ```bash Windows
      python cookbook/tools/webex_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# WhatsApp Tools
Source: https://docs.agno.com/examples/concepts/tools/social/whatsapp



## Code

```python cookbook/tools/whatsapp_tools.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.whatsapp import WhatsAppTools

agent = Agent(
    name="whatsapp",
    model=Gemini(id="gemini-2.0-flash"),
    tools=[WhatsAppTools()],
)

# Example: Send a template message
# Note: Replace '''hello_world''' with your actual template name
agent.print_response(
    "Send a template message using the '''hello_world''' template in English to +91 1234567890"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up WhatsApp Business API">
    1. Go to [Meta for Developers](https://developers.facebook.com/docs/whatsapp/cloud-api/get-started)
    2. Create a Meta App and set up the WhatsApp Business API.
    3. Obtain your Phone Number ID and a permanent System User Access Token.
  </Step>

  <Step title="Set your API keys and identifiers">
    ```bash
    export WHATSAPP_ACCESS_TOKEN=xxx
    export WHATSAPP_PHONE_NUMBER_ID=xxx
    export OPENAI_API_KEY=xxx # Or your preferred LLM API key
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai google-generativeai # Add any other necessary WhatsApp SDKs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/whatsapp_tools.py
      ```

      ```bash Windows
      python cookbook/tools/whatsapp_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# X (Twitter) Tools
Source: https://docs.agno.com/examples/concepts/tools/social/x



## Code

```python cookbook/tools/x_tools.py
from agno.agent import Agent
from agno.tools.x import XTools

agent = Agent(
    tools=[XTools()],
        markdown=True,
)
agent.print_response("Make a post saying 'Hello World from Agno!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your X credentials">
    ```bash
    export X_CONSUMER_KEY=xxx
    export X_CONSUMER_SECRET=xxx
    export X_ACCESS_TOKEN=xxx
    export X_ACCESS_TOKEN_SECRET=xxx
    export X_BEARER_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U tweepy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/x_tools.py
      ```

      ```bash Windows
      python cookbook/tools/x_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# BrightData Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/brightdata



## Code

```python cookbook/tools/brightdata_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.brightdata import BrightDataTools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        BrightDataTools(
            enable_get_screenshot=True,
        )
    ],
    markdown=True,
    )

# Example 1: Scrape a webpage as Markdown
agent.print_response(
    "Scrape this webpage as markdown: https://docs.agno.com/introduction",
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export BRIGHT_DATA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/brightdata_tools.py
      ```

      ```bash Windows
      python cookbook/tools/brightdata_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Firecrawl Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/firecrawl

Use Firecrawl with Agno to scrape and crawl the web.

## Code

```python cookbook/tools/firecrawl_tools.py
from agno.agent import Agent
from agno.tools.firecrawl import FirecrawlTools

agent = Agent(
    tools=[FirecrawlTools(enable_scrape=False, enable_crawl=True)],
        markdown=True,
)
agent.print_response("Summarize this https://finance.yahoo.com/")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIRECRAWL_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U firecrawl openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/firecrawl_tools.py
      ```

      ```bash Windows
      python cookbook/tools/firecrawl_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Jina Reader Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/jina_reader



## Code

```python cookbook/tools/jina_reader_tools.py
from agno.agent import Agent
from agno.tools.jina_reader import JinaReaderTools

agent = Agent(
    tools=[JinaReaderTools()],
        markdown=True,
)
agent.print_response("Read and summarize this PDF: https://example.com/sample.pdf")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U jina-reader openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/jina_reader_tools.py
      ```

      ```bash Windows
      python cookbook/tools/jina_reader_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Newspaper Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/newspaper



## Code

```python cookbook/tools/newspaper_tools.py
from agno.agent import Agent
from agno.tools.newspaper import NewspaperTools

agent = Agent(
    tools=[NewspaperTools()],
        markdown=True,
)
agent.print_response("Extract the main article content from https://example.com/article")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U newspaper3k openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/newspaper_tools.py
      ```

      ```bash Windows
      python cookbook/tools/newspaper_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Newspaper4k Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/newspaper4k



## Code

```python cookbook/tools/newspaper4k_tools.py
from agno.agent import Agent
from agno.tools.newspaper4k import Newspaper4kTools

agent = Agent(
    tools=[Newspaper4kTools()],
        markdown=True,
)
agent.print_response("Analyze and summarize this news article: https://example.com/news")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U newspaper4k openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/newspaper4k_tools.py
      ```

      ```bash Windows
      python cookbook/tools/newspaper4k_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Oxylabs Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/oxylabs

Use Oxylabs with Agno to scrape and crawl the web.

## Code

```python cookbook/tools/oxylabs_tools.py
from agno.agent import Agent
from agno.tools.oxylabs import OxylabsTools

agent = Agent(
    tools=[OxylabsTools()],
    markdown=True,
    )

agent.print_response("""
Let's search for 'latest iPhone reviews' and provide a summary of the top 3 results. 
""")

print(response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OXYLABS_USERNAME=your_oxylabs_username
    export OXYLABS_PASSWORD=your_oxylabs_password
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U oxylabs agno openai
    ```
  </Step>

  <Step title="Run the example">
    ```bash
    python cookbook/tools/oxylabs_tools.py
    ```
  </Step>
</Steps>


# Spider Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/spider



## Code

```python cookbook/tools/spider_tools.py
from agno.agent import Agent
from agno.tools.spider import SpiderTools

agent = Agent(
    tools=[SpiderTools()],
        markdown=True,
)
agent.print_response("Crawl https://example.com and extract all links")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U scrapy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/spider_tools.py
      ```

      ```bash Windows
      python cookbook/tools/spider_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Trafilatura Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/trafilatura



## Code

```python cookbook/tools/trafilatura_tools.py
from agno.agent import Agent
from agno.tools.trafilatura import TrafilaturaTools

agent = Agent(
    instructions=[
        "You are a web content extraction specialist",
        "Extract clean text and structured data from web pages",
        "Provide detailed analysis of web content and metadata",
    ],
    tools=[TrafilaturaTools()],
    markdown=True,
)

agent.print_response("Extract the main content from https://example.com/article")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U trafilatura openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/trafilatura_tools.py
      ```

      ```bash Windows
      python cookbook/tools/trafilatura_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Website Tools
Source: https://docs.agno.com/examples/concepts/tools/web_scrape/website



## Code

```python cookbook/tools/website_tools.py
from agno.agent import Agent
from agno.tools.website import WebsiteTools

agent = Agent(
    tools=[WebsiteTools()],
        markdown=True,
)
agent.print_response("Extract the main content from https://example.com")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U beautifulsoup4 requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/website_tools.py
      ```

      ```bash Windows
      python cookbook/tools/website_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cassandra Async
Source: https://docs.agno.com/examples/concepts/vectordb/cassandra-db/async-cassandra-db



## Code

```python cookbook/knowledge/vector_db/cassandra_db/async_cassandra_db.py
import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.mistral import MistralEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.mistral import MistralChat
from agno.vectordb.cassandra import Cassandra

try:
    from cassandra.cluster import Cluster  # type: ignore
except (ImportError, ModuleNotFoundError):
    raise ImportError(
        "Could not import cassandra-driver python package.Please install it with pip install cassandra-driver."
    )

cluster = Cluster()

session = cluster.connect()
session.execute(
    """
    CREATE KEYSPACE IF NOT EXISTS testkeyspace
    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }
    """
)

knowledge = Knowledge(
    vector_db=Cassandra(
        table_name="recipes",
        keyspace="testkeyspace",
        session=session,
        embedder=MistralEmbedder(),
    ),
)

agent = Agent(
    model=MistralChat(),
    knowledge=knowledge,
)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content(url="https://docs.agno.com/introduction/agents.md")
    )

    asyncio.run(
        agent.aprint_response(
            "What is the purpose of an Agno Agent?",
            markdown=True,
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U cassandra-driver pypdf mistralai agno
    ```
  </Step>

  <Step title="Run Cassandra">
    ```bash
    docker run -d \
    --name cassandra-db \
    -p 9042:9042 \
    cassandra:latest
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export CASSANDRA_HOST="localhost"
    export CASSANDRA_PORT="9042"
    export CASSANDRA_USER="cassandra"
    export CASSANDRA_PASSWORD="cassandra"
    export MISTRAL_API_KEY="your-mistral-api-key"
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/cassandra_db/async_cassandra_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/cassandra_db/async_cassandra_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cassandra
Source: https://docs.agno.com/examples/concepts/vectordb/cassandra-db/cassandra-db



## Code

```python cookbook/knowledge/vector_db/cassandra_db/cassandra_db.py
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.cassandra import Cassandra

try:
    from cassandra.cluster import Cluster  # type: ignore
except (ImportError, ModuleNotFoundError):
    raise ImportError(
        "Could not import cassandra-driver python package.Please install it with pip install cassandra-driver."
    )

cluster = Cluster()

session = cluster.connect()
session.execute(
    """
    CREATE KEYSPACE IF NOT EXISTS testkeyspace
    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }
    """
)
vector_db = Cassandra(
    table_name="recipes",
    keyspace="testkeyspace",
    session=session,
    embedder=OpenAIEmbedder(
        dimensions=1024,
    ),
)

knowledge = Knowledge(
    name="My Cassandra Knowledge Base",
    vector_db=vector_db,
)


knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

agent = Agent(
    knowledge=knowledge,
)

agent.print_response(
    "What are the health benefits of Khao Niew Dam Piek Maphrao Awn?",
    markdown=True,
    show_full_reasoning=True,
)

vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U cassandra-driver pypdf openai agno
    ```
  </Step>

  <Step title="Run Cassandra">
    ```bash
    docker run -d \
    --name cassandra-db \
    -p 9042:9042 \
    cassandra:latest
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export CASSANDRA_HOST="localhost"
    export CASSANDRA_PORT="9042"
    export CASSANDRA_USER="cassandra"
    export CASSANDRA_PASSWORD="cassandra"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/cassandra_db/cassandra_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/cassandra_db/cassandra_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ChromaDB Async
Source: https://docs.agno.com/examples/concepts/vectordb/chroma-db/async-chroma-db



## Code

```python cookbook/knowledge/vector_db/chroma_db/async_chroma_db.py


import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.chroma import ChromaDb

vector_db = ChromaDb(collection="recipes", path="tmp/chromadb", persistent_client=True)

knowledge = Knowledge(
    vector_db=vector_db,
)

agent = Agent(knowledge=knowledge)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(url="https://docs.agno.com/introduction/agents.md")
    )

    asyncio.run(
        agent.aprint_response("What is the purpose of an Agno Agent?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U chromadb pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/chroma_db/async_chroma_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/chroma_db/async_chroma_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ChromaDB
Source: https://docs.agno.com/examples/concepts/vectordb/chroma-db/chroma-db



## Code

```python cookbook/knowledge/vector_db/chroma_db/chroma_db.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.chroma import ChromaDb

# Create Knowledge Instance with ChromaDB
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with ChromaDB",
    vector_db=ChromaDb(
        collection="vectors", path="tmp/chromadb", persistent_client=True
    ),
)

knowledge.add_content(
        name="Recipes",
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        metadata={"doc_type": "recipe_book"},
    )


# Create and use the agent
agent = Agent(knowledge=knowledge)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)

# Delete operations examples
vector_db = knowledge.vector_db
vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"user_tag": "Recipes from website"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U chromadb pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/chroma_db/chroma_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/chroma_db/chroma_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ClickHouse Async
Source: https://docs.agno.com/examples/concepts/vectordb/clickhouse-db/async-clickhouse-db



## Code

```python cookbook/knowledge/vector_db/clickhouse_db/async_clickhouse.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.clickhouse import Clickhouse

agent = Agent(
    knowledge=Knowledge(
        vector_db=Clickhouse(
            table_name="recipe_documents",
            host="localhost",
            port=8123,
            username="ai",
            password="ai",
        ),
    ),
    search_knowledge=True,
    read_chat_history=True,
)

if __name__ == "__main__":
    asyncio.run(
        agent.knowledge.add_content_async(url="https://docs.agno.com/introduction/agents.md")
    )

    asyncio.run(
        agent.aprint_response("What is the purpose of an Agno Agent?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U clickhouse-connect pypdf openai agno
    ```
  </Step>

  <Step title="Run ClickHouse">
    ```bash
    docker run -d \
    -e CLICKHOUSE_DB=ai \
    -e CLICKHOUSE_USER=ai \
    -e CLICKHOUSE_PASSWORD=ai \
    -e CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1 \
    -v clickhouse_data:/var/lib/clickhouse/ \
    -v clickhouse_log:/var/log/clickhouse-server/ \
    -p 8123:8123 \
    -p 9000:9000 \
    --ulimit nofile=262144:262144 \
    --name clickhouse-server \
    clickhouse/clickhouse-server
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export CLICKHOUSE_HOST="localhost"
    export CLICKHOUSE_PORT="8123"
    export CLICKHOUSE_USER="ai"
    export CLICKHOUSE_PASSWORD="ai"
    export CLICKHOUSE_DB="ai"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/clickhouse_db/async_clickhouse.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/clickhouse_db/async_clickhouse.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ClickHouse
Source: https://docs.agno.com/examples/concepts/vectordb/clickhouse-db/clickhouse-db



## Code

```python cookbook/knowledge/vector_db/clickhouse_db/clickhouse.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.clickhouse import Clickhouse

vector_db = Clickhouse(
    table_name="recipe_documents",
    host="localhost",
    port=8123,
    username="ai",
    password="ai",
)

knowledge = Knowledge(
    name="My Clickhouse Knowledge Base",
    description="This is a knowledge base that uses a Clickhouse DB",
    vector_db=vector_db,
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("How do I make pad thai?", markdown=True)

vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U clickhouse-connect pypdf openai agno
    ```
  </Step>

  <Step title="Run ClickHouse">
    ```bash
    docker run -d \
    -e CLICKHOUSE_DB=ai \
    -e CLICKHOUSE_USER=ai \
    -e CLICKHOUSE_PASSWORD=ai \
    -e CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1 \
    -v clickhouse_data:/var/lib/clickhouse/ \
    -v clickhouse_log:/var/log/clickhouse-server/ \
    -p 8123:8123 \
    -p 9000:9000 \
    --ulimit nofile=262144:262144 \
    --name clickhouse-server \
    clickhouse/clickhouse-server
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export CLICKHOUSE_HOST="localhost"
    export CLICKHOUSE_PORT="8123"
    export CLICKHOUSE_USER="ai"
    export CLICKHOUSE_PASSWORD="ai"
    export CLICKHOUSE_DB="ai"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/clickhouse_db/clickhouse.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/clickhouse_db/clickhouse.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Couchbase Async
Source: https://docs.agno.com/examples/concepts/vectordb/couchbase-db/async-couchbase-db



## Code

```python cookbook/knowledge/vector_db/couchbase_db/async_couchbase_db.py
import asyncio
import os
import time

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.couchbase import CouchbaseSearch
from couchbase.auth import PasswordAuthenticator
from couchbase.management.search import SearchIndex
from couchbase.options import ClusterOptions, KnownConfigProfiles

# Couchbase connection settings
username = os.getenv("COUCHBASE_USER")  # Replace with your username
password = os.getenv("COUCHBASE_PASSWORD")  # Replace with your password
connection_string = os.getenv("COUCHBASE_CONNECTION_STRING")

# Create cluster options with authentication
auth = PasswordAuthenticator(username, password)
cluster_options = ClusterOptions(auth)
cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)

# Define the vector search index
search_index = SearchIndex(
    name="vector_search",
    source_type="gocbcore",
    idx_type="fulltext-index",
    source_name="recipe_bucket",
    plan_params={"index_partitions": 1, "num_replicas": 0},
    params={
        "doc_config": {
            "docid_prefix_delim": "",
            "docid_regexp": "",
            "mode": "scope.collection.type_field",
            "type_field": "type",
        },
        "mapping": {
            "default_analyzer": "standard",
            "default_datetime_parser": "dateTimeOptional",
            "index_dynamic": True,
            "store_dynamic": True,
            "default_mapping": {"dynamic": True, "enabled": False},
            "types": {
                "recipe_scope.recipes": {
                    "dynamic": False,
                    "enabled": True,
                    "properties": {
                        "content": {
                            "enabled": True,
                            "fields": [
                                {
                                    "docvalues": True,
                                    "include_in_all": False,
                                    "include_term_vectors": False,
                                    "index": True,
                                    "name": "content",
                                    "store": True,
                                    "type": "text",
                                }
                            ],
                        },
                        "embedding": {
                            "enabled": True,
                            "dynamic": False,
                            "fields": [
                                {
                                    "vector_index_optimized_for": "recall",
                                    "docvalues": True,
                                    "dims": 3072,
                                    "include_in_all": False,
                                    "include_term_vectors": False,
                                    "index": True,
                                    "name": "embedding",
                                    "similarity": "dot_product",
                                    "store": True,
                                    "type": "vector",
                                }
                            ],
                        },
                        "meta": {
                            "dynamic": True,
                            "enabled": True,
                            "properties": {
                                "name": {
                                    "enabled": True,
                                    "fields": [
                                        {
                                            "docvalues": True,
                                            "include_in_all": False,
                                            "include_term_vectors": False,
                                            "index": True,
                                            "name": "name",
                                            "store": True,
                                            "analyzer": "keyword",
                                            "type": "text",
                                        }
                                    ],
                                }
                            },
                        },
                    },
                }
            },
        },
    },
)

knowledge_base = Knowledge(
    vector_db=CouchbaseSearch(
        bucket_name="recipe_bucket",
        scope_name="recipe_scope",
        collection_name="recipes",
        couchbase_connection_string=connection_string,
        cluster_options=cluster_options,
        search_index=search_index,
        embedder=OpenAIEmbedder(
            id="text-embedding-3-large",
            dimensions=3072,
            api_key=os.getenv("OPENAI_API_KEY"),
        ),
        wait_until_index_ready=60,
        overwrite=True,
    ),
)

# Create and use the agent
agent = Agent(knowledge=knowledge_base)


async def run_agent():
    await knowledge_base.add_content_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    )
    time.sleep(5)  # wait for the vector index to be sync with kv
    await agent.aprint_response("How to make Thai curry?", markdown=True)


if __name__ == "__main__":
    asyncio.run(run_agent())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Start Couchbase">
    ```bash
    docker run -d --name couchbase-server \
      -p 8091-8096:8091-8096 \
      -p 11210:11210 \
      -e COUCHBASE_ADMINISTRATOR_USERNAME=Administrator \
      -e COUCHBASE_ADMINISTRATOR_PASSWORD=password \
      couchbase:latest
    ```

    Then access [http://localhost:8091](http://localhost:8091) and create:

    * Bucket: `recipe_bucket`
    * Scope: `recipe_scope`
    * Collection: `recipes`
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U couchbase pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export COUCHBASE_USER="Administrator"
    export COUCHBASE_PASSWORD="password"
    export COUCHBASE_CONNECTION_STRING="couchbase://localhost"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/couchbase_db/async_couchbase_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/couchbase_db/async_couchbase_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Couchbase
Source: https://docs.agno.com/examples/concepts/vectordb/couchbase-db/couchbase-db



## Code

```python cookbook/knowledge/vector_db/couchbase_db/couchbase_db.py
import os
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.couchbase import CouchbaseSearch
from couchbase.auth import PasswordAuthenticator
from couchbase.management.search import SearchIndex
from couchbase.options import ClusterOptions, KnownConfigProfiles

# Couchbase connection settings
username = os.getenv("COUCHBASE_USER")
password = os.getenv("COUCHBASE_PASSWORD")
connection_string = os.getenv("COUCHBASE_CONNECTION_STRING")

# Create cluster options with authentication
auth = PasswordAuthenticator(username, password)
cluster_options = ClusterOptions(auth)
cluster_options.apply_profile(KnownConfigProfiles.WanDevelopment)

# Define the vector search index
search_index = SearchIndex(
    name="vector_search",
    source_type="gocbcore",
    idx_type="fulltext-index",
    source_name="recipe_bucket",
    plan_params={"index_partitions": 1, "num_replicas": 0},
    params={
        "doc_config": {
            "docid_prefix_delim": "",
            "docid_regexp": "",
            "mode": "scope.collection.type_field",
            "type_field": "type",
        },
        "mapping": {
            "default_analyzer": "standard",
            "default_datetime_parser": "dateTimeOptional",
            "index_dynamic": True,
            "store_dynamic": True,
            "default_mapping": {"dynamic": True, "enabled": False},
            "types": {
                "recipe_scope.recipes": {
                    "dynamic": False,
                    "enabled": True,
                    "properties": {
                        "content": {
                            "enabled": True,
                            "fields": [
                                {
                                    "docvalues": True,
                                    "include_in_all": False,
                                    "include_term_vectors": False,
                                    "index": True,
                                    "name": "content",
                                    "store": True,
                                    "type": "text",
                                }
                            ],
                        },
                        "embedding": {
                            "enabled": True,
                            "dynamic": False,
                            "fields": [
                                {
                                    "vector_index_optimized_for": "recall",
                                    "docvalues": True,
                                    "dims": 1536,
                                    "include_in_all": False,
                                    "include_term_vectors": False,
                                    "index": True,
                                    "name": "embedding",
                                    "similarity": "dot_product",
                                    "store": True,
                                    "type": "vector",
                                }
                            ],
                        },
                        "meta": {
                            "dynamic": True,
                            "enabled": True,
                            "properties": {
                                "name": {
                                    "enabled": True,
                                    "fields": [
                                        {
                                            "docvalues": True,
                                            "include_in_all": False,
                                            "include_term_vectors": False,
                                            "index": True,
                                            "name": "name",
                                            "store": True,
                                            "analyzer": "keyword",
                                            "type": "text",
                                        }
                                    ],
                                }
                            },
                        },
                    },
                }
            },
        },
    },
)
vector_db = CouchbaseSearch(
    bucket_name="recipe_bucket",
    scope_name="recipe_scope",
    collection_name="recipes",
    couchbase_connection_string=connection_string,
    cluster_options=cluster_options,
    search_index=search_index,
    embedder=OpenAIEmbedder(
        dimensions=1536,
    ),
    wait_until_index_ready=60,
    overwrite=True,
)

knowledge = Knowledge(
    name="Couchbase Knowledge Base",
    description="This is a knowledge base that uses a Couchbase DB",
    vector_db=vector_db,
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)

vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Start Couchbase">
    ```bash
    docker run -d --name couchbase-server \
      -p 8091-8096:8091-8096 \
      -p 11210:11210 \
      -e COUCHBASE_ADMINISTRATOR_USERNAME=Administrator \
      -e COUCHBASE_ADMINISTRATOR_PASSWORD=password \
      couchbase:latest
    ```

    Then access [http://localhost:8091](http://localhost:8091) and create:

    * Bucket: `recipe_bucket`
    * Scope: `recipe_scope`
    * Collection: `recipes`
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U couchbase pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export COUCHBASE_USER="Administrator"
    export COUCHBASE_PASSWORD="password"
    export COUCHBASE_CONNECTION_STRING="couchbase://localhost"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/couchbase_db/couchbase_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/couchbase_db/couchbase_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LanceDB Async
Source: https://docs.agno.com/examples/concepts/vectordb/lance-db/async-lance-db



## Code

```python cookbook/knowledge/vector_db/lance_db/lance_db.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.lancedb import LanceDb

vector_db = LanceDb(
    table_name="vectors",
    uri="tmp/lancedb",
)

knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with LanceDB",
    vector_db=vector_db,
)

agent = Agent(knowledge=knowledge)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
            metadata={"doc_type": "recipe_book"},
        )
    )

    asyncio.run(
        agent.aprint_response("List down the ingredients to make Massaman Gai", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/lance_db/lance_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/lance_db/lance_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LanceDB
Source: https://docs.agno.com/examples/concepts/vectordb/lance-db/lance-db



## Code

```python cookbook/knowledge/vector_db/lance_db/lance_db.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.lancedb import LanceDb

vector_db = LanceDb(
    table_name="vectors",
    uri="tmp/lancedb",
)

knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with LanceDB",
    vector_db=vector_db,
)

knowledge.add_content(
        name="Recipes",
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        metadata={"doc_type": "recipe_book"},
    )


agent = Agent(knowledge=knowledge)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)

vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/lance_db/lance_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/lance_db/lance_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LanceDB Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/lance-db/lance-db-hybrid-search



## Code

```python cookbook/knowledge/vector_db/lance_db/lance_db_hybrid_search.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    name="My PG Vector Knowledge Base",
    description="This is a knowledge base that uses a PG Vector DB",
    vector_db=LanceDb(
        table_name="vectors",
        uri="tmp/lancedb",
        search_type=SearchType.hybrid,
    ),
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/lance_db/lance_db_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/lance_db/lance_db_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LangChain Async
Source: https://docs.agno.com/examples/concepts/vectordb/langchain/async-langchain-db



## Code

```python cookbook/knowledge/vector_db/langchain/langchain_db.py
import asyncio
import pathlib

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.langchaindb import LangChainVectorDb
from langchain.text_splitter import CharacterTextSplitter
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings

# Define the directory where the Chroma database is located
chroma_db_dir = pathlib.Path("./chroma_db")

# Define the path to the document to be loaded into the knowledge base
state_of_the_union = pathlib.Path(
    "cookbook/knowledge/testing_resources/state_of_the_union.txt"
)

# Load the document
raw_documents = TextLoader(str(state_of_the_union), encoding="utf-8").load()

# Split the document into chunks
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)

# Embed each chunk and load it into the vector store
Chroma.from_documents(
    documents, OpenAIEmbeddings(), persist_directory=str(chroma_db_dir)
)

# Get the vector database
db = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))

# Create a knowledge retriever from the vector store
knowledge_retriever = db.as_retriever()

knowledge = Knowledge(
    vector_db=LangChainVectorDb(knowledge_retriever=knowledge_retriever)
)

agent = Agent(knowledge=knowledge)

if __name__ == "__main__":
    asyncio.run(
        agent.aprint_response("What did the president say?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U langchain langchain-community langchain-openai langchain-chroma pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/langchain/langchain_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/langchain/langchain_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LangChain
Source: https://docs.agno.com/examples/concepts/vectordb/langchain/langchain-db



## Code

```python cookbook/knowledge/vector_db/langchain/langchain_db.py
import pathlib
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.langchaindb import LangChainVectorDb
from langchain.text_splitter import CharacterTextSplitter
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings

# Define the directory where the Chroma database is located
chroma_db_dir = pathlib.Path("./chroma_db")

# Define the path to the document to be loaded into the knowledge base
state_of_the_union = pathlib.Path(
    "cookbook/knowledge/testing_resources/state_of_the_union.txt"
)

# Load the document
raw_documents = TextLoader(str(state_of_the_union), encoding="utf-8").load()

# Split the document into chunks
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)

# Embed each chunk and load it into the vector store
Chroma.from_documents(
    documents, OpenAIEmbeddings(), persist_directory=str(chroma_db_dir)
)

# Get the vector database
db = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))

# Create a knowledge retriever from the vector store
knowledge_retriever = db.as_retriever()

knowledge = Knowledge(
    vector_db=LangChainVectorDb(knowledge_retriever=knowledge_retriever)
)

agent = Agent(knowledge=knowledge)

agent.print_response("What did the president say?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U langchain langchain-community langchain-openai langchain-chroma pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/langchain/langchain_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/langchain/langchain_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LightRAG Async
Source: https://docs.agno.com/examples/concepts/vectordb/lightrag/async-lightrag-db



## Code

```python cookbook/knowledge/vector_db/lightrag/lightrag.py
import asyncio
from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.wikipedia_reader import WikipediaReader
from agno.vectordb.lightrag import LightRag

vector_db = LightRag(
    api_key=getenv("LIGHTRAG_API_KEY"),
)

knowledge = Knowledge(
    name="My Pinecone Knowledge Base",
    description="This is a knowledge base that uses a Pinecone Vector DB",
    vector_db=vector_db,
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=False,
)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            path="cookbook/knowledge/testing_resources/cv_1.pdf",
            metadata={"doc_type": "recipe_book"},
        )
    )

    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            topics=["Manchester United"],
            reader=WikipediaReader(),
        )
    )

    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            url="https://en.wikipedia.org/wiki/Manchester_United_F.C.",
        )
    )

    asyncio.run(
        agent.aprint_response("What skills does Jordan Mitchell have?", markdown=True)
    )

    asyncio.run(
        agent.aprint_response(
            "In what year did Manchester United change their name?", markdown=True
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U lightrag pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export LIGHTRAG_API_KEY="your-lightrag-api-key"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/lightrag/lightrag.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/lightrag/lightrag.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LightRAG
Source: https://docs.agno.com/examples/concepts/vectordb/lightrag/lightrag-db



## Code

```python cookbook/knowledge/vector_db/lightrag/lightrag.py

from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.wikipedia_reader import WikipediaReader
from agno.vectordb.lightrag import LightRag

vector_db = LightRag(
    api_key=getenv("LIGHTRAG_API_KEY"),
)

knowledge = Knowledge(
    name="My Pinecone Knowledge Base",
    description="This is a knowledge base that uses a Pinecone Vector DB",
    vector_db=vector_db,
)



knowledge.add_content(
    name="Recipes",
    path="cookbook/knowledge/testing_resources/cv_1.pdf",
    metadata={"doc_type": "recipe_book"},
)


knowledge.add_content(
    name="Recipes",
    topics=["Manchester United"],
    reader=WikipediaReader(),
)


knowledge.add_content(
    name="Recipes",
    url="https://en.wikipedia.org/wiki/Manchester_United_F.C.",
)


agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=False,
)



agent.print_response("What skills does Jordan Mitchell have?", markdown=True)


agent.print_response(
    "In what year did Manchester United change their name?", markdown=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U lightrag pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export LIGHTRAG_API_KEY="your-lightrag-api-key"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/lightrag/lightrag.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/lightrag/lightrag.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LlamaIndex Async
Source: https://docs.agno.com/examples/concepts/vectordb/llamaindex-db/async-llamaindex-db



## Code

```python cookbook/knowledge/vector_db/llamaindex_db/llamaindex_db.py
import asyncio
from pathlib import Path
from shutil import rmtree

import httpx
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.llamaindex import LlamaIndexVectorDb
from llama_index.core import (
    SimpleDirectoryReader,
    StorageContext,
    VectorStoreIndex,
)
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core.retrievers import VectorIndexRetriever

data_dir = Path(__file__).parent.parent.parent.joinpath("wip", "data", "paul_graham")
if data_dir.is_dir():
    rmtree(path=data_dir, ignore_errors=True)
data_dir.mkdir(parents=True, exist_ok=True)

url = "https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt"
file_path = data_dir.joinpath("paul_graham_essay.txt")
response = httpx.get(url)
if response.status_code == 200:
    with open(file_path, "wb") as file:
        file.write(response.content)
    print(f"File downloaded and saved as {file_path}")
else:
    print("Failed to download the file")


documents = SimpleDirectoryReader(str(data_dir)).load_data()

splitter = SentenceSplitter(chunk_size=1024)

nodes = splitter.get_nodes_from_documents(documents)

storage_context = StorageContext.from_defaults()

index = VectorStoreIndex(nodes=nodes, storage_context=storage_context)

knowledge_retriever = VectorIndexRetriever(index)

knowledge = Knowledge(
    vector_db=LlamaIndexVectorDb(knowledge_retriever=knowledge_retriever)
)

# Create an agent with the knowledge instance
agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

if __name__ == "__main__":
    asyncio.run(
        agent.aprint_response(
            "Explain what this text means: low end eats the high end", markdown=True
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U llama-index-core llama-index-readers-file llama-index-embeddings-openai pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/llamaindex_db/llamaindex_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/llamaindex_db/llamaindex_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LlamaIndex
Source: https://docs.agno.com/examples/concepts/vectordb/llamaindex-db/llamaindex-db



## Code

```python cookbook/knowledge/vector_db/llamaindex_db/llamaindex_db.py
from pathlib import Path
from shutil import rmtree
import httpx
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.llamaindex import LlamaIndexVectorDb
from llama_index.core import (
    SimpleDirectoryReader,
    StorageContext,
    VectorStoreIndex,
)
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core.retrievers import VectorIndexRetriever

data_dir = Path(__file__).parent.parent.parent.joinpath("wip", "data", "paul_graham")
if data_dir.is_dir():
    rmtree(path=data_dir, ignore_errors=True)
data_dir.mkdir(parents=True, exist_ok=True)

url = "https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt"
file_path = data_dir.joinpath("paul_graham_essay.txt")
response = httpx.get(url)
if response.status_code == 200:
    with open(file_path, "wb") as file:
        file.write(response.content)
    print(f"File downloaded and saved as {file_path}")
else:
    print("Failed to download the file")


documents = SimpleDirectoryReader(str(data_dir)).load_data()

splitter = SentenceSplitter(chunk_size=1024)

nodes = splitter.get_nodes_from_documents(documents)

storage_context = StorageContext.from_defaults()

index = VectorStoreIndex(nodes=nodes, storage_context=storage_context)

knowledge_retriever = VectorIndexRetriever(index)

knowledge = Knowledge(
    vector_db=LlamaIndexVectorDb(knowledge_retriever=knowledge_retriever)
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    debug_mode=True,
)

agent.print_response(
    "Explain what this text means: low end eats the high end", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U llama-index-core llama-index-readers-file llama-index-embeddings-openai pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/llamaindex_db/llamaindex_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/llamaindex_db/llamaindex_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Milvus Async
Source: https://docs.agno.com/examples/concepts/vectordb/milvus-db/async-milvus-db



## Code

```python cookbook/knowledge/vector_db/milvus_db/async_milvus_db.py
import asyncio
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.milvus import Milvus

vector_db = Milvus(
    collection="recipes",
    uri="tmp/milvus.db",
)

knowledge = Knowledge(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
    vector_db=vector_db,
)

agent = Agent(knowledge=knowledge)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
    )

    asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymilvus pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/milvus_db/async_milvus_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/milvus_db/async_milvus_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Milvus Async Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/milvus-db/async-milvus-db-hybrid-search



## Code

```python cookbook/knowledge/vector_db/milvus_db/async_milvus_db_hybrid_search.py
import asyncio
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.milvus import Milvus, SearchType

vector_db = Milvus(
    collection="recipes", uri="tmp/milvus.db", search_type=SearchType.hybrid
)

knowledge = Knowledge(
    vector_db=vector_db,
)

asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
))

agent = Agent(knowledge=knowledge)
if __name__ == "__main__":
    asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymilvus pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/milvus_db/async_milvus_db_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/milvus_db/async_milvus_db_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Milvus
Source: https://docs.agno.com/examples/concepts/vectordb/milvus-db/milvus-db



## Code

```python cookbook/knowledge/vector_db/milvus_db/milvus_db.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.milvus import Milvus

vector_db = Milvus(
    collection="recipes",
    uri="tmp/milvus.db",
)

knowledge = Knowledge(
    name="My Milvus Knowledge Base",
    description="This is a knowledge base that uses a Milvus DB",
    vector_db=vector_db,
)

asyncio.run(
    knowledge.add_content_async(
        name="Recipes",
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        metadata={"doc_type": "recipe_book"},
    )
)

agent = Agent(knowledge=knowledge)
agent.print_response("How to make Tom Kha Gai", markdown=True)

vector_db.delete_by_name("Recipes")

vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymilvus pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/milvus_db/milvus_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/milvus_db/milvus_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Milvus Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/milvus-db/milvus-db-hybrid-search



## Code

```python cookbook/knowledge/vector_db/milvus_db/milvus_db_hybrid_search.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.milvus import Milvus, SearchType

vector_db = Milvus(
    collection="recipes", uri="tmp/milvus.db", search_type=SearchType.hybrid
)

knowledge = Knowledge(
    vector_db=vector_db,
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

agent = Agent(knowledge=knowledge)
agent.print_response("How to make Tom Kha Gai", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymilvus pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/milvus_db/milvus_db_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/milvus_db/milvus_db_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MongoDB Async
Source: https://docs.agno.com/examples/concepts/vectordb/mongo-db/async-mongo-db



## Code

```python cookbook/knowledge/vector_db/mongo_db/async_mongo_db.py

import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.mongodb import MongoDb

mdb_connection_string = "mongodb://localhost:27017"

knowledge = Knowledge(
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
    ),
)

agent = Agent(knowledge=knowledge)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
    )

    asyncio.run(agent.aprint_response("How to make Thai curry?", markdown=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymongo pypdf openai agno
    ```
  </Step>

  <Step title="Run MongoDB">
    ```bash
    docker run -d \
    --name local-mongo \
    -p 27017:27017 \
    -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
    -e MONGO_INITDB_ROOT_PASSWORD=secret \
    mongo
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/mongo_db/async_mongo_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/mongo_db/async_mongo_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MongoDB Cosmos vCore
Source: https://docs.agno.com/examples/concepts/vectordb/mongo-db/cosmos-mongodb-vcore



## Code

```python cookbook/knowledge/vector_db/mongo_db/cosmos_mongodb_vcore.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.mongodb import MongoDb


mdb_connection_string = "mongodb+srv://<username>:<encoded_password>@cluster0.mongocluster.cosmos.azure.com/?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000"

knowledge_base = Knowledge(
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
        search_index_name="recipes",
        cosmos_compatibility=True,
    ),
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(knowledge=knowledge_base)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymongo pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/mongo_db/cosmos_mongodb_vcore.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/mongo_db/cosmos_mongodb_vcore.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MongoDB
Source: https://docs.agno.com/examples/concepts/vectordb/mongo-db/mongo-db



## Code

```python cookbook/knowledge/vector_db/mongo_db/mongo_db.py

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.mongodb import MongoDb

mdb_connection_string = "mongodb://localhost:27017"
knowledge = Knowledge(
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
        search_index_name="recipes",
    ),
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

# Create and use the agent
agent = Agent(knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymongo pypdf openai agno
    ```
  </Step>

  <Step title="Run MongoDB">
    ```bash
    docker run -d \
    --name local-mongo \
    -p 27017:27017 \
    -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
    -e MONGO_INITDB_ROOT_PASSWORD=secret \
    mongo
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/mongo_db/mongo_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/mongo_db/mongo_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MongoDB Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/mongo-db/mongo-db-hybrid-search



## Code

```python cookbook/knowledge/vector_db/mongo_db/mongo_db_hybrid_search.py
import typer
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.mongodb import MongoDb
from agno.vectordb.search import SearchType
from rich.prompt import Prompt

mdb_connection_string = "mongodb://localhost:27017"

vector_db = MongoDb(
    collection_name="recipes",
    db_url=mdb_connection_string,
    search_index_name="recipes",
    search_type=SearchType.hybrid,
)

knowledge_base = Knowledge(
    vector_db=vector_db,
)

knowledge_base.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)


def mongodb_agent(user: str = "user"):
    agent = Agent(
        user_id=user,
        knowledge=knowledge_base,
        search_knowledge=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)


if __name__ == "__main__":
    typer.run(mongodb_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymongo typer rich pypdf openai agno
    ```
  </Step>

  <Step title="Run MongoDB">
    ```bash
    docker run -d \
    --name local-mongo \
    -p 27017:27017 \
    -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \
    -e MONGO_INITDB_ROOT_PASSWORD=secret \
    mongo
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/mongo_db/mongo_db_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/mongo_db/mongo_db_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PgVector Async
Source: https://docs.agno.com/examples/concepts/vectordb/pgvector/async-pgvector-db



## Code

```python cookbook/knowledge/vector_db/pgvector/async_pg_vector.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

vector_db = PgVector(table_name="recipes", db_url=db_url)

knowledge_base = Knowledge(
    vector_db=vector_db,
)

agent = Agent(knowledge=knowledge_base)

if __name__ == "__main__":

    asyncio.run(
        knowledge_base.add_content_async(url="https://docs.agno.com/introduction/agents.md")
    )


    asyncio.run(
        agent.aprint_response("What is the purpose of an Agno Agent?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U psycopg2-binary pgvector pypdf openai agno
    ```
  </Step>

  <Snippet file="run-pgvector.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/pgvector/async_pg_vector.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/pgvector/async_pg_vector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PgVector
Source: https://docs.agno.com/examples/concepts/vectordb/pgvector/pgvector-db



## Code

```python cookbook/knowledge/vector_db/pgvector/pgvector_db.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

vector_db = PgVector(table_name="vectors", db_url=db_url)

knowledge = Knowledge(
    name="My PG Vector Knowledge Base",
    description="This is a knowledge base that uses a PG Vector DB",
    vector_db=vector_db,
)
knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("How do I make pad thai?", markdown=True)

vector_db.delete_by_name("Recipes")

vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U psycopg2-binary pgvector pypdf openai agno
    ```
  </Step>

  <Snippet file="run-pgvector.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/pgvector/pgvector_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/pgvector/pgvector_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PgVector Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/pgvector/pgvector-hybrid-search



## Code

```python cookbook/knowledge/vector_db/pgvector/pgvector_hybrid_search.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    name="My PG Vector Knowledge Base",
    description="This is a knowledge base that uses a PG Vector DB",
    vector_db=PgVector(
        table_name="vectors", db_url=db_url, search_type=SearchType.hybrid
    ),
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
agent.print_response("What was my last question?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U psycopg2-binary pgvector pypdf openai agno
    ```
  </Step>

  <Snippet file="run-pgvector.mdx" />

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/pgvector/pgvector_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/pgvector/pgvector_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pinecone Async
Source: https://docs.agno.com/examples/concepts/vectordb/pinecone-db/async-pinecone-db



## Code

```python cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py
import asyncio
from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pineconedb import PineconeDb

api_key = getenv("PINECONE_API_KEY")
index_name = "thai-recipe-index"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
)

knowledge = Knowledge(
    name="My Pinecone Knowledge Base",
    description="This is a knowledge base that uses a Pinecone Vector DB",
    vector_db=vector_db,
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
            metadata={"doc_type": "recipe_book"},
        )
    )

    asyncio.run(
        agent.aprint_response("How do I make pad thai?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pinecone-client pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export PINECONE_API_KEY="your-pinecone-api-key"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pinecone
Source: https://docs.agno.com/examples/concepts/vectordb/pinecone-db/pinecone-db



## Code

```python cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py
from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pineconedb import PineconeDb

api_key = getenv("PINECONE_API_KEY")
index_name = "thai-recipe-index"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
)

knowledge = Knowledge(
    name="My Pinecone Knowledge Base",
    description="This is a knowledge base that uses a Pinecone Vector DB",
    vector_db=vector_db,
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("How do I make pad thai?", markdown=True)

vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pinecone-client pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export PINECONE_API_KEY="your-pinecone-api-key"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/pinecone_db/pinecone_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Qdrant Async
Source: https://docs.agno.com/examples/concepts/vectordb/qdrant-db/async-qdrant-db



## Code

```python cookbook/knowledge/vector_db/qdrant_db/async_qdrant_db.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant

COLLECTION_NAME = "thai-recipes"

vector_db = Qdrant(collection=COLLECTION_NAME, url="http://localhost:6333")

knowledge = Knowledge(
    vector_db=vector_db,
)

agent = Agent(knowledge=knowledge)


if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
        )
    )

    asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U qdrant-client pypdf openai agno
    ```
  </Step>

  <Step title="Run Qdrant">
    ```bash
    docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:latest
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/qdrant_db/async_qdrant_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/qdrant_db/async_qdrant_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Qdrant
Source: https://docs.agno.com/examples/concepts/vectordb/qdrant-db/qdrant-db



## Code

```python cookbook/knowledge/vector_db/qdrant_db/qdrant_db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant

COLLECTION_NAME = "thai-recipes"

vector_db = Qdrant(collection=COLLECTION_NAME, url="http://localhost:6333")

contents_db = PostgresDb(
    db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    knowledge_table="knowledge_contents",
)

knowledge = Knowledge(
    name="My Qdrant Vector Knowledge Base",
    description="This is a knowledge base that uses a Qdrant Vector DB",
    vector_db=vector_db,
    contents_db=contents_db,
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)


agent = Agent(knowledge=knowledge)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)


vector_db.delete_by_name("Recipes")

vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U qdrant-client pypdf openai agno
    ```
  </Step>

  <Step title="Run Qdrant">
    ```bash
    docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:latest
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/qdrant_db/qdrant_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/qdrant_db/qdrant_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Qdrant Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/qdrant-db/qdrant-db-hybrid-search



## Code

```python cookbook/knowledge/vector_db/qdrant_db/qdrant_db_hybrid_search.py
import typer
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.qdrant import Qdrant
from agno.vectordb.search import SearchType
from rich.prompt import Prompt

COLLECTION_NAME = "thai-recipes"

vector_db = Qdrant(
    collection=COLLECTION_NAME,
    url="http://localhost:6333",
    search_type=SearchType.hybrid,
)

knowledge = Knowledge(
    name="My Qdrant Vector Knowledge Base",
    vector_db=vector_db,
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)


def qdrantdb_agent(user: str = "user"):
    agent = Agent(
        user_id=user,
        knowledge=knowledge,
        search_knowledge=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)


if __name__ == "__main__":
    typer.run(qdrantdb_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U qdrant-client typer rich pypdf openai agno
    ```
  </Step>

  <Step title="Run Qdrant">
    ```bash
    docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:latest
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/qdrant_db/qdrant_db_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/qdrant_db/qdrant_db_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SingleStore Async
Source: https://docs.agno.com/examples/concepts/vectordb/singlestore-db/async-singlestore-db



## Code

```python cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py
import asyncio
from os import getenv

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.singlestore import SingleStore
from sqlalchemy.engine import create_engine

USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

db_engine = create_engine(db_url)

vector_db = SingleStore(
    collection="recipes",
    db_engine=db_engine,
    schema=DATABASE,
)

knowledge = Knowledge(name="My SingleStore Knowledge Base", vector_db=vector_db)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

if __name__ == "__main__":
    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
            metadata={"doc_type": "recipe_book"},
        )
    )

    asyncio.run(
        agent.aprint_response("How do I make pad thai?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U PyMySQL sqlalchemy pypdf openai agno
    ```
  </Step>

  <Step title="Run SingleStore">
    ```bash
    docker run -d --name singlestoredb \
    --platform linux/amd64 \
    -p 3306:3306 \
    -p 8080:8080 \
    -v /tmp:/var/lib/memsql \
    -e ROOT_PASSWORD=admin \
    -e SINGLESTORE_DB=AGNO \
    -e SINGLESTORE_USER=root \
    -e SINGLESTORE_PASSWORD=admin \
    -e LICENSE_KEY=accept \
    ghcr.io/singlestore-labs/singlestoredb-dev:latest

    docker start singlestoredb

    docker exec singlestoredb memsql -u root -padmin -e "CREATE DATABASE IF NOT EXISTS AGNO;" 
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export SINGLESTORE_HOST="localhost"
    export SINGLESTORE_PORT="3306"
    export SINGLESTORE_USERNAME="root"
    export SINGLESTORE_PASSWORD="admin"
    export SINGLESTORE_DATABASE="AGNO"
    export SINGLESTORE_SSL_CA=".certs/singlestore_bundle.pem"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SingleStore
Source: https://docs.agno.com/examples/concepts/vectordb/singlestore-db/singlestore-db



## Code

```python cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py
from os import getenv
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.singlestore import SingleStore
from sqlalchemy.engine import create_engine

USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

db_engine = create_engine(db_url)

vector_db = SingleStore(
    collection="recipes",
    db_engine=db_engine,
    schema=DATABASE,
)

knowledge = Knowledge(name="My SingleStore Knowledge Base", vector_db=vector_db)


knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)


agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("How do I make pad thai?", markdown=True)

vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U PyMySQL sqlalchemy pypdf openai agno
    ```
  </Step>

  <Step title="Run SingleStore">
    ```bash
    docker run -d --name singlestoredb \
    --platform linux/amd64 \
    -p 3306:3306 \
    -p 8080:8080 \
    -v /tmp:/var/lib/memsql \
    -e ROOT_PASSWORD=admin \
    -e SINGLESTORE_DB=AGNO \
    -e SINGLESTORE_USER=root \
    -e SINGLESTORE_PASSWORD=admin \
    -e LICENSE_KEY=accept \
    ghcr.io/singlestore-labs/singlestoredb-dev:latest

    docker start singlestoredb

    docker exec singlestoredb memsql -u root -padmin -e "CREATE DATABASE IF NOT EXISTS AGNO;" 
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export SINGLESTORE_HOST="localhost"
    export SINGLESTORE_PORT="3306"
    export SINGLESTORE_USERNAME="root"
    export SINGLESTORE_PASSWORD="admin"
    export SINGLESTORE_DATABASE="AGNO"
    export SINGLESTORE_SSL_CA=".certs/singlestore_bundle.pem"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/singlestore_db/singlestore_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SurrealDB Async
Source: https://docs.agno.com/examples/concepts/vectordb/surrealdb/async-surreal-db



## Code

```python cookbook/knowledge/vector_db/surrealdb/async_surreal_db.py
import asyncio

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.surrealdb import SurrealDb
from surrealdb import AsyncSurreal

SURREALDB_URL = "ws://localhost:8000"
SURREALDB_USER = "root"
SURREALDB_PASSWORD = "root"
SURREALDB_NAMESPACE = "test"
SURREALDB_DATABASE = "test"

# Create a client
client = AsyncSurreal(url=SURREALDB_URL)

surrealdb = SurrealDb(
    async_client=client,
    collection="recipes",  # Collection name for storing documents
    efc=150,  # HNSW construction time/accuracy trade-off
    m=12,  # HNSW max number of connections per element
    search_ef=40,  # HNSW search time/accuracy trade-off
    embedder=OpenAIEmbedder(),
)


async def async_demo():
    """Demonstrate asynchronous usage of SurrealDb"""

    await client.signin({"username": SURREALDB_USER, "password": SURREALDB_PASSWORD})
    await client.use(namespace=SURREALDB_NAMESPACE, database=SURREALDB_DATABASE)

    knowledge = Knowledge(
        vector_db=surrealdb,
    )

    await knowledge.add_content_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    )

    agent = Agent(knowledge=knowledge)
    await agent.aprint_response(
        "What are the 3 categories of Thai SELECT is given to restaurants overseas?",
        markdown=True,
    )


if __name__ == "__main__":
    # Run asynchronous demo
    print("\nRunning asynchronous demo...")
    asyncio.run(async_demo())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U surrealdb pypdf openai agno
    ```
  </Step>

  <Step title="Run SurrealDB">
    ```bash
    docker run --rm --pull always -p 8000:8000 surrealdb/surrealdb:latest start --user root --pass root     
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/surrealdb/async_surreal_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/surrealdb/async_surreal_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SurrealDB
Source: https://docs.agno.com/examples/concepts/vectordb/surrealdb/surreal-db



## Code

```python cookbook/knowledge/vector_db/surrealdb/surreal_db.py
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.surrealdb import SurrealDb
from surrealdb import Surreal

# SurrealDB connection parameters
SURREALDB_URL = "ws://localhost:8000"
SURREALDB_USER = "root"
SURREALDB_PASSWORD = "root"
SURREALDB_NAMESPACE = "test"
SURREALDB_DATABASE = "test"

# Create a client
client = Surreal(url=SURREALDB_URL)
client.signin({"username": SURREALDB_USER, "password": SURREALDB_PASSWORD})
client.use(namespace=SURREALDB_NAMESPACE, database=SURREALDB_DATABASE)

surrealdb = SurrealDb(
    client=client,
    collection="recipes",  # Collection name for storing documents
    efc=150,  # HNSW construction time/accuracy trade-off
    m=12,  # HNSW max number of connections per element
    search_ef=40,  # HNSW search time/accuracy trade-off
    embedder=OpenAIEmbedder(),
)


def sync_demo():
    """Demonstrate synchronous usage of SurrealDb"""
    knowledge = Knowledge(
        vector_db=surrealdb,
    )

    # Load data synchronously
    knowledge.add_content(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    )

    agent = Agent(knowledge=knowledge)
    agent.print_response(
        "What are the 3 categories of Thai SELECT is given to restaurants overseas?",
        markdown=True,
    )


if __name__ == "__main__":
    print("Running synchronous demo...")
    sync_demo()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U surrealdb pypdf openai agno
    ```
  </Step>

  <Step title="Run SurrealDB">
    ```bash
    docker run --rm --pull always -p 8000:8000 surrealdb/surrealdb:latest start --user root --pass root     
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/surrealdb/surreal_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/surrealdb/surreal_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Upstash Async
Source: https://docs.agno.com/examples/concepts/vectordb/upstash-db/async-upstash-db



## Code

```python cookbook/knowledge/vector_db/upstash_db/upstash_db.py
import asyncio
import os

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.upstashdb import UpstashVectorDb

# How to connect to an Upstash Vector index
# - Create a new index in Upstash Console with the correct dimension
# - Fetch the URL and token from Upstash Console
# - Replace the values below or use environment variables

vector_db = UpstashVectorDb(
    url=os.getenv("UPSTASH_VECTOR_REST_URL"),
    token=os.getenv("UPSTASH_VECTOR_REST_TOKEN"),
)

# Initialize Upstash DB
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with Upstash Vector DB",
    vector_db=vector_db,
)

# Create and use the agent
agent = Agent(knowledge=knowledge)

if __name__ == "__main__":
    # Comment out after first run
    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
            metadata={"doc_type": "recipe_book"},
        )
    )

    # Create and use the agent
    asyncio.run(
        agent.aprint_response("How to make Pad Thai?", markdown=True)
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U upstash-vector pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export UPSTASH_VECTOR_REST_URL="your-upstash-vector-rest-url"
    export UPSTASH_VECTOR_REST_TOKEN="your-upstash-vector-rest-token"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/upstash_db/upstash_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/upstash_db/upstash_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Upstash
Source: https://docs.agno.com/examples/concepts/vectordb/upstash-db/upstash-db



## Code

```python cookbook/knowledge/vector_db/upstash_db/upstash_db.py
import os

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.upstashdb import UpstashVectorDb

# How to connect to an Upstash Vector index
# - Create a new index in Upstash Console with the correct dimension
# - Fetch the URL and token from Upstash Console
# - Replace the values below or use environment variables

vector_db = UpstashVectorDb(
    url=os.getenv("UPSTASH_VECTOR_REST_URL"),
    token=os.getenv("UPSTASH_VECTOR_REST_TOKEN"),
)

# Initialize Upstash DB
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with Upstash Vector DB",
    vector_db=vector_db,
)

# Add content with metadata
knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
)

# Create and use the agent
agent = Agent(knowledge=knowledge)
agent.print_response("How to make Pad Thai?", markdown=True)


vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U upstash-vector pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export UPSTASH_VECTOR_REST_URL="your-upstash-vector-rest-url"
    export UPSTASH_VECTOR_REST_TOKEN="your-upstash-vector-rest-token"
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/upstash_db/upstash_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/upstash_db/upstash_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Weaviate Async
Source: https://docs.agno.com/examples/concepts/vectordb/weaviate-db/async-weaviate-db



## Code

```python cookbook/knowledge/vector_db/weaviate_db/async_weaviate_db.py

import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.search import SearchType
from agno.vectordb.weaviate import Distance, VectorIndex, Weaviate

vector_db = Weaviate(
    collection="recipes_async",
    search_type=SearchType.hybrid,
    vector_index=VectorIndex.HNSW,
    distance=Distance.COSINE,
    local=True,  # Set to False if using Weaviate Cloud and True if using local instance
)
# Create knowledge base
knowledge = Knowledge(
    vector_db=vector_db,
)

agent = Agent(
    knowledge=knowledge,
    search_knowledge=True,
)

if __name__ == "__main__":
    # Comment out after first run
    asyncio.run(
        knowledge.add_content_async(
            name="Recipes",
            url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
        )
    )

    # Create and use the agent
    asyncio.run(agent.aprint_response("How to make Tom Kha Gai", markdown=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U weaviate-client pypdf openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Setup Weaviate">
    <CodeGroup>
      ```bash Weaviate Cloud
      # 1. Create account at https://console.weaviate.cloud/
      # 2. Create a cluster and copy the "REST endpoint" and "Admin" API Key
      # 3. Set environment variables:
      export WCD_URL="your-cluster-url" 
      export WCD_API_KEY="your-api-key"
      # 4. Set local=False in the code
      ```

      ```bash Local Development
      # 1. Install Docker from https://docs.docker.com/get-docker/
      # 2. Run Weaviate locally:
      docker run -d \
          -p 8080:8080 \
          -p 50051:50051 \
          --name weaviate \
          cr.weaviate.io/semitechnologies/weaviate:1.28.4
      # 3. Set local=True in the code
      ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/weaviate_db/async_weaviate_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/weaviate_db/async_weaviate_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Weaviate
Source: https://docs.agno.com/examples/concepts/vectordb/weaviate-db/weaviate-db



## Code

```python cookbook/knowledge/vector_db/weaviate_db/weaviate_db.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.search import SearchType
from agno.vectordb.weaviate import Weaviate
from agno.vectordb.weaviate.index import Distance, VectorIndex

vector_db = Weaviate(
    collection="vectors",
    search_type=SearchType.vector,
    vector_index=VectorIndex.HNSW,
    distance=Distance.COSINE,
    local=False,  # Set to True if using Weaviate locally
)

# Create Knowledge Instance with Weaviate
knowledge = Knowledge(
    name="Basic SDK Knowledge Base",
    description="Agno 2.0 Knowledge Implementation with Weaviate",
    vector_db=vector_db,
)

knowledge.add_content(
    name="Recipes",
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    metadata={"doc_type": "recipe_book"},
    skip_if_exists=True,
)

# Create and use the agent
agent = Agent(knowledge=knowledge)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)

# Delete operations
vector_db.delete_by_name("Recipes")
# or
vector_db.delete_by_metadata({"doc_type": "recipe_book"})
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U weaviate-client pypdf openai agno
    ```
  </Step>

  <Step title="Setup Weaviate">
    <CodeGroup>
      ```bash Weaviate Cloud
      # 1. Create account at https://console.weaviate.cloud/
      # 2. Create a cluster and copy the "REST endpoint" and "Admin" API Key
      # 3. Set environment variables:
      export WCD_URL="your-cluster-url" 
      export WCD_API_KEY="your-api-key"
      # 4. Set local=False in the code
      ```

      ```bash Local Development
      # 1. Install Docker from https://docs.docker.com/get-docker/
      # 2. Run Weaviate locally:
      docker run -d \
          -p 8080:8080 \
          -p 50051:50051 \
          --name weaviate \
          cr.weaviate.io/semitechnologies/weaviate:1.28.4
      # 3. Set local=True in the code
      ```
    </CodeGroup>
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/weaviate_db/weaviate_db.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/weaviate_db/weaviate_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Weaviate Hybrid Search
Source: https://docs.agno.com/examples/concepts/vectordb/weaviate-db/weaviate-db-hybrid-search



## Code

```python cookbook/knowledge/vector_db/weaviate_db/weaviate_db_hybrid_search.py
import typer
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.search import SearchType
from agno.vectordb.weaviate import Distance, VectorIndex, Weaviate
from rich.prompt import Prompt

vector_db = Weaviate(
    collection="recipes",
    search_type=SearchType.hybrid,
    vector_index=VectorIndex.HNSW,
    distance=Distance.COSINE,
    local=False,  # Set to True if using Weaviate Cloud and False if using local instance
    # Adjust alpha for hybrid search (0.0-1.0, default is 0.5), where 0 is pure keyword search, 1 is pure vector search
    hybrid_search_alpha=0.6,
)

knowledge_base = Knowledge(
    name="Weaviate Hybrid Search",
    description="A knowledge base for Weaviate hybrid search",
    vector_db=vector_db,
)

knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)


def weaviate_agent(user: str = "user"):
    agent = Agent(
        user_id=user,
        knowledge=knowledge_base,
        search_knowledge=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)


if __name__ == "__main__":
    typer.run(weaviate_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U weaviate-client typer rich pypdf openai agno
    ```
  </Step>

  <Step title="Setup Weaviate">
    <CodeGroup>
      ```bash Weaviate Cloud
      # 1. Create account at https://console.weaviate.cloud/
      # 2. Create a cluster and copy the "REST endpoint" and "Admin" API Key
      # 3. Set environment variables:
      export WCD_URL="your-cluster-url" 
      export WCD_API_KEY="your-api-key"
      # 4. Set local=False in the code
      ```

      ```bash Local Development
      # 1. Install Docker from https://docs.docker.com/get-docker/
      # 2. Run Weaviate locally:
      docker run -d \
          -p 8080:8080 \
          -p 50051:50051 \
          --name weaviate \
          cr.weaviate.io/semitechnologies/weaviate:1.28.4
      # 3. Set local=True in the code
      ```
    </CodeGroup>
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/knowledge/vector_db/weaviate_db/weaviate_db_hybrid_search.py
      ```

      ```bash Windows
      python cookbook/knowledge/vector_db/weaviate_db/weaviate_db_hybrid_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Function instead of steps
Source: https://docs.agno.com/examples/concepts/workflows/01-basic-workflows/function_instead_of_steps

This example demonstrates how to use just a single function instead of steps in a workflow.

This example demonstrates **Workflows** using a single custom execution function instead of
discrete steps. This pattern gives you complete control over the orchestration logic while still
benefiting from workflow features like storage, streaming, and session management.

**When to use**: When you need maximum flexibility and control over the execution flow, similar
to Workflows 1.0 approach but with a better structured approach.

```python function_instead_of_steps.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.types import WorkflowExecutionInput
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)


def custom_execution_function(
    workflow: Workflow, execution_input: WorkflowExecutionInput
):
    print(f"Executing workflow: {workflow.name}")

    # Run the research team
    run_response = research_team.run(execution_input.input)
    research_content = run_response.content

    # Create intelligent planning prompt
    planning_prompt = f"""
        STRATEGIC CONTENT PLANNING REQUEST:

        Core Topic: {execution_input.input}

        Research Results: {research_content[:500]}

        Planning Requirements:
        1. Create a comprehensive content strategy based on the research
        2. Leverage the research findings effectively
        3. Identify content formats and channels
        4. Provide timeline and priority recommendations
        5. Include engagement and distribution strategies

        Please create a detailed, actionable content plan.
    """
    content_plan = content_planner.run(planning_prompt)

    # Return the content plan
    return content_plan.content


# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        steps=custom_execution_function,
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
    )
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Function instead of steps (sync streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_03_function_instead_of_steps/sync/function_instead_of_steps_stream.py)
* [Function instead of steps (async non-streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_03_function_instead_of_steps/async/function_instead_of_steps.py)
* [Function instead of steps (async streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_03_function_instead_of_steps/async/function_instead_of_steps_stream.py)


# Sequence of functions and agents
Source: https://docs.agno.com/examples/concepts/workflows/01-basic-workflows/sequence_of_functions_and_agents

This example demonstrates how to use a sequence of functions and agents in a workflow.

This example demonstrates **Workflows** combining custom functions with agents and teams
in a sequential execution pattern. This shows how to mix different component types for
maximum flexibility in your workflow design.

**When to use**: Linear processes where you need custom data preprocessing between AI agents,
or when combining multiple component types (functions, agents, teams) in sequence.

```python sequence_of_functions_and_agents.py
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.types import StepInput, StepOutput
from agno.workflow.workflow import Workflow

# Define agents
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)

writer_agent = Agent(
    name="Writer Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Write a blog post on the topic",
)


def prepare_input_for_web_search(step_input: StepInput) -> StepOutput:
    topic = step_input.input
    return StepOutput(
        content=dedent(f"""\
	I'm writing a blog post on the topic
	<topic>
	{topic}
	</topic>

	Search the web for atleast 10 articles\
	""")
    )


def prepare_input_for_writer(step_input: StepInput) -> StepOutput:
    topic = step_input.input
    research_team_output = step_input.previous_step_content

    return StepOutput(
        content=dedent(f"""\
	I'm writing a blog post on the topic:
	<topic>
	{topic}
	</topic>

	Here is information from the web:
	<research_results>
	{research_team_output}
	<research_results>\
	""")
    )


# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)


# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Blog Post Workflow",
        description="Automated blog post creation from Hackernews and the web",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        steps=[
            prepare_input_for_web_search,
            research_team,
            prepare_input_for_writer,
            writer_agent,
        ],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Sequence of functions and agents (sync streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/sync/sequence_of_functions_and_agents_stream.py)
* [Sequence of functions and agents (async non-streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/async/sequence_of_functions_and_agents.py)
* [Sequence of functions and agents (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/async/sequence_of_functions_and_agents_stream.py)


# Sequence of steps
Source: https://docs.agno.com/examples/concepts/workflows/01-basic-workflows/sequence_of_steps

This example demonstrates how to use named steps in a workflow.

This example demonstrates **Workflows** using named Step objects for better tracking
and organization. This pattern provides clear step identification and enhanced logging
while maintaining simple sequential execution.

## Pattern: Sequential Named Steps

**When to use**: Linear processes where you want clear step identification, better logging,
and future platform support. Ideal when you have distinct phases that benefit from naming.

```python sequence_of_steps.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

content_creation_workflow = Workflow(
    name="Content Creation Workflow",
    description="Automated content creation from blog posts to social media",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflow.db",
    ),
    steps=[research_step, content_planning_step],
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Sequence of steps (sync streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/sync/sequence_of_steps.py)
* [Sequence of steps (async non-streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/async/sequence_of_steps.py)
* [Sequence of steps (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/async/sequence_of_steps_stream.py)


# Step with function
Source: https://docs.agno.com/examples/concepts/workflows/01-basic-workflows/step_with_function

This example demonstrates how to use named steps with custom function executors.

This example demonstrates **Workflows** using named Step objects with custom function
executors. This pattern combines the benefits of named steps with the flexibility of
custom functions, allowing for sophisticated data processing within structured workflow steps.

**When to use**: When you need named step organization but want custom logic that goes
beyond what agents/teams provide. Ideal for complex data processing, multi-step operations,
or when you need to orchestrate multiple agents within a single step.

```python step_with_function.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step, StepInput, StepOutput
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    instructions="Extract key insights and content from Hackernews posts",
)

web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Analyze content and create comprehensive social media strategy",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)


def custom_content_planning_function(step_input: StepInput) -> StepOutput:
    """
    Custom function that does intelligent content planning with context awareness
    """
    message = step_input.input
    previous_step_content = step_input.previous_step_content

    # Create intelligent planning prompt
    planning_prompt = f"""
        STRATEGIC CONTENT PLANNING REQUEST:

        Core Topic: {message}

        Research Results: {previous_step_content[:500] if previous_step_content else "No research results"}

        Planning Requirements:
        1. Create a comprehensive content strategy based on the research
        2. Leverage the research findings effectively
        3. Identify content formats and channels
        4. Provide timeline and priority recommendations
        5. Include engagement and distribution strategies

        Please create a detailed, actionable content plan.
    """

    try:
        response = content_planner.run(planning_prompt)

        enhanced_content = f"""
            ## Strategic Content Plan

            **Planning Topic:** {message}

            **Research Integration:** {"‚úì Research-based" if previous_step_content else "‚úó No research foundation"}

            **Content Strategy:**
            {response.content}

            **Custom Planning Enhancements:**
            - Research Integration: {"High" if previous_step_content else "Baseline"}
            - Strategic Alignment: Optimized for multi-channel distribution
            - Execution Ready: Detailed action items included
        """.strip()

        return StepOutput(content=enhanced_content)

    except Exception as e:
        return StepOutput(
            content=f"Custom content planning failed: {str(e)}",
            success=False,
        )


# Define steps using different executor types

research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    executor=custom_content_planning_function,
)


# Define and use examples
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation with custom execution options",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        # Define the sequence of steps
        # First run the research_step, then the content_planning_step
        # You can mix and match agents, teams, and even regular python functions directly as steps
        steps=[research_step, content_planning_step],
    )
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

    print("\n" + "=" * 60 + "\n")
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Step with function (sync streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_02_step_with_function/sync/step_with_function_stream.py)
* [Step with function (async non-streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_01_basic_workflows/_02_step_with_function/async/step_with_function.py)
* [Step with function (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_01_basic_workflows/_02_step_with_function/async/step_with_function_stream.py)


# Workflow using steps
Source: https://docs.agno.com/examples/concepts/workflows/01-basic-workflows/workflow_using_steps

This example demonstrates how to use the Steps object to organize multiple individual steps into logical sequences.

This example demonstrates **Workflows** using the Steps object to organize multiple
individual steps into logical sequences. This pattern allows you to define reusable step
sequences and choose which sequences to execute in your workflow.

**When to use**: When you have logical groupings of steps that you want to organize, reuse,
or selectively execute. Ideal for creating modular workflow components that can be mixed
and matched based on different scenarios.

```python workflow_using_steps.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.workflow.step import Step
from agno.workflow.steps import Steps
from agno.workflow.workflow import Workflow

# Define agents for different tasks
researcher = Agent(
    name="Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Research the given topic and provide key facts and insights.",
)

writer = Agent(
    name="Writing Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Write a comprehensive article based on the research provided. Make it engaging and well-structured.",
)

editor = Agent(
    name="Editor Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Review and edit the article for clarity, grammar, and flow. Provide a polished final version.",
)

# Define individual steps
research_step = Step(
    name="research",
    agent=researcher,
    description="Research the topic and gather information",
)

writing_step = Step(
    name="writing",
    agent=writer,
    description="Write an article based on the research",
)

editing_step = Step(
    name="editing",
    agent=editor,
    description="Edit and polish the article",
)

# Create a Steps sequence that chains these above steps together
article_creation_sequence = Steps(
    name="article_creation",
    description="Complete article creation workflow from research to final edit",
    steps=[research_step, writing_step, editing_step],
)

# Create and use workflow
if __name__ == "__main__":
    article_workflow = Workflow(
        name="Article Creation Workflow",
        description="Automated article creation from research to publication",
        steps=[article_creation_sequence],
    )

    article_workflow.print_response(
        input="Write an article about the benefits of renewable energy",
        markdown=True,
    )
```

To see the async example, see the cookbook-

* [Workflow using steps (async)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_01_sequence_of_steps/sync/workflow_using_steps.py)


# Workflow using Steps with Nested Pattern
Source: https://docs.agno.com/examples/concepts/workflows/01-basic-workflows/workflow_using_steps_nested

This example demonstrates **Workflows 2.0** nested patterns using `Steps` to encapsulate a complex workflow with conditional parallel execution.

This example demonstrates **Workflows** nested patterns using `Steps` to encapsulate
a complex workflow with conditional parallel execution. It combines `Condition`, `Parallel`,
and `Steps` for modular and adaptive content creation.

```python workflow_using_steps_nested.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.exa import ExaTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.condition import Condition
from agno.workflow.parallel import Parallel
from agno.workflow.step import Step
from agno.workflow.steps import Steps
from agno.workflow.workflow import Workflow

# Define agents for different tasks
researcher = Agent(
    name="Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Research the given topic and provide key facts and insights.",
)

tech_researcher = Agent(
    name="Tech Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    instructions="Research tech-related topics from Hacker News and provide latest developments.",
)

news_researcher = Agent(
    name="News Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ExaTools()],
    instructions="Research current news and trends using Exa search.",
)

writer = Agent(
    name="Writing Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Write a comprehensive article based on the research provided. Make it engaging and well-structured.",
)

editor = Agent(
    name="Editor Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Review and edit the article for clarity, grammar, and flow. Provide a polished final version.",
)

content_agent = Agent(
    name="Content Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Prepare and format content for writing based on research inputs.",
)

# Define individual steps
initial_research_step = Step(
    name="InitialResearch",
    agent=researcher,
    description="Initial research on the topic",
)


# Condition evaluator function
def is_tech_topic(step_input) -> bool:
    """Check if the topic is tech-related and needs specialized research"""
    message = step_input.input.lower() if step_input.input else ""
    tech_keywords = [
        "ai",
        "machine learning",
        "technology",
        "software",
        "programming",
        "tech",
        "startup",
        "blockchain",
    ]
    return any(keyword in message for keyword in tech_keywords)


# Define parallel research steps
tech_research_step = Step(
    name="TechResearch",
    agent=tech_researcher,
    description="Research tech developments from Hacker News",
)

news_research_step = Step(
    name="NewsResearch",
    agent=news_researcher,
    description="Research current news and trends",
)

# Define content preparation step
content_prep_step = Step(
    name="ContentPreparation",
    agent=content_agent,
    description="Prepare and organize all research for writing",
)

writing_step = Step(
    name="Writing",
    agent=writer,
    description="Write an article based on the research",
)

editing_step = Step(
    name="Editing",
    agent=editor,
    description="Edit and polish the article",
)

# Create a Steps sequence with a Condition containing Parallel steps
article_creation_sequence = Steps(
    name="ArticleCreation",
    description="Complete article creation workflow from research to final edit",
    steps=[
        initial_research_step,
        # Condition with Parallel steps inside
        Condition(
            name="TechResearchCondition",
            description="If topic is tech-related, do specialized parallel research",
            evaluator=is_tech_topic,
            steps=[
                Parallel(
                    tech_research_step,
                    news_research_step,
                    name="SpecializedResearch",
                    description="Parallel tech and news research",
                ),
                content_prep_step,
            ],
        ),
        writing_step,
        editing_step,
    ],
)

# Create and use workflow
if __name__ == "__main__":
    article_workflow = Workflow(
        name="Enhanced Article Creation Workflow",
        description="Automated article creation with conditional parallel research",
        steps=[article_creation_sequence],
    )

    article_workflow.print_response(
        input="Write an article about the latest AI developments in machine learning",
        markdown=True,
        stream=True,
        stream_intermediate_steps=True,
    )
```


# Condition and Parallel Steps Workflow
Source: https://docs.agno.com/examples/concepts/workflows/02-workflows-conditional-execution/condition_and_parallel_steps_stream

This example demonstrates **Workflows 2.0** advanced pattern combining conditional execution with parallel processing.

This example shows how to create sophisticated workflows where multiple
conditions evaluate simultaneously, each potentially triggering different research strategies
based on comprehensive content analysis.

**When to use**: When you need comprehensive, multi-dimensional content analysis where
different aspects of the input may trigger different specialized research pipelines
simultaneously. Ideal for adaptive research workflows that can leverage multiple sources
based on various content characteristics.

```python condition_and_parallel_steps_stream.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.exa import ExaTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.condition import Condition
from agno.workflow.parallel import Parallel
from agno.workflow.step import Step
from agno.workflow.types import StepInput
from agno.workflow.workflow import Workflow

# === AGENTS ===
hackernews_agent = Agent(
    name="HackerNews Researcher",
    instructions="Research tech news and trends from Hacker News",
    tools=[HackerNewsTools()],
)

web_agent = Agent(
    name="Web Researcher",
    instructions="Research general information from the web",
    tools=[DuckDuckGoTools()],
)

exa_agent = Agent(
    name="Exa Search Researcher",
    instructions="Research using Exa advanced search capabilities",
    tools=[ExaTools()],
)

content_agent = Agent(
    name="Content Creator",
    instructions="Create well-structured content from research data",
)

# === RESEARCH STEPS ===
research_hackernews_step = Step(
    name="ResearchHackerNews",
    description="Research tech news from Hacker News",
    agent=hackernews_agent,
)

research_web_step = Step(
    name="ResearchWeb",
    description="Research general information from web",
    agent=web_agent,
)

research_exa_step = Step(
    name="ResearchExa",
    description="Research using Exa search",
    agent=exa_agent,
)

prepare_input_for_write_step = Step(
    name="PrepareInput",
    description="Prepare and organize research data for writing",
    agent=content_agent,
)

write_step = Step(
    name="WriteContent",
    description="Write the final content based on research",
    agent=content_agent,
)


# === CONDITION EVALUATORS ===
def check_if_we_should_search_hn(step_input: StepInput) -> bool:
    """Check if we should search Hacker News"""
    topic = step_input.input or step_input.previous_step_content or ""
    tech_keywords = [
        "ai",
        "machine learning",
        "programming",
        "software",
        "tech",
        "startup",
        "coding",
    ]
    return any(keyword in topic.lower() for keyword in tech_keywords)


def check_if_we_should_search_web(step_input: StepInput) -> bool:
    """Check if we should search the web"""
    topic = step_input.input or step_input.previous_step_content or ""
    general_keywords = ["news", "information", "research", "facts", "data"]
    return any(keyword in topic.lower() for keyword in general_keywords)


def check_if_we_should_search_x(step_input: StepInput) -> bool:
    """Check if we should search X/Twitter"""
    topic = step_input.input or step_input.previous_step_content or ""
    social_keywords = [
        "trending",
        "viral",
        "social",
        "discussion",
        "opinion",
        "twitter",
        "x",
    ]
    return any(keyword in topic.lower() for keyword in social_keywords)


def check_if_we_should_search_exa(step_input: StepInput) -> bool:
    """Check if we should use Exa search"""
    topic = step_input.input or step_input.previous_step_content or ""
    advanced_keywords = ["deep", "academic", "research", "analysis", "comprehensive"]
    return any(keyword in topic.lower() for keyword in advanced_keywords)


if __name__ == "__main__":
    workflow = Workflow(
        name="Conditional Workflow",
        steps=[
            Parallel(
                Condition(
                    name="HackerNewsCondition",
                    description="Check if we should search Hacker News for tech topics",
                    evaluator=check_if_we_should_search_hn,
                    steps=[research_hackernews_step],
                ),
                Condition(
                    name="WebSearchCondition",
                    description="Check if we should search the web for general information",
                    evaluator=check_if_we_should_search_web,
                    steps=[research_web_step],
                ),
                Condition(
                    name="ExaSearchCondition",
                    description="Check if we should use Exa for advanced search",
                    evaluator=check_if_we_should_search_exa,
                    steps=[research_exa_step],
                ),
                name="ConditionalResearch",
                description="Run conditional research steps in parallel",
            ),
            prepare_input_for_write_step,
            write_step,
        ],
    )

    try:
        workflow.print_response(
            input="Latest AI developments in machine learning",
            stream=True,
            stream_intermediate_steps=True,
        )
    except Exception as e:
        print(f"‚ùå Error: {e}")
    print()
```

This was a synchronous streaming example of this pattern. To checkout async and non-streaming versions, see the cookbooks-

* [Condition and Parallel Steps Workflow (sync)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_02_workflows_conditional_execution/sync/condition_and_parallel_steps.py)
* [Condition and Parallel Steps Workflow (async non-streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_02_workflows_conditional_execution/async/condition_and_parallel_steps.py)
* [Condition and Parallel Steps Workflow (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_02_workflows_conditional_execution/async/condition_and_parallel_steps_stream.py)


# Condition steps workflow
Source: https://docs.agno.com/examples/concepts/workflows/02-workflows-conditional-execution/condition_steps_workflow_stream

This example demonstrates how to use conditional steps in a workflow.

This example demonstrates **Workflows 2.0** conditional execution pattern. Shows how to conditionally execute steps based on content analysis,
providing intelligent selection of steps based on the actual data being processed.

**When to use**: When you need intelligent selection of steps based on content analysis rather than
simple input parameters or some other business logic. Ideal for quality gates, content-specific processing, or
adaptive workflows that respond to intermediate results.

```python condition_steps_workflow_stream.py
from agno.agent.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.workflow.condition import Condition
from agno.workflow.step import Step
from agno.workflow.types import StepInput
from agno.workflow.workflow import Workflow

# === BASIC AGENTS ===
researcher = Agent(
    name="Researcher",
    instructions="Research the given topic and provide detailed findings.",
    tools=[DuckDuckGoTools()],
)

summarizer = Agent(
    name="Summarizer",
    instructions="Create a clear summary of the research findings.",
)

fact_checker = Agent(
    name="Fact Checker",
    instructions="Verify facts and check for accuracy in the research.",
    tools=[DuckDuckGoTools()],
)

writer = Agent(
    name="Writer",
    instructions="Write a comprehensive article based on all available research and verification.",
)

# === CONDITION EVALUATOR ===


def needs_fact_checking(step_input: StepInput) -> bool:
    """Determine if the research contains claims that need fact-checking"""
    summary = step_input.previous_step_content or ""

    # Look for keywords that suggest factual claims
    fact_indicators = [
        "study shows",
        "research indicates",
        "according to",
        "statistics",
        "data shows",
        "survey",
        "report",
        "million",
        "billion",
        "percent",
        "%",
        "increase",
        "decrease",
    ]

    return any(indicator in summary.lower() for indicator in fact_indicators)


# === WORKFLOW STEPS ===
research_step = Step(
    name="research",
    description="Research the topic",
    agent=researcher,
)

summarize_step = Step(
    name="summarize",
    description="Summarize research findings",
    agent=summarizer,
)

# Conditional fact-checking step
fact_check_step = Step(
    name="fact_check",
    description="Verify facts and claims",
    agent=fact_checker,
)

write_article = Step(
    name="write_article",
    description="Write final article",
    agent=writer,
)

# === BASIC LINEAR WORKFLOW ===
basic_workflow = Workflow(
    name="Basic Linear Workflow",
    description="Research -> Summarize -> Condition(Fact Check) -> Write Article",
    steps=[
        research_step,
        summarize_step,
        Condition(
            name="fact_check_condition",
            description="Check if fact-checking is needed",
            evaluator=needs_fact_checking,
            steps=[fact_check_step],
        ),
        write_article,
    ],
)

if __name__ == "__main__":
    print("üöÄ Running Basic Linear Workflow Example")
    print("=" * 50)

    try:
        basic_workflow.print_response(
            input="Recent breakthroughs in quantum computing",
            stream=True,
            stream_intermediate_steps=True,
        )
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback

        traceback.print_exc()
```

To see the async example, see the cookbook-

* [Condition steps workflow (async streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_02_workflows_conditional_execution/sync/condition_steps_workflow_stream.py)


# Condition with list of steps
Source: https://docs.agno.com/examples/concepts/workflows/02-workflows-conditional-execution/condition_with_list_of_steps

This example demonstrates how to use conditional step to execute multiple steps in parallel.

This example demonstrates **Workflows 2.0** advanced conditional execution where conditions
can trigger multiple steps and run in parallel. Shows how to create sophisticated branching
logic with complex multi-step sequences based on content analysis.

**When to use**: When different topics or content types require completely different
processing pipelines. Ideal for adaptive workflows where the research methodology
should change based on the subject matter or complexity requirements.

```python condition_with_list_of_steps.py
from agno.agent.agent import Agent
from agno.tools.exa import ExaTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.condition import Condition
from agno.workflow.parallel import Parallel
from agno.workflow.step import Step
from agno.workflow.types import StepInput
from agno.workflow.workflow import Workflow

# === AGENTS ===
hackernews_agent = Agent(
    name="HackerNews Researcher",
    instructions="Research tech news and trends from Hacker News",
    tools=[HackerNewsTools()],
)

exa_agent = Agent(
    name="Exa Search Researcher",
    instructions="Research using Exa advanced search capabilities",
    tools=[ExaTools()],
)

content_agent = Agent(
    name="Content Creator",
    instructions="Create well-structured content from research data",
)

# Additional agents for multi-step condition
trend_analyzer_agent = Agent(
    name="Trend Analyzer",
    instructions="Analyze trends and patterns from research data",
)

fact_checker_agent = Agent(
    name="Fact Checker",
    instructions="Verify facts and cross-reference information",
)

# === RESEARCH STEPS ===
research_hackernews_step = Step(
    name="ResearchHackerNews",
    description="Research tech news from Hacker News",
    agent=hackernews_agent,
)

research_exa_step = Step(
    name="ResearchExa",
    description="Research using Exa search",
    agent=exa_agent,
)

# === MULTI-STEP CONDITION STEPS ===
deep_exa_analysis_step = Step(
    name="DeepExaAnalysis",
    description="Conduct deep analysis using Exa search capabilities",
    agent=exa_agent,
)

trend_analysis_step = Step(
    name="TrendAnalysis",
    description="Analyze trends and patterns from the research data",
    agent=trend_analyzer_agent,
)

fact_verification_step = Step(
    name="FactVerification",
    description="Verify facts and cross-reference information",
    agent=fact_checker_agent,
)

# === FINAL STEPS ===
write_step = Step(
    name="WriteContent",
    description="Write the final content based on research",
    agent=content_agent,
)


# === CONDITION EVALUATORS ===
def check_if_we_should_search_hn(step_input: StepInput) -> bool:
    """Check if we should search Hacker News"""
    topic = step_input.input or step_input.previous_step_content or ""
    tech_keywords = [
        "ai",
        "machine learning",
        "programming",
        "software",
        "tech",
        "startup",
        "coding",
    ]
    return any(keyword in topic.lower() for keyword in tech_keywords)


def check_if_comprehensive_research_needed(step_input: StepInput) -> bool:
    """Check if comprehensive multi-step research is needed"""
    topic = step_input.input or step_input.previous_step_content or ""
    comprehensive_keywords = [
        "comprehensive",
        "detailed",
        "thorough",
        "in-depth",
        "complete analysis",
        "full report",
        "extensive research",
    ]
    return any(keyword in topic.lower() for keyword in comprehensive_keywords)


if __name__ == "__main__":
    workflow = Workflow(
        name="Conditional Workflow with Multi-Step Condition",
        steps=[
            Parallel(
                Condition(
                    name="HackerNewsCondition",
                    description="Check if we should search Hacker News for tech topics",
                    evaluator=check_if_we_should_search_hn,
                    steps=[research_hackernews_step],  # Single step
                ),
                Condition(
                    name="ComprehensiveResearchCondition",
                    description="Check if comprehensive multi-step research is needed",
                    evaluator=check_if_comprehensive_research_needed,
                    steps=[  # Multiple steps
                        deep_exa_analysis_step,
                        trend_analysis_step,
                        fact_verification_step,
                    ],
                ),
                name="ConditionalResearch",
                description="Run conditional research steps in parallel",
            ),
            write_step,
        ],
    )

    try:
        workflow.print_response(
            input="Comprehensive analysis of climate change research",
            stream=True,
            stream_intermediate_steps=True,
        )
    except Exception as e:
        print(f"‚ùå Error: {e}")
    print()
```

To see the async example, see the cookbook-

* [Condition with list of steps (async)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_02_workflows_conditional_execution/async/condition_with_list_of_steps.py)


# Loop Steps Workflow
Source: https://docs.agno.com/examples/concepts/workflows/03_workflows_loop_execution/loop_steps_workflow

This example demonstrates **Workflows 2.0** loop execution for quality-driven iterative processes.

This example demonstrates **Workflows 2.0** to repeatedly execute steps until specific conditions are met,
ensuring adequate research depth before proceeding to content creation.

**When to use**: When you need iterative refinement, quality assurance, or when the
required output quality can't be guaranteed in a single execution. Ideal for research
gathering, data collection, or any process where "good enough" is determined by content
analysis rather than a fixed number of iterations.

```python loop_steps_workflow.py
from typing import List

from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow import Loop, Step, Workflow
from agno.workflow.types import StepOutput

# Create agents for research
research_agent = Agent(
    name="Research Agent",
    role="Research specialist",
    tools=[HackerNewsTools(), DuckDuckGoTools()],
    instructions="You are a research specialist. Research the given topic thoroughly.",
    markdown=True,
)

content_agent = Agent(
    name="Content Agent",
    role="Content creator",
    instructions="You are a content creator. Create engaging content based on research.",
    markdown=True,
)

# Create research steps
research_hackernews_step = Step(
    name="Research HackerNews",
    agent=research_agent,
    description="Research trending topics on HackerNews",
)

research_web_step = Step(
    name="Research Web",
    agent=research_agent,
    description="Research additional information from web sources",
)

content_step = Step(
    name="Create Content",
    agent=content_agent,
    description="Create content based on research findings",
)


# End condition function
def research_evaluator(outputs: List[StepOutput]) -> bool:
    """
    Evaluate if research results are sufficient
    Returns True to break the loop, False to continue
    """
    # Check if any outputs are present
    if not outputs:
        return False

    # Check if any output contains substantial content
    for output in outputs:
        if output.content and len(output.content) > 200:
            print(
                f"‚úÖ Research evaluation passed - found substantial content ({len(output.content)} chars)"
            )
            return True

    print("‚ùå Research evaluation failed - need more substantial research")
    return False


# Create workflow with loop
workflow = Workflow(
    name="Research and Content Workflow",
    description="Research topics in a loop until conditions are met, then create content",
    steps=[
        Loop(
            name="Research Loop",
            steps=[research_hackernews_step, research_web_step],
            end_condition=research_evaluator,
            max_iterations=3,  # Maximum 3 iterations
        ),
        content_step,
    ],
)

if __name__ == "__main__":
    # Test the workflow
    workflow.print_response(
        input="Research the latest trends in AI and machine learning, then create a summary",
    )
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Loop Steps Workflow (sync streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_03_workflows_loop_execution/sync/loop_steps_workflow_stream.py)
* [Loop Steps Workflow (async non-streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_03_workflows_loop_execution/async/loop_steps_workflow.py)
* [Loop Steps Workflow (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_03_workflows_loop_execution/async/loop_steps_workflow_stream.py)


# Loop with Parallel Steps Workflow
Source: https://docs.agno.com/examples/concepts/workflows/03_workflows_loop_execution/loop_with_parallel_steps_stream

This example demonstrates **Workflows 2.0** most sophisticated pattern combining loop execution with parallel processing and real-time streaming.

This example shows how to create iterative
workflows that execute multiple independent tasks simultaneously within each iteration,
optimizing both quality and performance.

**When to use**: When you need iterative quality improvement with parallel task execution
in each iteration. Ideal for comprehensive research workflows where multiple independent
tasks contribute to overall quality, and you need to repeat until quality thresholds are met.

```python loop_with_parallel_steps_stream.py
from typing import List

from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow import Loop, Parallel, Step, Workflow
from agno.workflow.types import StepOutput

# Create agents for research
research_agent = Agent(
    name="Research Agent",
    role="Research specialist",
    tools=[HackerNewsTools(), DuckDuckGoTools()],
    instructions="You are a research specialist. Research the given topic thoroughly.",
    markdown=True,
)

analysis_agent = Agent(
    name="Analysis Agent",
    role="Data analyst",
    instructions="You are a data analyst. Analyze and summarize research findings.",
    markdown=True,
)

content_agent = Agent(
    name="Content Agent",
    role="Content creator",
    instructions="You are a content creator. Create engaging content based on research.",
    markdown=True,
)

# Create research steps
research_hackernews_step = Step(
    name="Research HackerNews",
    agent=research_agent,
    description="Research trending topics on HackerNews",
)

research_web_step = Step(
    name="Research Web",
    agent=research_agent,
    description="Research additional information from web sources",
)

# Create analysis steps
trend_analysis_step = Step(
    name="Trend Analysis",
    agent=analysis_agent,
    description="Analyze trending patterns in the research",
)

sentiment_analysis_step = Step(
    name="Sentiment Analysis",
    agent=analysis_agent,
    description="Analyze sentiment and opinions from the research",
)

content_step = Step(
    name="Create Content",
    agent=content_agent,
    description="Create content based on research findings",
)


# End condition function
def research_evaluator(outputs: List[StepOutput]) -> bool:
    """
    Evaluate if research results are sufficient
    Returns True to break the loop, False to continue
    """
    # Check if we have good research results
    if not outputs:
        return False

    # Calculate total content length from all outputs
    total_content_length = sum(len(output.content or "") for output in outputs)

    # Check if we have substantial content (more than 500 chars total)
    if total_content_length > 500:
        print(
            f"‚úÖ Research evaluation passed - found substantial content ({total_content_length} chars total)"
        )
        return True

    print(
        f"‚ùå Research evaluation failed - need more substantial research (current: {total_content_length} chars)"
    )
    return False


# Create workflow with loop containing parallel steps
workflow = Workflow(
    name="Advanced Research and Content Workflow",
    description="Research topics with parallel execution in a loop until conditions are met, then create content",
    steps=[
        Loop(
            name="Research Loop with Parallel Execution",
            steps=[
                Parallel(
                    research_hackernews_step,
                    research_web_step,
                    trend_analysis_step,
                    name="Parallel Research & Analysis",
                    description="Execute research and analysis in parallel for efficiency",
                ),
                sentiment_analysis_step,
            ],
            end_condition=research_evaluator,
            max_iterations=3,  # Maximum 3 iterations
        ),
        content_step,
    ],
)

if __name__ == "__main__":
    workflow.print_response(
        input="Research the latest trends in AI and machine learning, then create a summary",
        stream=True,
        stream_intermediate_steps=True,
    )
```

This was a synchronous streaming example of this pattern. To checkout async and non-streaming versions, see the cookbooks-

* [Loop with Parallel Steps Workflow (sync)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_03_workflows_loop_execution/sync/loop_with_parallel_steps.py)
* [Loop with Parallel Steps Workflow (async non-streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_03_workflows_loop_execution/sync/loop_with_parallel_steps.py)
* [Loop with Parallel Steps Workflow (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_03_workflows_loop_execution/async/loop_with_parallel_steps_stream.py)


# Parallel Steps Workflow
Source: https://docs.agno.com/examples/concepts/workflows/04-workflows-parallel-execution/parallel_steps_workflow

This example demonstrates **Workflows 2.0** parallel execution for independent tasks that can run simultaneously. Shows how to optimize workflow performance by executing non-dependent steps in parallel, significantly reducing total execution time.

This example demonstrates **Workflows 2.0** parallel execution for independent tasks that
can run simultaneously. Shows how to optimize workflow performance by executing
non-dependent steps in parallel, significantly reducing total execution time.

**When to use**: When you have independent tasks that don't depend on each other's output
but can contribute to the same final goal. Ideal for research from multiple sources,
parallel data processing, or any scenario where tasks can run simultaneously.

```python parallel_steps_workflow.py
from agno.agent import Agent
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow import Step, Workflow
from agno.workflow.parallel import Parallel

# Create agents
researcher = Agent(name="Researcher", tools=[HackerNewsTools(), GoogleSearchTools()])
writer = Agent(name="Writer")
reviewer = Agent(name="Reviewer")

# Create individual steps
research_hn_step = Step(name="Research HackerNews", agent=researcher)
research_web_step = Step(name="Research Web", agent=researcher)
write_step = Step(name="Write Article", agent=writer)
review_step = Step(name="Review Article", agent=reviewer)

# Create workflow with direct execution
workflow = Workflow(
    name="Content Creation Pipeline",
    steps=[
        Parallel(research_hn_step, research_web_step, name="Research Phase"),
        write_step,
        review_step,
    ],
)

workflow.print_response("Write about the latest AI developments")
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Parallel Steps Workflow (sync streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_04_workflows_parallel_execution/sync/parallel_steps_workflow_stream.py)
* [Parallel Steps Workflow (async non-streaming)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_04_workflows_parallel_execution/sync/parallel_steps_workflow.py)
* [Parallel Steps Workflow (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_04_workflows_parallel_execution/async/parallel_steps_workflow_stream.py)


# Conditional Branching Workflow
Source: https://docs.agno.com/examples/concepts/workflows/05_workflows_conditional_branching/router_steps_workflow

This example demonstrates **Workflows 2.0** router pattern for intelligent, content-based workflow routing.

This example demonstrates **Workflows 2.0** to dynamically select the best execution path based on input
analysis, enabling adaptive workflows that choose optimal strategies per topic.

**When to use**: When you need mutually exclusive execution paths based on business logic.
Ideal for topic-specific workflows, expertise routing, or when different subjects require
completely different processing strategies. Unlike Conditions which can trigger multiple
parallel paths, Router selects exactly one path.

```python router_steps_workflow.py
from typing import List

from agno.agent.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.router import Router
from agno.workflow.step import Step
from agno.workflow.types import StepInput
from agno.workflow.workflow import Workflow

# Define the research agents
hackernews_agent = Agent(
    name="HackerNews Researcher",
    instructions="You are a researcher specializing in finding the latest tech news and discussions from Hacker News. Focus on startup trends, programming topics, and tech industry insights.",
    tools=[HackerNewsTools()],
)

web_agent = Agent(
    name="Web Researcher",
    instructions="You are a comprehensive web researcher. Search across multiple sources including news sites, blogs, and official documentation to gather detailed information.",
    tools=[DuckDuckGoTools()],
)

content_agent = Agent(
    name="Content Publisher",
    instructions="You are a content creator who takes research data and creates engaging, well-structured articles. Format the content with proper headings, bullet points, and clear conclusions.",
)

# Create the research steps
research_hackernews = Step(
    name="research_hackernews",
    agent=hackernews_agent,
    description="Research latest tech trends from Hacker News",
)

research_web = Step(
    name="research_web",
    agent=web_agent,
    description="Comprehensive web research on the topic",
)

publish_content = Step(
    name="publish_content",
    agent=content_agent,
    description="Create and format final content for publication",
)


# Now returns Step(s) to execute
def research_router(step_input: StepInput) -> List[Step]:
    """
    Decide which research method to use based on the input topic.
    Returns a list containing the step(s) to execute.
    """
    # Use the original workflow message if this is the first step
    topic = step_input.previous_step_content or step_input.input or ""
    topic = topic.lower()

    # Check if the topic is tech/startup related - use HackerNews
    tech_keywords = [
        "startup",
        "programming",
        "ai",
        "machine learning",
        "software",
        "developer",
        "coding",
        "tech",
        "silicon valley",
        "venture capital",
        "cryptocurrency",
        "blockchain",
        "open source",
        "github",
    ]

    if any(keyword in topic for keyword in tech_keywords):
        print(f"üîç Tech topic detected: Using HackerNews research for '{topic}'")
        return [research_hackernews]
    else:
        print(f"üåê General topic detected: Using web research for '{topic}'")
        return [research_web]


workflow = Workflow(
    name="Intelligent Research Workflow",
    description="Automatically selects the best research method based on topic, then publishes content",
    steps=[
        Router(
            name="research_strategy_router",
            selector=research_router,
            choices=[research_hackernews, research_web],
            description="Intelligently selects research method based on topic",
        ),
        publish_content,
    ],
)

if __name__ == "__main__":
    workflow.print_response(
        "Latest developments in artificial intelligence and machine learning"
    )
```

This was a synchronous non-streaming example of this pattern. To checkout async and streaming versions, see the cookbooks-

* [Router Steps Workflow (sync streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_05_workflows_conditional_branching/sync/router_steps_workflow_stream.py)
* [Router Steps Workflow (async non-streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_05_workflows_conditional_branching/async/router_steps_workflow.py)
* [Router Steps Workflow (async streaming)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_05_workflows_conditional_branching/async/router_steps_workflow_stream.py)


# Router with Loop Steps Workflow
Source: https://docs.agno.com/examples/concepts/workflows/05_workflows_conditional_branching/router_with_loop_steps

This example demonstrates **Workflows 2.0** advanced pattern combining Router-based intelligent path selection with Loop execution for iterative quality improvement.

This example shows how to create adaptive workflows that select optimal research strategies and execution patterns based on topic complexity.

**When to use**: When different topic types require fundamentally different research
methodologies - some needing simple single-pass research, others requiring iterative
deep-dive analysis. Ideal for content-adaptive workflows where processing complexity
should match content complexity.

```python router_with_loop_steps.py
from typing import List

from agno.agent.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.loop import Loop
from agno.workflow.router import Router
from agno.workflow.step import Step
from agno.workflow.types import StepInput, StepOutput
from agno.workflow.workflow import Workflow

# Define the research agents
hackernews_agent = Agent(
    name="HackerNews Researcher",
    instructions="You are a researcher specializing in finding the latest tech news and discussions from Hacker News. Focus on startup trends, programming topics, and tech industry insights.",
    tools=[HackerNewsTools()],
)

web_agent = Agent(
    name="Web Researcher",
    instructions="You are a comprehensive web researcher. Search across multiple sources including news sites, blogs, and official documentation to gather detailed information.",
    tools=[DuckDuckGoTools()],
)

content_agent = Agent(
    name="Content Publisher",
    instructions="You are a content creator who takes research data and creates engaging, well-structured articles. Format the content with proper headings, bullet points, and clear conclusions.",
)

# Create the research steps
research_hackernews = Step(
    name="research_hackernews",
    agent=hackernews_agent,
    description="Research latest tech trends from Hacker News",
)

research_web = Step(
    name="research_web",
    agent=web_agent,
    description="Comprehensive web research on the topic",
)

publish_content = Step(
    name="publish_content",
    agent=content_agent,
    description="Create and format final content for publication",
)

# End condition function for the loop


def research_quality_check(outputs: List[StepOutput]) -> bool:
    """
    Evaluate if research results are sufficient
    Returns True to break the loop, False to continue
    """
    if not outputs:
        return False

    # Check if any output contains substantial content
    for output in outputs:
        if output.content and len(output.content) > 300:
            print(
                f"‚úÖ Research quality check passed - found substantial content ({len(output.content)} chars)"
            )
            return True

    print("‚ùå Research quality check failed - need more substantial research")
    return False


# Create a Loop step for deep tech research
deep_tech_research_loop = Loop(
    name="Deep Tech Research Loop",
    steps=[research_hackernews],
    end_condition=research_quality_check,
    max_iterations=3,
    description="Perform iterative deep research on tech topics",
)

# Router function that selects between simple web research or deep tech research loop


def research_strategy_router(step_input: StepInput) -> List[Step]:
    """
    Decide between simple web research or deep tech research loop based on the input topic.
    Returns either a single web research step or a tech research loop.
    """
    # Use the original workflow message if this is the first step
    topic = step_input.previous_step_content or step_input.input or ""
    topic = topic.lower()

    # Check if the topic requires deep tech research
    deep_tech_keywords = [
        "startup trends",
        "ai developments",
        "machine learning research",
        "programming languages",
        "developer tools",
        "silicon valley",
        "venture capital",
        "cryptocurrency analysis",
        "blockchain technology",
        "open source projects",
        "github trends",
        "tech industry",
        "software engineering",
    ]

    # Check if it's a complex tech topic that needs deep research
    if any(keyword in topic for keyword in deep_tech_keywords) or (
        "tech" in topic and len(topic.split()) > 3
    ):
        print(
            f"üî¨ Deep tech topic detected: Using iterative research loop for '{topic}'"
        )
        return [deep_tech_research_loop]
    else:
        print(f"üåê Simple topic detected: Using basic web research for '{topic}'")
        return [research_web]


workflow = Workflow(
    name="Adaptive Research Workflow",
    description="Intelligently selects between simple web research or deep iterative tech research based on topic complexity",
    steps=[
        Router(
            name="research_strategy_router",
            selector=research_strategy_router,
            choices=[research_web, deep_tech_research_loop],
            description="Chooses between simple web research or deep tech research loop",
        ),
        publish_content,
    ],
)

if __name__ == "__main__":
    print("=== Testing with deep tech topic ===")
    workflow.print_response(
        "Latest developments in artificial intelligence and machine learning and deep tech research trends"
    )
```

To checkout async version, see the cookbook-

* [Router with Loop Steps Workflow (async)](https://github.com/agno-agi/agno/tree/main/cookbook/workflows/_05_workflows_conditional_branching/async/router_with_loop_steps.py)


# Selector for Image Video Generation Pipelines
Source: https://docs.agno.com/examples/concepts/workflows/05_workflows_conditional_branching/selector_for_image_video_generation_pipelines

This example demonstrates **Workflows 2.0** router pattern for dynamically selecting between image and video generation pipelines.

This example demonstrates **Workflows 2.0** router pattern for dynamically selecting between image and video generation pipelines. It uses `Steps` to encapsulate each media type's workflow and a `Router` to intelligently choose the pipeline based on input analysis.

## Key Features:

* **Dynamic Routing**: Selects pipelines (`Steps`) based on input keywords (e.g., "image" or "video").
* **Modular Pipelines**: Encapsulates image/video workflows as reusable `Steps` objects.
* **Structured Inputs**: Uses Pydantic models for type-safe configuration (e.g., resolution, style).

## Key Features:

* **Nested Logic**: Embeds `Condition` and `Parallel` within a `Steps` sequence.
* **Topic-Specialized Research**: Uses `Condition` to trigger parallel tech/news research for tech topics.
* **Modular Design**: Encapsulates the entire workflow as a reusable `Steps` object.

```python selector_for_image_video_generation_pipelines.py
from typing import List, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.gemini import GeminiTools
from agno.tools.openai import OpenAITools
from agno.workflow.router import Router
from agno.workflow.step import Step
from agno.workflow.steps import Steps
from agno.workflow.types import StepInput
from agno.workflow.workflow import Workflow
from pydantic import BaseModel


# Define the structured message data
class MediaRequest(BaseModel):
    topic: str
    content_type: str  # "image" or "video"
    prompt: str
    style: Optional[str] = "realistic"
    duration: Optional[int] = None  # For video, duration in seconds
    resolution: Optional[str] = "1024x1024"  # For image resolution


# Define specialized agents for different media types
image_generator = Agent(
    name="Image Generator",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[OpenAITools(image_model="gpt-image-1")],
    instructions="""You are an expert image generation specialist.
    When users request image creation, you should ACTUALLY GENERATE the image using your available image generation tools.

    Always use the generate_image tool to create the requested image based on the user's specifications.
    Include detailed, creative prompts that incorporate style, composition, lighting, and mood details.

    After generating the image, provide a brief description of what you created.""",
)

image_describer = Agent(
    name="Image Describer",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="""You are an expert image analyst and describer.
    When you receive an image (either as input or from a previous step), analyze and describe it in vivid detail, including:
    - Visual elements and composition
    - Colors, lighting, and mood
    - Artistic style and technique
    - Emotional impact and narrative

    If no image is provided, work with the image description or prompt from the previous step.
    Provide rich, engaging descriptions that capture the essence of the visual content.""",
)

video_generator = Agent(
    name="Video Generator",
    model=OpenAIChat(id="gpt-5-mini"),
    # Video Generation only works on VertexAI mode
    tools=[GeminiTools(vertexai=True)],
    instructions="""You are an expert video production specialist.
    Create detailed video generation prompts and storyboards based on user requests.
    Include scene descriptions, camera movements, transitions, and timing.
    Consider pacing, visual storytelling, and technical aspects like resolution and duration.
    Format your response as a comprehensive video production plan.""",
)

video_describer = Agent(
    name="Video Describer",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="""You are an expert video analyst and critic.
    Analyze and describe videos comprehensively, including:
    - Scene composition and cinematography
    - Narrative flow and pacing
    - Visual effects and production quality
    - Audio-visual harmony and mood
    - Technical execution and artistic merit
    Provide detailed, professional video analysis.""",
)

# Define steps for image pipeline
generate_image_step = Step(
    name="generate_image",
    agent=image_generator,
    description="Generate a detailed image creation prompt based on the user's request",
)

describe_image_step = Step(
    name="describe_image",
    agent=image_describer,
    description="Analyze and describe the generated image concept in vivid detail",
)

# Define steps for video pipeline
generate_video_step = Step(
    name="generate_video",
    agent=video_generator,
    description="Create a comprehensive video production plan and storyboard",
)

describe_video_step = Step(
    name="describe_video",
    agent=video_describer,
    description="Analyze and critique the video production plan with professional insights",
)

# Define the two distinct pipelines
image_sequence = Steps(
    name="image_generation",
    description="Complete image generation and analysis workflow",
    steps=[generate_image_step, describe_image_step],
)

video_sequence = Steps(
    name="video_generation",
    description="Complete video production and analysis workflow",
    steps=[generate_video_step, describe_video_step],
)


def media_sequence_selector(step_input: StepInput) -> List[Step]:
    """
    Simple pipeline selector based on keywords in the message.

    Args:
        step_input: StepInput containing message

    Returns:
        List of Steps to execute
    """

    # Check if message exists and is a string
    if not step_input.input or not isinstance(step_input.input, str):
        return [image_sequence]  # Default to image sequence

    # Convert message to lowercase for case-insensitive matching
    message_lower = step_input.input.lower()

    # Check for video keywords
    if "video" in message_lower:
        return [video_sequence]
    # Check for image keywords
    elif "image" in message_lower:
        return [image_sequence]
    else:
        # Default to image for any other case
        return [image_sequence]


# Usage examples
if __name__ == "__main__":
    # Create the media generation workflow
    media_workflow = Workflow(
        name="AI Media Generation Workflow",
        description="Generate and analyze images or videos using AI agents",
        steps=[
            Router(
                name="Media Type Router",
                description="Routes to appropriate media generation pipeline based on content type",
                selector=media_sequence_selector,
                choices=[image_sequence, video_sequence],
            )
        ],
    )

    print("=== Example 1: Image Generation (using message_data) ===")
    image_request = MediaRequest(
        topic="Create an image of magical forest for a movie scene",
        content_type="image",
        prompt="A mystical forest with glowing mushrooms",
        style="fantasy art",
        resolution="1920x1080",
    )

    media_workflow.print_response(
        input="Create an image of magical forest for a movie scene",
        markdown=True,
    )

    # print("\n=== Example 2: Video Generation (using message_data) ===")
    # video_request = MediaRequest(
    #     topic="Create a cinematic video city timelapse",
    #     content_type="video",
    #     prompt="A time-lapse of a city skyline from day to night",
    #     style="cinematic",
    #     duration=30,
    #     resolution="4K"
    # )

    # media_workflow.print_response(
    #     input="Create a cinematic video city timelapse",
    #     markdown=True,
    # )
```


# Access Multiple Previous Steps Output
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/access_multiple_previous_steps_output

This example demonstrates **Workflows 2.0** advanced data flow capabilities

This example demonstrates **Workflows 2.0** shows how to:

1. Access outputs from **specific named steps** (`get_step_content()`)
2. Aggregate **all previous outputs** (`get_all_previous_content()`)
3. Create comprehensive reports by combining multiple research sources

## Key Features:

* **Step Output Access**: Retrieve data from any previous step by name or collectively.
* **Custom Reporting**: Combine and analyze outputs from parallel or sequential steps.
* **Streaming Support**: Real-time updates during execution.

```python access_multiple_previous_steps_output.py
from agno.agent.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.types import StepInput, StepOutput
from agno.workflow.workflow import Workflow

# Define the research agents
hackernews_agent = Agent(
    name="HackerNews Researcher",
    instructions="You are a researcher specializing in finding the latest tech news and discussions from Hacker News. Focus on startup trends, programming topics, and tech industry insights.",
    tools=[HackerNewsTools()],
)

web_agent = Agent(
    name="Web Researcher",
    instructions="You are a comprehensive web researcher. Search across multiple sources including news sites, blogs, and official documentation to gather detailed information.",
    tools=[DuckDuckGoTools()],
)

reasoning_agent = Agent(
    name="Reasoning Agent",
    instructions="You are an expert analyst who creates comprehensive reports by analyzing and synthesizing information from multiple sources. Create well-structured, insightful reports.",
)

# Create the research steps
research_hackernews = Step(
    name="research_hackernews",
    agent=hackernews_agent,
    description="Research latest tech trends from Hacker News",
)

research_web = Step(
    name="research_web",
    agent=web_agent,
    description="Comprehensive web research on the topic",
)

# Custom function step that has access to ALL previous step outputs


def create_comprehensive_report(step_input: StepInput) -> StepOutput:
    """
    Custom function that creates a report using data from multiple previous steps.
    This function has access to ALL previous step outputs and the original workflow message.
    """

    # Access original workflow input
    original_topic = step_input.input or ""

    # Access specific step outputs by name
    hackernews_data = step_input.get_step_content("research_hackernews") or ""
    web_data = step_input.get_step_content("research_web") or ""

    # Or access ALL previous content
    _ = step_input.get_all_previous_content()

    # Create a comprehensive report combining all sources
    report = f"""
        # Comprehensive Research Report: {original_topic}

        ## Executive Summary
        Based on research from HackerNews and web sources, here's a comprehensive analysis of {original_topic}.

        ## HackerNews Insights
        {hackernews_data[:500]}...

        ## Web Research Findings  
        {web_data[:500]}...
    """

    return StepOutput(
        step_name="comprehensive_report", content=report.strip(), success=True
    )


comprehensive_report_step = Step(
    name="comprehensive_report",
    executor=create_comprehensive_report,
    description="Create comprehensive report from all research sources",
)

# Final reasoning step using reasoning agent
reasoning_step = Step(
    name="final_reasoning",
    agent=reasoning_agent,
    description="Apply reasoning to create final insights and recommendations",
)

workflow = Workflow(
    name="Enhanced Research Workflow",
    description="Multi-source research with custom data flow and reasoning",
    steps=[
        research_hackernews,
        research_web,
        comprehensive_report_step,  # Has access to both previous steps
        reasoning_step,  # Gets the last step output (comprehensive report)
    ],
)

if __name__ == "__main__":
    workflow.print_response(
        "Latest developments in artificial intelligence and machine learning",
        stream=True,
        stream_intermediate_steps=True,
    )
```


# Access Session State in Custom Python Function Step
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/access_session_state_in_custom_python_function_step

This example demonstrates how to access session state in a custom python function step

```python access_session_state_in_custom_python_function_step.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step, StepInput, StepOutput
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[HackerNewsTools()],
    instructions="Extract key insights and content from Hackernews posts",
)

web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    model=OpenAIChat(id="gpt-4o"),
    members=[hackernews_agent, web_agent],
    instructions="Analyze content and create comprehensive social media strategy",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-4o"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)


def custom_content_planning_function(
    step_input: StepInput, session_state: dict
) -> StepOutput:
    """
    Custom function that does intelligent content planning with context awareness
    and maintains a content plan history in session_state
    """
    message = step_input.input
    previous_step_content = step_input.previous_step_content

    # Initialize content history if not present
    if "content_plans" not in session_state:
        session_state["content_plans"] = []

    if "plan_counter" not in session_state:
        session_state["plan_counter"] = 0

    # Increment plan counter
    session_state["plan_counter"] += 1
    current_plan_id = session_state["plan_counter"]

    # Create intelligent planning prompt
    planning_prompt = f"""
        STRATEGIC CONTENT PLANNING REQUEST:

        Core Topic: {message}
        Plan ID: #{current_plan_id}

        Research Results: {previous_step_content[:500] if previous_step_content else "No research results"}

        Previous Plans Count: {len(session_state["content_plans"])}

        Planning Requirements:
        1. Create a comprehensive content strategy based on the research
        2. Leverage the research findings effectively
        3. Identify content formats and channels
        4. Provide timeline and priority recommendations
        5. Include engagement and distribution strategies

        Please create a detailed, actionable content plan.
    """

    try:
        response = content_planner.run(planning_prompt)

        # Store this plan in session state
        plan_data = {
            "id": current_plan_id,
            "topic": message,
            "content": response.content,
            "timestamp": f"Plan #{current_plan_id}",
            "has_research": bool(previous_step_content),
        }
        session_state["content_plans"].append(plan_data)

        enhanced_content = f"""
            ## Strategic Content Plan #{current_plan_id}

            **Planning Topic:** {message}

            **Research Integration:** {"‚úì Research-based" if previous_step_content else "‚úó No research foundation"}
            **Total Plans Created:** {len(session_state["content_plans"])}

            **Content Strategy:**
            {response.content}

            **Custom Planning Enhancements:**
            - Research Integration: {"High" if previous_step_content else "Baseline"}
            - Strategic Alignment: Optimized for multi-channel distribution
            - Execution Ready: Detailed action items included
            - Session History: {len(session_state["content_plans"])} plans stored
            
            **Plan ID:** #{current_plan_id}
        """.strip()

        return StepOutput(content=enhanced_content)

    except Exception as e:
        return StepOutput(
            content=f"Custom content planning failed: {str(e)}",
            success=False,
        )


def content_summary_function(step_input: StepInput, session_state: dict) -> StepOutput:
    """
    Custom function that summarizes all content plans created in the session
    """
    if "content_plans" not in session_state or not session_state["content_plans"]:
        return StepOutput(
            content="No content plans found in session state.", success=False
        )

    plans = session_state["content_plans"]
    summary = f"""
        ## Content Planning Session Summary
        
        **Total Plans Created:** {len(plans)}
        **Session Statistics:**
        - Plans with research: {len([p for p in plans if p["has_research"]])}
        - Plans without research: {len([p for p in plans if not p["has_research"]])}
        
        **Plan Overview:**
    """

    for plan in plans:
        summary += f"""
        
        ### Plan #{plan["id"]} - {plan["topic"]}
        - Research Available: {"‚úì" if plan["has_research"] else "‚úó"}
        - Status: Completed
        """

    # Update session state with summary info
    session_state["session_summarized"] = True
    session_state["total_plans_summarized"] = len(plans)

    return StepOutput(content=summary.strip())


# Define steps using different executor types

research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    executor=custom_content_planning_function,
)

content_summary_step = Step(
    name="Content Summary Step",
    executor=content_summary_function,
)


# Define and use examples
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation with custom execution options and session state",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        # Define the sequence of steps
        # First run the research_step, then the content_planning_step, then the summary_step
        # You can mix and match agents, teams, and even regular python functions directly as steps
        steps=[research_step, content_planning_step, content_summary_step],
        # Initialize session state with empty content plans
        session_state={"content_plans": [], "plan_counter": 0},
    )

    print("=== First Workflow Run ===")
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        markdown=True,
    )

    print(
        f"\nSession State After First Run: {content_creation_workflow.get_session_state()}"
    )

    print("\n" + "=" * 60 + "\n")

    print("=== Second Workflow Run (Same Session) ===")
    content_creation_workflow.print_response(
        input="Machine Learning automation tools",
        markdown=True,
    )

    print(f"\nFinal Session State: {content_creation_workflow.get_session_state()}")
```

See example of [cookbook with streaming](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_04_shared_session_state/access_session_state_in_custom_function_step_stream.py).


# Early Stop a Workflow
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/early_stop_workflow

This example demonstrates **Workflows 2.0** early termination of a running workflow.

This example shows how to create workflows that can terminate
gracefully when quality conditions aren't met, preventing downstream processing of
invalid or unsafe data.

**When to use**: When you need safety mechanisms, quality gates, or validation checkpoints
that should prevent downstream processing if conditions aren't met. Ideal for data
validation pipelines, security checks, quality assurance workflows, or any process where
continuing with invalid inputs could cause problems.

```python early_stop_workflow_with_agents.py
from agno.agent import Agent
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.workflow import Workflow
from agno.workflow.types import StepInput, StepOutput

# Create agents with more specific validation criteria
data_validator = Agent(
    name="Data Validator",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "You are a data validator. Analyze the provided data and determine if it's valid.",
        "For data to be VALID, it must meet these criteria:",
        "- user_count: Must be a positive number (> 0)",
        "- revenue: Must be a positive number (> 0)",
        "- date: Must be in a reasonable date format (YYYY-MM-DD)",
        "",
        "Return exactly 'VALID' if all criteria are met.",
        "Return exactly 'INVALID' if any criteria fail.",
        "Also briefly explain your reasoning.",
    ],
)

data_processor = Agent(
    name="Data Processor",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Process and transform the validated data.",
)

report_generator = Agent(
    name="Report Generator",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="Generate a final report from processed data.",
)


def early_exit_validator(step_input: StepInput) -> StepOutput:
    """
    Custom function that checks data quality and stops workflow early if invalid
    """
    # Get the validation result from previous step
    validation_result = step_input.previous_step_content or ""

    if "INVALID" in validation_result.upper():
        return StepOutput(
            content="‚ùå Data validation failed. Workflow stopped early to prevent processing invalid data.",
            stop=True,  # Stop the entire workflow here
        )
    else:
        return StepOutput(
            content="‚úÖ Data validation passed. Continuing with processing...",
            stop=False,  # Continue normally
        )


# Create workflow with conditional early termination
workflow = Workflow(
    name="Data Processing with Early Exit",
    description="Process data but stop early if validation fails",
    steps=[
        data_validator,  # Step 1: Validate data
        early_exit_validator,  # Step 2: Check validation and possibly stop early
        data_processor,  # Step 3: Process data (only if validation passed)
        report_generator,  # Step 4: Generate report (only if processing completed)
    ],
)

if __name__ == "__main__":
    print("\n=== Testing with INVALID data ===")
    workflow.print_response(
        input="Process this data: {'user_count': -50, 'revenue': 'invalid_amount', 'date': 'bad_date'}"
    )

    print("=== Testing with VALID data ===")
    workflow.print_response(
        input="Process this data: {'user_count': 1000, 'revenue': 50000, 'date': '2024-01-15'}"
    )
```

To checkout async version, see the cookbook-

* [Early Stop Workflow with Loop](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_02_early_stopping/early_stop_workflow_with_loop.py)
* [Early Stop Workflow with Parallel](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_02_early_stopping/early_stop_workflow_with_parallel.py)
* [Early Stop Workflow with Router](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_02_early_stopping/early_stop_workflow_with_router.py)
* [Early Stop Workflow with Step](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_02_early_stopping/early_stop_workflow_with_step.py)
* [Early Stop Workflow with Steps](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_02_early_stopping/early_stop_workflow_with_steps.py)


# Step with Function using Additional Data
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/step_with_function_additional_data

This example demonstrates **Workflows 2.0** support for passing metadata and contextual information to steps via `additional_data`.

This example shows how to pass metadata and contextual information to steps via `additional_data`. This allows separation of workflow logic from configuration, enabling dynamic behavior based on external context.

## Key Features:

* **Context-Aware Steps**: Access `step_input.additional_data` in custom functions
* **Flexible Metadata**: Pass user info, priorities, settings, etc.
* **Clean Separation**: Keep workflow logic focused while enriching steps with context

```python step_with_function_additional_data.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step, StepInput, StepOutput
from agno.workflow.workflow import Workflow

# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    instructions="Extract key insights and content from Hackernews posts",
)

web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Analyze content and create comprehensive social media strategy",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)


def custom_content_planning_function(step_input: StepInput) -> StepOutput:
    """
    Custom function that does intelligent content planning with context awareness
    Now also uses additional_data for extra context
    """
    message = step_input.input
    previous_step_content = step_input.previous_step_content

    # Access additional_data that was passed with the workflow
    additional_data = step_input.additional_data or {}
    user_email = additional_data.get("user_email", "No email provided")
    priority = additional_data.get("priority", "normal")
    client_type = additional_data.get("client_type", "standard")

    # Create intelligent planning prompt
    planning_prompt = f"""
        STRATEGIC CONTENT PLANNING REQUEST:

        Core Topic: {message}

        Research Results: {previous_step_content[:500] if previous_step_content else "No research results"}

        Additional Context:
        - Client Type: {client_type}
        - Priority Level: {priority}
        - Contact Email: {user_email}

        Planning Requirements:
        1. Create a comprehensive content strategy based on the research
        2. Leverage the research findings effectively
        3. Identify content formats and channels
        4. Provide timeline and priority recommendations
        5. Include engagement and distribution strategies
        {"6. Mark as HIGH PRIORITY delivery" if priority == "high" else "6. Standard delivery timeline"}

        Please create a detailed, actionable content plan.
    """

    try:
        response = content_planner.run(planning_prompt)

        enhanced_content = f"""
            ## Strategic Content Plan

            **Planning Topic:** {message}

            **Client Details:**
            - Type: {client_type}
            - Priority: {priority.upper()}
            - Contact: {user_email}

            **Research Integration:** {"‚úì Research-based" if previous_step_content else "‚úó No research foundation"}

            **Content Strategy:**
            {response.content}

            **Custom Planning Enhancements:**
            - Research Integration: {"High" if previous_step_content else "Baseline"}
            - Strategic Alignment: Optimized for multi-channel distribution
            - Execution Ready: Detailed action items included
            - Priority Level: {priority.upper()}
        """.strip()

        return StepOutput(content=enhanced_content, response=response)

    except Exception as e:
        return StepOutput(
            content=f"Custom content planning failed: {str(e)}",
            success=False,
        )


# Define steps using different executor types

research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    executor=custom_content_planning_function,
)


# Define and use examples
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation with custom execution options",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        steps=[research_step, content_planning_step],
    )

    # Run workflow with additional_data
    content_creation_workflow.print_response(
        input="AI trends in 2024",
        additional_data={
            "user_email": "kaustubh@agno.com",
            "priority": "high",
            "client_type": "enterprise",
        },
        markdown=True,
        stream=True,
        stream_intermediate_steps=True,
    )

    print("\n" + "=" * 60 + "\n")
```

To checkout async version, see the cookbook-

* [Step with Function using Additional Data (async)](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_01_basic_workflows/_02_step_with_function/async/step_with_function_additional_data.py)


# Store Events and Events to Skip in a Workflow
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/store_events_and_events_to_skip_in_a_workflow

This example demonstrates **Workflows 2.0** event storage capabilities

This example demonstrates **Workflows 2.0** event storage capabilities, showing how to:

1. **Store execution events** for debugging/auditing (`store_events=True`)
2. **Filter noisy events** (`events_to_skip`) to focus on critical workflow milestones
3. **Access stored events** post-execution via `workflow.run_response.events`

## Key Features:

* **Selective Storage**: Skip verbose events (e.g., `step_started`) while retaining key milestones.
* **Debugging/Audit**: Capture execution flow for analysis without manual logging.
* **Performance Optimization**: Reduce storage overhead by filtering non-essential events.

```python store_events_and_events_to_skip_in_a_workflow.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.run.agent import (
    RunContentEvent,
    ToolCallCompletedEvent,
    ToolCallStartedEvent,
)
from agno.run.workflow import WorkflowRunEvent, WorkflowRunOutput
from agno.tools.hackernews import HackerNewsTools
from agno.run.agent import RunEvent
from agno.workflow.parallel import Parallel
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow

# Define agents for different tasks
news_agent = Agent(
    name="News Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    instructions="You are a news researcher. Get the latest tech news and summarize key points.",
)

search_agent = Agent(
    name="Search Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a search specialist. Find relevant information on given topics.",
)

analysis_agent = Agent(
    name="Analysis Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are an analyst. Analyze the provided information and give insights.",
)

summary_agent = Agent(
    name="Summary Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions="You are a summarizer. Create concise summaries of the provided content.",
)

research_step = Step(
    name="Research Step",
    agent=news_agent,
)

search_step = Step(
    name="Search Step",
    agent=search_agent,
)


def print_stored_events(run_response: WorkflowRunOutput, example_name):
    """Helper function to print stored events in a nice format"""
    print(f"\n--- {example_name} - Stored Events ---")
    if run_response.events:
        print(f"Total stored events: {len(run_response.events)}")
        for i, event in enumerate(run_response.events, 1):
            print(f"  {i}. {event.event}")
    else:
        print("No events stored")
    print()


print("=== Simple Step Workflow with Event Storage ===")
step_workflow = Workflow(
    name="Simple Step Workflow",
    description="Basic workflow demonstrating step event storage",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflow.db",
    ),
    steps=[research_step, search_step],
    store_events=True,
    events_to_skip=[
        WorkflowRunEvent.step_started,
        WorkflowRunEvent.workflow_completed,
        RunEvent.run_content,
        RunEvent.run_started,
        RunEvent.run_completed,
    ],  # Skip step started events to reduce noise
)

print("Running Step workflow with streaming...")
for event in step_workflow.run(
    input="AI trends in 2024",
    stream=True,
    stream_intermediate_steps=True,
):
    # Filter out RunContentEvent from printing to reduce noise
    if not isinstance(
        event, (RunContentEvent, ToolCallStartedEvent, ToolCallCompletedEvent)
    ):
        print(
            f"Event: {event.event if hasattr(event, 'event') else type(event).__name__}"
        )
run_response = step_workflow.get_last_run_output()

print("\nStep workflow completed!")
print(
    f"Total events stored: {len(run_response.events) if run_response and run_response.events else 0}"
)

# Print stored events in a nice format
print_stored_events(run_response, "Simple Step Workflow")

# ------------------------------------------------------------------------------------------------ #
# ------------------------------------------------------------------------------------------------ #

# Example 2: Parallel Primitive with Event Storage
print("=== 2. Parallel Example ===")
parallel_workflow = Workflow(
    name="Parallel Research Workflow",
    steps=[
        Parallel(
            Step(name="News Research", agent=news_agent),
            Step(name="Web Search", agent=search_agent),
            name="Parallel Research",
        ),
        Step(name="Combine Results", agent=analysis_agent),
    ],
    db=SqliteDb(
        session_table="workflow_parallel",
        db_file="tmp/workflow_parallel.db",
    ),
    store_events=True,
    events_to_skip=[
        WorkflowRunEvent.parallel_execution_started,
        WorkflowRunEvent.parallel_execution_completed,
    ],
)

print("Running Parallel workflow...")
for event in parallel_workflow.run(
    input="Research machine learning developments",
    stream=True,
    stream_intermediate_steps=True,
):
    # Filter out RunContentEvent from printing
    if not isinstance(event, RunContentEvent):
        print(
            f"Event: {event.event if hasattr(event, 'event') else type(event).__name__}"
        )

run_response = parallel_workflow.get_last_run_output()
print(f"Parallel workflow stored {len(run_response.events)} events")
print_stored_events(run_response, "Parallel Workflow")
print()
```


# null
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/structured_io_at_each_step_level



Demonstrates **Workflows 2.0** type-safe data flow between agents/teams/custom python functions. Each step:

1. Receives structured (pydantic model, list, dict or raw string) input
2. Produces structured output (e.g., `ResearchFindings`, `ContentStrategy`)

You can also use this pattern to create a custom function that can be used in any step and you can-

1. Inspect incoming data types (raw strings or Pydantic models).
2. Analyze structured outputs from previous steps.
3. Generate reports while preserving type safety.

```python structured_io_at_each_step_level_agent.py
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow
from pydantic import BaseModel, Field


# Define structured models for each step
class ResearchFindings(BaseModel):
    """Structured research findings with key insights"""

    topic: str = Field(description="The research topic")
    key_insights: List[str] = Field(description="Main insights discovered", min_items=3)
    trending_technologies: List[str] = Field(
        description="Technologies that are trending", min_items=2
    )
    market_impact: str = Field(description="Potential market impact analysis")
    sources_count: int = Field(description="Number of sources researched")
    confidence_score: float = Field(
        description="Confidence in findings (0.0-1.0)", ge=0.0, le=1.0
    )


class ContentStrategy(BaseModel):
    """Structured content strategy based on research"""

    target_audience: str = Field(description="Primary target audience")
    content_pillars: List[str] = Field(description="Main content themes", min_items=3)
    posting_schedule: List[str] = Field(description="Recommended posting schedule")
    key_messages: List[str] = Field(
        description="Core messages to communicate", min_items=3
    )
    hashtags: List[str] = Field(description="Recommended hashtags", min_items=5)
    engagement_tactics: List[str] = Field(
        description="Ways to increase engagement", min_items=2
    )


class FinalContentPlan(BaseModel):
    """Final content plan with specific deliverables"""

    campaign_name: str = Field(description="Name for the content campaign")
    content_calendar: List[str] = Field(
        description="Specific content pieces planned", min_items=6
    )
    success_metrics: List[str] = Field(
        description="How to measure success", min_items=3
    )
    budget_estimate: str = Field(description="Estimated budget range")
    timeline: str = Field(description="Implementation timeline")
    risk_factors: List[str] = Field(
        description="Potential risks and mitigation", min_items=2
    )


# Define agents with response models
research_agent = Agent(
    name="AI Research Specialist",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools(), DuckDuckGoTools()],
    role="Research AI trends and extract structured insights",
    output_schema=ResearchFindings,
    instructions=[
        "Research the given topic thoroughly using available tools",
        "Provide structured findings with confidence scores",
        "Focus on recent developments and market trends",
        "Make sure to structure your response according to the ResearchFindings model",
    ],
)

strategy_agent = Agent(
    name="Content Strategy Expert",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Create content strategies based on research findings",
    output_schema=ContentStrategy,
    instructions=[
        "Analyze the research findings provided from the previous step",
        "Create a comprehensive content strategy based on the structured research data",
        "Focus on audience engagement and brand building",
        "Structure your response according to the ContentStrategy model",
    ],
)

planning_agent = Agent(
    name="Content Planning Specialist",
    model=OpenAIChat(id="gpt-5-mini"),
    role="Create detailed content plans and calendars",
    output_schema=FinalContentPlan,
    instructions=[
        "Use the content strategy from the previous step to create a detailed implementation plan",
        "Include specific timelines and success metrics",
        "Consider budget and resource constraints",
        "Structure your response according to the FinalContentPlan model",
    ],
)

# Define steps
research_step = Step(
    name="research_insights",
    agent=research_agent,
)

strategy_step = Step(
    name="content_strategy",
    agent=strategy_agent,
)

planning_step = Step(
    name="final_planning",
    agent=planning_agent,
)

# Create workflow
structured_workflow = Workflow(
    name="Structured Content Creation Pipeline",
    description="AI-powered content creation with structured data flow",
    steps=[research_step, strategy_step, planning_step],
)

if __name__ == "__main__":
    print("=== Testing Structured Output Flow Between Steps ===")

    # Test with simple string input
    structured_workflow.print_response(
        input="Latest developments in artificial intelligence and machine learning"
    )
```

Examples for some more scenarios where you can use this pattern:

* [Structured IO at each Step level Team](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_01_structured_io_at_each_level/structured_io_at_each_level_team_stream.py)
* [Structured IO at each Step level Custom Function-1](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_01_structured_io_at_each_level/structured_io_at_each_level_function_1.py)
* [Structured IO at each Step level Custom Function-2](https://github.com/agno-agi/agno/blob/main/cookbook/workflows/_06_advanced_concepts/_01_structured_io_at_each_level/structured_io_at_each_level_function_2.py)


# Workflow Cancellation
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/workflow_cancellation

This example demonstrates **Workflows 2.0** support for cancelling running workflow executions, including thread-based cancellation and handling cancelled responses.

This example shows how to cancel a running workflow execution in real-time. It demonstrates:

1. **Thread-based Execution**: Running workflows in separate threads for non-blocking operation
2. **Dynamic Cancellation**: Cancelling workflows while they're actively running
3. **Cancellation Events**: Handling and responding to cancellation events
4. **Status Tracking**: Monitoring workflow status throughout execution and cancellation

```python workflow_cancellation.py
import threading
import time

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunEvent
from agno.run.base import RunStatus
from agno.run.workflow import WorkflowRunEvent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow


def long_running_task(workflow: Workflow, run_id_container: dict):
    """
    Simulate a long-running workflow task that can be cancelled.

    Args:
        workflow: The workflow to run
        run_id_container: Dictionary to store the run_id for cancellation

    Returns:
        Dictionary with run results and status
    """
    try:
        # Start the workflow run - this simulates a long task
        final_response = None
        content_pieces = []

        for chunk in workflow.run(
            "Write a very long story about a dragon who learns to code. "
            "Make it at least 2000 words with detailed descriptions and dialogue. "
            "Take your time and be very thorough.",
            stream=True,
        ):
            if "run_id" not in run_id_container and chunk.run_id:
                print(f"üöÄ Workflow run started: {chunk.run_id}")
                run_id_container["run_id"] = chunk.run_id

            if chunk.event in [RunEvent.run_content]:
                print(chunk.content, end="", flush=True)
                content_pieces.append(chunk.content)
            elif chunk.event == RunEvent.run_cancelled:
                print(f"\nüö´ Workflow run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif chunk.event == WorkflowRunEvent.workflow_cancelled:
                print(f"\nüö´ Workflow run was cancelled: {chunk.run_id}")
                run_id_container["result"] = {
                    "status": "cancelled",
                    "run_id": chunk.run_id,
                    "cancelled": True,
                    "content": "".join(content_pieces)[:200] + "..."
                    if content_pieces
                    else "No content before cancellation",
                }
                return
            elif hasattr(chunk, "status") and chunk.status == RunStatus.completed:
                final_response = chunk

        # If we get here, the run completed successfully
        if final_response:
            run_id_container["result"] = {
                "status": final_response.status.value
                if final_response.status
                else "completed",
                "run_id": final_response.run_id,
                "cancelled": final_response.status == RunStatus.cancelled,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }
        else:
            run_id_container["result"] = {
                "status": "unknown",
                "run_id": run_id_container.get("run_id"),
                "cancelled": False,
                "content": ("".join(content_pieces)[:200] + "...")
                if content_pieces
                else "No content",
            }

    except Exception as e:
        print(f"\n‚ùå Exception in run: {str(e)}")
        run_id_container["result"] = {
            "status": "error",
            "error": str(e),
            "run_id": run_id_container.get("run_id"),
            "cancelled": True,
            "content": "Error occurred",
        }


def cancel_after_delay(
    workflow: Workflow, run_id_container: dict, delay_seconds: int = 3
):
    """
    Cancel the workflow run after a specified delay.

    Args:
        workflow: The workflow whose run should be cancelled
        run_id_container: Dictionary containing the run_id to cancel
        delay_seconds: How long to wait before cancelling
    """
    print(f"‚è∞ Will cancel workflow run in {delay_seconds} seconds...")
    time.sleep(delay_seconds)

    run_id = run_id_container.get("run_id")
    if run_id:
        print(f"üö´ Cancelling workflow run: {run_id}")
        success = workflow.cancel_run(run_id)
        if success:
            print(f"‚úÖ Workflow run {run_id} marked for cancellation")
        else:
            print(
                f"‚ùå Failed to cancel workflow run {run_id} (may not exist or already completed)"
            )
    else:
        print("‚ö†Ô∏è  No run_id found to cancel")


def main():
    """Main function demonstrating workflow run cancellation."""

    # Create workflow agents
    researcher = Agent(
        name="Research Agent",
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[DuckDuckGoTools()],
        instructions="Research the given topic and provide key facts and insights.",
    )

    writer = Agent(
        name="Writing Agent",
        model=OpenAIChat(id="gpt-5-mini"),
        instructions="Write a comprehensive article based on the research provided. Make it engaging and well-structured.",
    )
    research_step = Step(
        name="research",
        agent=researcher,
        description="Research the topic and gather information",
    )

    writing_step = Step(
        name="writing",
        agent=writer,
        description="Write an article based on the research",
    )

    # Create a Steps sequence that chains these above steps together
    article_workflow = Workflow(
        description="Automated article creation from research to writing",
        steps=[research_step, writing_step],
        debug_mode=True,
    )

    print("üöÄ Starting workflow run cancellation example...")
    print("=" * 50)

    # Container to share run_id between threads
    run_id_container = {}

    # Start the workflow run in a separate thread
    workflow_thread = threading.Thread(
        target=lambda: long_running_task(article_workflow, run_id_container),
        name="WorkflowRunThread",
    )

    # Start the cancellation thread
    cancel_thread = threading.Thread(
        target=cancel_after_delay,
        args=(article_workflow, run_id_container, 8),  # Cancel after 8 seconds
        name="CancelThread",
    )

    # Start both threads
    print("üèÉ Starting workflow run thread...")
    workflow_thread.start()

    print("üèÉ Starting cancellation thread...")
    cancel_thread.start()

    # Wait for both threads to complete
    print("‚åõ Waiting for threads to complete...")
    workflow_thread.join()
    cancel_thread.join()

    # Print the results
    print("\n" + "=" * 50)
    print("üìä RESULTS:")
    print("=" * 50)

    result = run_id_container.get("result")
    if result:
        print(f"Status: {result['status']}")
        print(f"Run ID: {result['run_id']}")
        print(f"Was Cancelled: {result['cancelled']}")

        if result.get("error"):
            print(f"Error: {result['error']}")
        else:
            print(f"Content Preview: {result['content']}")

        if result["cancelled"]:
            print("\n‚úÖ SUCCESS: Workflow run was successfully cancelled!")
        else:
            print("\n‚ö†Ô∏è  WARNING: Workflow run completed before cancellation")
    else:
        print("‚ùå No result obtained - check if cancellation happened during streaming")

    print("\nüèÅ Workflow cancellation example completed!")


if __name__ == "__main__":
    # Run the main example
    main()
```


# Workflow with Input Schema Validation
Source: https://docs.agno.com/examples/concepts/workflows/06_workflows_advanced_concepts/workflow_with_input_schema

This example demonstrates **Workflows** support for input schema validation using Pydantic models to ensure type safety and data integrity at the workflow entry point.

This example shows how to use input schema validation in workflows to enforce type safety and data structure validation. By defining an `input_schema` with a Pydantic model, you can ensure that your workflow receives properly structured and validated data before execution begins.

## Key Features:

* **Type Safety**: Automatic validation of input data against Pydantic models
* **Structure Validation**: Ensure all required fields are present and correctly typed
* **Clear Contracts**: Define exactly what data your workflow expects
* **Error Prevention**: Catch invalid inputs before workflow execution begins
* **Multiple Input Formats**: Support for Pydantic models and matching dictionaries

```python workflow_with_input_schema.py
from typing import List

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.workflow.step import Step
from agno.workflow.workflow import Workflow
from pydantic import BaseModel, Field


class DifferentModel(BaseModel):
    name: str


class ResearchTopic(BaseModel):
    """Structured research topic with specific requirements"""

    topic: str
    focus_areas: List[str] = Field(description="Specific areas to focus on")
    target_audience: str = Field(description="Who this research is for")
    sources_required: int = Field(description="Number of sources needed", default=5)


# Define agents
hackernews_agent = Agent(
    name="Hackernews Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[HackerNewsTools()],
    role="Extract key insights and content from Hackernews posts",
)
web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    role="Search the web for the latest news and trends",
)

# Define research team for complex analysis
research_team = Team(
    name="Research Team",
    members=[hackernews_agent, web_agent],
    instructions="Research tech topics from Hackernews and the web",
)

content_planner = Agent(
    name="Content Planner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Plan a content schedule over 4 weeks for the provided topic and research content",
        "Ensure that I have posts for 3 posts per week",
    ],
)

# Define steps
research_step = Step(
    name="Research Step",
    team=research_team,
)

content_planning_step = Step(
    name="Content Planning Step",
    agent=content_planner,
)

# Create and use workflow
if __name__ == "__main__":
    content_creation_workflow = Workflow(
        name="Content Creation Workflow",
        description="Automated content creation from blog posts to social media",
        db=SqliteDb(
            session_table="workflow_session",
            db_file="tmp/workflow.db",
        ),
        steps=[research_step, content_planning_step],
        input_schema=ResearchTopic,  # <-- Define input schema for validation
    )

    print("=== Example 1: Valid Pydantic Model Input ===")
    research_topic = ResearchTopic(
        topic="AI trends in 2024",
        focus_areas=[
            "Machine Learning",
            "Natural Language Processing",
            "Computer Vision",
            "AI Ethics",
        ],
        target_audience="Tech professionals and business leaders",
    )

    # ‚úÖ This will work properly - input matches the schema
    content_creation_workflow.print_response(
        input=research_topic,
        markdown=True,
    )

    print("\n=== Example 2: Valid Dictionary Input ===")
    # ‚úÖ This will also work - dict matches ResearchTopic structure
    content_creation_workflow.print_response(
        input={
            "topic": "AI trends in 2024",
            "focus_areas": ["Machine Learning", "Computer Vision"],
            "target_audience": "Tech professionals",
            "sources_required": 8
        },
        markdown=True,
    )

    print("\n=== Example 3: Missing Required Fields (Commented - Would Fail) ===")
    # ‚ùå This would fail - missing required 'target_audience' field
    # Uncomment to see validation error:
    # content_creation_workflow.print_response(
    #     input=ResearchTopic(
    #         topic="AI trends in 2024",
    #         focus_areas=[
    #             "Machine Learning",
    #             "Natural Language Processing",
    #             "Computer Vision",
    #             "AI Ethics",
    #         ],
    #         # target_audience missing - will raise ValidationError
    #     ),
    #     markdown=True,
    # )

    print("\n=== Example 4: Wrong Model Type (Commented - Would Fail) ===")
    # ‚ùå This would fail - different Pydantic model provided
    # Uncomment to see validation error:
    # content_creation_workflow.print_response(
    #     input=DifferentModel(name="test"),
    #     markdown=True,
    # )

    print("\n=== Example 5: Type Mismatch (Commented - Would Fail) ===")
    # ‚ùå This would fail - wrong data types
    # Uncomment to see validation error:
    # content_creation_workflow.print_response(
    #     input={
    #         "topic": 123,  # Should be string
    #         "focus_areas": "Machine Learning",  # Should be List[str]
    #         "target_audience": ["audience1", "audience2"],  # Should be string
    #     },
    #     markdown=True,
    # )
```


# Basic Agent
Source: https://docs.agno.com/examples/getting-started/01-basic-agent



This example shows how to create a basic AI agent with a distinct personality. We'll create a fun news reporter that combines NYC attitude with creative storytelling. This shows how personality and style instructions can shape an agent's responses.

Example prompts to try:

* "What's the latest scoop from Central Park?"
* "Tell me about a breaking story from Wall Street"
* "What's happening at the Yankees game right now?"
* "Give me the buzz about a new Broadway show"

## Code

```python basic_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Create our News Reporter with a fun personality
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are an enthusiastic news reporter with a flair for storytelling! üóΩ
        Think of yourself as a mix between a witty comedian and a sharp journalist.

        Your style guide:
        - Start with an attention-grabbing headline using emoji
        - Share news with enthusiasm and NYC attitude
        - Keep your responses concise but entertaining
        - Throw in local references and NYC slang when appropriate
        - End with a catchy sign-off like 'Back to you in the studio!' or 'Reporting live from the Big Apple!'

        Remember to verify all facts while keeping that NYC energy high!\
    """),
    markdown=True,
)

# Example usage
agent.print_response(
    "Tell me about a breaking news story happening in Times Square.", stream=True
)

# More example prompts to try:
"""
Try these fun scenarios:
1. "What's the latest food trend taking over Brooklyn?"
2. "Tell me about a peculiar incident on the subway today"
3. "What's the scoop on the newest rooftop garden in Manhattan?"
4. "Report on an unusual traffic jam caused by escaped zoo animals"
5. "Cover a flash mob wedding proposal at Grand Central"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python basic_agent.py
    ```
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/getting-started/02-agent-with-tools



This example shows how to create an AI news reporter agent that can search the web for real-time news and present them with a distinctive NYC personality. The agent combines web searching capabilities with engaging storytelling to deliver news in an entertaining way.

Example prompts to try:

* "What's the latest headline from Wall Street?"
* "Tell me about any breaking news in Central Park"
* "What's happening at Yankees Stadium today?"
* "Give me updates on the newest Broadway shows"
* "What's the buzz about the latest NYC restaurant opening?"

## Code

```python agent_with_tools.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Create a News Reporter Agent with a fun personality
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are an enthusiastic news reporter with a flair for storytelling! üóΩ
        Think of yourself as a mix between a witty comedian and a sharp journalist.

        Follow these guidelines for every report:
        1. Start with an attention-grabbing headline using relevant emoji
        2. Use the search tool to find current, accurate information
        3. Present news with authentic NYC enthusiasm and local flavor
        4. Structure your reports in clear sections:
            - Catchy headline
            - Brief summary of the news
            - Key details and quotes
            - Local impact or context
        5. Keep responses concise but informative (2-3 paragraphs max)
        6. Include NYC-style commentary and local references
        7. End with a signature sign-off phrase

        Sign-off examples:
        - 'Back to you in the studio, folks!'
        - 'Reporting live from the city that never sleeps!'
        - 'This is [Your Name], live from the heart of Manhattan!'

        Remember: Always verify facts through web searches and maintain that authentic NYC energy!\
    """),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Example usage
agent.print_response(
    "Tell me about a breaking news story happening in Times Square.", stream=True
)

# More example prompts to try:
"""
Try these engaging news queries:
1. "What's the latest development in NYC's tech scene?"
2. "Tell me about any upcoming events at Madison Square Garden"
3. "What's the weather impact on NYC today?"
4. "Any updates on the NYC subway system?"
5. "What's the hottest food trend in Manhattan right now?"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai ddgs agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_with_tools.py
    ```
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/getting-started/03-agent-with-knowledge



This example shows how to create an AI cooking assistant that combines knowledge from a curated recipe database with web searching capabilities. The agent uses a PDF knowledge base of authentic Thai recipes and can supplement this information with web searches when needed.

Example prompts to try:

* "How do I make authentic Pad Thai?"
* "What's the difference between red and green curry?"
* "Can you explain what galangal is and possible substitutes?"
* "Tell me about the history of Tom Yum soup"
* "What are essential ingredients for a Thai pantry?"
* "How do I make Thai basil chicken (Pad Kra Pao)?"

## Code

```python agent_with_knowledge.py
from textwrap import dedent

from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="recipe_knowledge",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

# Create a Recipe Expert Agent with knowledge of Thai recipes
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are a passionate and knowledgeable Thai cuisine expert! üßë‚Äçüç≥
        Think of yourself as a combination of a warm, encouraging cooking instructor,
        a Thai food historian, and a cultural ambassador.

        Follow these steps when answering questions:
        1. If the user asks a about Thai cuisine, ALWAYS search your knowledge base for authentic Thai recipes and cooking information
        2. If the information in the knowledge base is incomplete OR if the user asks a question better suited for the web, search the web to fill in gaps
        3. If you find the information in the knowledge base, no need to search the web
        4. Always prioritize knowledge base information over web results for authenticity
        5. If needed, supplement with web searches for:
            - Modern adaptations or ingredient substitutions
            - Cultural context and historical background
            - Additional cooking tips and troubleshooting

        Communication style:
        1. Start each response with a relevant cooking emoji
        2. Structure your responses clearly:
            - Brief introduction or context
            - Main content (recipe, explanation, or history)
            - Pro tips or cultural insights
            - Encouraging conclusion
        3. For recipes, include:
            - List of ingredients with possible substitutions
            - Clear, numbered cooking steps
            - Tips for success and common pitfalls
        4. Use friendly, encouraging language

        Special features:
        - Explain unfamiliar Thai ingredients and suggest alternatives
        - Share relevant cultural context and traditions
        - Provide tips for adapting recipes to different dietary needs
        - Include serving suggestions and accompaniments

        End each response with an uplifting sign-off like:
        - 'Happy cooking! ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡∏£‡πà‡∏≠‡∏¢ (Enjoy your meal)!'
        - 'May your Thai cooking adventure bring joy!'
        - 'Enjoy your homemade Thai feast!'

        Remember:
        - Always verify recipe authenticity with the knowledge base
        - Clearly indicate when information comes from web sources
        - Be encouraging and supportive of home cooks at all skill levels\
    """),
    knowledge=knowledge,
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
agent.print_response("What is the history of Thai curry?", stream=True)
agent.print_response("What ingredients do I need for Pad Thai?", stream=True)

# More example prompts to try:
"""
Explore Thai cuisine with these queries:
1. "What are the essential spices and herbs in Thai cooking?"
2. "Can you explain the different types of Thai curry pastes?"
3. "How do I make mango sticky rice dessert?"
4. "What's the proper way to cook Thai jasmine rice?"
5. "Tell me about regional differences in Thai cuisine"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai lancedb tantivy pypdf ddgs agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_with_knowledge.py
    ```
  </Step>
</Steps>


# Write Your Own Tool
Source: https://docs.agno.com/examples/getting-started/04-write-your-own-tool



This example shows how to create and use your own custom tool with Agno.
You can replace the Hacker News functionality with any API or service you want!

Some ideas for your own tools:

* Weather data fetcher
* Stock price analyzer
* Personal calendar integration
* Custom database queries
* Local file operations

## Code

```python custom_tools.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_top_hackernews_stories(num_stories: int = 10) -> str:
    """Use this function to get top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to return. Defaults to 10.

    Returns:
        str: JSON string of top stories.
    """

    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Fetch story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        stories.append(story)
    return json.dumps(stories)


# Create a Tech News Reporter Agent with a Silicon Valley personality
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are a tech-savvy Hacker News reporter with a passion for all things technology! ü§ñ
        Think of yourself as a mix between a Silicon Valley insider and a tech journalist.

        Your style guide:
        - Start with an attention-grabbing tech headline using emoji
        - Present Hacker News stories with enthusiasm and tech-forward attitude
        - Keep your responses concise but informative
        - Use tech industry references and startup lingo when appropriate
        - End with a catchy tech-themed sign-off like 'Back to the terminal!' or 'Pushing to production!'

        Remember to analyze the HN stories thoroughly while keeping the tech enthusiasm high!\
    """),
    tools=[get_top_hackernews_stories],
    markdown=True,
)

# Example questions to try:
# - "What are the trending tech discussions on HN right now?"
# - "Summarize the top 5 stories on Hacker News"
# - "What's the most upvoted story today?"
agent.print_response("Summarize the top 5 stories on hackernews?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai httpx agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python custom_tools.py
    ```
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/getting-started/05-structured-output



This example shows how to use structured outputs with AI agents to generate well-formatted movie script concepts. It shows two approaches:

1. JSON Mode: Traditional JSON response parsing
2. Structured Output: Enhanced structured data handling

Example prompts to try:

* "Tokyo" - Get a high-tech thriller set in futuristic Japan
* "Ancient Rome" - Experience an epic historical drama
* "Manhattan" - Explore a modern romantic comedy
* "Amazon Rainforest" - Adventure in an exotic location
* "Mars Colony" - Science fiction in a space settlement

## Code

```python structured_output.py
from textwrap import dedent
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    setting: str = Field(
        ...,
        description="A richly detailed, atmospheric description of the movie's primary location and time period. Include sensory details and mood.",
    )
    ending: str = Field(
        ...,
        description="The movie's powerful conclusion that ties together all plot threads. Should deliver emotional impact and satisfaction.",
    )
    genre: str = Field(
        ...,
        description="The film's primary and secondary genres (e.g., 'Sci-fi Thriller', 'Romantic Comedy'). Should align with setting and tone.",
    )
    name: str = Field(
        ...,
        description="An attention-grabbing, memorable title that captures the essence of the story and appeals to target audience.",
    )
    characters: List[str] = Field(
        ...,
        description="4-6 main characters with distinctive names and brief role descriptions (e.g., 'Sarah Chen - brilliant quantum physicist with a dark secret').",
    )
    storyline: str = Field(
        ...,
        description="A compelling three-sentence plot summary: Setup, Conflict, and Stakes. Hook readers with intrigue and emotion.",
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
        You are an acclaimed Hollywood screenwriter known for creating unforgettable blockbusters! üé¨
        With the combined storytelling prowess of Christopher Nolan, Aaron Sorkin, and Quentin Tarantino,
        you craft unique stories that captivate audiences worldwide.

        Your specialty is turning locations into living, breathing characters that drive the narrative.\
    """),
    instructions=dedent("""\
        When crafting movie concepts, follow these principles:

        1. Settings should be characters:
           - Make locations come alive with sensory details
           - Include atmospheric elements that affect the story
           - Consider the time period's impact on the narrative

        2. Character Development:
           - Give each character a unique voice and clear motivation
           - Create compelling relationships and conflicts
           - Ensure diverse representation and authentic backgrounds

        3. Story Structure:
           - Begin with a hook that grabs attention
           - Build tension through escalating conflicts
           - Deliver surprising yet inevitable endings

        4. Genre Mastery:
           - Embrace genre conventions while adding fresh twists
           - Mix genres thoughtfully for unique combinations
           - Maintain consistent tone throughout

        Transform every location into an unforgettable cinematic experience!\
    """),
    output_schema=MovieScript,
    use_json_mode=True,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
        You are an acclaimed Hollywood screenwriter known for creating unforgettable blockbusters! üé¨
        With the combined storytelling prowess of Christopher Nolan, Aaron Sorkin, and Quentin Tarantino,
        you craft unique stories that captivate audiences worldwide.

        Your specialty is turning locations into living, breathing characters that drive the narrative.\
    """),
    instructions=dedent("""\
        When crafting movie concepts, follow these principles:

        1. Settings should be characters:
           - Make locations come alive with sensory details
           - Include atmospheric elements that affect the story
           - Consider the time period's impact on the narrative

        2. Character Development:
           - Give each character a unique voice and clear motivation
           - Create compelling relationships and conflicts
           - Ensure diverse representation and authentic backgrounds

        3. Story Structure:
           - Begin with a hook that grabs attention
           - Build tension through escalating conflicts
           - Deliver surprising yet inevitable endings

        4. Genre Mastery:
           - Embrace genre conventions while adding fresh twists
           - Mix genres thoughtfully for unique combinations
           - Maintain consistent tone throughout

        Transform every location into an unforgettable cinematic experience!\
    """),
    output_schema=MovieScript,
)

# Example usage with different locations
json_mode_agent.print_response("Tokyo", stream=True)
structured_output_agent.print_response("Ancient Rome", stream=True)

# More examples to try:
"""
Creative location prompts to explore:
1. "Underwater Research Station" - For a claustrophobic sci-fi thriller
2. "Victorian London" - For a gothic mystery
3. "Dubai 2050" - For a futuristic heist movie
4. "Antarctic Research Base" - For a survival horror story
5. "Caribbean Island" - For a tropical adventure romance
"""

# To get the response in a variable:
# from rich.pretty import pprint

# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python structured_output.py
    ```
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/getting-started/06-agent-with-storage



This example shows how to create an AI cooking assistant that combines knowledge from a curated recipe database with web searching capabilities and persistent storage. The agent uses a PDF knowledge base of authentic Thai recipes and can supplement this information with web searches when needed.

Example prompts to try:

* "How do I make authentic Pad Thai?"
* "What's the difference between red and green curry?"
* "Can you explain what galangal is and possible substitutes?"
* "Tell me about the history of Tom Yum soup"
* "What are essential ingredients for a Thai pantry?"
* "How do I make Thai basil chicken (Pad Kra Pao)?"

## Code

```python agent_with_storage.py
from textwrap import dedent
from typing import List, Optional

import typer
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.session import AgentSession
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb, SearchType
from rich import print

agent_knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="recipe_knowledge",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

# Add content to the knowledge
agent_knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

# Setup the database
db = SqliteDb(db_file="tmp/agents.db")


def recipe_agent(user: str = "user"):
    session_id: Optional[str] = None

    # Ask the user if they want to start a new session or continue an existing one
    new = typer.confirm("Do you want to start a new session?")

    if not new:
        existing_sessions: List[AgentSession] = db.get_sessions(  # type: ignore
            user_id=user, session_type=SessionType.AGENT
        )
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0].session_id

    agent = Agent(
        user_id=user,
        session_id=session_id,
        model=OpenAIChat(id="gpt-5-mini"),
        instructions=dedent("""\
            You are a passionate and knowledgeable Thai cuisine expert! üßë‚Äçüç≥
            Think of yourself as a combination of a warm, encouraging cooking instructor,
            a Thai food historian, and a cultural ambassador.

            Follow these steps when answering questions:
            1. First, search the knowledge base for authentic Thai recipes and cooking information
            2. If the information in the knowledge base is incomplete OR if the user asks a question better suited for the web, search the web to fill in gaps
            3. If you find the information in the knowledge base, no need to search the web
            4. Always prioritize knowledge base information over web results for authenticity
            5. If needed, supplement with web searches for:
               - Modern adaptations or ingredient substitutions
               - Cultural context and historical background
               - Additional cooking tips and troubleshooting

            Communication style:
            1. Start each response with a relevant cooking emoji
            2. Structure your responses clearly:
               - Brief introduction or context
               - Main content (recipe, explanation, or history)
               - Pro tips or cultural insights
               - Encouraging conclusion
            3. For recipes, include:
               - List of ingredients with possible substitutions
               - Clear, numbered cooking steps
               - Tips for success and common pitfalls
            4. Use friendly, encouraging language

            Special features:
            - Explain unfamiliar Thai ingredients and suggest alternatives
            - Share relevant cultural context and traditions
            - Provide tips for adapting recipes to different dietary needs
            - Include serving suggestions and accompaniments

            End each response with an uplifting sign-off like:
            - 'Happy cooking! ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡∏£‡πà‡∏≠‡∏¢ (Enjoy your meal)!'
            - 'May your Thai cooking adventure bring joy!'
            - 'Enjoy your homemade Thai feast!'

            Remember:
            - Always verify recipe authenticity with the knowledge base
            - Clearly indicate when information comes from web sources
            - Be encouraging and supportive of home cooks at all skill levels\
        """),
        db=db,
        knowledge=agent_knowledge,
        tools=[DuckDuckGoTools()],
        # To provide the agent with the chat history
        # We can either:
        # 1. Provide the agent with a tool to read the chat history
        # 2. Automatically add the chat history to the messages sent to the model
        #
        # 1. Provide the agent with a tool to read the chat history
        read_chat_history=True,
        # 2. Automatically add the chat history to the messages sent to the model
        # add_history_to_context=True,
        # Number of historical responses to add to the messages.
        # num_history_runs=3,
        markdown=True,
    )

    print("You are about to chat with an agent!")
    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"Started Session: {session_id}\n")
        else:
            print("Started Session\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    # Runs the agent as a command line application
    agent.cli_app(markdown=True)


if __name__ == "__main__":
    typer.run(recipe_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai lancedb tantivy pypdf ddgs sqlalchemy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_with_storage.py
    ```
  </Step>
</Steps>


# Agent State
Source: https://docs.agno.com/examples/getting-started/07-agent-state



This example shows how to create an agent that maintains state across interactions. It demonstrates a simple counter mechanism, but this pattern can be extended to more complex state management like maintaining conversation context, user preferences, or tracking multi-step processes.

Example prompts to try:

* "Increment the counter 3 times and tell me the final count"
* "What's our current count? Add 2 more to it"
* "Let's increment the counter 5 times, but tell me each step"
* "Add 4 to our count and remind me where we started"
* "Increase the counter twice and summarize our journey"

## Code

```python agent_state.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def increment_counter(session_state) -> str:
    """Increment the counter in session state."""
    # Initialize counter if it doesn't exist
    if "count" not in session_state:
        session_state["count"] = 0

    # Increment the counter
    session_state["count"] += 1

    return f"Counter incremented! Current count: {session_state['count']}"


def get_counter(session_state) -> str:
    """Get the current counter value."""
    count = session_state.get("count", 0)
    return f"Current count: {count}"


# Create an Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Initialize the session state with a counter starting at 0
    session_state={"count": 0},
    tools=[increment_counter, get_counter],
    # Use variables from the session state in the instructions
    instructions="You can increment and check a counter. Current count is: {count}",
    # Important: Resolve the state in the messages so the agent can see state changes
    resolve_in_context=True,
    markdown=True,
)

# Test the counter functionality
print("Testing counter functionality...")
agent.print_response(
    "Let's increment the counter 3 times and observe the state changes!", stream=True
)
print(f"Final session state: {agent.get_session_state()}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_state.py
    ```
  </Step>
</Steps>


# Agent Context
Source: https://docs.agno.com/examples/getting-started/08-agent-context



This example shows how to inject external dependencies into an agent. The context is evaluated when the agent is run, acting like dependency injection for Agents.

Example prompts to try:

* "Summarize the top stories on HackerNews"
* "What are the trending tech discussions right now?"
* "Analyze the current top stories and identify trends"
* "What's the most upvoted story today?"

## Code

```python agent_context.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_top_hackernews_stories(num_stories: int = 5) -> str:
    """Fetch and return the top stories from HackerNews.

    Args:
        num_stories: Number of top stories to retrieve (default: 5)
    Returns:
        JSON string containing story details (title, url, score, etc.)
    """
    # Get top stories
    stories = [
        {
            k: v
            for k, v in httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{id}.json"
            )
            .json()
            .items()
            if k != "kids"  # Exclude discussion threads
        }
        for id in httpx.get(
            "https://hacker-news.firebaseio.com/v0/topstories.json"
        ).json()[:num_stories]
    ]
    return json.dumps(stories, indent=4)


# Create a Context-Aware Agent that can access real-time HackerNews data
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    # Each function in the context is evaluated when the agent is run,
    # think of it as dependency injection for Agents
    dependencies={"top_hackernews_stories": get_top_hackernews_stories},
    # Alternatively, you can manually add the context to the instructions. This gets resolved automatically
    instructions=dedent("""\
        You are an insightful tech trend observer! üì∞

        Here are the top stories on HackerNews:
        {top_hackernews_stories}\
    """),
    markdown=True,
)

# Example usage
agent.print_response(
    "Summarize the top stories on HackerNews and identify any interesting trends.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai httpx agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_context.py
    ```
  </Step>
</Steps>


# Agent Session
Source: https://docs.agno.com/examples/getting-started/09-agent-session



This example shows how to create an agent with persistent memory stored in a SQLite database. We set the session\_id on the agent when resuming the conversation, this way the previous chat history is preserved.

Key features:

* Stores conversation history in a SQLite database
* Continues conversations across multiple sessions
* References previous context in responses

## Code

```python agent_session.py
import json
from typing import List, Optional

import typer
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.session import AgentSession
from rich import print
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel
from rich.prompt import Prompt

console = Console()


def create_agent(user: str = "user"):
    session_id: Optional[str] = None

    # Ask if user wants to start new session or continue existing one
    new = typer.confirm("Do you want to start a new session?")

    # Get existing session if user doesn't want a new one
    db = SqliteDb(db_file="tmp/agents.db")

    if not new:
        existing_sessions: List[AgentSession] = db.get_sessions(
            user_id=user, session_type=SessionType.AGENT
        )  # type: ignore
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0].session_id

    agent = Agent(
        user_id=user,
        # Set the session_id on the agent to resume the conversation
        session_id=session_id,
        model=OpenAIChat(id="gpt-5-mini"),
        db=db,
        # Add chat history to messages
        add_history_to_context=True,
        num_history_runs=3,
        markdown=True,
    )

    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"Started Session: {session_id}\n")
        else:
            print("Started Session\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    return agent


def print_messages(agent):
    """Print the current chat history in a formatted panel"""
    console.print(
        Panel(
            JSON(
                json.dumps(
                    [
                        m.model_dump(include={"role", "content"})
                        for m in agent.get_messages_for_session()
                    ]
                ),
                indent=4,
            ),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )


def main(user: str = "user"):
    agent = create_agent(user)

    print("Chat with an OpenAI agent!")
    exit_on = ["exit", "quit", "bye"]
    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in exit_on:
            break

        agent.print_response(input=message, stream=True, markdown=True)
        print_messages(agent)


if __name__ == "__main__":
    typer.run(main)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_session.py
    ```
  </Step>
</Steps>


# User Memories and Session Summaries
Source: https://docs.agno.com/examples/getting-started/10-user-memories-and-summaries



This example shows how to create an agent with persistent memory that stores:

1. Personalized user memories - facts and preferences learned about specific users
2. Session summaries - key points and context from conversations
3. Chat history - stored in SQLite for persistence

Key features:

* Stores user-specific memories in SQLite database
* Maintains session summaries for context
* Continues conversations across sessions with memory
* References previous context and user information in responses

Examples:
User: "My name is John and I live in NYC"
Agent: *Creates memory about John's location*

User: "What do you remember about me?"
Agent: *Recalls previous memories about John*

## Code

```python user_memories.py
import json
from textwrap import dedent
from typing import List, Optional

import typer
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.session import AgentSession
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel
from rich.prompt import Prompt


def create_agent(user: str = "user"):
    session_id: Optional[str] = None

    # Ask if user wants to start new session or continue existing one
    new = typer.confirm("Do you want to start a new session?")

    # Initialize storage for both agent sessions and memories
    db = SqliteDb(db_file="tmp/agents.db")

    if not new:
        existing_sessions: List[AgentSession] = db.get_sessions(
            user_id=user, session_type=SessionType.AGENT
        )  # type: ignore
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0].session_id

    agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        user_id=user,
        session_id=session_id,
        enable_user_memories=True,
        enable_session_summaries=True,
        db=db,
        add_history_to_context=True,
        num_history_runs=3,
        # Enhanced system prompt for better personality and memory usage
        description=dedent("""\
        You are a helpful and friendly AI assistant with excellent memory.
        - Remember important details about users and reference them naturally
        - Maintain a warm, positive tone while being precise and helpful
        - When appropriate, refer back to previous conversations and memories
        - Always be truthful about what you remember or don't remember"""),
    )

    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"Started Session: {session_id}\n")
        else:
            print("Started Session\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    return agent


def print_agent_memory(agent):
    """Print the current state of agent's memory systems"""
    console = Console()

    # Print chat history
    messages = agent.get_messages_for_session()
    console.print(
        Panel(
            JSON(
                json.dumps(
                    [m.model_dump(include={"role", "content"}) for m in messages],
                    indent=4,
                ),
            ),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )

    # Print user memories
    user_memories = agent.get_user_memories(user_id=agent.user_id)
    if user_memories:
        memories_data = [memory.to_dict() for memory in user_memories]
        console.print(
            Panel(
                JSON(json.dumps(memories_data, indent=4)),
                title=f"Memories for user_id: {agent.user_id}",
                expand=True,
            )
        )

    # Print session summaries
    try:
        session_summary = agent.get_session_summary()
        if session_summary:
            console.print(
                Panel(
                    JSON(
                        json.dumps(session_summary.to_dict(), indent=4),
                    ),
                    title=f"Session Summary for session_id: {agent.session_id}",
                    expand=True,
                )
            )
        else:
            console.print(
                "Session summary: Not yet created (summaries are created after multiple interactions)"
            )
    except Exception as e:
        console.print(f"Session summary error: {e}")


def main(user: str = "user"):
    """Interactive chat loop with memory display"""
    agent = create_agent(user)

    print("Try these example inputs:")
    print("- 'My name is [name] and I live in [city]'")
    print("- 'I love [hobby/interest]'")
    print("- 'What do you remember about me?'")
    print("- 'What have we discussed so far?'\n")

    exit_on = ["exit", "quit", "bye"]
    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in exit_on:
            break

        agent.print_response(input=message, stream=True, markdown=True)
        print_agent_memory(agent)


if __name__ == "__main__":
    typer.run(main)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python user_memories.py
    ```
  </Step>
</Steps>


# Retry Function Call
Source: https://docs.agno.com/examples/getting-started/11-retry-function-call



This example shows how to retry a function call if it fails or you do not like the output. This is useful for:

* Handling temporary failures
* Improving output quality through retries
* Implementing human-in-the-loop validation

## Code

```python retry_function_call.py
from typing import Iterator

from agno.agent import Agent
from agno.exceptions import RetryAgentRun
from agno.tools import FunctionCall, tool

num_calls = 0


def pre_hook(fc: FunctionCall):
    global num_calls

    print(f"Pre-hook: {fc.function.name}")
    print(f"Arguments: {fc.arguments}")
    num_calls += 1
    if num_calls < 2:
        raise RetryAgentRun(
            "This wasn't interesting enough, please retry with a different argument"
        )


@tool(pre_hook=pre_hook)
def print_something(something: str) -> Iterator[str]:
    print(something)
    yield f"I have printed {something}"


agent = Agent(tools=[print_something], markdown=True)
agent.print_response("Print something interesting", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python retry_function_call.py
    ```
  </Step>
</Steps>


# Human in the Loop
Source: https://docs.agno.com/examples/getting-started/12-human-in-the-loop



This example shows how to implement human-in-the-loop functionality in your Agno tools.
It shows how to:

* Add pre-hooks to tools for user confirmation
* Handle user input during tool execution
* Gracefully cancel operations based on user choice

Some practical applications:

* Confirming sensitive operations before execution
* Reviewing API calls before they're made
* Validating data transformations
* Approving automated actions in critical systems

## Code

```python human_in_the_loop.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.tools import tool
from agno.utils import pprint
from rich.console import Console
from rich.prompt import Prompt

console = Console()


@tool(requires_confirmation=True)
def get_top_hackernews_stories(num_stories: int) -> str:
    """Fetch top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    all_stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        all_stories.append(story)
    return json.dumps(all_stories)


# Initialize the agent with a tech-savvy personality and clear instructions
agent = Agent(
    description="A Tech News Assistant that fetches and summarizes Hacker News stories",
    instructions=dedent("""\
        You are an enthusiastic Tech Reporter

        Your responsibilities:
        - Present Hacker News stories in an engaging and informative way
        - Provide clear summaries of the information you gather

        Style guide:
        - Use emoji to make your responses more engaging
        - Keep your summaries concise but informative
        - End with a friendly tech-themed sign-off\
    """),
    tools=[get_top_hackernews_stories],
    markdown=True,
)

# Example questions to try:
# - "What are the top 3 HN stories right now?"
# - "Show me the most recent story from Hacker News"
# - "Get the top 5 stories (you can try accepting and declining the confirmation)"
response = agent.run("What are the top 2 hackernews stories?")
if response.is_paused:
    for tool in response.tools:  # type: ignore
        # Ask for confirmation
        console.print(
            f"Tool name [bold blue]{tool.tool_name}({tool.tool_args})[/] requires confirmation."
        )
        message = (
            Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
            .strip()
            .lower()
        )

        if message == "n":
            break
        else:
            # We update the tools in place
            tool.confirmed = True

    run_response = agent.continue_run(run_response=response)
    pprint.pprint_run_response(run_response)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python human_in_the_loop.py
    ```
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/getting-started/13-image-agent



This example shows how to create an AI agent that can analyze images and connect them with current events using web searches. Perfect for:

1. News reporting and journalism
2. Travel and tourism content
3. Social media analysis
4. Educational presentations
5. Event coverage

Example images to try:

* Famous landmarks (Eiffel Tower, Taj Mahal, etc.)
* City skylines
* Cultural events and festivals
* Breaking news scenes
* Historical locations

## Code

```python image_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
        You are a world-class visual journalist and cultural correspondent with a gift
        for bringing images to life through storytelling! üì∏‚ú® With the observational skills
        of a detective and the narrative flair of a bestselling author, you transform visual
        analysis into compelling stories that inform and captivate.\
    """),
    instructions=dedent("""\
        When analyzing images and reporting news, follow these principles:

        1. Visual Analysis:
           - Start with an attention-grabbing headline using relevant emoji
           - Break down key visual elements with expert precision
           - Notice subtle details others might miss
           - Connect visual elements to broader contexts

        2. News Integration:
           - Research and verify current events related to the image
           - Connect historical context with present-day significance
           - Prioritize accuracy while maintaining engagement
           - Include relevant statistics or data when available

        3. Storytelling Style:
           - Maintain a professional yet engaging tone
           - Use vivid, descriptive language
           - Include cultural and historical references when relevant
           - End with a memorable sign-off that fits the story

        4. Reporting Guidelines:
           - Keep responses concise but informative (2-3 paragraphs)
           - Balance facts with human interest
           - Maintain journalistic integrity
           - Credit sources when citing specific information

        Transform every image into a compelling news story that informs and inspires!\
    """),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Example usage with a famous landmark
agent.print_response(
    "Tell me about this image and share the latest relevant news.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

# More examples to try:
"""
Sample prompts to explore:
1. "What's the historical significance of this location?"
2. "How has this place changed over time?"
3. "What cultural events happen here?"
4. "What's the architectural style and influence?"
5. "What recent developments affect this area?"

Sample image URLs to analyze:
1. Eiffel Tower: "https://upload.wikimedia.org/wikipedia/commons/8/85/Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg"
2. Taj Mahal: "https://upload.wikimedia.org/wikipedia/commons/b/bd/Taj_Mahal%2C_Agra%2C_India_edit3.jpg"
3. Golden Gate Bridge: "https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
"""

# To get the response in a variable:
# from rich.pretty import pprint
# response = agent.run(
#     "Analyze this landmark's architecture and recent news.",
#     images=[Image(url="YOUR_IMAGE_URL")],
# )
# pprint(response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai ddgs agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python image_agent.py
    ```
  </Step>
</Steps>


# Image Generation
Source: https://docs.agno.com/examples/getting-started/14-image-generation



This example shows how to create an AI agent that generates images using DALL-E.
You can use this agent to create various types of images, from realistic photos to artistic
illustrations and creative concepts.

Example prompts to try:

* "Create a surreal painting of a floating city in the clouds at sunset"
* "Generate a photorealistic image of a cozy coffee shop interior"
* "Design a cute cartoon mascot for a tech startup"
* "Create an artistic portrait of a cyberpunk samurai"

## Code

```python image_generation.py
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.tools.dalle import DalleTools

# Create an Creative AI Artist Agent
image_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DalleTools()],
    description=dedent("""\
        You are an experienced AI artist with expertise in various artistic styles,
        from photorealism to abstract art. You have a deep understanding of composition,
        color theory, and visual storytelling.\
    """),
    instructions=dedent("""\
        As an AI artist, follow these guidelines:
        1. Analyze the user's request carefully to understand the desired style and mood
        2. Before generating, enhance the prompt with artistic details like lighting, perspective, and atmosphere
        3. Use the `create_image` tool with detailed, well-crafted prompts
        4. Provide a brief explanation of the artistic choices made
        5. If the request is unclear, ask for clarification about style preferences

        Always aim to create visually striking and meaningful images that capture the user's vision!\
    """),
    markdown=True,
    db=SqliteDb(session_table="test_agent", db_file="tmp/test.db"),
)

# Example usage
image_agent.print_response(
    "Create a magical library with floating books and glowing crystals",
)

# Retrieve and display generated images
run_response = image_agent.get_last_run_output()
if run_response and isinstance(run_response, RunOutput):
    for image_response in run_response.images:
        image_url = image_response.url
        print("image_url: ", image_url)
else:
    print("No images found or images is not a list")

# More example prompts to try:
"""
Try these creative prompts:
1. "Generate a steampunk-style robot playing a violin"
2. "Design a peaceful zen garden during cherry blossom season"
3. "Create an underwater city with bioluminescent buildings"
4. "Generate a cozy cabin in a snowy forest at night"
5. "Create a futuristic cityscape with flying cars and skyscrapers"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python image_generation.py
    ```
  </Step>
</Steps>


# Video Generation
Source: https://docs.agno.com/examples/getting-started/15-video-generation



This example shows how to create an AI agent that generates videos using ModelsLabs.
You can use this agent to create various types of short videos, from animated scenes
to creative visual stories.

Example prompts to try:

* "Create a serene video of waves crashing on a beach at sunset"
* "Generate a magical video of butterflies flying in a enchanted forest"
* "Create a timelapse of a blooming flower in a garden"
* "Generate a video of northern lights dancing in the night sky"

## Code

```python video_generation.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models_labs import ModelsLabTools

# Create a Creative AI Video Director Agent
video_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ModelsLabTools()],
    description=dedent("""\
        You are an experienced AI video director with expertise in various video styles,
        from nature scenes to artistic animations. You have a deep understanding of motion,
        timing, and visual storytelling through video content.\
    """),
    instructions=dedent("""\
        As an AI video director, follow these guidelines:
        1. Analyze the user's request carefully to understand the desired style and mood
        2. Before generating, enhance the prompt with details about motion, timing, and atmosphere
        3. Use the `generate_media` tool with detailed, well-crafted prompts
        4. Provide a brief explanation of the creative choices made
        5. If the request is unclear, ask for clarification about style preferences

        The video will be displayed in the UI automatically below your response.
        Always aim to create captivating and meaningful videos that bring the user's vision to life!\
    """),
    markdown=True,
)

# Example usage
video_agent.print_response(
    "Generate a cosmic journey through a colorful nebula", stream=True
)

# Retrieve and display generated videos
run_response = video_agent.get_last_run_output()
if run_response and run_response.videos:
    for video in run_response.videos:
        print(f"Generated video URL: {video.url}")

# More example prompts to try:
"""
Try these creative prompts:
1. "Create a video of autumn leaves falling in a peaceful forest"
2. "Generate a video of a cat playing with a ball"
3. "Create a video of a peaceful koi pond with rippling water"
4. "Generate a video of a cozy fireplace with dancing flames"
5. "Create a video of a mystical portal opening in a magical realm"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export MODELS_LAB_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python video_generation.py
    ```
  </Step>
</Steps>


# Audio Input-Output Agent
Source: https://docs.agno.com/examples/getting-started/16-audio-agent



This example shows how to create an AI agent that can process audio input and generate audio responses. You can use this agent for various voice-based interactions, from analyzing speech content to generating natural-sounding responses.

Example audio interactions to try:

* Upload a recording of a conversation for analysis
* Have the agent respond to questions with voice output
* Process different languages and accents
* Analyze tone and emotion in speech

## Code

```python audio_input_output.py
from textwrap import dedent

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

# Create an AI Voice Interaction Agent
agent = Agent(
    model=OpenAIChat(
        id="gpt-5-mini-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
    description=dedent("""\
        You are an expert in audio processing and voice interaction, capable of understanding
        and analyzing spoken content while providing natural, engaging voice responses.
        You excel at comprehending context, emotion, and nuance in speech.\
    """),
    instructions=dedent("""\
        As a voice interaction specialist, follow these guidelines:
        1. Listen carefully to audio input to understand both content and context
        2. Provide clear, concise responses that address the main points
        3. When generating voice responses, maintain a natural, conversational tone
        4. Consider the speaker's tone and emotion in your analysis
        5. If the audio is unclear, ask for clarification

        Focus on creating engaging and helpful voice interactions!\
    """),
)

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()

# Process the audio and get a response
run_response = agent.run(
    "What's in this recording? Please analyze the content and tone.",
    audio=[Audio(content=response.content, format="wav")],
)

# Save the audio response if available
if run_response.response_audio is not None:
    write_audio_to_file(
        audio=run_response.response_audio.content, filename="tmp/response.wav"
    )

# More example interactions to try:
"""
Try these voice interaction scenarios:
1. "Can you summarize the main points discussed in this recording?"
2. "What emotions or tone do you detect in the speaker's voice?"
3. "Please provide a detailed analysis of the speech patterns and clarity"
4. "Can you identify any background noises or audio quality issues?"
5. "What is the overall context and purpose of this recording?"

Note: You can use your own audio files by converting them to base64 format.
Example for using your own audio file:

with open('your_audio.wav', 'rb') as audio_file:
    audio_data = audio_file.read()
    agent.run("Analyze this audio", audio=[Audio(content=audio_data, format="wav")])
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai requests agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python audio_input_output.py
    ```
  </Step>
</Steps>


# Agent Team
Source: https://docs.agno.com/examples/getting-started/17-agent-team



This example shows how to create a powerful team of AI agents working together to provide comprehensive financial analysis and news reporting. The team consists of:

1. Web Agent: Searches and analyzes latest news
2. Finance Agent: Analyzes financial data and market trends
3. Lead Editor: Coordinates and combines insights from both agents

Example prompts to try:

* "What's the latest news and financial performance of Apple (AAPL)?"
* "Analyze the impact of AI developments on NVIDIA's stock (NVDA)"
* "How are EV manufacturers performing? Focus on Tesla (TSLA) and Rivian (RIVN)"
* "What's the market outlook for semiconductor companies like AMD and Intel?"
* "Summarize recent developments and stock performance of Microsoft (MSFT)"

## Code

```python agent_team.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.exa import ExaTools

web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=dedent("""\
        You are an experienced web researcher and news analyst! üîç

        Follow these steps when searching for information:
        1. Start with the most recent and relevant sources
        2. Cross-reference information from multiple sources
        3. Prioritize reputable news outlets and official sources
        4. Always cite your sources with links
        5. Focus on market-moving news and significant developments

        Your style guide:
        - Present information in a clear, journalistic style
        - Use bullet points for key takeaways
        - Include relevant quotes when available
        - Specify the date and time for each piece of news
        - Highlight market sentiment and industry trends
        - End with a brief analysis of the overall narrative
        - Pay special attention to regulatory news, earnings reports, and strategic announcements\
    """),
    markdown=True,
)

finance_agent = Agent(
    name="Finance Agent",
    role="Get financial data",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ExaTools(
            include_domains=["trendlyne.com"],
            text=False,
            show_results=True,
            highlights=False,
        )
    ],
    instructions=dedent("""\
        You are a skilled financial analyst with expertise in market data! üìä

        Follow these steps when analyzing financial data:
        1. Start with the latest stock price, trading volume, and daily range
        2. Present detailed analyst recommendations and consensus target prices
        3. Include key metrics: P/E ratio, market cap, 52-week range
        4. Analyze trading patterns and volume trends
        5. Compare performance against relevant sector indices

        Your style guide:
        - Use tables for structured data presentation
        - Include clear headers for each data section
        - Add brief explanations for technical terms
        - Highlight notable changes with emojis (üìà üìâ)
        - Use bullet points for quick insights
        - Compare current values with historical averages
        - End with a data-driven financial outlook\
    """),
    markdown=True,
)

agent_team = Team(
    members=[web_agent, finance_agent],
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=dedent("""\
        You are the lead editor of a prestigious financial news desk! üì∞

        Your role:
        1. Coordinate between the web researcher and financial analyst
        2. Combine their findings into a compelling narrative
        3. Ensure all information is properly sourced and verified
        4. Present a balanced view of both news and data
        5. Highlight key risks and opportunities

        Your style guide:
        - Start with an attention-grabbing headline
        - Begin with a powerful executive summary
        - Present financial data first, followed by news context
        - Use clear section breaks between different types of information
        - Include relevant charts or tables when available
        - Add 'Market Sentiment' section with current mood
        - Include a 'Key Takeaways' section at the end
        - End with 'Risk Factors' when appropriate
        - Sign off with 'Market Watch Team' and the current date\
    """),
    add_datetime_to_context=True,
    markdown=True,
    show_members_responses=False,
)

# Example usage with diverse queries
agent_team.print_response(
    input="Summarize analyst recommendations and share the latest news for NVDA",
    stream=True,
)
agent_team.print_response(
    input="What's the market outlook and financial performance of AI semiconductor companies?",
    stream=True,
)
agent_team.print_response(
    input="Analyze recent developments and financial performance of TSLA",
    stream=True,
)

# More example prompts to try:
"""
Advanced queries to explore:
1. "Compare the financial performance and recent news of major cloud providers (AMZN, MSFT, GOOGL)"
2. "What's the impact of recent Fed decisions on banking stocks? Focus on JPM and BAC"
3. "Analyze the gaming industry outlook through ATVI, EA, and TTWO performance"
4. "How are social media companies performing? Compare META and SNAP"
5. "What's the latest on AI chip manufacturers and their market position?"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai ddgs exa agno
    ```
  </Step>

  <Step title="Set API keys">
    ```bash
    export EXA_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_team.py
    ```
  </Step>
</Steps>


# Research Agent
Source: https://docs.agno.com/examples/getting-started/18-research-agent-exa



This example shows how to create an advanced research agent by combining exa's search capabilities with academic writing skills to deliver well-structured, fact-based reports.

Key features demonstrated:

* Using Exa.ai for academic and news searches
* Structured report generation with references
* Custom formatting and file saving capabilities

Example prompts to try:

* "What are the latest developments in quantum computing?"
* "Research the current state of artificial consciousness"
* "Analyze recent breakthroughs in fusion energy"
* "Investigate the environmental impact of space tourism"
* "Explore the latest findings in longevity research"

## Code

```python research_agent.py
from datetime import datetime
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

cwd = Path(__file__).parent.resolve()
tmp = cwd.joinpath("tmp")
if not tmp.exists():
    tmp.mkdir(exist_ok=True, parents=True)

today = datetime.now().strftime("%Y-%m-%d")

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ExaTools(start_published_date=today, type="keyword")],
    description=dedent("""\
        You are Professor X-1000, a distinguished AI research scientist with expertise
        in analyzing and synthesizing complex information. Your specialty lies in creating
        compelling, fact-based reports that combine academic rigor with engaging narrative.

        Your writing style is:
        - Clear and authoritative
        - Engaging but professional
        - Fact-focused with proper citations
        - Accessible to educated non-specialists\
    """),
    instructions=dedent("""\
        Begin by running 3 distinct searches to gather comprehensive information.
        Analyze and cross-reference sources for accuracy and relevance.
        Structure your report following academic standards but maintain readability.
        Include only verifiable facts with proper citations.
        Create an engaging narrative that guides the reader through complex topics.
        End with actionable takeaways and future implications.\
    """),
    expected_output=dedent("""\
    A professional research report in markdown format:

    # {Compelling Title That Captures the Topic's Essence}

    ## Executive Summary
    {Brief overview of key findings and significance}

    ## Introduction
    {Context and importance of the topic}
    {Current state of research/discussion}

    ## Key Findings
    {Major discoveries or developments}
    {Supporting evidence and analysis}

    ## Implications
    {Impact on field/society}
    {Future directions}

    ## Key Takeaways
    - {Bullet point 1}
    - {Bullet point 2}
    - {Bullet point 3}

    ## References
    - [Source 1](link) - Key finding/quote
    - [Source 2](link) - Key finding/quote
    - [Source 3](link) - Key finding/quote

    ---
    Report generated by Professor X-1000
    Advanced Research Systems Division
    Date: {current_date}\
    """),
    markdown=True,
    add_datetime_to_context=True,
    save_response_to_file=str(tmp.joinpath("{message}.md")),
)

# Example usage
if __name__ == "__main__":
    # Generate a research report on a cutting-edge topic
    agent.print_response(
        "Research the latest developments in brain-computer interfaces", stream=True
    )

# More example prompts to try:
"""
Try these research topics:
1. "Analyze the current state of solid-state batteries"
2. "Research recent breakthroughs in CRISPR gene editing"
3. "Investigate the development of autonomous vehicles"
4. "Explore advances in quantum machine learning"
5. "Study the impact of artificial intelligence on healthcare"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa-py agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python research_agent.py
    ```
  </Step>
</Steps>


# Research Workflow
Source: https://docs.agno.com/examples/getting-started/19-blog-generator-workflow



This advanced example demonstrates how to build a sophisticated blog post generator using
the new workflow v2.0 architecture. The workflow combines web research capabilities with
professional writing expertise using a multi-stage approach:

1. Intelligent web research and source gathering
2. Content extraction and processing
3. Professional blog post writing with proper citations

Key capabilities:

* Advanced web research and source evaluation
* Content scraping and processing
* Professional writing with SEO optimization
* Automatic content caching for efficiency
* Source attribution and fact verification

## Code

```python blog-generator-workflow.py
import asyncio
import json
from textwrap import dedent
from typing import Dict, Optional

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow.workflow import Workflow
from pydantic import BaseModel, Field


# --- Response Models ---
class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )


class SearchResults(BaseModel):
    articles: list[NewsArticle]


class ScrapedArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )
    content: Optional[str] = Field(
        ...,
        description="Full article content in markdown format. None if content is unavailable.",
    )


# --- Agents ---
research_agent = Agent(
    name="Blog Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    description=dedent("""\
    You are BlogResearch-X, an elite research assistant specializing in discovering
    high-quality sources for compelling blog content. Your expertise includes:

    - Finding authoritative and trending sources
    - Evaluating content credibility and relevance
    - Identifying diverse perspectives and expert opinions
    - Discovering unique angles and insights
    - Ensuring comprehensive topic coverage
    """),
    instructions=dedent("""\
    1. Search Strategy üîç
       - Find 10-15 relevant sources and select the 5-7 best ones
       - Prioritize recent, authoritative content
       - Look for unique angles and expert insights
    2. Source Evaluation üìä
       - Verify source credibility and expertise
       - Check publication dates for timeliness
       - Assess content depth and uniqueness
    3. Diversity of Perspectives üåê
       - Include different viewpoints
       - Gather both mainstream and expert opinions
       - Find supporting data and statistics
    """),
    output_schema=SearchResults,
)

content_scraper_agent = Agent(
    name="Content Scraper Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[Newspaper4kTools()],
    description=dedent("""\
    You are ContentBot-X, a specialist in extracting and processing digital content
    for blog creation. Your expertise includes:

    - Efficient content extraction
    - Smart formatting and structuring
    - Key information identification
    - Quote and statistic preservation
    - Maintaining source attribution
    """),
    instructions=dedent("""\
    1. Content Extraction üìë
       - Extract content from the article
       - Preserve important quotes and statistics
       - Maintain proper attribution
       - Handle paywalls gracefully
    2. Content Processing üîÑ
       - Format text in clean markdown
       - Preserve key information
       - Structure content logically
    3. Quality Control ‚úÖ
       - Verify content relevance
       - Ensure accurate extraction
       - Maintain readability
    """),
    output_schema=ScrapedArticle,
)

blog_writer_agent = Agent(
    name="Blog Writer Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
    You are BlogMaster-X, an elite content creator combining journalistic excellence
    with digital marketing expertise. Your strengths include:

    - Crafting viral-worthy headlines
    - Writing engaging introductions
    - Structuring content for digital consumption
    - Incorporating research seamlessly
    - Optimizing for SEO while maintaining quality
    - Creating shareable conclusions
    """),
    instructions=dedent("""\
    1. Content Strategy üìù
       - Craft attention-grabbing headlines
       - Write compelling introductions
       - Structure content for engagement
       - Include relevant subheadings
    2. Writing Excellence ‚úçÔ∏è
       - Balance expertise with accessibility
       - Use clear, engaging language
       - Include relevant examples
       - Incorporate statistics naturally
    3. Source Integration üîç
       - Cite sources properly
       - Include expert quotes
       - Maintain factual accuracy
    4. Digital Optimization üíª
       - Structure for scanability
       - Include shareable takeaways
       - Optimize for SEO
       - Add engaging subheadings

    Format your blog post with this structure:
    # {Viral-Worthy Headline}

    ## Introduction
    {Engaging hook and context}

    ## {Compelling Section 1}
    {Key insights and analysis}
    {Expert quotes and statistics}

    ## {Engaging Section 2}
    {Deeper exploration}
    {Real-world examples}

    ## {Practical Section 3}
    {Actionable insights}
    {Expert recommendations}

    ## Key Takeaways
    - {Shareable insight 1}
    - {Practical takeaway 2}
    - {Notable finding 3}

    ## Sources
    {Properly attributed sources with links}
    """),
    markdown=True,
)


# --- Helper Functions ---
def get_cached_blog_post(session_state, topic: str) -> Optional[str]:
    """Get cached blog post from workflow session state"""
    logger.info("Checking if cached blog post exists")
    return session_state.get("blog_posts", {}).get(topic)


def cache_blog_post(session_state, topic: str, blog_post: str):
    """Cache blog post in workflow session state"""
    logger.info(f"Saving blog post for topic: {topic}")
    if "blog_posts" not in session_state:
        session_state["blog_posts"] = {}
    session_state["blog_posts"][topic] = blog_post


def get_cached_search_results(session_state, topic: str) -> Optional[SearchResults]:
    """Get cached search results from workflow session state"""
    logger.info("Checking if cached search results exist")
    search_results = session_state.get("search_results", {}).get(topic)
    if search_results and isinstance(search_results, dict):
        try:
            return SearchResults.model_validate(search_results)
        except Exception as e:
            logger.warning(f"Could not validate cached search results: {e}")
    return search_results if isinstance(search_results, SearchResults) else None


def cache_search_results(session_state, topic: str, search_results: SearchResults):
    """Cache search results in workflow session state"""
    logger.info(f"Saving search results for topic: {topic}")
    if "search_results" not in session_state:
        session_state["search_results"] = {}
    session_state["search_results"][topic] = search_results.model_dump()


def get_cached_scraped_articles(
    session_state, topic: str
) -> Optional[Dict[str, ScrapedArticle]]:
    """Get cached scraped articles from workflow session state"""
    logger.info("Checking if cached scraped articles exist")
    scraped_articles = session_state.get("scraped_articles", {}).get(topic)
    if scraped_articles and isinstance(scraped_articles, dict):
        try:
            return {
                url: ScrapedArticle.model_validate(article)
                for url, article in scraped_articles.items()
            }
        except Exception as e:
            logger.warning(f"Could not validate cached scraped articles: {e}")
    return scraped_articles if isinstance(scraped_articles, dict) else None


def cache_scraped_articles(
    session_state, topic: str, scraped_articles: Dict[str, ScrapedArticle]
):
    """Cache scraped articles in workflow session state"""
    logger.info(f"Saving scraped articles for topic: {topic}")
    if "scraped_articles" not in session_state:
        session_state["scraped_articles"] = {}
    session_state["scraped_articles"][topic] = {
        url: article.model_dump() for url, article in scraped_articles.items()
    }


async def get_search_results(
    session_state, topic: str, use_cache: bool = True, num_attempts: int = 3
) -> Optional[SearchResults]:
    """Get search results with caching support"""

    # Check cache first
    if use_cache:
        cached_results = get_cached_search_results(session_state, topic)
        if cached_results:
            logger.info(f"Found {len(cached_results.articles)} articles in cache.")
            return cached_results

    # Search for new results
    for attempt in range(num_attempts):
        try:
            print(
                f"üîç Searching for articles about: {topic} (attempt {attempt + 1}/{num_attempts})"
            )
            response = await research_agent.arun(topic)

            if (
                response
                and response.content
                and isinstance(response.content, SearchResults)
            ):
                article_count = len(response.content.articles)
                logger.info(f"Found {article_count} articles on attempt {attempt + 1}")
                print(f"‚úÖ Found {article_count} relevant articles")

                # Cache the results
                cache_search_results(session_state, topic, response.content)
                return response.content
            else:
                logger.warning(
                    f"Attempt {attempt + 1}/{num_attempts} failed: Invalid response type"
                )

        except Exception as e:
            logger.warning(f"Attempt {attempt + 1}/{num_attempts} failed: {str(e)}")

    logger.error(f"Failed to get search results after {num_attempts} attempts")
    return None


async def scrape_articles(
    session_state,
    topic: str,
    search_results: SearchResults,
    use_cache: bool = True,
) -> Dict[str, ScrapedArticle]:
    """Scrape articles with caching support"""

    # Check cache first
    if use_cache:
        cached_articles = get_cached_scraped_articles(session_state, topic)
        if cached_articles:
            logger.info(f"Found {len(cached_articles)} scraped articles in cache.")
            return cached_articles

    scraped_articles: Dict[str, ScrapedArticle] = {}

    print(f"üìÑ Scraping {len(search_results.articles)} articles...")

    for i, article in enumerate(search_results.articles, 1):
        try:
            print(
                f"üìñ Scraping article {i}/{len(search_results.articles)}: {article.title[:50]}..."
            )
            response = await content_scraper_agent.arun(article.url)

            if (
                response
                and response.content
                and isinstance(response.content, ScrapedArticle)
            ):
                scraped_articles[response.content.url] = response.content
                logger.info(f"Scraped article: {response.content.url}")
                print(f"‚úÖ Successfully scraped: {response.content.title[:50]}...")
            else:
                print(f"‚ùå Failed to scrape: {article.title[:50]}...")

        except Exception as e:
            logger.warning(f"Failed to scrape {article.url}: {str(e)}")
            print(f"‚ùå Error scraping: {article.title[:50]}...")

    # Cache the scraped articles
    cache_scraped_articles(session_state, topic, scraped_articles)
    return scraped_articles


# --- Main Execution Function ---
async def blog_generation_execution(
    session_state,
    topic: str = None,
    use_search_cache: bool = True,
    use_scrape_cache: bool = True,
    use_blog_cache: bool = True,
) -> str:
    """
    Blog post generation workflow execution function.

    Args:
        session_state: The shared session state
        topic: Blog post topic (if not provided, uses execution_input.input)
        use_search_cache: Whether to use cached search results
        use_scrape_cache: Whether to use cached scraped articles
        use_blog_cache: Whether to use cached blog posts
    """

    blog_topic = topic

    if not blog_topic:
        return "‚ùå No blog topic provided. Please specify a topic."

    print(f"üé® Generating blog post about: {blog_topic}")
    print("=" * 60)

    # Check for cached blog post first
    if use_blog_cache:
        cached_blog = get_cached_blog_post(session_state, blog_topic)
        if cached_blog:
            print("üìã Found cached blog post!")
            return cached_blog

    # Phase 1: Research and gather sources
    print("\nüîç PHASE 1: RESEARCH & SOURCE GATHERING")
    print("=" * 50)

    search_results = await get_search_results(
        session_state, blog_topic, use_search_cache
    )

    if not search_results or len(search_results.articles) == 0:
        return f"‚ùå Sorry, could not find any articles on the topic: {blog_topic}"

    print(f"üìä Found {len(search_results.articles)} relevant sources:")
    for i, article in enumerate(search_results.articles, 1):
        print(f"   {i}. {article.title[:60]}...")

    # Phase 2: Content extraction
    print("\nüìÑ PHASE 2: CONTENT EXTRACTION")
    print("=" * 50)

    scraped_articles = await scrape_articles(
        session_state, blog_topic, search_results, use_scrape_cache
    )

    if not scraped_articles:
        return f"‚ùå Could not extract content from any articles for topic: {blog_topic}"

    print(f"üìñ Successfully extracted content from {len(scraped_articles)} articles")

    # Phase 3: Blog post writing
    print("\n‚úçÔ∏è PHASE 3: BLOG POST CREATION")
    print("=" * 50)

    # Prepare input for the writer
    writer_input = {
        "topic": blog_topic,
        "articles": [article.model_dump() for article in scraped_articles.values()],
    }

    print("ü§ñ AI is crafting your blog post...")
    writer_response = await blog_writer_agent.arun(json.dumps(writer_input, indent=2))

    if not writer_response or not writer_response.content:
        return f"‚ùå Failed to generate blog post for topic: {blog_topic}"

    blog_post = writer_response.content

    # Cache the blog post
    cache_blog_post(session_state, blog_topic, blog_post)

    print("‚úÖ Blog post generated successfully!")
    print(f"üìù Length: {len(blog_post)} characters")
    print(f"üìö Sources: {len(scraped_articles)} articles")

    return blog_post


# --- Workflow Definition ---
blog_generator_workflow = Workflow(
    name="Blog Post Generator",
    description="Advanced blog post generator with research and content creation capabilities",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/blog_generator.db",
    ),
    steps=blog_generation_execution,
    session_state={},  # Initialize empty session state for caching
)


if __name__ == "__main__":
    import random

    async def main():
        # Fun example topics to showcase the generator's versatility
        example_topics = [
            "The Rise of Artificial General Intelligence: Latest Breakthroughs",
            "How Quantum Computing is Revolutionizing Cybersecurity",
            "Sustainable Living in 2024: Practical Tips for Reducing Carbon Footprint",
            "The Future of Work: AI and Human Collaboration",
            "Space Tourism: From Science Fiction to Reality",
            "Mindfulness and Mental Health in the Digital Age",
            "The Evolution of Electric Vehicles: Current State and Future Trends",
            "Why Cats Secretly Run the Internet",
            "The Science Behind Why Pizza Tastes Better at 2 AM",
            "How Rubber Ducks Revolutionized Software Development",
        ]

        # Test with a random topic
        topic = random.choice(example_topics)

        print("üß™ Testing Blog Post Generator v2.0")
        print("=" * 60)
        print(f"üìù Topic: {topic}")
        print()

        # Generate the blog post
        resp = await blog_generator_workflow.arun(
            topic=topic,
            use_search_cache=True,
            use_scrape_cache=True,
            use_blog_cache=True,
        )

        pprint_run_response(resp, markdown=True, show_time=True)

    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    openai googlesearch-python newspaper4k lxml_html_clean sqlalchemy agno
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
        python blog-generator-workflow.py
    ```
  </Step>
</Steps>


# Introduction
Source: https://docs.agno.com/examples/getting-started/introduction



This guide walks through the basics of building Agents with Agno.

The examples build on each other, introducing new concepts and capabilities progressively. Each example contains detailed comments, example prompts, and required dependencies.

## Setup

Create a virtual environment:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

Install the required dependencies:

```bash
pip install openai ddgs lancedb tantivy pypdf requests exa-py newspaper4k lxml_html_clean sqlalchemy agno
```

Export your OpenAI API key:

```bash
export OPENAI_API_KEY=your_api_key
```

## Examples

<CardGroup cols={3}>
  <Card title="Basic Agent" icon="robot" iconType="duotone" href="./01-basic-agent">
    Build a news reporter with a vibrant personality. This Agent only shows basic LLM inference.
  </Card>

  <Card title="Agent with Tools" icon="toolbox" iconType="duotone" href="./02-agent-with-tools">
    Add web search capabilities using DuckDuckGo for real-time information gathering.
  </Card>

  <Card title="Agent with Knowledge" icon="brain" iconType="duotone" href="./03-agent-with-knowledge">
    Add a vector database to your agent to store and search knowledge.
  </Card>

  <Card title="Agent with Storage" icon="database" iconType="duotone" href="./06-agent-with-storage">
    Add persistence to your agents with session management and history capabilities.
  </Card>

  <Card title="Agent Team" icon="users" iconType="duotone" href="./17-agent-team">
    Create an agent team specializing in market research and financial analysis.
  </Card>

  <Card title="Structured Output" icon="code" iconType="duotone" href="./05-structured-output">
    Generate a structured output using a Pydantic model.
  </Card>

  <Card title="Custom Tools" icon="wrench" iconType="duotone" href="./04-write-your-own-tool">
    Create and integrate custom tools with your agent.
  </Card>

  <Card title="Research Agent" icon="magnifying-glass" iconType="duotone" href="./18-research-agent-exa">
    Build an AI research agent using Exa with controlled output steering.
  </Card>

  <Card title="Research Workflow" icon="diagram-project" iconType="duotone" href="./19-blog-generator-workflow">
    Create a research workflow combining web searches and content scraping.
  </Card>

  <Card title="Image Agent" icon="image" iconType="duotone" href="./13-image-agent">
    Create an agent that can understand images.
  </Card>

  <Card title="Image Generation" icon="paintbrush" iconType="duotone" href="./14-image-generation">
    Create an Agent that can generate images using DALL-E.
  </Card>

  <Card title="Video Generation" icon="video" iconType="duotone" href="./15-video-generation">
    Create an Agent that can generate videos using ModelsLabs.
  </Card>

  <Card title="Audio Agent" icon="microphone" iconType="duotone" href="./16-audio-agent">
    Create an Agent that can process audio input and generate responses.
  </Card>

  <Card title="Agent with State" icon="database" iconType="duotone" href="./07-agent-state">
    Create an Agent with session state management.
  </Card>

  <Card title="Agent Context" icon="sitemap" iconType="duotone" href="./08-agent-context">
    Evaluate dependencies at agent.run and inject them into the instructions.
  </Card>

  <Card title="Agent Session" icon="clock-rotate-left" iconType="duotone" href="./09-agent-session">
    Create an Agent with persistent session memory across conversations.
  </Card>

  <Card title="User Memories" icon="memory" iconType="duotone" href="./10-user-memories-and-summaries">
    Create an Agent that stores user memories and summaries.
  </Card>

  <Card title="Function Retries" icon="rotate" iconType="duotone" href="./11-retry-function-call">
    Handle function retries for failed or unsatisfactory outputs.
  </Card>

  <Card title="Human in the Loop" icon="user-check" iconType="duotone" href="./12-human-in-the-loop">
    Add user confirmation and safety checks for interactive agent control.
  </Card>
</CardGroup>

Each example includes runnable code and detailed explanations. We recommend following them in order, as concepts build upon previous examples.


# Examples Gallery
Source: https://docs.agno.com/examples/introduction

Explore Agno's example gallery showcasing everything from single-agent tasks to sophisticated multi-agent workflows.

Welcome to Agno's example gallery! Here you'll discover examples showcasing everything from **single-agent tasks** to sophisticated **multi-agent workflows**. You can either:

* Run the examples individually
* Clone the entire [Agno cookbook](https://github.com/agno-agi/agno/tree/main/cookbook)

Have an interesting example to share? Please consider [contributing](https://github.com/agno-agi/agno-docs) to our growing collection.

## Getting Started

If you're just getting started, follow the [Getting Started](/examples/getting-started) guide for a step-by-step tutorial. The examples build on each other, introducing new concepts and capabilities progressively.

## Use Cases

Build real-world applications with Agno.

<CardGroup cols={3}>
  <Card title="Simple Agents" icon="user-astronaut" iconType="duotone" href="/examples/use-cases/agents">
    Simple agents for web scraping, data processing, financial analysis, etc.
  </Card>

  <Card title="Multi-Agent Teams" icon="people-group" iconType="duotone" href="/examples/use-cases/teams/">
    Multi-agent teams that collaborate to solve tasks.
  </Card>

  <Card title="Advanced Workflows" icon="diagram-project" iconType="duotone" href="/examples/use-cases/workflows/">
    Advanced workflows for creating blog posts, investment reports, etc.
  </Card>

  {/* <Card
      title="Full stack Applications"
      icon="brain-circuit"
      iconType="duotone"
      href="/examples/applications/"
    >
      Full stack applications like the LLM OS that come with a UI, database etc.
    </Card> */}
</CardGroup>

## Agent Concepts

Explore Agent concepts with detailed examples.

<CardGroup cols={3}>
  <Card title="Multimodal" icon="image" iconType="duotone" href="/examples/concepts/multimodal">
    Learn how to use multimodal Agents
  </Card>

  <Card title="Knowledge" icon="brain-circuit" iconType="duotone" href="/examples/concepts/knowledge">
    Add domain-specific knowledge to your Agents
  </Card>

  <Card title="RAG" icon="book-bookmark" iconType="duotone" href="/examples/concepts/knowledge/rag">
    Learn how to use Agentic RAG
  </Card>

  <Card title="Hybrid search" icon="magnifying-glass-plus" iconType="duotone" href="/examples/concepts/knowledge/search_type/hybrid-search">
    Combine semantic and keyword search
  </Card>

  <Card title="Memory" icon="database" iconType="duotone" href="/examples/concepts/memory">
    Let Agents remember past conversations
  </Card>

  <Card title="Tools" icon="screwdriver-wrench" iconType="duotone" href="/examples/concepts/tools">
    Extend your Agents with 100s or tools
  </Card>

  <Card title="Storage" icon="hard-drive" iconType="duotone" href="/examples/concepts/db">
    Store Agents sessions in a database
  </Card>

  <Card title="Vector Databases" icon="database" iconType="duotone" href="/examples/concepts/vectordb">
    Store Knowledge in Vector Databases
  </Card>

  <Card title="Embedders" icon="database" iconType="duotone" href="/examples/concepts/knowledge/embedders">
    Convert text to embeddings to store in VectorDbs
  </Card>
</CardGroup>

## Models

Explore different models with Agno.

<CardGroup cols={3}>
  <Card title="OpenAI" icon="network-wired" iconType="duotone" href="/examples/models/openai">
    Examples using OpenAI GPT models
  </Card>

  <Card title="Ollama" icon="laptop-code" iconType="duotone" href="/examples/models/ollama">
    Examples using Ollama models locally
  </Card>

  <Card title="Anthropic" icon="network-wired" iconType="duotone" href="/examples/models/anthropic">
    Examples using Anthropic models like Claude
  </Card>

  <Card title="Cohere" icon="brain-circuit" iconType="duotone" href="/examples/models/cohere">
    Examples using Cohere command models
  </Card>

  <Card title="DeepSeek" icon="circle-nodes" iconType="duotone" href="/examples/models/deepseek">
    Examples using DeepSeek models
  </Card>

  <Card title="Gemini" icon="google" iconType="duotone" href="/examples/models/gemini">
    Examples using Google Gemini models
  </Card>

  <Card title="Groq" icon="bolt" iconType="duotone" href="/examples/models/groq">
    Examples using Groq's fast inference
  </Card>

  <Card title="Mistral" icon="wind" iconType="duotone" href="/examples/models/mistral">
    Examples using Mistral models
  </Card>

  <Card title="Azure" icon="microsoft" iconType="duotone" href="/examples/models/azure">
    Examples using Azure OpenAI
  </Card>

  <Card title="Fireworks" icon="sparkles" iconType="duotone" href="/examples/models/fireworks">
    Examples using Fireworks models
  </Card>

  <Card title="AWS" icon="aws" iconType="duotone" href="/examples/models/aws">
    Examples using Amazon Bedrock
  </Card>

  <Card title="Hugging Face" icon="face-awesome" iconType="duotone" href="/examples/models/huggingface">
    Examples using Hugging Face models
  </Card>

  <Card title="NVIDIA" icon="microchip" iconType="duotone" href="/examples/models/nvidia">
    Examples using NVIDIA models
  </Card>

  <Card title="Nebius" icon="people-group" iconType="duotone" href="/examples/models/nebius">
    Examples using Nebius AI models
  </Card>

  <Card title="Together" icon="people-group" iconType="duotone" href="/examples/models/together">
    Examples using Together AI models
  </Card>

  <Card title="xAI" icon="brain-circuit" iconType="duotone" href="/examples/models/xai">
    Examples using xAI models
  </Card>

  <Card title="LangDB" icon="rust" iconType="duotone" href="/examples/models/langdb">
    Examples using LangDB AI Gateway.
  </Card>
</CardGroup>


# Basic Agent
Source: https://docs.agno.com/examples/models/anthropic/basic



## Code

```python cookbook/models/anthropic/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.anthropic import Claude

agent = Agent(model=Claude(id="claude-sonnet-4-20250514"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/basic.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/anthropic/basic_stream



## Code

```python cookbook/models/anthropic/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.anthropic import Claude

agent = Agent(model=Claude(id="claude-sonnet-4-20250514"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Code Execution Tool
Source: https://docs.agno.com/examples/models/anthropic/code_execution

Learn how to use Anthropic's code execution tool with Agno.

With Anthropic's [code execution tool](https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/code-execution-tool), your model can execute Python code in a secure, sandboxed environment.
This is useful for your model to perform tasks as analyzing data, creating visualizations, or performing complex calculations.

## Working example

```python
from agno.agent import Agent
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(
        id="claude-sonnet-4-20250514",
        default_headers={"anthropic-beta": "code-execution-2025-05-22"},
    ),
    tools=[
        {
            "type": "code_execution_20250522",
            "name": "code_execution",
        }
    ],
    markdown=True,
)

agent.print_response(
    "Calculate the mean and standard deviation of [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]",
    stream=True,
)
```


# File Upload
Source: https://docs.agno.com/examples/models/anthropic/file_upload

Learn how to use Anthropic's Files API with Agno.

With Anthropic's [Files API](https://docs.anthropic.com/en/docs/build-with-claude/files), you can upload files and later reference them in other API calls.
This is handy when a file is referenced multiple times in the same flow.

## Usage

<Steps>
  <Step title="Upload a file">
    Initialize the Anthropic client and use `client.beta.files.upload`:

    ```python
    from anthropic import Anthropic

    file_path = Path("path/to/your/file.pdf")

    client = Anthropic()
    uploaded_file = client.beta.files.upload(file=file_path)
    ```
  </Step>

  <Step title="Initialize the Claude model">
    When initializing the `Claude` model, pass the necessary beta header:

    ```python
    from agno.agent import Agent
    from agno.models.anthropic import Claude

    agent = Agent(
        model=Claude(
            id="claude-opus-4-20250514",
            default_headers={"anthropic-beta": "files-api-2025-04-14"},
        )
    )
    ```
  </Step>

  <Step title="Reference the file">
    You can now reference the uploaded file when interacting with your Agno agent:

    ```python
    agent.print_response(
        "Summarize the contents of the attached file.",
        files=[File(external=uploaded_file)],
    )
    ```
  </Step>
</Steps>

Notice there are some storage limits attached to this feature. You can read more about that on Anthropic's [docs](https://docs.anthropic.com/en/docs/build-with-claude/files#file-storage-and-limits).

## Working example

```python cookbook/models/anthropic/pdf_input_file_upload.py
from pathlib import Path

from agno.agent import Agent
from agno.media import File
from agno.models.anthropic import Claude
from agno.utils.media import download_file
from anthropic import Anthropic

pdf_path = Path(__file__).parent.joinpath("ThaiRecipes.pdf")

# Download the file using the download_file function
download_file(
    "https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf", str(pdf_path)
)

# Initialize Anthropic client
client = Anthropic()

# Upload the file to Anthropic
uploaded_file = client.beta.files.upload(
    file=Path(pdf_path),
)

if uploaded_file is not None:
    agent = Agent(
        model=Claude(
            id="claude-opus-4-20250514",
            default_headers={"anthropic-beta": "files-api-2025-04-14"},
        ),
        markdown=True,
    )

    agent.print_response(
        "Summarize the contents of the attached file.",
        files=[File(external=uploaded_file)],
    )
```


# Image Input Bytes Content
Source: https://docs.agno.com/examples/models/anthropic/image_input_bytes



## Code

```python cookbook/models/anthropic/image_input_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.anthropic.claude import Claude
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.media import download_image

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

download_image(
    url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg",
    output_path=str(image_path),
)

# Read the image file content as bytes
image_bytes = image_path.read_bytes()

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/image_input_bytes.py 
      ```

      ```bash Windows
      python cookbook/models/anthropic/image_input_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Input URL
Source: https://docs.agno.com/examples/models/anthropic/image_input_url



## Code

```python cookbook/models/anthropic/image_input_url.py
from agno.agent import Agent
from agno.media import Image
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and search the web for more information.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"
        ),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/image_input_url.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/image_input_url.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/anthropic/knowledge



## Code

```python cookbook/models/anthropic/knowledge.py
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.anthropic import Claude
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    knowledge=knowledge,
    debug_mode=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic sqlalchemy pgvector pypdf openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PDF Input Bytes Agent
Source: https://docs.agno.com/examples/models/anthropic/pdf_input_bytes



## Code

```python cookbook/models/anthropic/pdf_input_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import File
from agno.models.anthropic import Claude
from agno.utils.media import download_file

pdf_path = Path(__file__).parent.joinpath("ThaiRecipes.pdf")

# Download the file using the download_file function
download_file(
    "https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf", str(pdf_path)
)

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file.",
    files=[
        File(
            content=pdf_path.read_bytes(),
        ),
    ],
)
run_response = agent.get_last_run_output()
print("Citations:")
print(run_response.citations)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/pdf_input_bytes.py 
      ```

      ```bash Windows
      python cookbook/models/anthropic/pdf_input_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PDF Input Local Agent
Source: https://docs.agno.com/examples/models/anthropic/pdf_input_local



## Code

```python cookbook/models/anthropic/pdf_input_local.py
from pathlib import Path

from agno.agent import Agent
from agno.media import File
from agno.models.anthropic import Claude
from agno.utils.media import download_file

pdf_path = Path(__file__).parent.joinpath("ThaiRecipes.pdf")

# Download the file using the download_file function
download_file(
    "https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf", str(pdf_path)
)

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file.",
    files=[
        File(
            filepath=pdf_path,
        ),
    ],
)
run_response = agent.get_last_run_output()
print("Citations:")
print(run_response.citations)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/pdf_input_local.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/pdf_input_local.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PDF Input URL Agent
Source: https://docs.agno.com/examples/models/anthropic/pdf_input_url



## Code

```python cookbook/models/anthropic/pdf_input_url.py
from agno.agent import Agent
from agno.media import File
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file.",
    files=[
        File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"),
    ],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/pdf_input_url.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/pdf_input_url.py 
      ```
    </CodeGroup>
  </Step>
</Steps>


# Prompt Caching
Source: https://docs.agno.com/examples/models/anthropic/prompt_caching

Learn how to use prompt caching with Anthropic models and Agno.

Prompt caching can help reducing processing time and costs. Consider it if you are using the same prompt multiple times in any flow.

You can read more about prompt caching with Anthropic models [here](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching).

## Usage

To use prompt caching in your Agno setup, pass the `cache_system_prompt` argument when initializing the `Claude` model:

```python
from agno.agent import Agent
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(
        id="claude-3-5-sonnet-20241022",
        cache_system_prompt=True,
    ),
)
```

Notice that for prompt caching to work, the prompt needs to be of a certain length. You can read more about this on Anthropic's [docs](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching#cache-limitations).

## Extended cache

You can also use Anthropic's extended cache beta feature. This updates the cache duration from 5 minutes to 1 hour. To activate it, pass the `extended_cache_time` argument and the following beta header:

```python
from agno.agent import Agent
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(
        id="claude-3-5-sonnet-20241022",
        default_headers={"anthropic-beta": "extended-cache-ttl-2025-04-11"},
        cache_system_prompt=True,
        extended_cache_time=True,
    ),
)
```

## Working example

```python cookbook/models/anthropic/prompt_caching_extended.py
from pathlib import Path
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.utils.media import download_file

# Load an example large system message from S3. A large prompt like this would benefit from caching.
txt_path = Path(__file__).parent.joinpath("system_prompt.txt")
download_file(
    "https://agno-public.s3.amazonaws.com/prompts/system_promt.txt",
    str(txt_path),
)
system_message = txt_path.read_text()

agent = Agent(
    model=Claude(
        id="claude-sonnet-4-20250514",
        cache_system_prompt=True,  # Activate prompt caching for Anthropic to cache the system prompt
    ),
    system_message=system_message,
    markdown=True,
)

# First run - this will create the cache
response = agent.run(
    "Explain the difference between REST and GraphQL APIs with examples"
)
if response and response.metrics:
    print(f"First run cache write tokens = {response.metrics.cache_write_tokens}")

# Second run - this will use the cached system prompt
response = agent.run(
    "What are the key principles of clean code and how do I apply them in Python?"
)
if response and response.metrics:
    print(f"Second run cache read tokens = {response.metrics.cache_read_tokens}")
```


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/anthropic/structured_output



## Code

```python cookbook/models/anthropic/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.anthropic import Claude
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
run: RunOutput = movie_agent.run("New York")
pprint(run.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/anthropic/tool_use



## Code

```python cookbook/models/anthropic/tool_use.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="claude-sonnet-4-20250514"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Web Fetch
Source: https://docs.agno.com/examples/models/anthropic/web_fetch



## Code

```python cookbook/models/anthropic/web_fetch.py
from agno.agent import Agent
from agno.models.anthropic import Claude

agent = Agent(
    model=Claude(
        id="claude-opus-4-1-20250805",
        default_headers={"anthropic-beta": "web-fetch-2025-09-10"},
    ),
    tools=[
        {
            "type": "web_fetch_20250910",
            "name": "web_fetch",
            "max_uses": 5,
        }
    ],
    markdown=True,
)

agent.print_response(
    "Tell me more about https://en.wikipedia.org/wiki/Glacier_National_Park_(U.S.)",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/web_fetch.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/web_fetch.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/aws/bedrock/basic



## Code

```python cookbook/models/aws/bedrock/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.aws import AwsBedrock

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"), markdown=True
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/basic.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/aws/bedrock/basic_stream



## Code

```python cookbook/models/aws/bedrock/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.aws import AwsBedrock

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"), markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Image Input
Source: https://docs.agno.com/examples/models/aws/bedrock/image_agent



AWS Bedrock supports image input with models like `amazon.nova-pro-v1:0`. You can use this to analyze images and get information about them.

## Code

```python cookbook/models/aws/bedrock/image_agent.py
from pathlib import Path
from agno.agent import Agent
from agno.media import Image
from agno.models.aws import AwsBedrock
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=AwsBedrock(id="amazon.nova-pro-v1:0"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

# Read the image file content as bytes
with open(image_path, "rb") as img_file:
    image_bytes = img_file.read()

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(content=image_bytes, format="jpeg"),
    ],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 ddgs agno
    ```
  </Step>

  <Step title="Add an Image">
    Place an image file named `sample.jpg` in the same directory as your script.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/aws/bedrock/knowledge



## Code

```python cookbook/models/aws/bedrock/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.aws import AwsBedrock
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.add_content(
  url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"), markdown=True
    knowledge=knowledge_base,
    )
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 sqlalchemy pgvector pypdf openai psycopg agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/aws/bedrock/storage



## Code

```python cookbook/models/aws/bedrock/storage.py
from agno.agent import Agent
from agno.models.aws import AwsBedrock
from agno.db.postgres import PostgresDb
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"),
    db=PostgresDb(session_table="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 ddgs sqlalchemy psycopg agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/storage.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/aws/bedrock/structured_output



## Code

```python cookbook/models/aws/bedrock/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.aws import AwsBedrock
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
# movie_agent: RunOutput = movie_agent.run("New York")
# pprint(movie_agent.content)

movie_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/aws/bedrock/tool_use



## Code

```python cookbook/models/aws/bedrock/tool_use.py
from agno.agent import Agent
from agno.models.aws import AwsBedrock
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=AwsBedrock(id="mistral.mistral-large-2402-v1:0"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/aws/claude/basic



## Code

```python cookbook/models/aws/claude/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.aws import Claude

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"), markdown=True
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic[bedrock] agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/claude/basic.py
      ```

      ```bash Windows
      python cookbook/models/aws/claude/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/aws/claude/basic_stream



## Code

```python cookbook/models/aws/claude/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.aws import Claude

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"), markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic[bedrock] agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/claude/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/aws/claude/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/aws/claude/knowledge



## Code

```python cookbook/models/aws/claude/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.aws import Claude
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.add_content(
  url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20241022"),
    knowledge=knowledge_base,
    )
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic[bedrock] sqlalchemy pgvector pypdf openai psycopg agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/claude/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/aws/claude/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/aws/claude/storage



## Code

```python cookbook/models/aws/claude/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.aws import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install ddgs sqlalchemy anthropic agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/claude/db.py
      ```

      ```bash Windows
      python cookbook\models\aws\claude\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/aws/claude/structured_output



## Code

```python cookbook/models/aws/claude/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.aws import Claude
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
# movie_agent: RunOutput = movie_agent.run("New York")
# pprint(movie_agent.content)

movie_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic[bedrock] agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/claude/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/aws/claude/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/aws/claude/tool_use



## Code

```python cookbook/models/aws/claude/tool_use.py
from agno.agent import Agent
from agno.models.aws import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic[bedrock] ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/claude/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/aws/claude/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/azure/ai_foundry/basic



## Code

```python cookbook/models/azure/ai_foundry/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.azure import AzureAIFoundry

agent = Agent(model=AzureAIFoundry(id="Phi-4"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/ai_foundry/basic.py
      ```

      ```bash Windows
      python cookbook/models/azure/ai_foundry/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming
Source: https://docs.agno.com/examples/models/azure/ai_foundry/basic_stream



## Code

```python cookbook/models/azure/ai_foundry/basic_stream.py
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.azure import AzureAIFoundry

agent = Agent(
    model=AzureAIFoundry(
        id="Phi-4",
        azure_endpoint="",
    ),
    markdown=True,
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/ai_foundry/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/azure/ai_foundry/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge Base
Source: https://docs.agno.com/examples/models/azure/ai_foundry/knowledge



## Code

```python cookbook/models/azure/ai_foundry/knowledge.py
"""Run `pip install ddgs sqlalchemy pgvector pypdf openai` to install dependencies."""
import asyncio
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.azure import AzureAIFoundry
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
))

agent = Agent(
    model=AzureAIFoundry(id="Cohere-command-r-08-2024"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno ddgs sqlalchemy pgvector pypdf
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/ai_foundry/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/azure/ai_foundry/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/azure/ai_foundry/storage



## Code

```python cookbook/models/azure/ai_foundry/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.azure import AzureAIFoundry
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=AzureAIFoundry(id="Phi-4"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference ddgs sqlalchemy anthropic agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/ai_foundry/db.py
      ```

      ```bash Windows
      python cookbook/models/azure/ai_foundry/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/azure/ai_foundry/structured_output



## Code

```python cookbook/models/azure/ai_foundry/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.azure import AzureAIFoundry
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(
    model=AzureAIFoundry(id="gpt-5-mini"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
# run: RunOutput = agent.run("New York")
# pprint(run.content)

agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/ai_foundry/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/azure/ai_foundry/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/azure/ai_foundry/tool_use



## Code

```python cookbook/models/azure/ai_foundry/tool_use.py
from agno.agent import Agent
from agno.models.azure import AzureAIFoundry
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=AzureAIFoundry(id="Cohere-command-r-08-2024"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("What is currently happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_API_KEY=xxx
    export AZURE_ENDPOINT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U azure-ai-inference agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/ai_foundry/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/azure/ai_foundry/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/azure/openai/basic



## Code

```python cookbook/models/azure/openai/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.azure import AzureOpenAI

agent = Agent(model=AzureOpenAI(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/basic.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming
Source: https://docs.agno.com/examples/models/azure/openai/basic_stream



## Code

```python cookbook/models/azure/openai/basic_stream.py
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.azure import AzureOpenAI

agent = Agent(model=AzureOpenAI(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge Base
Source: https://docs.agno.com/examples/models/azure/openai/knowledge



## Code

```python cookbook/models/azure/openai/knowledge.py
import asyncio
from agno.agent import Agent
from agno.knowledge.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.azure import AzureOpenAI
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
# Add content to the knowledge
asyncio.run(knowledge.add_content_async(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
))

agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs sqlalchemy pgvector pypdf
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/azure/openai/storage



## Code

```python cookbook/models/azure/openai/db.py
"""Run `pip install ddgs sqlalchemy anthropic` to install dependencies."""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.azure import AzureOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy psycopg ddgs agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/db.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/azure/openai/structured_output



## Code

```python cookbook/models/azure/openai/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.azure import AzureOpenAI
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
run: RunOutput = agent.run("New York")
pprint(run.content)

# agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/azure/openai/tool_use



## Code

```python cookbook/models/azure/openai/tool_use.py
from agno.agent import Agent
from agno.models.azure import AzureOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=AzureOpenAI(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/cerebras/basic



## Code

```python cookbook/models/cerebras/basic.py
from agno.agent import Agent
from agno.models.cerebras import Cerebras

agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cerebras-cloud-sdk agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras/basic.py
      ```

      ```bash Windows
      python cookbook/models/cerebras/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/cerebras/basic_stream



## Code

```python cookbook/models/cerebras/basic_stream.py
from agno.agent import Agent  # noqa
from agno.models.cerebras import Cerebras

agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cerebras-cloud-sdk agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/cerebras/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge Base
Source: https://docs.agno.com/examples/models/cerebras/knowledge



## Code

```python cookbook/models/cerebras/basic_knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.cerebras import Cerebras
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Cerebras(id="llama-4-scout-17b-16e-instruct"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs sqlalchemy pgvector pypdf cerebras_cloud_sdk
    ```
  </Step>

  <Step title="Start your Postgres server">
    Ensure your Postgres server is running and accessible at the connection string used in `db_url`.
  </Step>

  <Step title="Run Agent (first time)">
    The first run will load and index the PDF. This may take a while.

    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras/basic_knowledge.py
      ```

      ```bash Windows
      python cookbook/models/cerebras/basic_knowledge.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Subsequent Runs">
    After the first run, comment out or remove `knowledge_base.load(recreate=True)` to avoid reloading the PDF each time.
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/cerebras/storage



## Code

```python cookbook/models/cerebras/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cerebras import Cerebras
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy cerebras_cloud_sdk agno
    ```
  </Step>

  <Step title="Start your Postgres server">
    Ensure your Postgres server is running and accessible at the connection string used in `db_url`.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras/db.py
      ```

      ```bash Windows
      python cookbook/models/cerebras/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/cerebras/structured_output



## Code

```python cookbook/models/cerebras/basic_json_schema.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.cerebras import Cerebras
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses a JSON schema output
json_schema_output_agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    description="You are a helpful assistant. Summarize the movie script based on the location in a JSON object.",
    output_schema=MovieScript,
)

json_schema_output_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cerebras-cloud-sdk agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras/basic_json_schema.py
      ```

      ```bash Windows
      python cookbook/models/cerebras/basic_json_schema.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/cerebras/tool_use



## Code

```python cookbook/models/cerebras/basic_tools.py
from agno.agent import Agent
from agno.models.cerebras import Cerebras
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cerebras-cloud-sdk agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras/basic_tools.py
      ```

      ```bash Windows
      python cookbook/models/cerebras/basic_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/cerebras_openai/basic



## Code

```python cookbook/models/cerebras_openai/basic.py
from agno.agent import Agent
from agno.models.cerebras import CerebrasOpenAI

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras_openai/basic.py
      ```

      ```bash Windows
      python cookbook/models/cerebras_openai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/cerebras_openai/basic_stream



## Code

```python cookbook/models/cerebras_openai/basic_stream.py
from agno.agent import Agent
from agno.models.cerebras import CerebrasOpenAI

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras_openai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/cerebras_openai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/cerebras_openai/knowledge



## Code

```python cookbook/models/cerebras_openai/knowledge.py

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.cerebras import CerebrasOpenAI
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"), knowledge=knowledge
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras_openai/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/cerebras_openai/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/cerebras_openai/storage



## Code

```python cookbook/models/cerebras_openai/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cerebras import CerebrasOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras_openai/db.py
      ```

      ```bash Windows
      python cookbook/models/cerebras_openai/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/cerebras_openai/structured_output



## Code

```python cookbook/models/cerebras_openai/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.cerebras import CerebrasOpenAI
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses a structured output
structured_output_agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    description="You are a helpful assistant. Summarize the movie script based on the location in a JSON object.",
    output_schema=MovieScript,
)

structured_output_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras_openai/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/cerebras_openai/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/cerebras_openai/tool_use



## Code

```python cookbook/models/cerebras_openai/basic_tools.py
from agno.agent import Agent
from agno.models.cerebras import CerebrasOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=CerebrasOpenAI(id="llama-4-scout-17b-16e-instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CEREBRAS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cerebras_openai/basic_tools.py
      ```

      ```bash Windows
      python cookbook/models/cerebras_openai/basic_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/cohere/basic



## Code

```python cookbook/models/cohere/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.cohere import Cohere

agent = Agent(model=Cohere(id="command-a-03-2025"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/basic.py
      ```

      ```bash Windows
      python cookbook/models/cohere/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/cohere/basic_stream



## Code

```python cookbook/models/cohere/basic_stream.py
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.cohere import Cohere

agent = Agent(model=Cohere(id="command-a-03-2025"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/cohere/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/cohere/image_agent



## Code

```python cookbook/models/cohere/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.cohere import Cohere

agent = Agent(
    model=Cohere(id="c4ai-aya-vision-8b"),
    markdown=True,
)

agent.print_response(
    "Tell me about this image.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/cohere/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/cohere/knowledge



## Code

```python cookbook/models/cohere/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.cohere import Cohere
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Cohere(id="command-a-03-2025"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/cohere/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/cohere/storage



## Code

```python cookbook/models/cohere/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.cohere import Cohere
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Cohere(id="command-a-03-2025"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy cohere agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/db.py
      ```

      ```bash Windows
      python cookbook/models/cohere/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/cohere/structured_output



## Code

```python cookbook/models/cohere/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.cohere import Cohere
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


structured_output_agent = Agent(
    model=Cohere(id="command-a-03-2025"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
response: RunOutput = structured_output_agent.run("New York")
pprint(response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/cohere/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/cohere/tool_use



## Code

```python cookbook/models/cohere/tool_use.py
from agno.agent import Agent
from agno.models.cohere import Cohere
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Cohere(id="command-a-03-2025"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/cohere/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/dashscope/basic



## Code

```python cookbook/models/dashscope/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.dashscope import DashScope

agent = Agent(model=DashScope(id="qwen-plus", temperature=0.5), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/basic.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent with Streaming
Source: https://docs.agno.com/examples/models/dashscope/basic_stream



## Code

```python cookbook/models/dashscope/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.dashscope import DashScope

agent = Agent(model=DashScope(id="qwen-plus", temperature=0.5), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/dashscope/image_agent



## Code

```python cookbook/models/dashscope/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.dashscope import DashScope
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=DashScope(id="qwen-vl-plus"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Analyze this image in detail and tell me what you see. Also search for more information about the subject.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent with Bytes
Source: https://docs.agno.com/examples/models/dashscope/image_agent_bytes



## Code

```python cookbook/models/dashscope/image_agent_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.dashscope import DashScope
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.media import download_image

agent = Agent(
    model=DashScope(id="qwen-vl-plus"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

download_image(
    url="https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",
    output_path=str(image_path),
)

# Read the image file content as bytes
image_bytes = image_path.read_bytes()

agent.print_response(
    "Analyze this image of an ant. Describe its features, species characteristics, and search for more information about this type of ant.",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/image_agent_bytes.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/image_agent_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output Agent
Source: https://docs.agno.com/examples/models/dashscope/structured_output



## Code

```python cookbook/models/dashscope/structured_output.py
from typing import List

from agno.agent import Agent
from agno.models.dashscope import DashScope
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that returns a structured output
structured_output_agent = Agent(
    model=DashScope(id="qwen-plus"),
    description="You write movie scripts and return them as structured JSON data.",
    output_schema=MovieScript,
)

structured_output_agent.print_response(
    "Create a movie script about llamas ruling the world. "
    "Return a JSON object with: name (movie title), setting, ending, genre, "
    "characters (list of character names), and storyline (3 sentences)."
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Thinking Agent
Source: https://docs.agno.com/examples/models/dashscope/thinking_agent



## Code

```python cookbook/models/dashscope/thinking_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.dashscope import DashScope

agent = Agent(
    model=DashScope(id="qvq-max", enable_thinking=True),
)

image_url = "https://img.alicdn.com/imgextra/i1/O1CN01gDEY8M1W114Hi3XcN_!!6000000002727-0-tps-1024-406.jpg"

agent.print_response(
    "How do I solve this problem? Please think through each step carefully.",
    images=[Image(url=image_url)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/thinking_agent.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/thinking_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/dashscope/tool_use



## Code

```python cookbook/models/dashscope/tool_use.py
from agno.agent import Agent
from agno.models.dashscope import DashScope
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=DashScope(id="qwen-plus"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("What's happening in AI today?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DASHSCOPE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/dashscope/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/dashscope/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/deepinfra/basic



## Code

```python cookbook/models/deepinfra/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.deepinfra import DeepInfra  # noqa


agent = Agent(
    model=DeepInfra(id="meta-llama/Llama-2-70b-chat-hf"),
    markdown=True,
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPINFRA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepinfra/basic.py
      ```

      ```bash Windows
      python cookbook/models/deepinfra/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/deepinfra/basic_stream



## Code

```python cookbook/models/deepinfra/basic_stream.py
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.deepinfra import DeepInfra  # noqa

agent = Agent(
    model=DeepInfra(id="meta-llama/Llama-2-70b-chat-hf"),
    markdown=True,
)

# Get the response in a variable
run_response: Iterator[RunOutputEvent] = agent.run(
    "Share a 2 sentence horror story", stream=True
)
for chunk in run_response:
    print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPINFRA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepinfra/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/deepinfra/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/deepinfra/structured_output



## Code

```python cookbook/models/deepinfra/json_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.deepinfra import DeepInfra  # noqa
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
agent = Agent(
    model=DeepInfra(id="microsoft/phi-4"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
# response: RunOutput = agent.run("New York")
# pprint(response.content)

agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPINFRA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepinfra/json_output.py
      ```

      ```bash Windows
      python cookbook/models/deepinfra/json_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/deepinfra/tool_use



## Code

```python cookbook/models/deepinfra/tool_use.py
from agno.agent import Agent  # noqa
from agno.models.deepinfra import DeepInfra  # noqa
from agno.tools.duckduckgo import DuckDuckGoTools  # noqa

agent = Agent(
    model=DeepInfra(id="meta-llama/Llama-2-70b-chat-hf"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPINFRA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepinfra/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/deepinfra/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/deepseek/basic



## Code

```python cookbook/models/deepseek/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.deepseek import DeepSeek

agent = Agent(model=DeepSeek(id="deepseek-chat"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/basic.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/deepseek/basic_stream



## Code

```python cookbook/models/deepseek/basic_stream.py
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.deepseek import DeepSeek

agent = Agent(model=DeepSeek(id="deepseek-chat"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/deepseek/structured_output



## Code

```python cookbook/models/deepseek/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.deepseek import DeepSeek
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=DeepSeek(id="deepseek-chat"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)

# Get the response in a variable
json_mode_response: RunOutput = json_mode_agent.run("New York")
pprint(json_mode_response.content)

# json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/deepseek/tool_use



## Code

```python cookbook/models/deepseek/tool_use.py
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=DeepSeek(id="deepseek-chat"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/fireworks/basic



## Code

```python cookbook/models/fireworks/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.fireworks import Fireworks

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    markdown=True,
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/basic.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/fireworks/basic_stream



## Code

```python cookbook/models/fireworks/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.fireworks import Fireworks

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    markdown=True,
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/fireworks/structured_output



## Code

```python cookbook/models/fireworks/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.fireworks import Fireworks
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
response: RunOutput = agent.run("New York")
pprint(response.content)

# agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/fireworks/tool_use



## Code

```python cookbook/models/fireworks/tool_use.py
from agno.agent import Agent
from agno.models.fireworks import Fireworks
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input (Bytes Content)
Source: https://docs.agno.com/examples/models/gemini/audio_input_bytes_content



## Code

```python cookbook/models/google/gemini/audio_input_bytes_content.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"

# Download the audio file from the URL as bytes
response = requests.get(url)
audio_content = response.content

agent.print_response(
    "Tell me about this audio",
    audio=[Audio(content=audio_content)],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai requests agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/audio_input_bytes_content.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/audio_input_bytes_content.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input (Upload the file)
Source: https://docs.agno.com/examples/models/gemini/audio_input_file_upload



## Code

```python cookbook/models/google/gemini/audio_input_file_upload.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

model = Gemini(id="gemini-2.0-flash-exp")
agent = Agent(
    model=model,
    markdown=True,
)

# Please download a sample audio file to test this Agent and upload using:
audio_path = Path(__file__).parent.joinpath("sample.mp3")
audio_file = None

remote_file_name = f"files/{audio_path.stem.lower()}"
try:
    audio_file = model.get_client().files.get(name=remote_file_name)
except Exception as e:
    print(f"Error getting file {audio_path.stem}: {e}")
    pass

if not audio_file:
    try:
        audio_file = model.get_client().files.upload(
            file=audio_path,
            config=dict(name=audio_path.stem, display_name=audio_path.stem),
        )
        print(f"Uploaded audio: {audio_file}")
    except Exception as e:
        print(f"Error uploading audio: {e}")

agent.print_response(
    "Tell me about this audio",
    audio=[Audio(content=audio_file)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/audio_input_file_upload.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/audio_input_file_upload.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input (Local file)
Source: https://docs.agno.com/examples/models/gemini/audio_input_local_file_upload



## Code

```python cookbook/models/google/gemini/audio_input_local_file_upload.py
from pathlib import Path
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

# Please download a sample audio file to test this Agent and upload using:
audio_path = Path(__file__).parent.joinpath("sample.mp3")

agent.print_response(
    "Tell me about this audio",
    audio=[Audio(filepath=audio_path)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/audio_input_local_file_upload.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/audio_input_local_file_upload.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/gemini/basic



## Code

```python cookbook/models/google/gemini/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-001"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/basic.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/gemini/basic_stream



## Code

```python cookbook/models/google/gemini/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-001"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Flash Thinking Agent
Source: https://docs.agno.com/examples/models/gemini/flash_thinking



## Code

```python cookbook/models/google/gemini/flash_thinking_agent.py
from agno.agent import Agent
from agno.models.google import Gemini

task = (
    "Three missionaries and three cannibals need to cross a river. "
    "They have a boat that can carry up to two people at a time. "
    "If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. "
    "How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram"
)

agent = Agent(model=Gemini(id="gemini-2.0-flash-thinking-exp-1219"), markdown=True)
agent.print_response(task, stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/flash_thinking_agent.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/flash_thinking_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Grounding
Source: https://docs.agno.com/examples/models/gemini/grounding



## Code

```python cookbook/models/google/gemini/grounding.py
"""Grounding with Gemini.

Grounding enables Gemini to search the web and provide responses backed by
real-time information with citations. This is a legacy tool - for Gemini 2.0+
models, consider using the 'search' parameter instead.

"""

from agno.agent import Agent
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash",
        grounding=True,
        grounding_dynamic_threshold=0.7,  # Optional: set threshold for grounding
    ),
    add_datetime_to_context=True,
)

# Ask questions that benefit from real-time information
agent.print_response(
    "What are the current market trends in renewable energy?",
    stream=True,
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/grounding.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/grounding.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Editing Agent
Source: https://docs.agno.com/examples/models/gemini/image_editing



## Code

```python cookbook/models/google/gemini/image_editing.py
from io import BytesIO

from agno.agent import Agent, RunOutput  # noqa
from agno.media import Image
from agno.models.google import Gemini
from PIL import Image as PILImage

# No system message should be provided (Gemini requires only the image)
agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash-exp-image-generation",
        response_modalities=["Text", "Image"],
    )
)

# Print the response in the terminal
response = agent.run(
    "Can you add a Llama in the background of this image?",
    images=[Image(filepath="tmp/test_photo.png")],
)

# Retrieve and display generated images using get_last_run_output
run_response = agent.get_last_run_output()
if run_response and isinstance(run_response, RunOutput) and run_response.images:
    for image_response in run_response.images:
        image_bytes = image_response.content
        if image_bytes:
            image = PILImage.open(BytesIO(image_bytes))
            image.show()
            # Save the image to a file
            # image.save("generated_image.png")
else:
    print("No images found in run response")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Prepare your image">
    Place an image file at `tmp/test_photo.png` or update the filepath in the code to point to your image.
  </Step>

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai pillow agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/image_editing.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/image_editing.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Generation Agent
Source: https://docs.agno.com/examples/models/gemini/image_generation



## Code

```python cookbook/models/google/gemini/image_generation.py
from io import BytesIO

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini
from PIL import Image

# No system message should be provided
agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash-exp-image-generation",
        response_modalities=["Text", "Image"],
    )
)

# Print the response in the terminal
run_response = agent.run("Make me an image of a cat in a tree.")

if run_response and isinstance(run_response, RunOutput) and run_response.images:
    for image_response in run_response.images:
        image_bytes = image_response.content
        if image_bytes:
            image = Image.open(BytesIO(image_bytes))
            image.show()
            # Save the image to a file
            # image.save("generated_image.png")
else:
    print("No images found in run response")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai pillow agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/image_generation.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/image_generation.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Generation Agent (Streaming)
Source: https://docs.agno.com/examples/models/gemini/image_generation_stream



## Code

```python cookbook/models/google/gemini/image_generation_stream.py
from io import BytesIO

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini
from PIL import Image

# No system message should be provided
agent = Agent(
    model=Gemini(
        id="gemini-2.0-flash-exp-image-generation",
        response_modalities=["Text", "Image"],
    )
)

# Print the response in the terminal
response = agent.run("Make me an image of a cat in a tree.", stream=True)

for chunk in response:
    if hasattr(chunk, "images") and chunk.images:  # type: ignore
        images = chunk.images  # type: ignore
        if images and isinstance(images, list):
            for image_response in images:
                image_bytes = image_response.content
                if image_bytes:
                    image = Image.open(BytesIO(image_bytes))
                    image.show()
                    # Save the image to a file
                    # image.save("generated_image.png")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai pillow agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/image_generation_stream.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/image_generation_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/gemini/image_input



## Code

```python cookbook/models/google/gemini/image_input.py
from agno.agent import Agent
from agno.media import Image
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/b/bf/Krakow_-_Kosciol_Mariacki.jpg"
        ),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/image_input.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/image_input.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent with File Upload
Source: https://docs.agno.com/examples/models/gemini/image_input_file_upload



## Code

```python cookbook/models/google/gemini/image_input_file_upload.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools
from google.generativeai import upload_file
from google.generativeai.types import file_types

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
# Please download the image using
# wget https://upload.wikimedia.org/wikipedia/commons/b/bf/Krakow_-_Kosciol_Mariacki.jpg
image_path = Path(__file__).parent.joinpath("Krakow_-_Kosciol_Mariacki.jpg")
image_file: file_types.File = upload_file(image_path)
print(f"Uploaded image: {image_file}")

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[Image(content=image_file)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Download the image">
    ```bash
    wget https://upload.wikimedia.org/wikipedia/commons/b/bf/Krakow_-_Kosciol_Mariacki.jpg
    ```
  </Step>

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/image_input_file_upload.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/image_input_file_upload.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Imagen Tool with OpenAI
Source: https://docs.agno.com/examples/models/gemini/imagen_tool



## Code

```python cookbook/models/google/gemini/imagen_tool.py
"""üîß Example: Using the GeminiTools Toolkit for Image Generation

Make sure you have set the GOOGLE_API_KEY environment variable.
Example prompts to try:
- "Create a surreal painting of a floating city in the clouds at sunset"
- "Generate a photorealistic image of a cozy coffee shop interior"
- "Design a cute cartoon mascot for a tech startup, vector style"
- "Create an artistic portrait of a cyberpunk samurai in a rainy city"

"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.gemini import GeminiTools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GeminiTools()],
)

response = agent.run(
    "Create an artistic portrait of a cyberpunk samurai in a rainy city",
)
if response and response.images:
    save_base64_data(str(response.images[0].content), "tmp/cyberpunk_samurai.png")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export GOOGLE_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/imagen_tool.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/imagen_tool.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Advanced Imagen Tool with Vertex AI
Source: https://docs.agno.com/examples/models/gemini/imagen_tool_advanced



## Code

```python cookbook/models/google/gemini/imagen_tool_advanced.py
"""üîß Example: Using the GeminiTools Toolkit for Image Generation

An Agent using the Gemini image generation tool.

Make sure to set the Vertex AI credentials. Here's the authentication guide: https://cloud.google.com/sdk/docs/initializing

"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.gemini import GeminiTools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        GeminiTools(
            image_generation_model="imagen-4.0-generate-preview-05-20", vertexai=True
        )
    ],
)

agent.print_response(
    "Cinematic a visual shot using a stabilized drone flying dynamically alongside a pod of immense baleen whales as they breach spectacularly in deep offshore waters. The camera maintains a close, dramatic perspective as these colossal creatures launch themselves skyward from the dark blue ocean, creating enormous splashes and showering cascades of water droplets that catch the sunlight. In the background, misty, fjord-like coastlines with dense coniferous forests provide context. The focus expertly tracks the whales, capturing their surprising agility, immense power, and inherent grace. The color palette features the deep blues and greens of the ocean, the brilliant white spray, the dark grey skin of the whales, and the muted tones of the distant wild coastline, conveying the thrilling magnificence of marine megafauna."
)
response = agent.get_last_run_output()
if response and response.images:
    save_base64_data(str(response.images[0].content), "tmp/baleen_whale.png")

"""
Example prompts to try:
- A horizontally oriented rectangular stamp features the Mission District's vibrant culture, portrayed in shades of warm terracotta orange using an etching style. The scene might depict a sun-drenched street like Valencia or Mission Street, lined with a mix of Victorian buildings and newer structures.
- Painterly landscape featuring a simple, isolated wooden cabin nestled amongst tall pine trees on the shore of a calm, reflective lake.
- Filmed cinematically from the driver's seat, offering a clear profile view of the young passenger on the front seat with striking red hair.
- A pile of books seen from above. The topmost book contains a watercolor illustration of a bird. VERTEX AI is written in bold letters on the book.
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up Vertex AI authentication">
    Follow the [authentication guide](https://cloud.google.com/sdk/docs/initializing) to set up Vertex AI credentials.

    ```bash
    gcloud auth application-default login
    ```
  </Step>

  <Step title="Set your API keys">
    ```bash
    export GOOGLE_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    export GOOGLE_CLOUD_PROJECT=your-project-id
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/imagen_tool_advanced.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/imagen_tool_advanced.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/gemini/knowledge



## Code

```python cookbook/models/google/gemini/knowledge.py
from agno.agent import Agent
from agno.knowledge.embedder.google import GeminiEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.google import Gemini
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=GeminiEmbedder(),
    ),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Gemini(id="gemini-2.0-flash-001"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai sqlalchemy pgvector pypdf openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with PDF Input (Local file)
Source: https://docs.agno.com/examples/models/gemini/pdf_input_local



## Code

```python cookbook/models/google/gemini/pdf_input_local.py
from pathlib import Path
from agno.agent import Agent
from agno.media import File
from agno.models.google import Gemini
from agno.utils.media import download_file

pdf_path = Path(__file__).parent.joinpath("ThaiRecipes.pdf")

# Download the file using the download_file function
download_file(
    "https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf", str(pdf_path)
)

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
    add_history_to_context=True,
)

agent.print_response(
    "Summarize the contents of the attached file.",
    files=[File(filepath=pdf_path)],
)
agent.print_response("Suggest me a recipe from the attached file.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/pdf_input_local.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/pdf_input_local.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with PDF Input (URL)
Source: https://docs.agno.com/examples/models/gemini/pdf_input_url



## Code

```python cookbook/models/google/gemini/pdf_input_url.py
from agno.agent import Agent
from agno.media import File
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file.",
    files=[File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf")],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/pdf_input_url.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/pdf_input_url.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/gemini/storage



## Code

```python cookbook/models/google/gemini/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai sqlalchemy psycopg ddgs agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/db.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/gemini/structured_output



## Code

```python cookbook/models/google/gemini/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


structured_output_agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

structured_output_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/gemini/tool_use



## Code

```python cookbook/models/google/gemini/tool_use.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-001"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with URL Context
Source: https://docs.agno.com/examples/models/gemini/url_context



## Code

```python cookbook/models/google/gemini/url_context.py
from agno.agent import Agent
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.5-flash", url_context=True),
    markdown=True,
)

url1 = "https://www.foodnetwork.com/recipes/ina-garten/perfect-roast-chicken-recipe-1940592"
url2 = "https://www.allrecipes.com/recipe/83557/juicy-roasted-chicken/"

agent.print_response(
    f"Compare the ingredients and cooking times from the recipes at {url1} and {url2}"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/url_context.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/url_context.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with URL Context and Search
Source: https://docs.agno.com/examples/models/gemini/url_context_with_search



## Code

```python cookbook/models/google/gemini/url_context_with_search.py
"""Combine URL context with Google Search for comprehensive web analysis.

"""

from agno.agent import Agent
from agno.models.google import Gemini

# Create agent with both Google Search and URL context enabled
agent = Agent(
    model=Gemini(id="gemini-2.5-flash", search=True, url_context=True),
    markdown=True,
)

# The agent will first search for relevant URLs, then analyze their content in detail
agent.print_response(
    "Analyze the content of the following URL: https://docs.agno.com/introduction and also give me latest updates on AI agents"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/url_context_with_search.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/url_context_with_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Vertex AI
Source: https://docs.agno.com/examples/models/gemini/vertexai



## Code

```python cookbook/models/google/gemini/vertexai.py
"""
To use Vertex AI, with the Gemini Model class, you need to set the following environment variables:

export GOOGLE_GENAI_USE_VERTEXAI="true"
export GOOGLE_CLOUD_PROJECT="your-project-id"
export GOOGLE_CLOUD_LOCATION="your-location"

Or you can set the following parameters in the `Gemini` class:

gemini = Gemini(
    vertexai=True,
    project_id="your-google-cloud-project-id",
    location="your-google-cloud-location",
)
"""

from agno.agent import Agent, RunOutput  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-001"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up Vertex AI">
    Set your environment variables:

    ```bash
    export GOOGLE_GENAI_USE_VERTEXAI="true"
    export GOOGLE_CLOUD_PROJECT="your-project-id"
    export GOOGLE_CLOUD_LOCATION="your-location"
    ```

    Or configure in code:

    ```python
    gemini = Gemini(
        vertexai=True,
        project_id="your-google-cloud-project-id",
        location="your-google-cloud-location",
    )
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/vertexai.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/vertexai.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Input (Bytes Content)
Source: https://docs.agno.com/examples/models/gemini/video_input_bytes_content



## Code

```python cookbook/models/google/gemini/video_input_bytes_content.py
import requests
from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://videos.pexels.com/video-files/5752729/5752729-uhd_2560_1440_30fps.mp4"

# Download the video file from the URL as bytes
response = requests.get(url)
video_content = response.content

agent.print_response(
    "Tell me about this video",
    videos=[Video(content=video_content)],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/video_input_bytes_content.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/video_input_bytes_content.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Input (File Upload)
Source: https://docs.agno.com/examples/models/gemini/video_input_file_upload



## Code

```python cookbook/models/google/gemini/video_input_file_upload.py
import time
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini
from agno.utils.log import logger

model = Gemini(id="gemini-2.0-flash-exp")
agent = Agent(
    model=model,
    markdown=True,
)

# Please download a sample video file to test this Agent
# Run: `wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4` to download a sample video
video_path = Path(__file__).parent.joinpath("samplevideo.mp4")
video_file = None
remote_file_name = f"files/{video_path.stem.lower().replace('_', '')}"
try:
    video_file = model.get_client().files.get(name=remote_file_name)
except Exception as e:
    logger.info(f"Error getting file {video_path.stem}: {e}")
    pass

# Upload the video file if it doesn't exist
if not video_file:
    try:
        logger.info(f"Uploading video: {video_path}")
        video_file = model.get_client().files.upload(
            file=video_path,
            config=dict(name=video_path.stem, display_name=video_path.stem),
        )

        # Check whether the file is ready to be used.
        while video_file.state.name == "PROCESSING":
            time.sleep(2)
            video_file = model.get_client().files.get(name=video_file.name)

        logger.info(f"Uploaded video: {video_file}")
    except Exception as e:
        logger.error(f"Error uploading video: {e}")

if __name__ == "__main__":
    agent.print_response(
        "Tell me about this video",
        videos=[Video(content=video_file)],
        stream=True,
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/video_input_file_upload.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/video_input_file_upload.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Input (Local File Upload)
Source: https://docs.agno.com/examples/models/gemini/video_input_local_file_upload



## Code

```python cookbook/models/google/gemini/video_input_local_file_upload.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

# Get sample videos from https://www.pexels.com/search/videos/sample/
video_path = Path(__file__).parent.joinpath("sample_video.mp4")

agent.print_response("Tell me about this video?", videos=[Video(filepath=video_path)])
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-genai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/video_input_local_file_upload.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/video_input_local_file_upload.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/groq/basic



## Code

```python cookbook/models/groq/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.3-70b-versatile"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/basic.py
      ```

      ```bash Windows
      python cookbook/models/groq/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/groq/basic_stream



## Code

```python cookbook/models/groq/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.3-70b-versatile"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/groq/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Browser Search Agent
Source: https://docs.agno.com/examples/models/groq/browser_search



## Code

```python cookbook/models/groq/browser_search.py
from agno.agent import Agent
from agno.models.groq import Groq

agent = Agent(
    model=Groq(id="openai/gpt-oss-20b"),
    tools=[{"type": "browser_search"}],
)
agent.print_response("Is the Going-to-the-sun road open for public?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/browser_search.py
      ```

      ```bash Windows
      python cookbook/models/groq/browser_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Deep Knowledge Agent
Source: https://docs.agno.com/examples/models/groq/deep_knowledge



## Code

```python cookbook/models/groq/deep_knowledge.py
"""ü§î DeepKnowledge - An AI Agent that iteratively searches a knowledge base to answer questions

This agent performs iterative searches through its knowledge base, breaking down complex
queries into sub-questions, and synthesizing comprehensive answers. It's designed to explore
topics deeply and thoroughly by following chains of reasoning.

In this example, the agent uses the Agno documentation as a knowledge base

Key Features:
- Iteratively searches a knowledge base
- Source attribution and citations
"""

from textwrap import dedent
from typing import List, Optional

import inquirer
import typer
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.vectordb.lancedb import LanceDb, SearchType
from rich import print


def initialize_knowledge_base():
    """Initialize the knowledge base with your preferred documentation or knowledge source
    Here we use Agno docs as an example, but you can replace with any relevant URLs
    """
    agent_knowledge = Knowledge(
        vector_db=LanceDb(
            uri="tmp/lancedb",
            table_name="deep_knowledge_knowledge",
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        ),
    )
    agent_knowledge.add_content(url="https://docs.agno.com/llms-full.txt")
    return agent_knowledge


def get_db():
    return SqliteDb(db_file="tmp/agents.db")


def create_agent(session_id: Optional[str] = None) -> Agent:
    """Create and return a configured DeepKnowledge agent."""
    agent_knowledge = initialize_knowledge_base()
    db = get_db()
    return Agent(
        name="DeepKnowledge",
        session_id=session_id,
        model=Groq(id="llama-3.3-70b-versatile"),
        description=dedent("""\
        You are DeepKnowledge, an advanced reasoning agent designed to provide thorough,
        well-researched answers to any query by searching your knowledge base.

        Your strengths include:
        - Breaking down complex topics into manageable components
        - Connecting information across multiple domains
        - Providing nuanced, well-researched answers
        - Maintaining intellectual honesty and citing sources
        - Explaining complex concepts in clear, accessible terms"""),
        instructions=dedent("""\
        Your mission is to leave no stone unturned in your pursuit of the correct answer.

        To achieve this, follow these steps:
        1. **Analyze the input and break it down into key components**.
        2. **Search terms**: You must identify at least 3-5 key search terms to search for.
        3. **Initial Search:** Searching your knowledge base for relevant information. You must make atleast 3 searches to get all relevant information.
        4. **Evaluation:** If the answer from the knowledge base is incomplete, ambiguous, or insufficient - Ask the user for clarification. Do not make informed guesses.
        5. **Iterative Process:**
            - Continue searching your knowledge base till you have a comprehensive answer.
            - Reevaluate the completeness of your answer after each search iteration.
            - Repeat the search process until you are confident that every aspect of the question is addressed.
        4. **Reasoning Documentation:** Clearly document your reasoning process:
            - Note when additional searches were triggered.
            - Indicate which pieces of information came from the knowledge base and where it was sourced from.
            - Explain how you reconciled any conflicting or ambiguous information.
        5. **Final Synthesis:** Only finalize and present your answer once you have verified it through multiple search passes.
            Include all pertinent details and provide proper references.
        6. **Continuous Improvement:** If new, relevant information emerges even after presenting your answer,
            be prepared to update or expand upon your response.

        **Communication Style:**
        - Use clear and concise language.
        - Organize your response with numbered steps, bullet points, or short paragraphs as needed.
        - Be transparent about your search process and cite your sources.
        - Ensure that your final answer is comprehensive and leaves no part of the query unaddressed.

        Remember: **Do not finalize your answer until every angle of the question has been explored.**"""),
        additional_context=dedent("""\
        You should only respond with the final answer and the reasoning process.
        No need to include irrelevant information.

        - User ID: {user_id}
        - Memory: You have access to your previous search results and reasoning process.
        """),
        knowledge=agent_knowledge,
        db=db,
        add_history_to_context=True,
        num_history_runs=3,
        read_chat_history=True,
        markdown=True,
    )


def get_example_topics() -> List[str]:
    """Return a list of example topics for the agent."""
    return [
        "What are AI agents and how do they work in Agno?",
        "What chunking strategies does Agno support for text processing?",
        "How can I implement custom tools in Agno?",
        "How does knowledge retrieval work in Agno?",
        "What types of embeddings does Agno support?",
    ]


def handle_session_selection() -> Optional[str]:
    """Handle session selection and return the selected session ID."""
    db = get_db()

    new = typer.confirm("Do you want to start a new session?", default=True)
    if new:
        return None

    existing_sessions = db.get_sessions()
    if not existing_sessions:
        print("No existing sessions found. Starting a new session.")
        return None

    print("\nExisting sessions:")
    for i, session in enumerate(existing_sessions, 1):
        print(f"{i}. {session.session_id}")  # type: ignore

    session_idx = typer.prompt(
        "Choose a session number to continue (or press Enter for most recent)",
        default=1,
    )

    try:
        return existing_sessions[int(session_idx) - 1].session_id  # type: ignore
    except (ValueError, IndexError):
        return existing_sessions[0].session_id  # type: ignore


def run_interactive_loop(agent: Agent):
    """Run the interactive question-answering loop."""
    example_topics = get_example_topics()

    while True:
        choices = [f"{i + 1}. {topic}" for i, topic in enumerate(example_topics)]
        choices.extend(["Enter custom question...", "Exit"])

        questions = [
            inquirer.List(
                "topic",
                message="Select a topic or ask a different question:",
                choices=choices,
            )
        ]
        answer = inquirer.prompt(questions)

        if answer and answer["topic"] == "Exit":
            break

        if answer and answer["topic"] == "Enter custom question...":
            questions = [inquirer.Text("custom", message="Enter your question:")]
            custom_answer = inquirer.prompt(questions)
            topic = custom_answer["custom"]  # type: ignore
        else:
            topic = example_topics[int(answer["topic"].split(".")[0]) - 1]  # type: ignore

        agent.print_response(topic, stream=True)


def deep_knowledge_agent():
    """Main function to run the DeepKnowledge agent."""

    session_id = handle_session_selection()
    agent = create_agent(session_id)

    print("\nü§î Welcome to DeepKnowledge - Your Advanced Research Assistant! üìö")
    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"[bold green]Started New Session: {session_id}[/bold green]\n")
        else:
            print("[bold green]Started New Session[/bold green]\n")
    else:
        print(f"[bold blue]Continuing Previous Session: {session_id}[/bold blue]\n")

    run_interactive_loop(agent)


if __name__ == "__main__":
    typer.run(deep_knowledge_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy inquirer agno groq
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/deep_knowledge.py
      ```

      ```bash Windows
      python cookbook/models/groq/deep_knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/groq/image_agent



## Code

```python cookbook/models/groq/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.groq import Groq

agent = Agent(model=Groq(id="meta-llama/llama-4-scout-17b-16e-instruct"))

agent.print_response(
    "Tell me about this image",
    images=[
        Image(url="https://upload.wikimedia.org/wikipedia/commons/f/f2/LPU-v1-die.jpg"),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/groq/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/groq/knowledge



## Code

```python cookbook/models/groq/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.groq import Groq
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    knowledge=knowledge,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy pgvector pypdf openai groq agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/groq/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Metrics
Source: https://docs.agno.com/examples/models/groq/metrics



## Code

```python cookbook/models/groq/metrics.py
from agno.agent import Agent, RunOutput
from agno.models.groq import Groq
from agno.tools.yfinance import YFinanceTools
from agno.utils.pprint import pprint_run_response
from rich.pretty import pprint

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    tools=[YFinanceTools(stock_price=True)],
    markdown=True,
)

run_output: RunOutput = agent.run("What is the stock price of NVDA")
pprint_run_response(run_output)

# Print metrics per message
if run_output.messages:
    for message in run_output.messages:  # type: ignore
        if message.role == "assistant":
            if message.content:
                print(f"Message: {message.content}")
            elif message.tool_calls:
                print(f"Tool calls: {message.tool_calls}")
            print("---" * 5, "Metrics", "---" * 5)
            pprint(message.metrics)
            print("---" * 20)

# Print the metrics
print("---" * 5, "Collected Metrics", "---" * 5)
pprint(run_output.metrics)  # type: ignore
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq yfinance agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/metrics.py
      ```

      ```bash Windows
      python cookbook/models/groq/metrics.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning Agent
Source: https://docs.agno.com/examples/models/groq/reasoning_agent



## Code

```python cookbook/models/groq/reasoning_agent.py
from agno.agent import Agent
from agno.models.groq import Groq

# Create a reasoning agent that uses:
# - `deepseek-r1-distill-llama-70b` as the reasoning model
# - `llama-3.3-70b-versatile` to generate the final response
reasoning_agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    reasoning_model=Groq(
        id="deepseek-r1-distill-llama-70b", temperature=0.6, max_tokens=1024, top_p=0.95
    ),
)

# Prompt the agent to solve the problem
reasoning_agent.print_response("Is 9.11 bigger or 9.9?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/reasoning_agent.py
      ```

      ```bash Windows
      python cookbook/models/groq/reasoning_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/groq/storage



## Code

```python cookbook/models/groq/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy groq agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/db.py
      ```

      ```bash Windows
      python cookbook/models/groq/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/groq/structured_output



## Code

```python cookbook/models/groq/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.groq import Groq
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)

# Get the response in a variable
run: RunOutput = json_mode_agent.run("New York")
pprint(run.content)

# json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/groq/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/groq/tool_use



## Code

```python cookbook/models/groq/tool_use.py
from agno.agent import Agent
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    tools=[DuckDuckGoTools(), Newspaper4kTools()],
    description="You are a senior NYT researcher writing an article on a topic.",
    instructions=[
        "For a given topic, search for the top 5 links.",
        "Then read each URL and extract the article text, if a URL isn't available, ignore it.",
        "Analyse and prepare an NYT worthy article based on the information.",
    ],
    markdown=True,
    add_datetime_to_context=True,
)
agent.print_response("Simulation theory", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq ddgs newspaper4k lxml_html_clean agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/groq/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Transcription Agent
Source: https://docs.agno.com/examples/models/groq/transcription_agent



## Code

```python cookbook/models/groq/transcription_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.groq import GroqTools

url = "https://agno-public.s3.amazonaws.com/demo_data/sample_conversation.wav"

agent = Agent(
    name="Groq Transcription Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GroqTools(exclude_tools=["generate_speech"])],
)

agent.print_response(f"Please transcribe the audio file located at '{url}' to English")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/transcription_agent.py
      ```

      ```bash Windows
      python cookbook/models/groq/transcription_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Translation Agent
Source: https://docs.agno.com/examples/models/groq/translation_agent



## Code

```python cookbook/models/groq/translation_agent.py
import base64
from pathlib import Path

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models.groq import GroqTools
from agno.utils.media import save_base64_data

path = "tmp/sample-fr.mp3"

agent = Agent(
    name="Groq Translation Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[GroqTools()],
    cache_session=True,
)

response = agent.run(
    f"Let's transcribe the audio file located at '{path}' and translate it to English. After that generate a new music audio file using the translated text."
)

if response and response.audio:
    base64_audio = base64.b64encode(response.audio[0].content).decode("utf-8")
    save_base64_data(base64_audio, Path("tmp/sample-en.mp3"))  # type: ignore
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/translation_agent.py
      ```

      ```bash Windows
      python cookbook/models/groq/translation_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic.Py
Source: https://docs.agno.com/examples/models/huggingface/async_basic



## Code

```python cookbook/models/huggingface/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="mistralai/Mistral-7B-Instruct-v0.2", max_tokens=4096, temperature=0
    ),
)
asyncio.run(
    agent.aprint_response(
        "What is meaning of life and then recommend 5 best books to read about it"
    )
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Stream.Py
Source: https://docs.agno.com/examples/models/huggingface/async_basic_stream



## Code

```python cookbook/models/huggingface/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="mistralai/Mistral-7B-Instruct-v0.2", max_tokens=4096, temperature=0
    ),
)
asyncio.run(
    agent.aprint_response(
        "What is meaning of life and then recommend 5 best books to read about it",
        stream=True,
    )
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/huggingface/basic



## Code

```python cookbook/models/huggingface/basic.py
from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="mistralai/Mistral-7B-Instruct-v0.2", max_tokens=4096, temperature=0
    ),
)
agent.print_response(
    "What is meaning of life and then recommend 5 best books to read about it"
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/basic.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/huggingface/basic_stream



## Code

```python cookbook/models/huggingface/basic_stream.py
from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="mistralai/Mistral-7B-Instruct-v0.2", max_tokens=4096, temperature=0
    ),
)
agent.print_response(
    "What is meaning of life and then recommend 5 best books to read about it",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Llama Essay Writer
Source: https://docs.agno.com/examples/models/huggingface/llama_essay_writer



## Code

```python cookbook/models/huggingface/llama_essay_writer.py
from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="meta-llama/Meta-Llama-3-8B-Instruct",
        max_tokens=4096,
    ),
    description="You are an essay writer. Write a 300 words essay on topic that will be provided by user",
)
agent.print_response("topic: AI")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/llama_essay_writer.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/llama_essay_writer.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use
Source: https://docs.agno.com/examples/models/huggingface/tool_use



## Code

```python cookbook/models/huggingface/tool_use.py
"""Please install dependencies using:
pip install openai ddgs newspaper4k lxml_html_clean agno
"""

from agno.agent import Agent
from agno.models.huggingface import HuggingFace
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=HuggingFace(id="Qwen/Qwen2.5-Coder-32B-Instruct"),
    tools=[DuckDuckGoTools()],
    description="You are a senior NYT researcher writing an article on a topic.",
    instructions=[
        "For a given topic, search for the top 5 links.",
        "Then read each URL and extract the article text, if a URL isn't available, ignore it.",
        "Analyse and prepare an NYT worthy article based on the information.",
    ],
    markdown=True,
    add_datetime_to_context=True,
)
agent.print_response("Simulation theory")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/ibm/async_basic



## Code

```python cookbook/models/ibm/watsonx/async_basic.py
import asyncio

from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(model=WatsonX(id="ibm/granite-20b-code-instruct"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/async_basic.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example shows how to use the asynchronous API of Agno with IBM WatsonX. It creates an agent and uses `asyncio.run()` to execute the asynchronous `aprint_response` method.


# Async Streaming Agent
Source: https://docs.agno.com/examples/models/ibm/async_basic_stream



## Code

```python cookbook/models/ibm/watsonx/async_basic_stream.py
import asyncio

from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(
    model=WatsonX(id="ibm/granite-20b-code-instruct"), debug_mode=True, markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example combines asynchronous execution with streaming. It creates an agent with `debug_mode=True` for additional logging and uses the asynchronous API with streaming to get and display responses as they're generated.


# Agent with Async Tool Usage
Source: https://docs.agno.com/examples/models/ibm/async_tool_use



## Code

```python cookbook/models/ibm/watsonx/async_tool_use.py
import asyncio

from agno.agent import Agent
from agno.models.ibm import WatsonX
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=WatsonX(id="meta-llama/llama-3-3-70b-instruct"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)

asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/async_tool_use.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/ibm/basic



## Code

```python cookbook/models/ibm/watsonx/basic.py
from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(model=WatsonX(id="ibm/granite-20b-code-instruct"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/basic.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example creates an agent using the IBM WatsonX model and prints a response directly to the terminal. The `markdown=True` parameter tells the agent to format the output as markdown, which can be useful for displaying rich text content.


# Streaming Basic Agent
Source: https://docs.agno.com/examples/models/ibm/basic_stream



## Code

```python cookbook/models/ibm/watsonx/basic_stream.py
from typing import Iterator
from agno.agent import Agent, RunOutput
from agno.models.ibm import WatsonX

agent = Agent(model=WatsonX(id="ibm/granite-20b-code-instruct"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/basic_stream.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example shows how to use streaming with IBM WatsonX. Setting `stream=True` when calling `print_response()` or `run()` enables token-by-token streaming, which can provide a more interactive user experience.


# Image Agent
Source: https://docs.agno.com/examples/models/ibm/image_agent_bytes



## Code

```python cookbook/models/ibm/watsonx/image_agent_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.ibm import WatsonX
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=WatsonX(id="meta-llama/llama-3-2-11b-vision-instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

# Read the image file content as bytes
with open(image_path, "rb") as img_file:
    image_bytes = img_file.read()

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai ddgs agno
    ```
  </Step>

  <Step title="Add sample image">
    Place a sample image named "sample.jpg" in the same directory as the script.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/image_agent_bytes.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\image_agent_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example shows how to use IBM WatsonX with vision capabilities. It loads an image from a file and passes it to the model along with a prompt. The model can then analyze the image and provide relevant information.

Note: This example uses a vision-capable model (`meta-llama/llama-3-2-11b-vision-instruct`) and requires a sample image file.


# RAG Agent
Source: https://docs.agno.com/examples/models/ibm/knowledge



## Code

```python cookbook/models/ibm/watsonx/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.ibm import WatsonX
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.add_content(
  url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=WatsonX(id="ibm/granite-20b-code-instruct"),
    knowledge=knowledge_base,
    )
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai sqlalchemy pgvector psycopg pypdf openai agno
    ```
  </Step>

  <Step title="Set up PostgreSQL with pgvector">
    You need a PostgreSQL database with the pgvector extension installed. Adjust the `db_url` in the code to match your database configuration.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/knowledge.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\knowledge.py
      ```
    </CodeGroup>
  </Step>

  <Step title="For subsequent runs">
    After the first run, comment out the `knowledge_base.load(recreate=True)` line to avoid reloading the PDF.
  </Step>
</Steps>

This example shows how to integrate a knowledge base with IBM WatsonX. It loads a PDF from a URL, processes it into a vector database (PostgreSQL with pgvector in this case), and then creates an agent that can query this knowledge base.

Note: You need to install several packages (`pgvector`, `pypdf`, etc.) and have a PostgreSQL database with the pgvector extension available.


# Agent with Storage
Source: https://docs.agno.com/examples/models/ibm/storage



## Code

```python cookbook/models/ibm/watsonx/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.ibm import WatsonX
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=WatsonX(id="mistralai/mistral-small-3-1-24b-instruct-2503"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs psycopg sqlalchemy ibm-watsonx-ai agno
    ```
  </Step>

  <Step title="Set up PostgreSQL">
    Make sure you have a PostgreSQL database running. You can adjust the `db_url` in the code to match your database configuration.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/db.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example shows how to use PostgreSQL storage with IBM WatsonX to maintain conversation state across multiple interactions. It creates an agent with a PostgreSQL storage backend and sends multiple messages, with the conversation history being preserved between them.

Note: You need to install the `sqlalchemy` package and have a PostgreSQL database available.


# Agent with Structured Output
Source: https://docs.agno.com/examples/models/ibm/structured_output



## Code

```python cookbook/models/ibm/watsonx/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.ibm import WatsonX
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=WatsonX(id="mistralai/mistral-small-3-1-24b-instruct-2503"),
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
# movie_agent: RunOutput = movie_agent.run("New York")
# pprint(movie_agent.content)

movie_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai pydantic rich agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/structured_output.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>

This example shows how to use structured output with IBM WatsonX. It defines a Pydantic model `MovieScript` with various fields and their descriptions, then creates an agent using this model as the `output_schema`. The model's output will be parsed into this structured format.


# Agent with Tools
Source: https://docs.agno.com/examples/models/ibm/tool_use



## Code

```python cookbook/models/ibm/watsonx/tool_use.py
from agno.agent import Agent
from agno.models.ibm import WatsonX
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=WatsonX(id="meta-llama/llama-3-3-70b-instruct"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export IBM_WATSONX_API_KEY=xxx
    export IBM_WATSONX_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ibm-watsonx-ai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ibm/watsonx/tool_use.py
      ```

      ```bash Windows
      python cookbook\models\ibm\watsonx\tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/langdb/basic



## Code

```python cookbook/models/langdb/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.langdb import LangDB

agent = Agent(model=LangDB(id="llama3-1-70b-instruct-v1.0"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LANGDB_API_KEY=xxx
    export LANGDB_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/langdb/basic.py
      ```

      ```bash Windows
      python cookbook/models/langdb/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming Agent
Source: https://docs.agno.com/examples/models/langdb/basic_stream



## Code

```python cookbook/models/langdb/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.langdb import LangDB

agent = Agent(
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    markdown=True,
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LANGDB_API_KEY=xxx
    export LANGDB_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/langdb/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/langdb/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Data Analyst Agent
Source: https://docs.agno.com/examples/models/langdb/data_analyst



## Code

```python cookbook/models/langdb/data_analyst.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.langdb import LangDB
from agno.tools.duckdb import DuckDbTools

duckdb_tools = DuckDbTools(
    create_tables=False, export_tables=False, summarize_tables=False
)
duckdb_tools.create_table_from_path(
    path="https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    table="movies",
)

agent = Agent(
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    tools=[duckdb_tools],
    markdown=True,
    additional_context=dedent("""\
    You have access to the following tables:
    - movies: contains information about movies from IMDB.
    """),
)
agent.print_response("What is the average rating of movies?", stream=False)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LANGDB_API_KEY=xxx
    export LANGDB_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno duckdb
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/langdb/data_analyst.py
      ```

      ```bash Windows
      python cookbook/models/langdb/data_analyst.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/langdb/structured_output



## Code

```python cookbook/models/langdb/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.langdb import LangDB
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)


# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")
structured_output_agent.print_response("New York")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LANGDB_API_KEY=xxx
    export LANGDB_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/langdb/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/langdb/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Web Search Agent
Source: https://docs.agno.com/examples/models/langdb/tool_use



## Code

```python cookbook/models/langdb/web_search.py
from agno.agent import Agent
from agno.models.langdb import LangDB
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LangDB(id="llama3-1-70b-instruct-v1.0"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LANGDB_API_KEY=xxx
    export LANGDB_PROJECT_ID=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/langdb/web_search.py
      ```

      ```bash Windows
      python cookbook/models/langdb/web_search.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/litellm/async_basic



## Code

```python cookbook/models/litellm/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.litellm import LiteLLM

openai_agent = Agent(
    model=LiteLLM(
        id="gpt-5-mini",
        name="LiteLLM",
    ),
    markdown=True,
)

asyncio.run(openai_agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/litellm/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Streaming Agent
Source: https://docs.agno.com/examples/models/litellm/async_basic_stream



## Code

```python cookbook/models/litellm/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.litellm import LiteLLM

openai_agent = Agent(
    model=LiteLLM(
        id="gpt-5-mini",
        name="LiteLLM",
    ),
    markdown=True,
)

# Print the response in the terminal
asyncio.run(
    openai_agent.aprint_response("Share a 2 sentence horror story", stream=True)
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/litellm/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Tool Use
Source: https://docs.agno.com/examples/models/litellm/async_tool_use



## Code

```python cookbook/models/litellm/async_tool_use.py
import asyncio

from agno.agent import Agent
from agno.models.litellm import LiteLLM
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LiteLLM(
        id="gpt-5-mini",
        name="LiteLLM",
    ),
    markdown=True,
    tools=[DuckDuckGoTools()],
)

# Ask a question that would likely trigger tool use
asyncio.run(agent.aprint_response("What is happening in France?"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/litellm/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input Agent
Source: https://docs.agno.com/examples/models/litellm/audio_input_agent



## Code

```python cookbook/models/litellm/audio_input_agent.py
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.litellm import LiteLLM

# Fetch the QA audio file and convert it to a base64 encoded string
url = "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/QA-01.mp3"
response = requests.get(url)
response.raise_for_status()
mp3_data = response.content

# Audio input requires specific audio-enabled models like gpt-5-mini-audio-preview
agent = Agent(
    model=LiteLLM(id="gpt-5-mini-audio-preview"),
    markdown=True,
)
agent.print_response(
    "What's the audio about?",
    audio=[Audio(content=mp3_data, format="mp3")],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/audio_input_agent.py
      ```

      ```bash Windows
      python cookbook/models/litellm/audio_input_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/litellm/basic



## Code

```python cookbook/models/litellm/basic.py
from agno.agent import Agent
from agno.models.litellm import LiteLLM

openai_agent = Agent(
    model=LiteLLM(
        id="huggingface/mistralai/Mistral-7B-Instruct-v0.2",
        top_p=0.95,
    ),
    markdown=True,
)

openai_agent.print_response("Whats happening in France?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/basic.py
      ```

      ```bash Windows
      python cookbook/models/litellm/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/litellm/basic_stream



## Code

```python cookbook/models/litellm/basic_stream.py
from agno.agent import Agent
from agno.models.litellm import LiteLLM

openai_agent = Agent(
    model=LiteLLM(
        id="gpt-5-mini",
        name="LiteLLM",
    ),
    markdown=True,
)

openai_agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/litellm/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/litellm/knowledge



## Code

```python cookbook/models/litellm/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.litellm import LiteLLM
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=LiteLLM(id="gpt-5-mini"),
    knowledge=knowledge_base,
    )
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm openai agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/litellm/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/litellm/storage



## Code

```python cookbook/models/litellm/db.py
from agno.agent import Agent
from agno.models.litellm import LiteLLM
from agno.db.sqlite import SqliteDb
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db = SqliteDb(
    db_file="tmp/data.db",
)

# Add storage to the Agent
agent = Agent(
    model=LiteLLM(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)

agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm ddgs openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/db.py
      ```

      ```bash Windows
      python cookbook\models\litellm\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/litellm/structured_output



## Code

```python cookbook/models/litellm/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.litellm import LiteLLM
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=LiteLLM(id="gpt-5-mini"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    debug_mode=True,
)

json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/litellm/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/litellm/tool_use



## Code

```python cookbook/models/litellm/tool_use.py
from agno.agent import Agent
from agno.models.litellm import LiteLLM
from agno.tools.duckduckgo import DuckDuckGoTools

openai_agent = Agent(
    model=LiteLLM(
        id="gpt-5-mini",
        name="LiteLLM",
    ),
    markdown=True,
    tools=[DuckDuckGoTools()],
)

# Ask a question that would likely trigger tool use
openai_agent.print_response("What is happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm openai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/litellm/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/litellm_openai/basic



Make sure to start the proxy server:

```shell
litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
```

## Code

```python cookbook/models/litellm_openai/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.litellm import LiteLLMOpenAI

agent = Agent(model=LiteLLMOpenAI(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm[proxy] openai agno
    ```
  </Step>

  <Step title="Start the proxy server">
    ```bash
    litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm_openai/basic.py
      ```

      ```bash Windows
      python cookbook/models/litellm_openai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/litellm_openai/basic_stream



Make sure to start the proxy server:

```shell
litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
```

## Code

```python cookbook/models/litellm_openai/basic_stream.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.litellm import LiteLLMOpenAI

agent = Agent(model=LiteLLMOpenAI(id="gpt-5-mini"), markdown=True)

agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm[proxy] openai agno
    ```
  </Step>

  <Step title="Start the proxy server">
    ```bash
    litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/litellm/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/litellm_openai/tool_use



Make sure to start the proxy server:

```shell
litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
```

## Code

```python cookbook/models/litellm_openai/tool_use.py
from agno.agent import Agent
from agno.models.litellm import LiteLLMOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LiteLLMOpenAI(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LITELLM_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U litellm[proxy] openai agno ddgs
    ```
  </Step>

  <Step title="Start the proxy server">
    ```bash
    litellm --model gpt-5-mini --host 127.0.0.1 --port 4000
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/litellm_openai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/litellm_openai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic
Source: https://docs.agno.com/examples/models/llama_cpp/basic



## Code

```python cookbook/models/llama_cpp/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.llama_cpp import LlamaCpp

agent = Agent(model=LlamaCpp(id="ggml-org/gpt-oss-20b-GGUF"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LlamaCpp">
    Follow the [LlamaCpp installation guide](https://github.com/ggerganov/llama.cpp) and start the server:

    ```bash
    llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/llama_cpp/basic.py
      ```

      ```bash Windows
      python cookbook/models/llama_cpp/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Stream
Source: https://docs.agno.com/examples/models/llama_cpp/basic_stream



## Code

```python cookbook/models/llama_cpp/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.llama_cpp import LlamaCpp

agent = Agent(model=LlamaCpp(id="ggml-org/gpt-oss-20b-GGUF"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LlamaCpp">
    Follow the [LlamaCpp installation guide](https://github.com/ggerganov/llama.cpp) and start the server:

    ```bash
    llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/llama_cpp/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/llama_cpp/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/llama_cpp/structured_output



## Code

```python cookbook/models/llama_cpp/structured_output.py
from typing import List

from agno.agent import Agent
from agno.models.llama_cpp import LlamaCpp
from agno.run.agent import RunOutput
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that returns a structured output
structured_output_agent = Agent(
    model=LlamaCpp(id="ggml-org/gpt-oss-20b-GGUF"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Run the agent synchronously
structured_output_response: RunOutput = structured_output_agent.run("New York")
pprint(structured_output_response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LlamaCpp">
    Follow the [LlamaCpp installation guide](https://github.com/ggerganov/llama.cpp) and start the server:

    ```bash
    llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U pydantic rich agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/llama_cpp/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/llama_cpp/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/llama_cpp/tool_use



## Code

```python cookbook/models/llama_cpp/tool_use.py
"""Run `pip install ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.llama_cpp import LlamaCpp
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LlamaCpp(id="ggml-org/gpt-oss-20b-GGUF"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LlamaCpp">
    Follow the [LlamaCpp installation guide](https://github.com/ggerganov/llama.cpp) and start the server:

    ```bash
    llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/llama_cpp/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/llama_cpp/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools Stream
Source: https://docs.agno.com/examples/models/llama_cpp/tool_use_stream



## Code

```python cookbook/models/llama_cpp/tool_use_stream.py
"""Run `pip install ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.llama_cpp import LlamaCpp
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LlamaCpp(id="ggml-org/gpt-oss-20b-GGUF"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LlamaCpp">
    Follow the [LlamaCpp installation guide](https://github.com/ggerganov/llama.cpp) and start the server:

    ```bash
    llama-server -hf ggml-org/gpt-oss-20b-GGUF --ctx-size 0 --jinja -ub 2048 -b 2048
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/llama_cpp/tool_use_stream.py
      ```

      ```bash Windows
      python cookbook/models/llama_cpp/tool_use_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/lmstudio/basic



## Code

```python cookbook/models/lmstudio/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.lmstudio import LMStudio

agent = Agent(model=LMStudio(id="qwen2.5-7b-instruct-1m"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">`bash pip install -U agno `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/basic.py
      ```

      ```bash Windows
      python cookbook/models/lmstudio/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/lmstudio/basic_stream



## Code

```python cookbook/models/lmstudio/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.lmstudio import LMStudio

agent = Agent(model=LMStudio(id="qwen2.5-7b-instruct-1m"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">`bash pip install -U agno `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/lmstudio/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/lmstudio/image_agent



## Code

```python cookbook/models/lmstudio/image_agent.py
import httpx

from agno.agent import Agent
from agno.media import Image
from agno.models.lmstudio import LMStudio

agent = Agent(
    model=LMStudio(id="llama3.2-vision"),
    markdown=True,
)

response = httpx.get(
    "https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
)

agent.print_response(
    "Tell me about this image",
    images=[Image(content=response.content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">`bash pip install -U agno `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/lmstudio/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/lmstudio/knowledge



## Code

```python cookbook/models/lmstudio/knowledge.py
from agno.agent import Agent
from agno.knowledge.embedder.ollama import OllamaEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.lmstudio import LMStudio
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=OllamaEmbedder(id="llama3.2", dimensions=3072),
    ),
)
knowledge_base.add_content(
  url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=LMStudio(id="qwen2.5-7b-instruct-1m"),
    knowledge=knowledge_base,
    )
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/lmstudio/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/lmstudio/storage



## Code

```python cookbook/models/lmstudio/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.lmstudio import LMStudio
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=LMStudio(id="qwen2.5-7b-instruct-1m"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy psycopg ddgs agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/db.py
      ```

      ```bash Windows
      python cookbook\models\lmstudio\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/lmstudio/structured_output



## Code

```python cookbook/models/lmstudio/structured_output.py
import asyncio
from typing import List

from agno.agent import Agent
from agno.models.lmstudio import LMStudio
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that returns a structured output
structured_output_agent = Agent(
    model=LMStudio(id="qwen2.5-7b-instruct-1m"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Run the agent synchronously
structured_output_agent.print_response("
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/lmstudio/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/lmstudio/tool_use



## Code

```python cookbook/models/lmstudio/tool_use.py
from agno.agent import Agent
from agno.models.lmstudio import LMStudio
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=LMStudio(id="qwen2.5-7b-instruct-1m"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install LM Studio">
    Install LM Studio from [here](https://lmstudio.ai/download) and download the
    model you want to use.
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/lmstudio/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/lmstudio/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Asynchronous Agent
Source: https://docs.agno.com/examples/models/meta/async_basic



## Code

```python cookbook/models/meta/llama/async_basic.py
import asyncio

from agno.agent import Agent, RunOutput  # noqa
from agno.models.meta import Llama

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"),
    markdown=True
)

# Get the response in a variable
# run: RunOutput = asyncio.run(agent.arun("Share a 2 sentence horror story"))
# print(run.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/llama/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/meta/llama/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Asynchronous Streaming Agent
Source: https://docs.agno.com/examples/models/meta/async_stream



## Code

```python cookbook/models/meta/llama/async_basic_stream.py
import asyncio
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutput  # noqa
from agno.models.meta import Llama

agent = Agent(model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = asyncio.run(agent.arun("Share a 2 sentence horror story", stream=True))
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/async_stream.py
      ```

      ```bash Windows
      python cookbook/models/meta/async_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Async Tool Usage
Source: https://docs.agno.com/examples/models/meta/async_tool_use



## Code

```python cookbook/models/meta/llama/async_tool_use.py
"""Run `pip install agno llama-api-client` to install dependencies."""

import asyncio

from agno.agent import Agent
from agno.models.meta import Llama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"),
    tools=[DuckDuckGoTools()],
    debug_mode=True,
)
asyncio.run(agent.aprint_response("Whats happening in UK and in USA?"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/meta/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/meta/basic



## Code

```python cookbook/models/meta/llama/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.meta import Llama

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"),
    markdown=True,
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/llama/basic.py
      ```

      ```bash Windows
      python cookbook/models/meta/llama/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/meta/basic_stream



## Code

```python cookbook/models/meta/llama/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.meta import Llama

agent = Agent(model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/llama/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/meta/llama/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Asynchronous Agent with Image Input
Source: https://docs.agno.com/examples/models/meta/image_input_bytes



## Code

```python cookbook/models/meta/llama/image_input_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.meta import LlamaOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.media import download_image

agent = Agent(
    model=LlamaOpenAI(id="Llama-4-Maverick-17B-128E-Instruct-FP8"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

download_image(
    url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg",
    output_path=str(image_path),
)

# Read the image file content as bytes
image_bytes = image_path.read_bytes()

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/async_image_input.py
      ```

      ```bash Windows
      python cookbook/models/meta/async_image_input.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent With Knowledge
Source: https://docs.agno.com/examples/models/meta/knowledge



## Code

```python cookbook/models/meta/llama/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.meta import Llama
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"), knowledge=knowledge
)
agent.print_response("How to make Thai curry?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install ddgs sqlalchemy pgvector pypdf llama-api-client
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python python cookbook/models/meta/llama/knowledge.py
      ```

      ```bash Windows
      python python cookbook/models/meta/llama/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Memory
Source: https://docs.agno.com/examples/models/meta/memory



## Code

```python cookbook/models/meta/llama/memory.py

from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.postgres import PostgresDb
from agno.models.meta import Llama
from rich.pretty import pprint

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"),
    user_id="test_user",
    session_id="test_session",
    # Pass the database to the Agent
    db=db,
    # Enable user memories
    enable_user_memories=True,
    # Enable session summaries
    enable_session_summaries=True,
    # Show debug logs so, you can see the memory being created
    debug_mode=True,
)

# -*- Share personal information
agent.print_response("My name is John Billings", stream=True)

# -*- Print memories and session summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.db.get_session(
            session_id="test_session", session_type=SessionType.AGENT
        ).summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I live in NYC", stream=True)
# -*- Print memories and session summary
if agent.db:
    pprint(agent.db.get_user_memories(user_id="test_user"))
    pprint(
        agent.db.get_session(
            session_id="test_session", session_type=SessionType.AGENT
        ).summary  # type: ignore
    )


# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)


```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install openai sqlalchemy psycopg pgvector llama-api-client
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python python cookbook/models/meta/llama/memory.py
      ```

      ```bash Windows
      python python cookbook/models/meta/llama/memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/meta/structured_output



## Code

```python cookbook/models/meta/llama/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.meta import Llama
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses a JSON schema output
agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8", temperature=0.1),
    output_schema=MovieScript,
)

agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/meta/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/meta/tool_use



## Code

```python cookbook/models/meta/llama/tool_use.py
"""Run `pip install agno llama-api-client` to install dependencies."""

from agno.agent import Agent
from agno.models.meta import Llama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Llama(id="Llama-4-Maverick-17B-128E-Instruct-FP8"),
    tools=[YFinanceTools()],
)
agent.print_response("Whats happening in UK and in USA?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your LLAMA API key">
    ```bash
    export LLAMA_API_KEY=YOUR_API_KEY
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install llama-api-client ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/meta/llama/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/meta/llama/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/mistral/async_basic



## Code

```python cookbook/models/mistral/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.mistral.mistral import MistralChat

agent = Agent(
    model=MistralChat(id="mistral-large-latest"),
    markdown=True,
)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/mistral/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Streaming Agent
Source: https://docs.agno.com/examples/models/mistral/async_basic_stream



## Code

```python cookbook/models/mistral/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.mistral.mistral import MistralChat

agent = Agent(
    model=MistralChat(id="mistral-large-latest"),
    markdown=True,
)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/mistral/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Structured Output Agent
Source: https://docs.agno.com/examples/models/mistral/async_structured_output



## Code

```python cookbook/models/mistral/async_structured_output.py
import asyncio
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(
    model=MistralChat(
        id="mistral-small-latest",
    ),
    tools=[DuckDuckGoTools()],
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

asyncio.run(agent.aprint_response("Find a cool movie idea about London and write it."))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/async_structured_output.py
      ```

      ```bash Windows
      python cookbook/models/mistral/async_structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Tools
Source: https://docs.agno.com/examples/models/mistral/async_tool_use



## Code

```python cookbook/models/mistral/async_tool_use.py
import asyncio

from agno.agent import Agent
from agno.models.mistral.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=MistralChat(id="mistral-large-latest"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/mistral/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/mistral/basic



## Code

```python cookbook/models/mistral/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.mistral import MistralChat


agent = Agent(
    model=MistralChat(id="mistral-small-latest"),
    markdown=True,
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/basic.py
      ```

      ```bash Windows
      python cookbook/models/mistral/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming Agent
Source: https://docs.agno.com/examples/models/mistral/basic_stream



## Code

```python cookbook/models/mistral/basic_stream.py
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.mistral import MistralChat

agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
    ),
    markdown=True,
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/mistral/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Bytes Input Agent
Source: https://docs.agno.com/examples/models/mistral/image_bytes_input_agent



## Code

```python cookbook/models/mistral/image_bytes_input_agent.py
import requests
from agno.agent import Agent
from agno.media import Image
from agno.models.mistral.mistral import MistralChat

agent = Agent(
    model=MistralChat(id="pixtral-12b-2409"),
    markdown=True,
)

image_url = (
    "https://tripfixers.com/wp-content/uploads/2019/11/eiffel-tower-with-snow.jpeg"
)


def fetch_image_bytes(url: str) -> bytes:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
    }
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    return response.content


image_bytes_from_url = fetch_image_bytes(image_url)

agent.print_response(
    "Tell me about this image.",
    images=[
        Image(content=image_bytes_from_url),
    ],
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/image_bytes_input_agent.py
      ```

      ```bash Windows
      python cookbook/models/mistral/image_bytes_input_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Compare Agent
Source: https://docs.agno.com/examples/models/mistral/image_compare_agent



## Code

```python cookbook/models/mistral/image_compare_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.mistral.mistral import MistralChat

agent = Agent(
    model=MistralChat(id="pixtral-12b-2409"),
    markdown=True,
)

agent.print_response(
    "what are the differences between two images?",
    images=[
        Image(
            url="https://tripfixers.com/wp-content/uploads/2019/11/eiffel-tower-with-snow.jpeg"
        ),
        Image(
            url="https://assets.visitorscoverage.com/production/wp-content/uploads/2024/04/AdobeStock_626542468-min-1024x683.jpeg"
        ),
    ],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/image_compare_agent.py
      ```

      ```bash Windows
      python cookbook/models/mistral/image_compare_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image File Input Agent
Source: https://docs.agno.com/examples/models/mistral/image_file_input_agent



## Code

```python cookbook/models/mistral/image_file_input_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.mistral.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=MistralChat(id="pixtral-12b-2409"),
    tools=[
        DuckDuckGoTools()
    ],  # pixtral-12b-2409 is not so great at tool calls, but it might work.
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpeg")

agent.print_response(
    "Tell me about this image and give me the latest news about it from duckduckgo.",
    images=[
        Image(filepath=image_path),
    ],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/image_file_input_agent.py
      ```

      ```bash Windows
      python cookbook/models/mistral/image_file_input_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Ocr With Structured Output
Source: https://docs.agno.com/examples/models/mistral/image_ocr_with_structured_output



## Code

```python cookbook/models/mistral/image_ocr_with_structured_output.py
from typing import List

from agno.agent import Agent
from agno.media import Image
from agno.models.mistral.mistral import MistralChat
from pydantic import BaseModel


class GroceryItem(BaseModel):
    item_name: str
    price: float


class GroceryListElements(BaseModel):
    bill_number: str
    items: List[GroceryItem]
    total_price: float


agent = Agent(
    model=MistralChat(id="pixtral-12b-2409"),
    instructions=[
        "Extract the text elements described by the user from the picture",
    ],
    output_schema=GroceryListElements,
    markdown=True,
)

agent.print_response(
    "From this restaurant bill, extract the bill number, item names and associated prices, and total price and return it as a string in a Json object",
    images=[Image(url="https://i.imghippo.com/files/kgXi81726851246.jpg")],
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/image_ocr_with_structured_output.py
      ```

      ```bash Windows
      python cookbook/models/mistral/image_ocr_with_structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Transcribe Document Agent
Source: https://docs.agno.com/examples/models/mistral/image_transcribe_document_agent



## Code

```python cookbook/models/mistral/image_transcribe_document_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.mistral.mistral import MistralChat

agent = Agent(
    model=MistralChat(id="pixtral-12b-2409"),
    markdown=True,
)

agent.print_response(
    "Transcribe this document.",
    images=[
        Image(url="https://ciir.cs.umass.edu/irdemo/hw-demo/page_example.jpg"),
    ],
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/image_transcribe_document_agent.py
      ```

      ```bash Windows
      python cookbook/models/mistral/image_transcribe_document_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Memory
Source: https://docs.agno.com/examples/models/mistral/memory



## Code

```python cookbook/models/mistral/memory.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.mistral.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
# Setup the database
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=MistralChat(id="mistral-large-latest"),
    tools=[DuckDuckGoTools()],
    # Pass the database to the Agent
    db=db,
    # Enable user memories
    enable_user_memories=True,
    # Enable session summaries
    enable_session_summaries=True,
    # Show debug logs so, you can see the memory being created
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)

# -*- Make tool call
agent.print_response("What is the weather in nyc?", stream=True)

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs sqlalchemy psycopg pgvector
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/memory.py
      ```

      ```bash Windows
      python cookbook/models/mistral/memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Mistral Small
Source: https://docs.agno.com/examples/models/mistral/mistral_small



## Code

```python cookbook/models/mistral/mistral_small.py
from agno.agent import Agent
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=MistralChat(id="mistral-small-latest"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Tell me about mistrall small, any news", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/mistral_small.py
      ```

      ```bash Windows
      python cookbook/models/mistral/mistral_small.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/mistral/structured_output



## Code

```python cookbook/models/mistral/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


structured_output_agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
    ),
    tools=[DuckDuckGoTools()],
    description="You help people write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
structured_output_response: RunOutput = structured_output_agent.run("New York")
pprint(structured_output_response.content)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/mistral/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output With Tool Use
Source: https://docs.agno.com/examples/models/mistral/structured_output_with_tool_use



## Code

```python cookbook/models/mistral/structured_output_with_tool_use.py
from agno.agent import Agent
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools
from pydantic import BaseModel


class Person(BaseModel):
    name: str
    description: str


model = MistralChat(
    id="mistral-medium-latest",
    temperature=0.0,
)

researcher = Agent(
    name="Researcher",
    model=model,
    role="You find people with a specific role at a provided company.",
    instructions=[
        "- Search the web for the person described"
        "- Find out if they have public contact details"
        "- Return the information in a structured format"
    ],
    tools=[DuckDuckGoTools()],
    output_schema=Person,
    add_datetime_to_context=True,
)

researcher.print_response("Find information about Elon Musk")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/structured_output_with_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/mistral/structured_output_with_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/mistral/tool_use



## Code

```python cookbook/models/mistral/tool_use.py
"""Run `pip install ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
    ),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/mistral/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/nebius/basic



## Code

```python cookbook/models/nebius/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.nebius import Nebius

agent = Agent(
    model=Nebius(),
        markdown=True,
    debug_mode=True,
)

# Get the response in a variable
# run: RunOutput = agent.run("write a two sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("write a two sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
        export NEBIUS_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
        pip install -U openai agno 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nebius/basic.py
      ```

      ```bash Windows
      python cookbook/models/nebius/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/nebius/basic_stream



## Code

```python cookbook/models/nebius/basic_stream.py
from agno.agent import Agent
from agno.models.nebius import Nebius

agent = Agent(
    model=Nebius(),
        markdown=True,
    debug_mode=True,
)

# Print the response in the terminal
agent.print_response("write a two sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NEBIUS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nebius/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/nebius/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/nebius/knowledge



## Code

```python cookbook/models/nebius/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.nebius import Nebius
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(
    model=Nebius(id="Qwen/Qwen3-30B-A3B"),
    knowledge=knowledge_base,
    )
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
        export NEBIUS_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install ddgs sqlalchemy pgvector pypdf cerebras_cloud_sdk
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nebius/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/nebius/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/nebius/storage



## Code

```python cookbook/models/nebius/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.nebius import Nebius
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Nebius(),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
        export NEBIUS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy cerebras_cloud_sdk agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nebius/db.py
      ```

      ```bash Windows
      python cookbook\models\nebius\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/nebius/structured_output



## Code

```python cookbook/models/nebius/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.nebius import Nebius
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses a structured output
structured_output_agent = Agent(
    model=Nebius(id="Qwen/Qwen3-30B-A3B"),
    description="You are a helpful assistant. Summarize the movie script based on the location in a JSON object.",
    output_schema=MovieScript,
)

structured_output_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NEBIUS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nebius/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/nebius/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/nebius/tool_use



## Code

```python cookbook/models/nebius/tool_use.py
from agno.agent import Agent
from agno.models.nebius import Nebius
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Nebius(id="meta/llama-3.3-70b-instruct"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NEBIUS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nebius/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/nebius/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/nexus/async_basic



## Code

```python cookbook/models/nexus/async_basic.py
"""
Basic async example using Nexus.
"""

import asyncio

from agno.agent import Agent
from agno.models.nexus import Nexus

agent = Agent(model=Nexus(id="anthropic/claude-sonnet-4-20250514"), markdown=True)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nexus/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/nexus/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Streaming Agent
Source: https://docs.agno.com/examples/models/nexus/async_basic_stream



## Code

```python cookbook/models/nexus/async_basic_stream.py
"""
Basic streaming async example using Nexus.
"""

import asyncio

from agno.agent import Agent
from agno.models.nexus import Nexus

agent = Agent(model=Nexus(id="anthropic/claude-sonnet-4-20250514"), markdown=True)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nexus/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/nexus/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Tools
Source: https://docs.agno.com/examples/models/nexus/async_tool_use



## Code

```python cookbook/models/nexus/async_tool_use.py
"""
Async example using Nexus with tool calls
"""

import asyncio

from agno.agent import Agent
from agno.models.nexus import Nexus
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Nexus(id="anthropic/claude-sonnet-4-20250514"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

asyncio.run(agent.aprint_response("Whats happening in France?"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs openai 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nexus/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/nexus/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/nexus/basic



## Code

```python cookbook/models/nexus/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.nexus import Nexus

agent = Agent(model=Nexus(id="anthropic/claude-sonnet-4-20250514"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nexus/basic.py
      ```

      ```bash Windows
      python cookbook/models/nexus/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming Agent
Source: https://docs.agno.com/examples/models/nexus/basic_stream



## Code

```python cookbook/models/nexus/basic_stream.py
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nexus/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/nexus/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/nexus/tool_use



## Code

```python cookbook/models/nexus/tool_use.py
"""Run `pip install ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.nexus import Nexus
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Nexus(id="anthropic/claude-sonnet-4-20250514"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export ANTHROPIC_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs openai 
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nexus/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/nexus/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/nvidia/async_basic



## Code

```python cookbook/models/nvidia/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Streaming Agent
Source: https://docs.agno.com/examples/models/nvidia/async_basic_stream



## Code

```python cookbook/models/nvidia/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Tools
Source: https://docs.agno.com/examples/models/nvidia/async_tool_use



## Code

```python cookbook/models/nvidia/async_tool_use.py
import asyncio

from agno.agent import Agent
from agno.models.nvidia import Nvidia
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Nvidia(id="meta/llama-3.3-70b-instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/nvidia/basic



## Code

```python cookbook/models/nvidia/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/basic.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming Agent
Source: https://docs.agno.com/examples/models/nvidia/basic_stream



## Code

```python cookbook/models/nvidia/basic_stream.py
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/nvidia/tool_use



## Code

```python cookbook/models/nvidia/tool_use.py
from agno.agent import Agent
from agno.models.nvidia import Nvidia
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Nvidia(id="meta/llama-3.3-70b-instruct"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic
Source: https://docs.agno.com/examples/models/ollama/async_basic



## Code

```python cookbook/models/ollama/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    description="You help people with their health and fitness goals.",
    instructions=["Recipes should be under 5 ingredients"],
)
# -*- Print a response to the cli
asyncio.run(agent.aprint_response("Share a breakfast recipe.", markdown=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/ollama/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Stream
Source: https://docs.agno.com/examples/models/ollama/async_basic_stream



## Code

```python cookbook/models/ollama/async_basic_stream.py
import asyncio
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run the example">
    <CodeGroup>
      ```bash Mac/Linux
      python examples/models/ollama/async_basic_stream.py
      ```

      ```bash Windows
      python examples/models/ollama/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic
Source: https://docs.agno.com/examples/models/ollama/basic



## Code

```python cookbook/models/ollama/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/basic.py
      ```

      ```bash Windows
      python cookbook/models/ollama/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Cloud Alternative

For easier setup without local installation, you can use [Ollama Cloud](/examples/models/ollama/cloud) with your API key:

```python
from agno.agent import Agent
from agno.models.ollama import Ollama

# No local setup required - just set OLLAMA_API_KEY
agent = Agent(model=Ollama(id="gpt-oss:120b-cloud", host="https://ollama.com"))
agent.print_response("Share a 2 sentence horror story")
```


# Basic Stream
Source: https://docs.agno.com/examples/models/ollama/basic_stream



## Code

```python cookbook/models/ollama/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/ollama/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Cloud Alternative

For easier setup without local installation, you can use [Ollama Cloud](/examples/models/ollama/cloud) with your API key:

```python
from agno.agent import Agent
from agno.models.ollama import Ollama

# No local setup required - just set OLLAMA_API_KEY
agent = Agent(model=Ollama(id="gpt-oss:120b-cloud", host="https://ollama.com"))
agent.print_response("Share a 2 sentence horror story", stream=True)
```


# Ollama Cloud
Source: https://docs.agno.com/examples/models/ollama/cloud



## Code

```python cookbook/models/ollama/ollama_cloud.py
from agno.agent import Agent
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="gpt-oss:120b-cloud", host="https://ollama.com"),
)

agent.print_response("How many r's in the word 'strawberry'?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set up Ollama Cloud API Key">
    Sign up at [ollama.com](https://ollama.com) and get your API key, then export it:

    ```bash
    export OLLAMA_API_KEY=your_api_key_here
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/ollama_cloud.py
      ```

      ```bash Windows
      python cookbook/models/ollama/ollama_cloud.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Key Features

* **No local setup required**: Access powerful models instantly without downloading or managing local installations
* **Production-ready**: Enterprise-grade infrastructure with reliable uptime and performance
* **Wide model selection**: Access to powerful models including GPT-OSS and other optimized cloud models
* **Automatic configuration**: When `api_key` is provided, the host automatically defaults to `https://ollama.com`


# Db
Source: https://docs.agno.com/examples/models/ollama/db



## Code

```python cookbook/models/ollama/db.py
"""Run `pip install ddgs sqlalchemy ollama` to install dependencies."""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/db.py
      ```

      ```bash Windows
      python cookbook/models/ollama/db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Demo Deepseek R1
Source: https://docs.agno.com/examples/models/ollama/demo_deepseek_r1



## Code

```python cookbook/models/ollama/demo_deepseek_r1.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="deepseek-r1:14b"), markdown=True)

# Print the response in the terminal
agent.print_response(
    "Write me python code to solve quadratic equations. Explain your reasoning."
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull deepseek-r1:14b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/demo_deepseek_r1.py
      ```

      ```bash Windows
      python cookbook/models/ollama/demo_deepseek_r1.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Demo Gemma
Source: https://docs.agno.com/examples/models/ollama/demo_gemma



## Code

```python cookbook/models/ollama/demo_gemma.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="gemma3:12b"), markdown=True)

image_path = Path(__file__).parent.joinpath("super-agents.png")
agent.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull gemma3:12b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/demo_gemma.py
      ```

      ```bash Windows
      python cookbook/models/ollama/demo_gemma.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Demo Phi4
Source: https://docs.agno.com/examples/models/ollama/demo_phi4



## Code

```python cookbook/models/ollama/demo_phi4.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="phi4"), markdown=True)

# Print the response in the terminal
agent.print_response("Tell me a scary story in exactly 10 words.")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull phi4
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/demo_phi4.py
      ```

      ```bash Windows
      python cookbook/models/ollama/demo_phi4.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Demo Qwen
Source: https://docs.agno.com/examples/models/ollama/demo_qwen



## Code

```python cookbook/models/ollama/demo_qwen.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=Ollama(id="qwen3:8b"),
    tools=[
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        ),
    ],
    instructions="Use tables to display data.",
)

agent.print_response("Write a report on NVDA", stream=True, markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull qwen3:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/demo_qwen.py
      ```

      ```bash Windows
      python cookbook/models/ollama/demo_qwen.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/ollama/image_agent



## Code

```python cookbook/models/ollama/image_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="llama3.2-vision"),
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("super-agents.png")
agent.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2-vision
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/ollama/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Knowledge
Source: https://docs.agno.com/examples/models/ollama/knowledge



## Code

```python cookbook/models/ollama/knowledge.py
from agno.agent import Agent
from agno.knowledge.embedder.ollama import OllamaEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.ollama import Ollama
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=OllamaEmbedder(id="llama3.2", dimensions=3072),
    ),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Ollama(id="llama3.2"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs sqlalchemy pgvector pypdf openai ollama
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/ollama/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory
Source: https://docs.agno.com/examples/models/ollama/memory



## Code

```python cookbook/models/ollama/memory.py
"""
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.ollama.chat import Ollama

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Ollama(id="qwen2.5:latest"),
    # Pass the database to the Agent
    db=db,
    # Enable user memories
    enable_user_memories=True,
    # Enable session summaries
    enable_session_summaries=True,
    # Show debug logs so, you can see the memory being created
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull qwen2.5:latest
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno sqlalchemy psycopg pgvector
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/memory.py
      ```

      ```bash Windows
      python cookbook/models/ollama/memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Multimodal Agent
Source: https://docs.agno.com/examples/models/ollama/multimodal



## Code

```python cookbook/models/ollama/image_agent_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="gemma3"),
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")
agent.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull gemma3
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Add sample image">
    Place a sample image named `sample.jpg` in the same directory as your script, or update the `image_path` to point to your desired image.
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/image_agent_bytes.py
      ```

      ```bash Windows
      python cookbook/models/ollama/image_agent_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Set Client
Source: https://docs.agno.com/examples/models/ollama/set_client



## Code

```python cookbook/models/ollama/set_client.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama
from ollama import Client as OllamaClient

agent = Agent(
    model=Ollama(id="llama3.1:8b", client=OllamaClient()),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/set_client.py
      ```

      ```bash Windows
      python cookbook/models/ollama/set_client.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Set Temperature
Source: https://docs.agno.com/examples/models/ollama/set_temperature



## Code

```python cookbook/models/ollama/set_temperature.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.2", options={"temperature": 0.5}), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/set_temperature.py
      ```

      ```bash Windows
      python cookbook/models/ollama/set_temperature.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/ollama/storage



## Code

```python cookbook/models/ollama/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install-U ddgs sqlalchemy psycopg ollama agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/db.py
      ```

      ```bash Windows
      python cookbook\models\ollama\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/ollama/structured_output



## Code

```python cookbook/models/ollama/structured_output.py
from typing import List
from agno.agent import Agent, RunOutput  # noqa
from agno.models.ollama import Ollama
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that returns a structured output
structured_output_agent = Agent(
    model=Ollama(id="llama3.2"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

# Run the agent
structured_output_agent.print_response("New York")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/ollama/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use
Source: https://docs.agno.com/examples/models/ollama/tool_use



## Code

```python cookbook/models/ollama/tool_use.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Ollama(id="llama3.2:latest"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2:latest
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/ollama/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use Stream
Source: https://docs.agno.com/examples/models/ollama/tool_use_stream



## Code

```python cookbook/models/ollama/tool_use_stream.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Ollama(id="llama3.2:latest"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [Ollama installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2:latest
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/tool_use_stream.py
      ```

      ```bash Windows
      python cookbook/models/ollama/tool_use_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input Agent
Source: https://docs.agno.com/examples/models/openai/chat/audio_input_agent



## Code

```python cookbook/models/openai/chat/audio_input_agent.py
import requests
from agno.agent import Agent, RunOutput  # noqa
from agno.media import Audio
from agno.models.openai import OpenAIChat

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

# Provide the agent with the audio file and get result as text
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-audio-preview", modalities=["text"]),
    markdown=True,
)
agent.print_response(
    "What is in this audio?", audio=[Audio(content=wav_data, format="wav")]
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai requests agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/audio_input_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/audio_input_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Output Agent
Source: https://docs.agno.com/examples/models/openai/chat/audio_output_agent



## Code

```python cookbook/models/openai/chat/audio_output_agent.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from agno.db.in_memory import InMemoryDb


# Provide the agent with the audio file and audio configuration and get result as text + audio
agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "sage", "format": "wav"},
    ),
    db=InMemoryDb(),
    add_history_to_context=True,
    markdown=True,
)
run_output: RunOutput = agent.run("Tell me a 5 second scary story")

# Save the response audio to a file
if run_output.response_audio:
    write_audio_to_file(
        audio=run_output.response_audio.content, filename="tmp/scary_story.wav"
    )

run_output: RunOutput = agent.run("What would be in a sequal of this story?")

# Save the response audio to a file
if run_output.response_audio:
    write_audio_to_file(
        audio=run_output.response_audio.content,
        filename="tmp/scary_story_sequal.wav",
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/audio_output_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/audio_output_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/openai/chat/basic



## Code

```python cookbook/models/openai/chat/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
run_response = agent.run("Share a 2 sentence horror story")

# Access metrics from the response
# print(run_response.metrics)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
        python cookbook/models/openai/chat/basic.py
      ```

      ```bash Windows
        python cookbook/models/openai/chat/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/openai/chat/basic_stream



## Code

```python cookbook/models/openai/chat/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Images
Source: https://docs.agno.com/examples/models/openai/chat/generate_images



## Code

```python cookbook/models/openai/chat/generate_images.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools

image_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DalleTools()],
    description="You are an AI agent that can generate images using DALL-E.",
    instructions="When the user asks you to create an image, use the `create_image` tool to create the image.",
    markdown=True,
)

image_agent.print_response("Generate an image of a white siamese cat")

images = image_agent.get_images()
if images and isinstance(images, list):
    for image_response in images:
        image_url = image_response.url
        print(image_url)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/generate_images.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/generate_images.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/openai/chat/image_agent



## Code

```python cookbook/models/openai/chat/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/b/bf/Krakow_-_Kosciol_Mariacki.jpg"
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/openai/chat/knowledge



## Code

```python cookbook/models/openai/chat/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.add_content(
      url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    knowledge=knowledge_base,
    use_tools=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Reasoning Effort
Source: https://docs.agno.com/examples/models/openai/chat/reasoning_effort



## Code

```python cookbook/reasoning/models/openai/reasoning_effort.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini", reasoning_effort="high"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)

agent.print_response("Write a report on the latest news on AI?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/reasoning/models/openai/reasoning_effort.py
      ```

      ```bash Windows
      python cookbook/reasoning/models/openai/reasoning_effort.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/openai/chat/storage



## Code

```python cookbook/models/openai/chat/db.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy psycopg openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/db.py
      ```

      ```bash Windows
      python cookbook\models\openai\chat\db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/openai/chat/structured_output



## Code

```python cookbook/models/openai/chat/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini-2024-08-06"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)


# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")
structured_output_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/openai/chat/tool_use



## Code

```python cookbook/models/openai/chat/tool_use.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
        markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/chat/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/openai/chat/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Flex Tier
Source: https://docs.agno.com/examples/models/openai/responses/agent_flex_tier



## Code

```python cookbook/models/openai/responses/agent_flex_tier.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses

agent = Agent(
    model=OpenAIResponses(id="o4-mini", service_tier="flex"),
    markdown=True,
)

agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/agent_flex_tier.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/agent_flex_tier.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic
Source: https://docs.agno.com/examples/models/openai/responses/async_basic



## Code

```python cookbook/models/openai/responses/async_basic.py
import asyncio

from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Stream
Source: https://docs.agno.com/examples/models/openai/responses/async_basic_stream



## Code

```python cookbook/models/openai/responses/async_basic_stream.py
import asyncio
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.openai import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Tool Use
Source: https://docs.agno.com/examples/models/openai/responses/async_tool_use



## Code

```python cookbook/models/openai/responses/async_tool_use.py
"""Run `pip install ddgs` to install dependencies."""

import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic
Source: https://docs.agno.com/examples/models/openai/responses/basic



## Code

```python cookbook/models/openai/responses/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/basic.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Stream
Source: https://docs.agno.com/examples/models/openai/responses/basic_stream



## Code

```python cookbook/models/openai/responses/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.openai import OpenAIResponses

agent = Agent(model=OpenAIResponses(id="gpt-5-mini"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Db
Source: https://docs.agno.com/examples/models/openai/responses/db



## Code

```python cookbook/models/openai/responses/db.py
"""Run `pip install ddgs sqlalchemy openai` to install dependencies."""

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIResponses
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/db.py
      ```

      ```bash Windows
      python cookbook\models\openai\responses\db.py
      ```
    </CodeGroup>
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/openai/responses/db.py
    ```
  </Step>
</Steps>


# Deep Research Agent
Source: https://docs.agno.com/examples/models/openai/responses/deep_research_agent



## Code

```python cookbook/models/openai/responses/deep_research_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIResponses

agent = Agent(
    model=OpenAIResponses(id="o4-mini-deep-research", max_tool_calls=1),
    instructions=dedent("""
        You are an expert research analyst with access to advanced research tools.

        When you are given a schema to use, pass it to the research tool as output_schema parameter to research tool.

        The research tool has two parameters:
        - instructions (str): The research topic/question
        - output_schema (dict, optional): A JSON schema for structured output
    """),
)

agent.print_response(
    """Research the economic impact of semaglutide on global healthcare systems.
    Do:
    - Include specific figures, trends, statistics, and measurable outcomes.
    - Prioritize reliable, up-to-date sources: peer-reviewed research, health
      organizations (e.g., WHO, CDC), regulatory agencies, or pharmaceutical
      earnings reports.
    - Include inline citations and return all source metadata.

    Be analytical, avoid generalities, and ensure that each section supports
    data-backed reasoning that could inform healthcare policy or financial modeling."""
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/deep_research_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/deep_research_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/openai/responses/image_agent



## Code

```python cookbook/models/openai/responses/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIResponses
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent Bytes
Source: https://docs.agno.com/examples/models/openai/responses/image_agent_bytes



## Code

```python cookbook/models/openai/responses/image_agent_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIResponses
from agno.tools.googlesearch import GoogleSearchTools
from agno.utils.media import download_image

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

download_image(
    url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg",
    output_path=str(image_path),
)

# Read the image file content as bytes
image_bytes = image_path.read_bytes()

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/image_agent_bytes.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/image_agent_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent With Memory
Source: https://docs.agno.com/examples/models/openai/responses/image_agent_with_memory



## Code

```python cookbook/models/openai/responses/image_agent_with_memory.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIResponses
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    markdown=True,
    add_history_to_context=True,
    num_history_runs=3,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
)

agent.print_response("Tell me where I can get more images?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/image_agent_with_memory.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/image_agent_with_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Generation Agent
Source: https://docs.agno.com/examples/models/openai/responses/image_generation_agent



## Code

```python cookbook/models/openai/responses/image_generation_agent.py
"""üîß Example: Using the OpenAITools Toolkit for Image Generation

This script demonstrates how to use the `OpenAITools` toolkit, which includes a tool for generating images using OpenAI's DALL-E within an Agno Agent.

Example prompts to try:
- "Create a surreal painting of a floating city in the clouds at sunset"
- "Generate a photorealistic image of a cozy coffee shop interior"
- "Design a cute cartoon mascot for a tech startup"
- "Create an artistic portrait of a cyberpunk samurai"

Run `pip install openai agno` to install the necessary dependencies.
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.openai import OpenAITools
from agno.utils.media import save_base64_data

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[OpenAITools(image_model="gpt-image-1")],
    markdown=True,
)

response = agent.run(
    "Generate a photorealistic image of a cozy coffee shop interior",
)

if response.images and response.images[0].content:
    save_base64_data(str(response.images[0].content), "tmp/coffee_shop.png")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/image_generation_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/image_generation_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Knowledge
Source: https://docs.agno.com/examples/models/openai/responses/knowledge



## Code

```python cookbook/models/openai/responses/knowledge.py
"""Run `pip install ddgs sqlalchemy pgvector pypdf openai` to install dependencies."""

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIResponses
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=OpenAIResponses(id="gpt-5-mini"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memory
Source: https://docs.agno.com/examples/models/openai/responses/memory



## Code

```python cookbook/models/openai/responses/memory.py
"""
This recipe shows how to use personalized memories and summaries in an agent.
Steps:
1. Run: `./cookbook/scripts/run_pgvector.sh` to start a postgres container with pgvector
2. Run: `pip install openai sqlalchemy 'psycopg[binary]' pgvector` to install the dependencies
3. Run: `python cookbook/agents/personalized_memories_and_summaries.py` to run the agent
"""

from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.postgres import PostgresDb
from agno.models.openai import OpenAIResponses
from rich.pretty import pprint

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    user_id="test_user",
    session_id="test_session",
    # Pass the database to the Agent
    db=db,
    # Enable user memories
    enable_user_memories=True,
    # Enable session summaries
    enable_session_summaries=True,
    # Show debug logs so, you can see the memory being created
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.db.get_user_memories(user_id="test_user"))
    pprint(
        agent.db.get_session(
            session_id="test_session", session_type=SessionType.AGENT
        ).summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)
# -*- Print memories
if agent.db:
    pprint(agent.db.get_user_memories(user_id="test_user"))
    pprint(
        agent.db.get_session(
            session_id="test_session", session_type=SessionType.AGENT
        ).summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)
# -*- Print memories
if agent.db:
    pprint(agent.db.get_user_memories(user_id="test_user"))
    pprint(
        agent.db.get_session(
            session_id="test_session", session_type=SessionType.AGENT
        ).summary  # type: ignore
    )

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/memory.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pdf Input Local
Source: https://docs.agno.com/examples/models/openai/responses/pdf_input_local



## Code

```python cookbook/models/openai/responses/pdf_input_local.py
from pathlib import Path

from agno.agent import Agent
from agno.media import File
from agno.models.openai.responses import OpenAIResponses
from agno.utils.media import download_file

pdf_path = Path(__file__).parent.joinpath("ThaiRecipes.pdf")

# Download the file using the download_file function
download_file(
    "https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf", str(pdf_path)
)

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[{"type": "file_search"}],
    markdown=True,
    add_history_to_context=True,
)

agent.print_response(
    "Summarize the contents of the attached file.",
    files=[File(filepath=pdf_path)],
)
agent.print_response("Suggest me a recipe from the attached file.")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/pdf_input_local.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/pdf_input_local.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pdf Input Url
Source: https://docs.agno.com/examples/models/openai/responses/pdf_input_url



## Code

```python cookbook/models/openai/responses/pdf_input_url.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.media import File
from agno.models.openai.responses import OpenAIResponses

# Setup the database for the Agent Session to be stored
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    db=db,
    tools=[{"type": "file_search"}, {"type": "web_search_preview"}],
    markdown=True,
)

agent.print_response(
    "Summarize the contents of the attached file and search the web for more information.",
    files=[File(url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf")],
)

# Get the stored Agent session, to check the response citations
session = agent.get_session()
if session and session.runs and session.runs[-1].citations:
    print("Citations:")
    print(session.runs[-1].citations)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/pdf_input_url.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/pdf_input_url.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning O3 Mini
Source: https://docs.agno.com/examples/models/openai/responses/reasoning_o3_mini



## Code

```python cookbook/models/openai/responses/reasoning_o3_mini.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Write a report on the latest news on AI?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/reasoning_o3_mini.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/reasoning_o3_mini.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/openai/responses/structured_output



## Code

```python cookbook/models/openai/responses/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.openai import OpenAIResponses
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)


# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")
structured_output_agent.print_response("New York")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use
Source: https://docs.agno.com/examples/models/openai/responses/tool_use



## Code

```python cookbook/models/openai/responses/tool_use.py
"""Run `pip install ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use Gpt 5
Source: https://docs.agno.com/examples/models/openai/responses/tool_use_gpt_5



## Code

```python cookbook/models/openai/responses/tool_use_gpt_5.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5"),
    tools=[YFinanceTools(cache_results=True)],
    markdown=True,
    telemetry=False,
)

agent.print_response("What is the current price of TSLA?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/tool_use_gpt_5.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/tool_use_gpt_5.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use O3
Source: https://docs.agno.com/examples/models/openai/responses/tool_use_o3



## Code

```python cookbook/models/openai/responses/tool_use_o3.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIResponses(id="o3"),
    tools=[YFinanceTools(cache_results=True)],
    markdown=True,
    telemetry=False,
)

agent.print_response("What is the current price of TSLA?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/tool_use_o3.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/tool_use_o3.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use Stream
Source: https://docs.agno.com/examples/models/openai/responses/tool_use_stream



## Code

```python cookbook/models/openai/responses/tool_use_stream.py
"""Run `pip install ddgs` to install dependencies."""

from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/tool_use_stream.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/tool_use_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Verbosity Control
Source: https://docs.agno.com/examples/models/openai/responses/verbosity_control



## Code

```python cookbook/models/openai/responses/verbosity_control.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIChat(id="gpt-5", verbosity="high"),
    tools=[
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        )
    ],
    instructions="Use tables to display data.",
    markdown=True,
)
agent.print_response("Write a report comparing NVDA to TSLA", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/verbosity_control.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/verbosity_control.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Websearch Builtin Tool
Source: https://docs.agno.com/examples/models/openai/responses/websearch_builtin_tool



## Code

```python cookbook/models/openai/responses/websearch_builtin_tool.py
from agno.agent import Agent
from agno.models.openai import OpenAIResponses
from agno.tools.file import FileTools

agent = Agent(
    model=OpenAIResponses(id="gpt-5-mini"),
    tools=[{"type": "web_search_preview"}, FileTools()],
    instructions="Save the results to a file with a relevant name.",
    markdown=True,
)
agent.print_response("Whats happening in France?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/websearch_builtin_tool.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/websearch_builtin_tool.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ZDR Reasoning Agent
Source: https://docs.agno.com/examples/models/openai/responses/zdr_reasoning_agent



## Code

```python cookbook/models/openai/responses/zdr_reasoning_agent.py
"""
An example of using OpenAI Responses with reasoning features and ZDR mode enabled.

Read more about ZDR mode here: https://openai.com/enterprise-privacy/.
"""

from agno.agent import Agent
from agno.db.in_memory import InMemoryDb
from agno.models.openai import OpenAIResponses

agent = Agent(
    name="ZDR Compliant Agent",
    session_id="zdr_demo_session",
    model=OpenAIResponses(
        id="o4-mini",
        store=False,
        reasoning_summary="auto",  # Requesting a reasoning summary
    ),
    instructions="You are a helpful AI assistant operating in Zero Data Retention mode for maximum privacy and compliance.",
    db=InMemoryDb(),
    add_history_to_context=True,
    stream=True,
)

agent.print_response("What's the largest country in Europe by area?")
agent.print_response("What's the population of that country?")
agent.print_response("What's the population density per square kilometer?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/responses/zdr_reasoning_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/responses/zdr_reasoning_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/perplexity/async_basic



## Code

```python cookbook/models/perplexity/async_basic.py
import asyncio

from agno.agent import Agent, RunOutput  # noqa
from agno.models.perplexity import Perplexity

agent = Agent(model=Perplexity(id="sonar"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Streaming Agent
Source: https://docs.agno.com/examples/models/perplexity/async_basic_stream



## Code

```python cookbook/models/perplexity/async_basic_stream.py
import asyncio
from typing import Iterator  # noqa

from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.perplexity import Perplexity

agent = Agent(model=Perplexity(id="sonar"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/perplexity/basic



## Code

```python cookbook/models/perplexity/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.perplexity import Perplexity

agent = Agent(model=Perplexity(id="sonar-pro"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/basic.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming Agent
Source: https://docs.agno.com/examples/models/perplexity/basic_stream



## Code

```python cookbook/models/perplexity/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.perplexity import Perplexity

agent = Agent(model=Perplexity(id="sonar"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/perplexity/knowledge



## Code

```python cookbook/models/perplexity/knowledge.py
from agno.agent import Agent
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.perplexity import Perplexity
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=OpenAIEmbedder(),
    ),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=Perplexity(id="sonar-pro"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai sqlalchemy pgvector pypdf
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Memory
Source: https://docs.agno.com/examples/models/perplexity/memory



## Code

```python cookbook/models/perplexity/memory.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.perplexity import Perplexity
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
agent = Agent(
    model=Perplexity(id="sonar-pro"),
    # Store the memories and summary in a database
    db=PostgresDb(db_url=db_url),
    enable_user_memories=True,
    enable_session_summaries=True,
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.get_session(session_id="test_session").summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.get_session(session_id="test_session").summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.get_session(session_id="test_session").summary  # type: ignore
    )

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai sqlalchemy psycopg pgvector
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/memory.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Output
Source: https://docs.agno.com/examples/models/perplexity/structured_output



## Code

```python cookbook/models/perplexity/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.perplexity import Perplexity
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=Perplexity(id="sonar-pro"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    markdown=True,
)

# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PERPLEXITY_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/perplexity/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/perplexity/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/portkey/basic



## Code

```python cookbook/models/portkey/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.portkey import Portkey

# Create model using Portkey
model = Portkey(
    id="@first-integrati-707071/gpt-5-nano",
)

agent = Agent(model=model, markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("What is Portkey and why would I use it as an AI gateway?")
# print(run.content)

# Print the response in the terminal
agent.print_response("What is Portkey and why would I use it as an AI gateway?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export PORTKEY_API_KEY=***
    export PORTKEY_VIRTUAL_KEY=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/portkey/basic.py
      ```

      ```bash Windows
      python cookbook/models/portkey/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent with Streaming
Source: https://docs.agno.com/examples/models/portkey/basic_stream



## Code

```python cookbook/models/portkey/basic_stream.py
from agno.agent import Agent
from agno.models.portkey import Portkey

agent = Agent(
    model=Portkey(
        id="@first-integrati-707071/gpt-5-nano",
    ),
    markdown=True,
)

# Print the response in the terminal
agent.print_response(
    "What is Portkey and why would I use it as an AI gateway?", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export PORTKEY_API_KEY=***
    export PORTKEY_VIRTUAL_KEY=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/portkey/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/portkey/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output Agent
Source: https://docs.agno.com/examples/models/portkey/structured_output



## Code

```python cookbook/models/portkey/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.portkey import Portkey
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(
    model=Portkey(id="@first-integrati-707071/gpt-5-nano"),
    output_schema=MovieScript,
    markdown=True,
)

# Get the response in a variable
# run: RunOutput = agent.run("New York")
# print(run.content)

agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export PORTKEY_API_KEY=***
    export PORTKEY_VIRTUAL_KEY=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/portkey/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/portkey/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/portkey/tool_use



## Code

```python cookbook/models/portkey/tool_use.py
from agno.agent import Agent
from agno.models.portkey import Portkey
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Portkey(id="@first-integrati-707071/gpt-5-nano"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Print the response in the terminal
agent.print_response("What are the latest developments in AI gateways?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export PORTKEY_API_KEY=***
    export PORTKEY_VIRTUAL_KEY=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/portkey/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/portkey/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools and Streaming
Source: https://docs.agno.com/examples/models/portkey/tool_use_stream



## Code

```python cookbook/models/portkey/tool_use_stream.py
from agno.agent import Agent
from agno.models.portkey import Portkey
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Portkey(id="@first-integrati-707071/gpt-5-nano"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

# Print the response in the terminal
agent.print_response("What are the latest developments in AI gateways?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export PORTKEY_API_KEY=***
    export PORTKEY_VIRTUAL_KEY=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/portkey/tool_use_stream.py
      ```

      ```bash Windows
      python cookbook/models/portkey/tool_use_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/siliconflow/async_basic



## Code

```python cookbook/models/siliconflow/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.siliconflow import Siliconflow

agent = Agent(model=Siliconflow(id="openai/gpt-oss-120b"), markdown=True)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">`bash export SILICONFLOW_API_KEY=xxx `</Step>

  <Step title="Install libraries">`bash pip install -U agno openai `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/siliconflow/async_basic.py
      ```

      ```bash Windows
      python cookbook/models/siliconflow/async_basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Streaming Agent
Source: https://docs.agno.com/examples/models/siliconflow/async_basic_stream



## Code

```python cookbook/models/siliconflow/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.siliconflow import Siliconflow

agent = Agent(model=Siliconflow(id="openai/gpt-oss-120b"), markdown=True)

asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">`bash export SILICONFLOW_API_KEY=xxx `</Step>

  <Step title="Install libraries">`bash pip install -U agno openai `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/siliconflow/async_basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/siliconflow/async_basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent with Tools
Source: https://docs.agno.com/examples/models/siliconflow/async_tool_use



## Code

```python cookbook/models/siliconflow/async_tool_use.py
import asyncio

from agno.agent import Agent
from agno.models.siliconflow import Siliconflow
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Siliconflow(id="openai/gpt-oss-120b"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">`bash export SILICONFLOW_API_KEY=xxx `</Step>

  <Step title="Install libraries">
    `bash pip install -U agno ddgs openai `
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/siliconflow/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/siliconflow/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/siliconflow/basic



## Code

```python cookbook/models/siliconflow/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.siliconflow import Siliconflow

agent = Agent(model=Siliconflow(id="openai/gpt-oss-120b"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">`bash export SILICONFLOW_API_KEY=xxx `</Step>

  <Step title="Install libraries">`bash pip install -U agno openai `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/siliconflow/basic.py
      ```

      ```bash Windows
      python cookbook/models/siliconflow/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming Agent
Source: https://docs.agno.com/examples/models/siliconflow/basic_stream



## Code

```python cookbook/models/siliconflow/basic_stream.py
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.siliconflow import Siliconflow

agent = Agent(model=Siliconflow(id="openai/gpt-oss-120b"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">`bash export SILICONFLOW_API_KEY=xxx `</Step>

  <Step title="Install libraries">`bash pip install -U agno openai `</Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/siliconflow/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/siliconflow/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/siliconflow/tool_use



## Code

```python cookbook/models/siliconflow/tool_use.py
from agno.agent import Agent
from agno.models.siliconflow import Siliconflow
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
  model=Siliconflow(id="openai/gpt-oss-120b"),
  tools=[DuckDuckGoTools()],
  markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">`bash export SILICONFLOW_API_KEY=xxx `</Step>

  <Step title="Install libraries">
    `bash pip install -U agno ddgs openai `
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/siliconflow/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/siliconflow/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/together/basic



## Code

```python cookbook/models/together/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"), markdown=True
)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/basic.py
      ```

      ```bash Windows
      python cookbook/models/together/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/together/basic_stream



## Code

```python cookbook/models/together/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"), markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/together/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/together/image_agent



## Code

```python cookbook/models/together/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Llama-Vision-Free"),
    markdown=True,
)

agent.print_response(
    "Tell me about this image",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/together/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Input Bytes Content
Source: https://docs.agno.com/examples/models/together/image_agent_bytes



## Code

```python cookbook/models/together/image_agent_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Llama-Vision-Free"),
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

# Read the image file content as bytes
image_bytes = image_path.read_bytes()

agent.print_response(
    "Tell me about this image",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Add sample image">
    Add a sample image file:

    ```bash
    # Add your sample.jpg file to examples/models/together/together/ directory
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/image_agent_bytes.py
      ```

      ```bash Windows
      python cookbook/models/together/image_agent_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent with Memory
Source: https://docs.agno.com/examples/models/together/image_agent_memory



## Code

```python cookbook/models/together/image_agent_memory.py
from agno.agent import Agent
from agno.media import Image
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Llama-Vision-Free"),
    markdown=True,
    add_history_to_context=True,
    num_history_runs=3,
)

agent.print_response(
    "Tell me about this image",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

agent.print_response("Tell me where I can get more images?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/image_agent_memory.py
      ```

      ```bash Windows
      python cookbook/models/together/image_agent_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs
Source: https://docs.agno.com/examples/models/together/structured_output



## Code

```python cookbook/models/together/structured_output.py
from typing import List

from agno.agent import Agent, RunOutput  # noqa
from agno.models.together import Together
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"),
    description="You write movie scripts.",
    output_schema=MovieScript,
    use_json_mode=True,
)

# Get the response in a variable
# json_mode_response: RunOutput = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunOutput = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/together/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/together/tool_use



## Code

```python cookbook/models/together/tool_use.py
from agno.agent import Agent
from agno.models.together import Together
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/together/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/vercel/basic



## Code

```python cookbook/models/vercel/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.vercel import V0

agent = Agent(model=V0(id="v0-1.0-md"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

# agent.print_response("Create a simple web app that displays a random number between 1 and 100.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export V0_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vercel/basic.py
      ```

      ```bash Windows
      python cookbook/models/vercel/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent
Source: https://docs.agno.com/examples/models/vercel/basic_stream



## Code

```python cookbook/models/vercel/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutput  # noqa
from agno.models.vercel import V0

agent = Agent(model=V0(id="v0-1.0-md"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export V0_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vercel/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/vercel/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/vercel/image_agent



## Code

```python cookbook/models/vercel/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.vercel import V0
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=V0(id="v0-1.0-md"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export V0_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vercel/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/vercel/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge
Source: https://docs.agno.com/examples/models/vercel/knowledge



## Code

```python cookbook/models/vercel/knowledge.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.vercel import V0
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
# Add content to the knowledge
knowledge.add_content(
    url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"
)

agent = Agent(model=V0(id="v0-1.0-md"), knowledge=knowledge)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export V0_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ddgs sqlalchemy pgvector pypdf openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vercel/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/vercel/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/vercel/tool_use



## Code

```python cookbook/models/vercel/tool_use.py
from agno.agent import Agent
from agno.models.vercel import V0
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=V0(id="v0-1.0-md"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export V0_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vercel/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/vercel/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Agent
Source: https://docs.agno.com/examples/models/vllm/async_basic



## Code

```python cookbook/models/vllm/async_basic.py
import asyncio

from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(model=VLLM(id="Qwen/Qwen2.5-7B-Instruct"), markdown=True)
asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai vllm
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/async_basic.py
    ```
  </Step>
</Steps>


# Async Agent with Streaming
Source: https://docs.agno.com/examples/models/vllm/async_basic_stream



## Code

```python cookbook/models/vllm/async_basic_stream.py
import asyncio

from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(model=VLLM(id="Qwen/Qwen2.5-7B-Instruct"), markdown=True)
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/async_basic_stream.py
    ```
  </Step>
</Steps>


# Async Agent with Tools
Source: https://docs.agno.com/examples/models/vllm/async_tool_use



## Code

```python cookbook/models/vllm/async_tool_use.py
"""Run `pip install ddgs` to install dependencies."""

import asyncio

from agno.agent import Agent
from agno.models.vllm import VLLM
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct", top_k=20, enable_thinking=False),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm ddgs
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/async_tool_use.py
    ```
  </Step>
</Steps>


# Basic Agent
Source: https://docs.agno.com/examples/models/vllm/basic



## Code

```python cookbook/models/vllm/basic.py
from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct", top_k=20, enable_thinking=False),
    markdown=True,
)

agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Setup vLLM Server">
    Start a vLLM server locally:

    ```bash
    pip install vllm
    python -m vllm.entrypoints.openai.api_server \
      --model Qwen/Qwen2.5-7B-Instruct \
      --port 8000
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vllm/basic.py
      ```

      ```bash Windows
      python cookbook/models/vllm/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Streaming
Source: https://docs.agno.com/examples/models/vllm/basic_stream



## Code

```python cookbook/models/vllm/basic_stream.py
from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct", top_k=20, enable_thinking=False),
    markdown=True,
)
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/basic_stream.py
    ```
  </Step>
</Steps>


# Code Generation
Source: https://docs.agno.com/examples/models/vllm/code_generation



## Code

```python cookbook/models/vllm/code_generation.py
from agno.agent import Agent
from agno.models.vllm import VLLM

agent = Agent(
    model=VLLM(id="deepseek-ai/deepseek-coder-6.7b-instruct"),
    description="You are an expert Python developer.",
    markdown=True,
)

agent.print_response(
    "Write a Python function that returns the nth Fibonacci number using dynamic programming."
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve deepseek-ai/deepseek-coder-6.7b-instruct \
        --dtype float32 \
        --tool-call-parser pythonic
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/code_generation.py
    ```
  </Step>
</Steps>


# Agent with Memory
Source: https://docs.agno.com/examples/models/vllm/memory



## Code

```python cookbook/models/vllm/memory.py
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.vllm import VLLM
from agno.utils.pprint import pprint

# Change this if your Postgres container is running elsewhere
DB_URL = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=VLLM(id="microsoft/Phi-3-mini-128k-instruct"),
    db=PostgresDb(db_url=DB_URL),
    enable_user_memories=True,
    enable_session_summaries=True,
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.get_session(session_id="test_session").summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.get_session(session_id="test_session").summary  # type: ignore
    )

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)
# -*- Print memories and summary
if agent.db:
    pprint(agent.get_user_memories(user_id="test_user"))
    pprint(
        agent.get_session(session_id="test_session").summary  # type: ignore
    )

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)
```

<Note>
  Ensure Postgres database is running.
</Note>

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Start Postgres database">
    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm sqlalchemy psycopg pgvector
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve microsoft/Phi-3-mini-128k-instruct \
        --dtype float32 \
        --enable-auto-tool-choice \
        --tool-call-parser pythonic
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/memory.py
    ```
  </Step>
</Steps>


# Agent with Storage
Source: https://docs.agno.com/examples/models/vllm/storage



## Code

```python cookbook/models/vllm/db.py

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.models.vllm import VLLM
from agno.tools.duckduckgo import DuckDuckGoTools

# Setup the database
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
db = PostgresDb(db_url=db_url)

agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct"),
    db=db,
    tools=[DuckDuckGoTools()],
    add_history_to_context=True,
)

agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

<Note>
  Ensure Postgres database is running.
</Note>

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm sqlalchemy psycopg ddgs
    ```
  </Step>

  <Step title="Start Postgres database">
    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/db.py
    ```
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/vllm/structured_output



## Code

```python cookbook/models/vllm/structured_output.py
from typing import List

from agno.agent import Agent
from agno.models.vllm import VLLM
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(
    model=VLLM(id="Qwen/Qwen2.5-7B-Instruct", top_k=20, enable_thinking=False),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

agent.print_response("Llamas ruling the world")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno pydantic vllm openai
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve Qwen/Qwen2.5-7B-Instruct \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/structured_output.py
    ```
  </Step>
</Steps>


# Agent with Tools
Source: https://docs.agno.com/examples/models/vllm/tool_use



## Code

```python cookbook/models/vllm/tool_use.py
"""Build a Web Search Agent using xAI."""

from agno.agent import Agent
from agno.models.vllm import VLLM
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=VLLM(
        id="NousResearch/Nous-Hermes-2-Mistral-7B-DPO", top_k=20, enable_thinking=False
    ),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Libraries">
    ```bash
    pip install -U agno openai vllm ddgs
    ```
  </Step>

  <Step title="Start vLLM server">
    ```bash
    vllm serve NousResearch/Nous-Hermes-2-Mistral-7B-DPO \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --dtype float16 \
        --max-model-len 8192 \
        --gpu-memory-utilization 0.9
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/vllm/tool_use.py
    ```
  </Step>
</Steps>


# Async Tool Use
Source: https://docs.agno.com/examples/models/xai/async_tool_use



## Code

```python cookbook/models/xai/async_tool_use.py
"""Run `pip install ddgs` to install dependencies."""

import asyncio

from agno.agent import Agent
from agno.models.xai import xAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=xAI(id="grok-2"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
asyncio.run(agent.aprint_response("Whats happening in France?", stream=True))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/async_tool_use.py
      ```

      ```bash Windows
      python cookbook/models/xai/async_tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic
Source: https://docs.agno.com/examples/models/xai/basic



## Code

```python cookbook/models/xai/basic.py
from agno.agent import Agent, RunOutput  # noqa
from agno.models.xai import xAI

agent = Agent(model=xAI(id="grok-2"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/basic.py
      ```

      ```bash Windows
      python cookbook/models/xai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Async Basic Agent
Source: https://docs.agno.com/examples/models/xai/basic_async



## Code

```python cookbook/models/xai/basic_async.py
import asyncio

from agno.agent import Agent, RunOutput
from agno.models.xai import xAI

agent = Agent(model=xAI(id="grok-3"), markdown=True)

# Get the response in a variable
# run: RunOutput = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/xai/basic_async.py
    ```
  </Step>
</Steps>


# Async Streaming Agent
Source: https://docs.agno.com/examples/models/xai/basic_async_stream



## Code

```python cookbook/models/xai/basic_async_stream.py
import asyncio
from typing import Iterator

from agno.agent import Agent, RunOutputEvent
from agno.models.xai import xAI

agent = Agent(model=xAI(id="grok-3"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
asyncio.run(agent.aprint_response("Share a 2 sentence horror story", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    python cookbook/models/xai/basic_async_stream.py
    ```
  </Step>
</Steps>


# Basic Stream
Source: https://docs.agno.com/examples/models/xai/basic_stream



## Code

```python cookbook/models/xai/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunOutputEvent  # noqa
from agno.models.xai import xAI

agent = Agent(model=xAI(id="grok-2"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunOutputEvent] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/xai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent
Source: https://docs.agno.com/examples/models/xai/image_agent



## Code

```python cookbook/models/xai/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.xai import xAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=xAI(id="grok-2-vision-latest"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/xai/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent Bytes
Source: https://docs.agno.com/examples/models/xai/image_agent_bytes



## Code

```python cookbook/models/xai/image_agent_bytes.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.xai import xAI
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.media import download_image

agent = Agent(
    model=xAI(id="grok-2-vision-latest"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("sample.jpg")

download_image(
    url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg",
    output_path=str(image_path),
)

# Read the image file content as bytes
image_bytes = image_path.read_bytes()

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(content=image_bytes),
    ],
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/image_agent_bytes.py
      ```

      ```bash Windows
      python cookbook/models/xai/image_agent_bytes.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Live Search Agent
Source: https://docs.agno.com/examples/models/xai/live_search_agent



## Code

```python cookbook/models/xai/live_search_agent.py
from agno.agent import Agent
from agno.models.xai.xai import xAI

agent = Agent(
    model=xAI(
        id="grok-3",
        search_parameters={
            "mode": "on",
            "max_search_results": 20,
            "return_citations": True,
        },
    ),
    markdown=True,
)
agent.print_response("Provide me a digest of world news in the last 24 hours.")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/live_search_agent.py
      ```

      ```bash Windows
      python cookbook/models/xai/live_search_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Live Search Agent Stream
Source: https://docs.agno.com/examples/models/xai/live_search_agent_stream



## Code

```python cookbook/models/xai/live_search_agent_stream.py
from agno.agent import Agent
from agno.models.xai.xai import xAI

agent = Agent(
    model=xAI(
        id="grok-3",
        search_parameters={
            "mode": "on",
            "max_search_results": 20,
            "return_citations": True,
        },
    ),
    markdown=True,
)
agent.print_response(
    "Provide me a digest of world news in the last 24 hours.", stream=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/live_search_agent_stream.py
      ```

      ```bash Windows
      python cookbook/models/xai/live_search_agent_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning Agent
Source: https://docs.agno.com/examples/models/xai/reasoning_agent



## Code

```python cookbook/models/xai/reasoning_agent.py
from agno.agent import Agent
from agno.models.xai import xAI
from agno.tools.reasoning import ReasoningTools
from agno.tools.yfinance import YFinanceTools

reasoning_agent = Agent(
    model=xAI(id="grok-3-beta"),
    tools=[
        ReasoningTools(add_instructions=True, add_few_shot=True),
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            company_info=True,
            company_news=True,
        ),
    ],
    instructions=[
        "Use tables to display data",
        "Only output the report, no other text",
    ],
    markdown=True,
)
reasoning_agent.print_response(
    "Write a report on TSLA",
    stream=True,
    show_full_reasoning=True,
    stream_intermediate_steps=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai yfinance agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/reasoning_agent.py
      ```

      ```bash Windows
      python cookbook/models/xai/reasoning_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Output
Source: https://docs.agno.com/examples/models/xai/structured_output



## Code

```python cookbook/models/xai/structured_output.py
from typing import List

from agno.agent import Agent
from agno.models.xai.xai import xAI
from agno.run.agent import RunOutput
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that returns a structured output
structured_output_agent = Agent(
    model=xAI(id="grok-2-latest"),
    description="You write movie scripts.",
    output_schema=MovieScript,
)

# Run the agent synchronously
structured_output_response: RunOutput = structured_output_agent.run(
    "Llamas ruling the world"
)
pprint(structured_output_response.content)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/xai/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use
Source: https://docs.agno.com/examples/models/xai/tool_use



## Code

```python cookbook/models/xai/tool_use.py
"""Build a Web Search Agent using xAI."""

from agno.agent import Agent
from agno.models.xai import xAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=xAI(id="grok-2"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/xai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tool Use Stream
Source: https://docs.agno.com/examples/models/xai/tool_use_stream



## Code

```python cookbook/models/xai/tool_use_stream.py
"""Build a Web Search Agent using xAI."""

from agno.agent import Agent
from agno.models.xai import xAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=xAI(id="grok-2"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U xai ddgs agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/tool_use_stream.py
      ```

      ```bash Windows
      python cookbook/models/xai/tool_use_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agno Assist
Source: https://docs.agno.com/examples/use-cases/agents/agno_assist



This example shows how to create a specialized AI assistant that helps users understand and work with the Agno framework. Learn how to build domain-specific agents that provide expert guidance, answer technical questions, and help users navigate complex systems. Perfect for creating help desk agents, technical support systems, and educational AI assistants.

## Code

```python cookbook/examples/agents/agno_assist.py
import asyncio

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

knowledge = Knowledge(
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="agno_assist_knowledge",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

asyncio.run(
    knowledge.add_content_async(name="Agno Docs", url="https://docs.agno.com/llms-full.txt")
)

agno_assist = Agent(
    name="Agno Assist",
    model=OpenAIChat(id="gpt-5-mini"),
    description="You help answer questions about the Agno framework.",
    instructions="Search your knowledge before answering the question.",
    knowledge=knowledge,
    db=SqliteDb(session_table="agno_assist_sessions", db_file="tmp/agents.db"),
    add_history_to_context=True,
    add_datetime_to_context=True,
    markdown=True,
)

if __name__ == "__main__":
    agno_assist.print_response("What is Agno?")

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/agno_assist.py
      ```

      ```bash Windows
      python cookbook/examples/agents/agno_assist.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Airbnb Mcp
Source: https://docs.agno.com/examples/use-cases/agents/airbnb_mcp



üè† MCP Airbnb Agent - Search for Airbnb listings!

This example shows how to create an agent that uses MCP and Llama 4 to search for Airbnb listings.

## Code

```python cookbook/examples/agents/airbnb_mcp.py
import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.models.groq import Groq
from agno.tools.mcp import MCPTools
from agno.tools.reasoning import ReasoningTools


async def run_agent(message: str) -> None:
    async with MCPTools(
        "npx -y @openbnb/mcp-server-airbnb --ignore-robots-txt"
    ) as mcp_tools:
        agent = Agent(
            model=Groq(id="meta-llama/llama-4-scout-17b-16e-instruct"),
            tools=[ReasoningTools(add_instructions=True), mcp_tools],
            instructions=dedent("""\
            ## General Instructions
            - Always start by using the think tool to map out the steps needed to complete the task.
            - After receiving tool results, use the think tool as a scratchpad to validate the results for correctness
            - Before responding to the user, use the think tool to jot down final thoughts and ideas.
            - Present final outputs in well-organized tables whenever possible.
            - Always provide links to the listings in your response.
            - Show your top 10 recommendations in a table and make a case for why each is the best choice.

            ## Using the think tool
            At every step, use the think tool as a scratchpad to:
            - Restate the object in your own words to ensure full comprehension.
            - List the  specific rules that apply to the current request
            - Check if all required information is collected and is valid
            - Verify that the planned action completes the task\
            """),
            add_datetime_to_context=True,
            markdown=True,
        )
        await agent.aprint_response(message, stream=True)


if __name__ == "__main__":
    task = dedent("""\
    I'm traveling to San Francisco from April 20th - May 8th. Can you find me the best deals for a 1 bedroom apartment?
    I'd like a dedicated workspace and close proximity to public transport.\
    """)
    asyncio.run(run_agent(task))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq mcp agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/airbnb_mcp.py
      ```

      ```bash Windows
      python cookbook/examples/agents/airbnb_mcp.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Books Recommender
Source: https://docs.agno.com/examples/use-cases/agents/books-recommender



This example shows how to create an intelligent book recommendation system that provides
comprehensive literary suggestions based on your preferences. The agent combines book databases,
ratings, reviews, and upcoming releases to deliver personalized reading recommendations.

Example prompts to try:

* "I loved 'The Seven Husbands of Evelyn Hugo' and 'Daisy Jones & The Six', what should I read next?"
* "Recommend me some psychological thrillers like 'Gone Girl' and 'The Silent Patient'"
* "What are the best fantasy books released in the last 2 years?"
* "I enjoy historical fiction with strong female leads, any suggestions?"
* "Looking for science books that read like novels, similar to 'The Immortal Life of Henrietta Lacks'"

## Code

```python books_recommender.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

book_recommendation_agent = Agent(
    name="Shelfie",
    tools=[ExaTools()],
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
        You are Shelfie, a passionate and knowledgeable literary curator with expertise in books worldwide! üìö

        Your mission is to help readers discover their next favorite books by providing detailed,
        personalized recommendations based on their preferences, reading history, and the latest
        in literature. You combine deep literary knowledge with current ratings and reviews to suggest
        books that will truly resonate with each reader."""),
    instructions=dedent("""\
        Approach each recommendation with these steps:

        1. Analysis Phase üìñ
           - Understand reader preferences from their input
           - Consider mentioned favorite books' themes and styles
           - Factor in any specific requirements (genre, length, content warnings)

        2. Search & Curate üîç
           - Use Exa to search for relevant books
           - Ensure diversity in recommendations
           - Verify all book data is current and accurate

        3. Detailed Information üìù
           - Book title and author
           - Publication year
           - Genre and subgenres
           - Goodreads/StoryGraph rating
           - Page count
           - Brief, engaging plot summary
           - Content advisories
           - Awards and recognition

        4. Extra Features ‚ú®
           - Include series information if applicable
           - Suggest similar authors
           - Mention audiobook availability
           - Note any upcoming adaptations

        Presentation Style:
        - Use clear markdown formatting
        - Present main recommendations in a structured table
        - Group similar books together
        - Add emoji indicators for genres (üìö üîÆ üíï üî™)
        - Minimum 5 recommendations per query
        - Include a brief explanation for each recommendation
        - Highlight diversity in authors and perspectives
        - Note trigger warnings when relevant"""),
    markdown=True,
    add_datetime_to_context=True,
    )

# Example usage with different types of book queries
book_recommendation_agent.print_response(
    "I really enjoyed 'Anxious People' and 'Lessons in Chemistry', can you suggest similar books?",
    stream=True,
)

# More example prompts to explore:
"""
Genre-specific queries:
1. "Recommend contemporary literary fiction like 'Beautiful World, Where Are You'"
2. "What are the best fantasy series completed in the last 5 years?"
3. "Find me atmospheric gothic novels like 'Mexican Gothic' and 'Ninth House'"
4. "What are the most acclaimed debut novels from this year?"

Contemporary Issues:
1. "Suggest books about climate change that aren't too depressing"
2. "What are the best books about artificial intelligence for non-technical readers?"
3. "Recommend memoirs about immigrant experiences"
4. "Find me books about mental health with hopeful endings"

Book Club Selections:
1. "What are good book club picks that spark discussion?"
2. "Suggest literary fiction under 350 pages"
3. "Find thought-provoking novels that tackle current social issues"
4. "Recommend books with multiple perspectives/narratives"

Upcoming Releases:
1. "What are the most anticipated literary releases next month?"
2. "Show me upcoming releases from my favorite authors"
3. "What debut novels are getting buzz this season?"
4. "List upcoming books being adapted for screen"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python books_recommender.py
    ```
  </Step>
</Steps>


# Competitor Analysis Agent
Source: https://docs.agno.com/examples/use-cases/agents/competitor_analysis_agent



This example demonstrates how to build a sophisticated competitor analysis agent that combines powerful search and scraping capabilities with advanced reasoning tools to provide
comprehensive competitive intelligence. The agent performs deep analysis of competitors including
market positioning, product offerings, and strategic insights.

Key capabilities:

* Company discovery using Firecrawl search
* Website scraping and content analysis
* Competitive intelligence gathering
* SWOT analysis with reasoning
* Strategic recommendations
* Structured thinking and analysis

Example queries to try:

* "Analyze OpenAI's main competitors in the LLM space"
* "Compare Uber vs Lyft in the ride-sharing market"
* "Analyze Tesla's competitive position vs traditional automakers"
* "Research fintech competitors to Stripe"
* "Analyze Nike vs Adidas in the athletic apparel market"

## Code

```python cookbook/examples/agents/competitor_analysis_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.firecrawl import FirecrawlTools
from agno.tools.reasoning import ReasoningTools

competitor_analysis_agent = Agent(
    model=OpenAIChat(id="gpt-4.1"),
    tools=[
        FirecrawlTools(
            search=True,
            crawl=True,
            mapping=True,
            formats=["markdown", "links", "html"],
            search_params={
                "limit": 2,
            },
            limit=5,
        ),
        ReasoningTools(
            add_instructions=True,
        ),
    ],
    instructions=[
        "1. Initial Research & Discovery:",
        "   - Use search tool to find information about the target company",
        "   - Search for '[company name] competitors', 'companies like [company name]'",
        "   - Search for industry reports and market analysis",
        "   - Use the think tool to plan your research approach",
        "2. Competitor Identification:",
        "   - Search for each identified competitor using Firecrawl",
        "   - Find their official websites and key information sources",
        "   - Map out the competitive landscape",
        "3. Website Analysis:",
        "   - Scrape competitor websites using Firecrawl",
        "   - Map their site structure to understand their offerings",
        "   - Extract product information, pricing, and value propositions",
        "   - Look for case studies and customer testimonials",
        "4. Deep Competitive Analysis:",
        "   - Use the analyze tool after gathering information on each competitor",
        "   - Compare features, pricing, and market positioning",
        "   - Identify patterns and competitive dynamics",
        "   - Think through the implications of your findings",
        "5. Strategic Synthesis:",
        "   - Conduct SWOT analysis for each major competitor",
        "   - Use reasoning to identify competitive advantages",
        "   - Analyze market trends and opportunities",
        "   - Develop strategic recommendations",
        "- Always use the think tool before starting major research phases",
        "- Use the analyze tool to process findings and draw insights",
        "- Search for multiple perspectives on each competitor",
        "- Verify information by checking multiple sources",
        "- Be thorough but focused in your analysis",
        "- Provide evidence-based recommendations",
    ],
    expected_output=dedent("""\
    # Competitive Analysis Report: {Target Company}

    ## Executive Summary
    {High-level overview of competitive landscape and key findings}

    ## Research Methodology
    - Search queries used
    - Websites analyzed
    - Key information sources

    ## Market Overview
    ### Industry Context
    - Market size and growth rate
    - Key trends and drivers
    - Regulatory environment

    ### Competitive Landscape
    - Major players identified
    - Market segmentation
    - Competitive dynamics

    ## Competitor Analysis

    ### Competitor 1: {Name}
    #### Company Overview
    - Website: {URL}
    - Founded: {Year}
    - Headquarters: {Location}
    - Company size: {Employees/Revenue if available}

    #### Products & Services
    - Core offerings
    - Key features and capabilities
    - Pricing model and tiers
    - Target market segments

    #### Digital Presence Analysis
    - Website structure and user experience
    - Key messaging and value propositions
    - Content strategy and resources
    - Customer proof points

    #### SWOT Analysis
    **Strengths:**
    - {Evidence-based strengths}

    **Weaknesses:**
    - {Identified weaknesses}

    **Opportunities:**
    - {Market opportunities}

    **Threats:**
    - {Competitive threats}

    ### Competitor 2: {Name}
    {Similar structure as above}

    ### Competitor 3: {Name}
    {Similar structure as above}

    ## Comparative Analysis

    ### Feature Comparison Matrix
    | Feature | {Target} | Competitor 1 | Competitor 2 | Competitor 3 |
    |---------|----------|--------------|--------------|--------------|
    | {Feature 1} | ‚úì/‚úó | ‚úì/‚úó | ‚úì/‚úó | ‚úì/‚úó |
    | {Feature 2} | ‚úì/‚úó | ‚úì/‚úó | ‚úì/‚úó | ‚úì/‚úó |

    ### Pricing Comparison
    | Company | Entry Level | Professional | Enterprise |
    |---------|-------------|--------------|------------|
    | {Pricing details extracted from websites} |

    ### Market Positioning Analysis
    {Analysis of how each competitor positions themselves}

    ## Strategic Insights

    ### Key Findings
    1. {Major insight with evidence}
    2. {Competitive dynamics observed}
    3. {Market gaps identified}

    ### Competitive Advantages
    - {Target company's advantages}
    - {Unique differentiators}

    ### Competitive Risks
    - {Main threats from competitors}
    - {Market challenges}

    ## Strategic Recommendations

    ### Immediate Actions (0-3 months)
    1. {Quick competitive responses}
    2. {Low-hanging fruit opportunities}

    ### Short-term Strategy (3-12 months)
    1. {Product/service enhancements}
    2. {Market positioning adjustments}

    ### Long-term Strategy (12+ months)
    1. {Sustainable differentiation}
    2. {Market expansion opportunities}

    ## Conclusion
    {Summary of competitive position and strategic imperatives}
    """),
    markdown=True,
    add_datetime_to_context=True,
    stream_intermediate_steps=True,
)

competitor_analysis_agent.print_response(
    """Analyze the competitive landscape for Stripe in the payments industry.
    Focus on their products, pricing models, and market positioning.""",
    stream=True,
    show_full_reasoning=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=****
    export FIRECRAWL_API_KEY=****
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai firecrawl-py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/competitor_analysis_agent.py
      ```

      ```bash Windows
      python cookbook/examples/agents/competitor_analysis_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Deep Knowledge
Source: https://docs.agno.com/examples/use-cases/agents/deep_knowledge



This agent performs iterative searches through its knowledge base, breaking down complex
queries into sub-questions, and synthesizing comprehensive answers. It's designed to explore
topics deeply and thoroughly by following chains of reasoning.

In this example, the agent uses the Agno documentation as a knowledge base

Key Features:

* Iteratively searches a knowledge base
* Source attribution and citations

## Code

```python cookbook/examples/agents/deep_knowledge.py
from textwrap import dedent
from typing import List, Optional

import inquirer
import typer
from agno.agent import Agent
from agno.db.base import SessionType
from agno.db.sqlite import SqliteDb
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType
from rich import print


def initialize_knowledge_base():
    """Initialize the knowledge base with your preferred documentation or knowledge source
    Here we use Agno docs as an example, but you can replace with any relevant URLs
    """
    agent_knowledge = Knowledge(
        vector_db=LanceDb(
            uri="tmp/lancedb",
            table_name="deep_knowledge_knowledge",
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        ),
    )
    agent_knowledge.add_content(
        url="https://docs.agno.com/llms-full.txt",
    )
    return agent_knowledge


def get_agent_db():
    """Return agent storage"""
    return SqliteDb(session_table="deep_knowledge_sessions", db_file="tmp/agents.db")


def create_agent(session_id: Optional[str] = None) -> Agent:
    """Create and return a configured DeepKnowledge agent."""
    agent_knowledge = initialize_knowledge_base()
    agent_db = get_agent_db()
    return Agent(
        name="DeepKnowledge",
        session_id=session_id,
        model=OpenAIChat(id="gpt-5-mini"),
        description=dedent("""\
        You are DeepKnowledge, an advanced reasoning agent designed to provide thorough,
        well-researched answers to any query by searching your knowledge base.

        Your strengths include:
        - Breaking down complex topics into manageable components
        - Connecting information across multiple domains
        - Providing nuanced, well-researched answers
        - Maintaining intellectual honesty and citing sources
        - Explaining complex concepts in clear, accessible terms"""),
        instructions=dedent("""\
        Your mission is to leave no stone unturned in your pursuit of the correct answer.

        To achieve this, follow these steps:
        1. **Analyze the input and break it down into key components**.
        2. **Search terms**: You must identify at least 3-5 key search terms to search for.
        3. **Initial Search:** Searching your knowledge base for relevant information. You must make atleast 3 searches to get all relevant information.
        4. **Evaluation:** If the answer from the knowledge base is incomplete, ambiguous, or insufficient - Ask the user for clarification. Do not make informed guesses.
        5. **Iterative Process:**
            - Continue searching your knowledge base till you have a comprehensive answer.
            - Reevaluate the completeness of your answer after each search iteration.
            - Repeat the search process until you are confident that every aspect of the question is addressed.
        4. **Reasoning Documentation:** Clearly document your reasoning process:
            - Note when additional searches were triggered.
            - Indicate which pieces of information came from the knowledge base and where it was sourced from.
            - Explain how you reconciled any conflicting or ambiguous information.
        5. **Final Synthesis:** Only finalize and present your answer once you have verified it through multiple search passes.
            Include all pertinent details and provide proper references.
        6. **Continuous Improvement:** If new, relevant information emerges even after presenting your answer,
            be prepared to update or expand upon your response.

        **Communication Style:**
        - Use clear and concise language.
        - Organize your response with numbered steps, bullet points, or short paragraphs as needed.
        - Be transparent about your search process and cite your sources.
        - Ensure that your final answer is comprehensive and leaves no part of the query unaddressed.

        Remember: **Do not finalize your answer until every angle of the question has been explored.**"""),
        additional_context=dedent("""\
        You should only respond with the final answer and the reasoning process.
        No need to include irrelevant information.

        - User ID: {user_id}
        - Memory: You have access to your previous search results and reasoning process.
        """),
        knowledge=agent_knowledge,
        db=agent_db,
        add_history_to_context=True,
        num_history_runs=3,
        read_chat_history=True,
        markdown=True,
    )


def get_example_topics() -> List[str]:
    """Return a list of example topics for the agent."""
    return [
        "What are AI agents and how do they work in Agno?",
        "What chunking strategies does Agno support for text processing?",
        "How can I implement custom tools in Agno?",
        "How does knowledge retrieval work in Agno?",
        "What types of embeddings does Agno support?",
    ]


def handle_session_selection() -> Optional[str]:
    """Handle session selection and return the selected session ID."""
    agent_db = get_agent_db()

    new = typer.confirm("Do you want to start a new session?", default=True)
    if new:
        return None

    existing_sessions: List[str] = agent_db.get_sessions(session_type=SessionType.AGENT)
    if not existing_sessions:
        print("No existing sessions found. Starting a new session.")
        return None

    print("\nExisting sessions:")
    for i, session in enumerate(existing_sessions, 1):
        print(f"{i}. {session}")

    session_idx = typer.prompt(
        "Choose a session number to continue (or press Enter for most recent)",
        default=1,
    )

    try:
        return existing_sessions[int(session_idx) - 1]
    except (ValueError, IndexError):
        return existing_sessions[0]


def run_interactive_loop(agent: Agent):
    """Run the interactive question-answering loop."""
    example_topics = get_example_topics()

    while True:
        choices = [f"{i + 1}. {topic}" for i, topic in enumerate(example_topics)]
        choices.extend(["Enter custom question...", "Exit"])

        questions = [
            inquirer.List(
                "topic",
                message="Select a topic or ask a different question:",
                choices=choices,
            )
        ]
        answer = inquirer.prompt(questions)

        if answer["topic"] == "Exit":
            break

        if answer["topic"] == "Enter custom question...":
            questions = [inquirer.Text("custom", message="Enter your question:")]
            custom_answer = inquirer.prompt(questions)
            topic = custom_answer["custom"]
        else:
            topic = example_topics[int(answer["topic"].split(".")[0]) - 1]

        agent.print_response(topic, stream=True)


def deep_knowledge_agent():
    """Main function to run the DeepKnowledge agent."""

    session_id = handle_session_selection()
    agent = create_agent(session_id)

    print("\nü§î Welcome to DeepKnowledge - Your Advanced Research Assistant! üìö")
    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"[bold green]Started New Session: {session_id}[/bold green]\n")
        else:
            print("[bold green]Started New Session[/bold green]\n")
    else:
        print(f"[bold blue]Continuing Previous Session: {session_id}[/bold blue]\n")

    run_interactive_loop(agent)


if __name__ == "__main__":
    typer.run(deep_knowledge_agent)

# Example prompts to try:
"""
Explore Agno's capabilities with these queries:
1. "What are the different types of agents in Agno?"
2. "How does Agno handle knowledge base management?"
3. "What embedding models does Agno support?"
4. "How can I implement custom tools in Agno?"
5. "What storage options are available for workflow caching?"
6. "How does Agno handle streaming responses?"
7. "What types of LLM providers does Agno support?"
8. "How can I implement custom knowledge sources?"
"""

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai lancedb tantivy inquirer
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/deep_knowledge.py
      ```

      ```bash Windows
      python cookbook/examples/agents/deep_knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Deep Research Agent
Source: https://docs.agno.com/examples/use-cases/agents/deep_research_agent_exa



This example demonstrates how to use the Exa research tool for complex,
structured research tasks with automatic citation tracking.

## Code

```python cookbook/examples/agents/deep_research_agent_exa.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ExaTools(research=True, research_model="exa-research-pro")],
    instructions=dedent("""
        You are an expert research analyst with access to advanced research tools.
        
        When you are given a schema to use, pass it to the research tool as output_schema parameter to research tool. 

        The research tool has two parameters:
        - instructions (str): The research topic/question 
        - output_schema (dict, optional): A JSON schema for structured output

        Example: If user says "Research X. Use this schema {'type': 'object', ...}", you must call research tool with the schema.

        If no schema is provided, the tool will auto-infer an appropriate schema.

        Present the findings exactly as provided by the research tool.
    """),
)

# Example 1: Basic research with simple string
agent.print_response(
    "Perform a comprehensive research on the current flagship GPUs from NVIDIA, AMD and Intel. Return a table of model name, MSRP USD, TDP watts, and launch date. Include citations for each cell."
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export EXA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai exa_py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/deep_research_agent_exa.py
      ```

      ```bash Windows
      python cookbook/examples/agents/deep_research_agent_exa.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Legal Consultant
Source: https://docs.agno.com/examples/use-cases/agents/legal_consultant



This example demonstrates how to create a specialized AI agent that provides legal information and guidance based on a knowledge base of legal documents. The Legal Consultant agent is designed to help users understand legal concepts, consequences, and procedures by leveraging a vector database of legal content.

**Key Features:**

* **Legal Knowledge Base**: Integrates with a PostgreSQL vector database containing legal documents and resources
* **Document Processing**: Automatically ingests and indexes legal PDFs from authoritative sources (e.g., Department of Justice manuals)
* **Contextual Responses**: Provides relevant legal information with proper citations and sources
* **Professional Disclaimers**: Always clarifies that responses are for informational purposes only, not professional legal advice
* **Attorney Referrals**: Recommends consulting licensed attorneys for specific legal situations

**Use Cases:**

* Legal research and education
* Understanding criminal penalties and consequences
* Learning about legal procedures and requirements
* Getting preliminary legal information before consulting professionals

## Code

```python cookbook/examples/agents/legal_consultant.py
import asyncio

from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge = Knowledge(
    vector_db=PgVector(table_name="legal_docs", db_url=db_url),
)

asyncio.run(
    knowledge.add_content_async(
        url="https://www.justice.gov/d9/criminal-ccips/legacy/2015/01/14/ccmanual_0.pdf",
    )
)

legal_agent = Agent(
    name="LegalAdvisor",
    knowledge=knowledge,
    search_knowledge=True,
    model=OpenAIChat(id="gpt-5-mini"),
    markdown=True,
    instructions=[
        "Provide legal information and advice based on the knowledge base.",
        "Include relevant legal citations and sources when answering questions.",
        "Always clarify that you're providing general legal information, not professional legal advice.",
        "Recommend consulting with a licensed attorney for specific legal situations.",
    ],
)

legal_agent.print_response(
    "What are the legal consequences and criminal penalties for spoofing Email Address?",
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno sqlalchemy openai psycopg
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/legal_consultant.py
      ```

      ```bash Windows
      python cookbook/examples/agents/legal_consultant.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Media Trend Analysis Agent
Source: https://docs.agno.com/examples/use-cases/agents/media_trend_analysis_agent



The Media Trend Analysis Agent Example demonstrates a sophisticated AI-powered tool designed to analyze media trends, track digital conversations, and provide actionable insights across various online platforms. This agent combines web search capabilities with content scraping to deliver comprehensive trend analysis reports.

### What It Does

This agent specializes in:

* **Trend Identification**: Detects emerging patterns and shifts in media coverage
* **Source Analysis**: Identifies key influencers and authoritative sources
* **Data Extraction**: Gathers information from news sites, social platforms, and digital media
* **Insight Generation**: Provides actionable recommendations based on trend analysis
* **Future Forecasting**: Predicts potential developments based on current patterns

### Key Features

* **Multi-Source Analysis**: Combines Exa search tools with Firecrawl scraping capabilities
* **Intelligent Filtering**: Uses keyword-based searches with date filtering for relevant results
* **Smart Scraping**: Only scrapes content when search results are insufficient
* **Structured Reporting**: Generates comprehensive markdown reports with executive summaries
* **Real-time Data**: Analyzes current trends with configurable time windows

## Code

```python cookbook/examples/agents/media_trend_analysis_agent.py
"""Please install dependencies using:
pip install openai exa-py agno firecrawl
"""

from datetime import datetime, timedelta
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools
from agno.tools.firecrawl import FirecrawlTools


def calculate_start_date(days: int) -> str:
    """Calculate start date based on number of days."""
    start_date = datetime.now() - timedelta(days=days)
    return start_date.strftime("%Y-%m-%d")


agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ExaTools(start_published_date=calculate_start_date(30), type="keyword"),
        FirecrawlTools(scrape=True),
    ],
    description=dedent("""\
        You are an expert media trend analyst specializing in:
        1. Identifying emerging trends across news and digital platforms
        2. Recognizing pattern changes in media coverage
        3. Providing actionable insights based on data
        4. Forecasting potential future developments
    """),
    instructions=[
        "Analyze the provided topic according to the user's specifications:",
        "1. Use keywords to perform targeted searches",
        "2. Identify key influencers and authoritative sources",
        "3. Extract main themes and recurring patterns",
        "4. Provide actionable recommendations",
        "5. if got sources less then 2, only then scrape them using firecrawl tool, dont crawl it  and use them to generate the report",
        "6. growth rate should be in percentage , and if not possible dont give growth rate",
    ],
    expected_output=dedent("""\
    # Media Trend Analysis Report

    ## Executive Summary
    {High-level overview of findings and key metrics}

    ## Trend Analysis
    ### Volume Metrics
    - Peak discussion periods: {dates}
    - Growth rate: {percentage or dont show this}

    ## Source Analysis
    ### Top Sources
    1. {Source 1}

    2. {Source 2}


    ## Actionable Insights
    1. {Insight 1}
       - Evidence: {data points}
       - Recommended action: {action}

    ## Future Predictions
    1. {Prediction 1}
       - Supporting evidence: {evidence}

    ## References
    {Detailed source list with links}
    """),
    markdown=True,
    add_datetime_to_context=True,
)

# Example usage:
analysis_prompt = """\
Analyze media trends for:
Keywords: ai agents
Sources: verge.com ,linkedin.com, x.com
"""

agent.print_response(analysis_prompt, stream=True)

# Alternative prompt example
crypto_prompt = """\
Analyze media trends for:
Keywords: cryptocurrency, bitcoin, ethereum
Sources: coindesk.com, cointelegraph.com
"""

# agent.print_response(crypto_prompt, stream=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export EXA_API_KEY=xxx
    export FIRECRAWL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai exa-py agno firecrawl
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/media_trend_analysis_agent.py
      ```

      ```bash Windows
      python cookbook/examples/agents/media_trend_analysis_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>

## Customization Options

You can customize the agent's behavior by:

* **Adjusting Time Windows**: Modify the `calculate_start_date()` function to analyze different time periods
* **Adding Sources**: Include additional websites or platforms in your analysis prompts
* **Modifying Keywords**: Change search terms to focus on specific topics or industries
* **Customizing Output**: Modify the `expected_output` template to match your reporting needs

## Example Prompts

Here are some additional prompt examples you can try:

```python
# Technology trends
tech_prompt = """\
Analyze media trends for:
Keywords: artificial intelligence, machine learning, automation
Sources: techcrunch.com, arstechnica.com, wired.com
"""

# Business trends
business_prompt = """\
Analyze media trends for:
Keywords: remote work, digital transformation, sustainability
Sources: forbes.com, bloomberg.com, hbr.org
"""

# Entertainment trends
entertainment_prompt = """\
Analyze media trends for:
Keywords: streaming, gaming, social media
Sources: variety.com, polygon.com, theverge.com
"""
```


# Meeting Summarizer Agent
Source: https://docs.agno.com/examples/use-cases/agents/meeting_summarizer_agent



This agent uses OpenAITools (transcribe\_audio, generate\_image, generate\_speech)
to process a meeting recording, summarize it, visualize it, and create an audio summary.

## Code

```python cookbook/examples/agents/meeting_summarizer_agent.py
"""Example: Meeting Summarizer & Visualizer Agent

This script uses OpenAITools (transcribe_audio, generate_image, generate_speech)
to process a meeting recording, summarize it, visualize it, and create an audio summary.

Requires: pip install openai agno
"""

import base64
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.openai import OpenAITools
from agno.tools.reasoning import ReasoningTools
from agno.utils.media import download_file, save_base64_data

input_audio_url: str = (
    "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/sample_audio.mp3"
)

local_audio_path = Path("tmp/meeting_recording.mp3")
print(f"Downloading file to local path: {local_audio_path}")
download_file(input_audio_url, local_audio_path)

meeting_agent: Agent = Agent(
    model=Gemini(id="gemini-2.0-flash"),
    tools=[OpenAITools(), ReasoningTools()],
    description=dedent("""\
        You are an efficient Meeting Assistant AI.
        Your purpose is to process audio recordings of meetings, extract key information,
        create a visual representation, and provide an audio summary.
    """),
    instructions=dedent("""\
        Follow these steps precisely:
        1. Receive the path to an audio file.
        2. Use the `transcribe_audio` tool to get the text transcription.
        3. Analyze the transcription and write a concise summary highlighting key discussion points, decisions, and action items.
        4. Based *only* on the summary created in step 3, generating important meeting points. This should be a essentially an overview of the summary's content properly ordered and formatted in the form of meeting minutes.
        5. Convert the meeting minutes into an audio summary using the `generate_speech` tool.
    """),
    markdown=True,
)

response = meeting_agent.run(
    f"Please process the meeting recording located at '{local_audio_path}'"
)
if response.audio:
    base64_audio = base64.b64encode(response.audio[0].content).decode("utf-8")
    save_base64_data(base64_audio, Path("tmp/meeting_summary.mp3"))
    print(f"Meeting summary saved to: {Path('tmp/meeting_summary.mp3')}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai google-genai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/meeting_summarizer_agent.py
      ```

      ```bash Windows
      python cookbook/examples/agents/meeting_summarizer_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Movie Recommender
Source: https://docs.agno.com/examples/use-cases/agents/movie-recommender



This example shows how to create an intelligent movie recommendation system that provides
comprehensive film suggestions based on your preferences. The agent combines movie databases,
ratings, reviews, and upcoming releases to deliver personalized movie recommendations.

Example prompts to try:

* "Suggest thriller movies similar to Inception and Shutter Island"
* "What are the top-rated comedy movies from the last 2 years?"
* "Find me Korean movies similar to Parasite and Oldboy"
* "Recommend family-friendly adventure movies with good ratings"
* "What are the upcoming superhero movies in the next 6 months?"

## Code

```python movie_recommender.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

movie_recommendation_agent = Agent(
    name="PopcornPal",
    tools=[ExaTools()],
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
        You are PopcornPal, a passionate and knowledgeable film curator with expertise in cinema worldwide! üé•

        Your mission is to help users discover their next favorite movies by providing detailed,
        personalized recommendations based on their preferences, viewing history, and the latest
        in cinema. You combine deep film knowledge with current ratings and reviews to suggest
        movies that will truly resonate with each viewer."""),
    instructions=dedent("""\
        Approach each recommendation with these steps:
        1. Analysis Phase
           - Understand user preferences from their input
           - Consider mentioned favorite movies' themes and styles
           - Factor in any specific requirements (genre, rating, language)

        2. Search & Curate
           - Use Exa to search for relevant movies
           - Ensure diversity in recommendations
           - Verify all movie data is current and accurate

        3. Detailed Information
           - Movie title and release year
           - Genre and subgenres
           - IMDB rating (focus on 7.5+ rated films)
           - Runtime and primary language
           - Brief, engaging plot summary
           - Content advisory/age rating
           - Notable cast and director

        4. Extra Features
           - Include relevant trailers when available
           - Suggest upcoming releases in similar genres
           - Mention streaming availability when known

        Presentation Style:
        - Use clear markdown formatting
        - Present main recommendations in a structured table
        - Group similar movies together
        - Add emoji indicators for genres (üé≠ üé¨ üé™)
        - Minimum 5 recommendations per query
        - Include a brief explanation for each recommendation
    """),
    markdown=True,
    add_datetime_to_context=True,
    )

# Example usage with different types of movie queries
movie_recommendation_agent.print_response(
    "Suggest some thriller movies to watch with a rating of 8 or above on IMDB. "
    "My previous favourite thriller movies are The Dark Knight, Venom, Parasite, Shutter Island.",
    stream=True,
)
```

## More example prompts to explore:

**Genre-specific queries:**

1. "Find me psychological thrillers similar to Black Swan and Gone Girl"
2. "What are the best animated movies from Studio Ghibli?"
3. "Recommend some mind-bending sci-fi movies like Inception and Interstellar"
4. "What are the highest-rated crime documentaries from the last 5 years?"

**International Cinema:**

1. "Suggest Korean movies similar to Parasite and Train to Busan"
2. "What are the must-watch French films from the last decade?"
3. "Recommend Japanese animated movies for adults"
4. "Find me award-winning European drama films"

**Family & Group Watching:**

1. "What are good family movies for kids aged 8-12?"
2. "Suggest comedy movies perfect for a group movie night"
3. "Find educational documentaries suitable for teenagers"
4. "Recommend adventure movies that both adults and children would enjoy"

**Upcoming Releases:**

1. "What are the most anticipated movies coming out next month?"
2. "Show me upcoming superhero movie releases"
3. "What horror movies are releasing this Halloween season?"
4. "List upcoming book-to-movie adaptations"

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python movie_recommender.py
    ```
  </Step>
</Steps>


# Readme Generator
Source: https://docs.agno.com/examples/use-cases/agents/readme_generator



The README Generator Agent is an intelligent automation tool that creates comprehensive, professional README files for open source projects. This agent leverages the power of AI to analyze GitHub repositories and generate well-structured documentation automatically.

## Code

```python cookbook/examples/agents/readme_generator.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.github import GithubTools
from agno.tools.local_file_system import LocalFileSystemTools

readme_gen_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    name="Readme Generator Agent",
    tools=[GithubTools(), LocalFileSystemTools()],
    markdown=True,
    instructions=[
        "You are readme generator agent",
        "You'll be given repository url or repository name from user."
        "You'll use the `get_repository` tool to get the repository details."
        "You have to pass the repo_name as argument to the tool. It should be in the format of owner/repo_name. If given url extract owner/repo_name from it."
        "Also call the `get_repository_languages` tool to get the languages used in the repository."
        "Write a useful README for a open source project, including how to clone and install the project, run the project etc. Also add badges for the license, size of the repo, etc"
        "Don't include the project's languages-used in the README"
        "Write the produced README to the local filesystem",
    ],
)

readme_gen_agent.print_response(
    "Get details of https://github.com/agno-agi/agno", markdown=True
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export GITHUB_ACCESS_TOKEN=xxx

    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno PyGithub
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/readme_generator.py
      ```

      ```bash Windows
      python cookbook/examples/agents/readme_generator.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Recipe Creator
Source: https://docs.agno.com/examples/use-cases/agents/recipe-creator



This example shows how to create an intelligent recipe recommendation system that provides
detailed, personalized recipes based on your ingredients, dietary preferences, and time constraints.
The agent combines culinary knowledge, nutritional data, and cooking techniques to deliver
comprehensive cooking instructions.

Example prompts to try:

* "I have chicken, rice, and vegetables. What can I make in 30 minutes?"
* "Create a vegetarian pasta recipe with mushrooms and spinach"
* "Suggest healthy breakfast options with oats and fruits"
* "What can I make with leftover turkey and potatoes?"
* "Need a quick dessert recipe using chocolate and bananas"

## Code

```python recipe_creator.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

recipe_agent = Agent(
    name="ChefGenius",
    tools=[ExaTools()],
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
        You are ChefGenius, a passionate and knowledgeable culinary expert with expertise in global cuisine! üç≥

        Your mission is to help users create delicious meals by providing detailed,
        personalized recipes based on their available ingredients, dietary restrictions,
        and time constraints. You combine deep culinary knowledge with nutritional wisdom
        to suggest recipes that are both practical and enjoyable."""),
    instructions=dedent("""\
        Approach each recipe recommendation with these steps:

        1. Analysis Phase üìã
           - Understand available ingredients
           - Consider dietary restrictions
           - Note time constraints
           - Factor in cooking skill level
           - Check for kitchen equipment needs

        2. Recipe Selection üîç
           - Use Exa to search for relevant recipes
           - Ensure ingredients match availability
           - Verify cooking times are appropriate
           - Consider seasonal ingredients
           - Check recipe ratings and reviews

        3. Detailed Information üìù
           - Recipe title and cuisine type
           - Preparation time and cooking time
           - Complete ingredient list with measurements
           - Step-by-step cooking instructions
           - Nutritional information per serving
           - Difficulty level
           - Serving size
           - Storage instructions

        4. Extra Features ‚ú®
           - Ingredient substitution options
           - Common pitfalls to avoid
           - Plating suggestions
           - Wine pairing recommendations
           - Leftover usage tips
           - Meal prep possibilities

        Presentation Style:
        - Use clear markdown formatting
        - Present ingredients in a structured list
        - Number cooking steps clearly
        - Add emoji indicators for:
          üå± Vegetarian
          üåø Vegan
          üåæ Gluten-free
          ü•ú Contains nuts
          ‚è±Ô∏è Quick recipes
        - Include tips for scaling portions
        - Note allergen warnings
        - Highlight make-ahead steps
        - Suggest side dish pairings"""),
    markdown=True,
    add_datetime_to_context=True,
    )

# Example usage with different types of recipe queries
recipe_agent.print_response(
    "I have chicken breast, broccoli, garlic, and rice. Need a healthy dinner recipe that takes less than 45 minutes.",
    stream=True,
)

# More example prompts to explore:
"""
Quick Meals:
1. "15-minute dinner ideas with pasta and vegetables"
2. "Quick healthy lunch recipes for meal prep"
3. "Easy breakfast recipes with eggs and avocado"
4. "No-cook dinner ideas for hot summer days"

Dietary Restrictions:
1. "Keto-friendly dinner recipes with salmon"
2. "Gluten-free breakfast options without eggs"
3. "High-protein vegetarian meals for athletes"
4. "Low-carb alternatives to pasta dishes"

Special Occasions:
1. "Impressive dinner party main course for 6 people"
2. "Romantic dinner recipes for two"
3. "Kid-friendly birthday party snacks"
4. "Holiday desserts that can be made ahead"

International Cuisine:
1. "Authentic Thai curry with available ingredients"
2. "Simple Japanese recipes for beginners"
3. "Mediterranean diet dinner ideas"
4. "Traditional Mexican recipes with modern twists"

Seasonal Cooking:
1. "Summer salad recipes with seasonal produce"
2. "Warming winter soups and stews"
3. "Fall harvest vegetable recipes"
4. "Spring picnic recipe ideas"

Batch Cooking:
1. "Freezer-friendly meal prep recipes"
2. "One-pot meals for busy weeknights"
3. "Make-ahead breakfast ideas"
4. "Bulk cooking recipes for large families"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai exa_py
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python recipe_creator.py
    ```
  </Step>
</Steps>


# Recipe Rag Image
Source: https://docs.agno.com/examples/use-cases/agents/recipe_rag_image



An agent that uses Llama 4 for multi-modal RAG and OpenAITools to create a visual, step-by-step image manual for a recipe.

## Code

```python cookbook/examples/agents/recipe_rag_image.py
import asyncio
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.embedder.cohere import CohereEmbedder
from agno.knowledge.knowledge import Knowledge

# from agno.models.groq import Groq
from agno.tools.openai import OpenAITools
from agno.utils.media import download_image
from agno.vectordb.pgvector import PgVector

knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="embed_vision_documents",
        embedder=CohereEmbedder(
            id="embed-v4.0",
        ),
    ),
)

asyncio.run(
    knowledge.add_content_async(
        url="https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf",
    )
)

agent = Agent(
    name="EmbedVisionRAGAgent",
    model=Groq(id="meta-llama/llama-4-scout-17b-16e-instruct"),
    tools=[OpenAITools()],
    knowledge=knowledge,
    instructions=[
        "You are a specialized recipe assistant.",
        "When asked for a recipe:",
        "1. Search the knowledge base to retrieve the relevant recipe details.",
        "2. Analyze the retrieved recipe steps carefully.",
        "3. Use the `generate_image` tool to create a visual, step-by-step image manual for the recipe.",
        "4. Present the recipe text clearly and mention that you have generated an accompanying image manual. Add instructions while generating the image.",
    ],
    markdown=True,
)

agent.print_response(
    "What is the recipe for a Thai curry?",
)
response = agent.get_last_run_output()

if response.images:
    download_image(response.images[0].url, Path("tmp/recipe_image.png"))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai groq cohere
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/recipe_rag_image.py
      ```

      ```bash Windows
      python cookbook/examples/agents/recipe_rag_image.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reddit Post Generator
Source: https://docs.agno.com/examples/use-cases/agents/reddit-post-generator



**Reddit Post Generator** is a team of agents that can research topics on the web and make posts for a subreddit on Reddit.

Create a file `reddit_post_generator_team.py` with the following code:

```python reddit_post_generator_team.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reddit import RedditTools

web_searcher = Agent(
    name="Web Searcher",
    role="Searches the web for information on a topic",
    description="An intelligent agent that performs comprehensive web searches to gather current and accurate information",
    tools=[DuckDuckGoTools()],
    instructions=[
        "1. Perform focused web searches using relevant keywords",
        "2. Filter results for credibility and recency",
        "3. Extract key information and main points",
        "4. Organize information in a logical structure",
        "5. Verify facts from multiple sources when possible",
        "6. Focus on authoritative and reliable sources",
    ],
)

reddit_agent = Agent(
    name="Reddit Agent",
    role="Uploads post on Reddit",
    description="Specialized agent for crafting and publishing engaging Reddit posts",
    tools=[RedditTools()],
    instructions=[
        "1. Get information regarding the subreddit",
        "2. Create attention-grabbing yet accurate titles",
        "3. Format posts using proper Reddit markdown",
        "4. Avoid including links ",
        "5. Follow subreddit-specific rules and guidelines",
        "6. Structure content for maximum readability",
        "7. Add appropriate tags and flairs if required",
    ],
    )

post_team = Agent(
    team=[web_searcher, reddit_agent],
    instructions=[
        "Work together to create engaging and informative Reddit posts",
        "Start by researching the topic thoroughly using web searches",
        "Craft a well-structured post with accurate information and sources",
        "Follow Reddit guidelines and best practices for posting",
    ],
        markdown=True,
)

post_team.print_response(
    "Create a post on web technologies and frameworks to focus in 2025 on the subreddit r/webdev ",
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai praw ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export REDDIT_CLIENT_ID=****
    export REDDIT_CLIENT_SECRET=****
    export REDDIT_USERNAME=****
    export REDDIT_PASSWORD=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python reddit_post_generator_team.py
    ```
  </Step>
</Steps>


# Research Agent
Source: https://docs.agno.com/examples/use-cases/agents/research-agent



This example shows how to create a sophisticated research agent that combines
web search capabilities with professional journalistic writing skills. The agent performs
comprehensive research using multiple sources, fact-checks information, and delivers
well-structured, NYT-style articles on any topic.

Key capabilities:

* Advanced web search across multiple sources
* Content extraction and analysis
* Cross-reference verification
* Professional journalistic writing
* Balanced and objective reporting

Example prompts to try:

* "Analyze the impact of AI on healthcare delivery and patient outcomes"
* "Report on the latest breakthroughs in quantum computing"
* "Investigate the global transition to renewable energy sources"
* "Explore the evolution of cybersecurity threats and defenses"
* "Research the development of autonomous vehicle technology"

## Code

```python research_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools

# Initialize the research agent with advanced journalistic capabilities
research_agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(), Newspaper4kTools()],
    description=dedent("""\
        You are an elite investigative journalist with decades of experience at the New York Times.
        Your expertise encompasses: üì∞

        - Deep investigative research and analysis
        - Meticulous fact-checking and source verification
        - Compelling narrative construction
        - Data-driven reporting and visualization
        - Expert interview synthesis
        - Trend analysis and future predictions
        - Complex topic simplification
        - Ethical journalism practices
        - Balanced perspective presentation
        - Global context integration\
    """),
    instructions=dedent("""\
        1. Research Phase üîç
           - Search for 10+ authoritative sources on the topic
           - Prioritize recent publications and expert opinions
           - Identify key stakeholders and perspectives

        2. Analysis Phase üìä
           - Extract and verify critical information
           - Cross-reference facts across multiple sources
           - Identify emerging patterns and trends
           - Evaluate conflicting viewpoints

        3. Writing Phase ‚úçÔ∏è
           - Craft an attention-grabbing headline
           - Structure content in NYT style
           - Include relevant quotes and statistics
           - Maintain objectivity and balance
           - Explain complex concepts clearly

        4. Quality Control ‚úì
           - Verify all facts and attributions
           - Ensure narrative flow and readability
           - Add context where necessary
           - Include future implications
    """),
    expected_output=dedent("""\
        # {Compelling Headline} üì∞

        ## Executive Summary
        {Concise overview of key findings and significance}

        ## Background & Context
        {Historical context and importance}
        {Current landscape overview}

        ## Key Findings
        {Main discoveries and analysis}
        {Expert insights and quotes}
        {Statistical evidence}

        ## Impact Analysis
        {Current implications}
        {Stakeholder perspectives}
        {Industry/societal effects}

        ## Future Outlook
        {Emerging trends}
        {Expert predictions}
        {Potential challenges and opportunities}

        ## Expert Insights
        {Notable quotes and analysis from industry leaders}
        {Contrasting viewpoints}

        ## Sources & Methodology
        {List of primary sources with key contributions}
        {Research methodology overview}

        ---
        Research conducted by AI Investigative Journalist
        New York Times Style Report
        Published: {current_date}
        Last Updated: {current_time}\
    """),
    markdown=True,
    add_datetime_to_context=True,
)

# Example usage with detailed research request
if __name__ == "__main__":
    research_agent.print_response(
        "Analyze the current state and future implications of artificial intelligence regulation worldwide",
        stream=True,
    )

# Advanced research topics to explore:
"""
Technology & Innovation:
1. "Investigate the development and impact of large language models in 2024"
2. "Research the current state of quantum computing and its practical applications"
3. "Analyze the evolution and future of edge computing technologies"
4. "Explore the latest advances in brain-computer interface technology"

Environmental & Sustainability:
1. "Report on innovative carbon capture technologies and their effectiveness"
2. "Investigate the global progress in renewable energy adoption"
3. "Analyze the impact of circular economy practices on global sustainability"
4. "Research the development of sustainable aviation technologies"

Healthcare & Biotechnology:
1. "Explore the latest developments in CRISPR gene editing technology"
2. "Analyze the impact of AI on drug discovery and development"
3. "Investigate the evolution of personalized medicine approaches"
4. "Research the current state of longevity science and anti-aging research"

Societal Impact:
1. "Examine the effects of social media on democratic processes"
2. "Analyze the impact of remote work on urban development"
3. "Investigate the role of blockchain in transforming financial systems"
4. "Research the evolution of digital privacy and data protection measures"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai ddgs newspaper4k lxml_html_clean agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python research_agent.py
    ```
  </Step>
</Steps>


# Research Agent using Exa
Source: https://docs.agno.com/examples/use-cases/agents/research-agent-exa



This example shows how to create a sophisticated research agent that combines
academic search capabilities with scholarly writing expertise. The agent performs
thorough research using Exa's academic search, analyzes recent publications, and delivers
well-structured, academic-style reports on any topic.

Key capabilities:

* Advanced academic literature search
* Recent publication analysis
* Cross-disciplinary synthesis
* Academic writing expertise
* Citation management

Example prompts to try:

* "Explore recent advances in quantum machine learning"
* "Analyze the current state of fusion energy research"
* "Investigate the latest developments in CRISPR gene editing"
* "Research the intersection of blockchain and sustainable energy"
* "Examine recent breakthroughs in brain-computer interfaces"

## Code

```python research_agent_exa.py
from datetime import datetime
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

# Initialize the academic research agent with scholarly capabilities
research_scholar = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        ExaTools(
            start_published_date=datetime.now().strftime("%Y-%m-%d"), type="keyword"
        )
    ],
    description=dedent("""\
        You are a distinguished research scholar with expertise in multiple disciplines.
        Your academic credentials include: üìö

        - Advanced research methodology
        - Cross-disciplinary synthesis
        - Academic literature analysis
        - Scientific writing excellence
        - Peer review experience
        - Citation management
        - Data interpretation
        - Technical communication
        - Research ethics
        - Emerging trends analysis\
    """),
    instructions=dedent("""\
        1. Research Methodology üîç
           - Conduct 3 distinct academic searches
           - Focus on peer-reviewed publications
           - Prioritize recent breakthrough findings
           - Identify key researchers and institutions

        2. Analysis Framework üìä
           - Synthesize findings across sources
           - Evaluate research methodologies
           - Identify consensus and controversies
           - Assess practical implications

        3. Report Structure üìù
           - Create an engaging academic title
           - Write a compelling abstract
           - Present methodology clearly
           - Discuss findings systematically
           - Draw evidence-based conclusions

        4. Quality Standards ‚úì
           - Ensure accurate citations
           - Maintain academic rigor
           - Present balanced perspectives
           - Highlight future research directions\
    """),
    expected_output=dedent("""\
        # {Engaging Title} üìö

        ## Abstract
        {Concise overview of the research and key findings}

        ## Introduction
        {Context and significance}
        {Research objectives}

        ## Methodology
        {Search strategy}
        {Selection criteria}

        ## Literature Review
        {Current state of research}
        {Key findings and breakthroughs}
        {Emerging trends}

        ## Analysis
        {Critical evaluation}
        {Cross-study comparisons}
        {Research gaps}

        ## Future Directions
        {Emerging research opportunities}
        {Potential applications}
        {Open questions}

        ## Conclusions
        {Summary of key findings}
        {Implications for the field}

        ## References
        {Properly formatted academic citations}

        ---
        Research conducted by AI Academic Scholar
        Published: {current_date}
        Last Updated: {current_time}\
    """),
    markdown=True,
    add_datetime_to_context=True,
    save_response_to_file="tmp/{message}.md",
)

# Example usage with academic research request
if __name__ == "__main__":
    research_scholar.print_response(
        "Analyze recent developments in quantum computing architectures",
        stream=True,
    )

# Advanced research topics to explore:
"""
Quantum Science & Computing:
1. "Investigate recent breakthroughs in quantum error correction"
2. "Analyze the development of topological quantum computing"
3. "Research quantum machine learning algorithms and applications"
4. "Explore advances in quantum sensing technologies"

Biotechnology & Medicine:
1. "Examine recent developments in mRNA vaccine technology"
2. "Analyze breakthroughs in organoid research"
3. "Investigate advances in precision medicine"
4. "Research developments in neurotechnology"

Materials Science:
1. "Explore recent advances in metamaterials"
2. "Analyze developments in 2D materials beyond graphene"
3. "Research progress in self-healing materials"
4. "Investigate new battery technologies"

Artificial Intelligence:
1. "Examine recent advances in foundation models"
2. "Analyze developments in AI safety research"
3. "Research progress in neuromorphic computing"
4. "Investigate advances in explainable AI"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python research_agent_exa.py
    ```
  </Step>
</Steps>


# Run As Cli
Source: https://docs.agno.com/examples/use-cases/agents/run_as_cli



This example shows how to create an interactive CLI app with an agent.

## Code

```python cookbook/examples/agents/run_as_cli.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

writing_assistant = Agent(
    name="Writing Assistant",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=dedent("""\
        You are a friendly and professional writing assistant! 
        
        Your capabilities include:
        - **Brainstorming**: Help generate ideas, topics, and creative concepts
        - **Research**: Find current information and facts to support writing
        - **Editing**: Improve grammar, style, clarity, and flow
        - **Feedback**: Provide constructive suggestions for improvement
        - **Content Creation**: Help write articles, emails, stories, and more
        
        Always:
        - Ask clarifying questions to better understand the user's needs
        - Provide specific, actionable suggestions
        - Maintain an encouraging and supportive tone
        - Use web search when current information is needed
        - Format your responses clearly with headings and lists when helpful
        
        Start conversations by asking what writing project they're working on!
        """),
    markdown=True,
)

if __name__ == "__main__":
    print("üîç I can research topics, help brainstorm, edit text, and more!")
    print("‚úèÔ∏è Type 'exit', 'quit', or 'bye' to end our session.\n")

    writing_assistant.cli_app(
        input="Hello! What writing project are you working on today? I'm here to help with brainstorming, research, editing, or any other writing needs you have!",
        user="Writer",
        emoji="‚úçÔ∏è",
        stream=True,
    )

    ###########################################################################
    # ASYNC CLI APP
    ###########################################################################
    # import asyncio

    # asyncio.run(writing_assistant.acli_app(
    #     input="Hello! What writing project are you working on today? I'm here to help with brainstorming, research, editing, or any other writing needs you have!",
    #     user="Writer",
    #     emoji="‚úçÔ∏è",
    #     stream=True,
    # ))

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno ddgs
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/run_as_cli.py
      ```

      ```bash Windows
      python cookbook/examples/agents/run_as_cli.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Shopping Partner
Source: https://docs.agno.com/examples/use-cases/agents/shopping_partner



The Shopping Partner agent is an AI-powered product recommendation system that helps users find the perfect products based on their specific preferences and requirements. This agent specializes in:

* **Smart Product Matching**: Analyzes user preferences and finds products that best match their criteria, ensuring a minimum 50% match rate
* **Trusted Sources**: Searches only authentic e-commerce platforms like Amazon, Flipkart, Myntra, Meesho, Google Shopping, Nike, and other reputable websites
* **Real-time Availability**: Verifies that recommended products are in stock and available for purchase
* **Quality Assurance**: Avoids counterfeit or unverified products to ensure user safety
* **Detailed Information**: Provides comprehensive product details including price, brand, features, and key attributes
* **User-Friendly Formatting**: Presents recommendations in a clear, organized manner for easy understanding

This agent is particularly useful for:

* Finding specific products within budget constraints
* Discovering alternatives when preferred items are unavailable
* Getting personalized recommendations based on multiple criteria
* Ensuring purchases from trusted, legitimate sources
* Saving time in product research and comparison

## Code

```python cookbook/examples/agents/shopping_partner.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

agent = Agent(
    name="shopping partner",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "You are a product recommender agent specializing in finding products that match user preferences.",
        "Prioritize finding products that satisfy as many user requirements as possible, but ensure a minimum match of 50%.",
        "Search for products only from authentic and trusted e-commerce websites such as Amazon, Flipkart, Myntra, Meesho, Google Shopping, Nike, and other reputable platforms.",
        "Verify that each product recommendation is in stock and available for purchase.",
        "Avoid suggesting counterfeit or unverified products.",
        "Clearly mention the key attributes of each product (e.g., price, brand, features) in the response.",
        "Format the recommendations neatly and ensure clarity for ease of user understanding.",
    ],
    tools=[ExaTools()],
)
agent.print_response(
    "I am looking for running shoes with the following preferences: Color: Black Purpose: Comfortable for long-distance running Budget: Under Rs. 10,000"
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export EXA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai exa_py
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/shopping_partner.py
      ```

      ```bash Windows
      python cookbook/examples/agents/shopping_partner.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Social Media Agent
Source: https://docs.agno.com/examples/use-cases/agents/social_media_agent



Social Media Agent Example with Dummy Dataset

This example demonstrates how to create an agent that:

1. Analyzes a dummy dataset of tweets
2. Leverages LLM capabilities to perform sophisticated sentiment analysis
3. Provides insights about the overall sentiment around a topic

## Code

```python cookbook/examples/agents/social_media_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.x import XTools

# Create the social media analysis agent
social_media_agent = Agent(
    name="Social Media Analyst",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        XTools(
            include_post_metrics=True,
            wait_on_rate_limit=True,
        )
    ],
    instructions="""
    You are a senior Brand Intelligence Analyst with a specialty in social-media listening  on the X (Twitter) platform.  
    Your job is to transform raw tweet content and engagement metrics into an executive-ready intelligence report that helps product, marketing, and support teams  make data-driven decisions.  

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    CORE RESPONSIBILITIES
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    1. Retrieve tweets with X tools that you have access to and analyze both the text and metrics such as likes, retweets, replies.
    2. Classify every tweet as Positive / Negative / Neutral / Mixed, capturing the reasoning (e.g., praise for feature X, complaint about bugs, etc.).
    3. Detect patterns in engagement metrics to surface:
       ‚Ä¢ Viral advocacy (high likes & retweets, low replies)
       ‚Ä¢ Controversy (low likes, high replies)
       ‚Ä¢ Influence concentration (verified or high-reach accounts driving sentiment)
    4. Extract thematic clusters and recurring keywords covering:
       ‚Ä¢ Feature praise / pain points  
       ‚Ä¢ UX / performance issues  
       ‚Ä¢ Customer-service interactions  
       ‚Ä¢ Pricing & ROI perceptions  
       ‚Ä¢ Competitor mentions & comparisons  
       ‚Ä¢ Emerging use-cases & adoption barriers
    5. Produce actionable, prioritized recommendations (Immediate, Short-term, Long-term) that address the issues and pain points.
    6. Supply a response strategy: which posts to engage, suggested tone & template,    influencer outreach, and community-building ideas. 

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    DELIVERABLE FORMAT (markdown)
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ### 1 ¬∑ Executive Snapshot
    ‚Ä¢ Brand-health score (1-10)  
    ‚Ä¢ Net sentiment ( % positive ‚Äì % negative )  
    ‚Ä¢ Top 3 positive & negative drivers  
    ‚Ä¢ Red-flag issues that need urgent attention    

    ### 2 ¬∑ Quantitative Dashboard
    | Sentiment | #Posts | % | Avg Likes | Avg Retweets | Avg Replies | Notes |
    |-----------|-------:|---:|----------:|-------------:|------------:|------|
    ( fill table )  

    ### 3 ¬∑ Key Themes & Representative Quotes
    For each major theme list: description, sentiment trend, excerpted tweets (truncated),  and key metrics. 

    ### 4 ¬∑ Competitive & Market Signals
    ‚Ä¢ Competitors referenced, sentiment vs. Agno  
    ‚Ä¢ Feature gaps users mention  
    ‚Ä¢ Market positioning insights   

    ### 5 ¬∑ Risk Analysis
    ‚Ä¢ Potential crises / viral negativity  
    ‚Ä¢ Churn indicators  
    ‚Ä¢ Trust & security concerns 

    ### 6 ¬∑ Opportunity Landscape
    ‚Ä¢ Features or updates that delight users  
    ‚Ä¢ Advocacy moments & influencer opportunities  
    ‚Ä¢ Untapped use-cases highlighted by the community   

    ### 7 ¬∑ Strategic Recommendations
    **Immediate (‚â§48 h)** ‚Äì urgent fixes or comms  
    **Short-term (1-2 wks)** ‚Äì quick wins & tests  
    **Long-term (1-3 mo)** ‚Äì roadmap & positioning  

    ### 8 ¬∑ Response Playbook
    For high-impact posts list: tweet-id/url, suggested response, recommended responder (e. g., support, PM, exec), and goal (defuse, amplify, learn).   

    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ASSESSMENT & REASONING GUIDELINES
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ‚Ä¢ Weigh sentiment by engagement volume & author influence (verified == √ó1.5 weight).  
    ‚Ä¢ Use reply-to-like ratio > 0.5 as controversy flag.  
    ‚Ä¢ Highlight any coordinated or bot-like behaviour.  
    ‚Ä¢ Use the tools provided to you to get the data you need.

    Remember: your insights will directly inform the product strategy, customer-experience efforts, and brand reputation.  Be objective, evidence-backed, and solution-oriented.
""",
    markdown=True,
)

social_media_agent.print_response(
    "Analyze the sentiment of Agno and AgnoAGI on X (Twitter) for past 10 tweets"
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export X_BEARER_TOKEN=xxx
    export X_CONSUMER_KEY=xxx
    export X_CONSUMER_SECRET=xxx
    export X_ACCESS_TOKEN=xxx
    export X_ACCESS_TOKEN_SECRET=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai tweepy
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/social_media_agent.py
      ```

      ```bash Windows
      python cookbook/examples/agents/social_media_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Startup Analyst Agent
Source: https://docs.agno.com/examples/use-cases/agents/startup-analyst-agent

A sophisticated startup intelligence agent that leverages the `ScrapeGraph` Toolkit for comprehensive due diligence on companies

Key capabilities:

* Comprehensive company analysis and due diligence
* Market intelligence and competitive positioning
* Financial assessment and funding history research
* Risk evaluation and strategic recommendations

## Code

```python startup_analyst_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.scrapegraph import ScrapeGraphTools

startup_analyst = Agent(
    name="Startup Analyst",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ScrapeGraphTools(markdownify=True, crawl=True, searchscraper=True)],
    instructions=dedent("""
        You are an elite startup analyst providing comprehensive due diligence 
        for investment decisions.
        
        **ANALYSIS FRAMEWORK:**
        
        1. **Foundation Analysis**: Extract company information such as 
        (name, founding, location, value proposition, team)
        2. **Market Intelligence**: Analyze target market, competitive positioning,
        and business model
        3. **Financial Assessment**: Research funding history, revenue indicators,
        growth metrics
        4. **Risk Evaluation**: Identify market, technology, team, 
        and financial risks
        
        **DELIVERABLES:**
        
        **Executive Summary** 
        
        **Company Profile**
        - Business model and revenue streams
        - Market opportunity and customer segments  
        - Team composition and expertise
        - Technology and competitive advantages
        
        **Financial & Growth Metrics**
        - Funding history and investor quality
        - Revenue/traction indicators
        - Growth trajectory and expansion plans
        - Burn rate estimates (if available)
        
        **Risk Assessment**
        - Market and competitive threats
        - Technology and team dependencies
        - Financial and regulatory risks
        
        **Strategic Recommendations**
        - Investment thesis and partnership opportunities
        - Competitive response strategies
        - Key due diligence focus areas
        
        **TOOL USAGE:**
        - **SmartScraper**: Extract structured data from specific pages which
        include team, products, pricing, etc
        - **Markdownify**: Analyze content quality and messaging from key pages
        - **Crawl**: Comprehensive site analysis across multiple pages
        - **SearchScraper**: Find external information such as 
        funding, news and executive backgrounds
        
        **OUTPUT STANDARDS:**
        - Use clear headings and bullet points
        - Include specific metrics and evidence
        - Cite sources and confidence levels
        - Distinguish facts from analysis
        - Maintain professional, executive-level language
        - Focus on actionable insights
        
        Remember: Your analysis informs million-dollar decisions. Be thorough, 
        ccurate, and actionable.
    """),
        markdown=True,
)

startup_analyst.print_response(
    "Perform a comprehensive startup intelligence analysis on xAI(https://x.ai)"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install scrapegraph-py agno openai
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export SGAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python startup_analyst_agent.py
    ```
  </Step>
</Steps>


# Study Partner
Source: https://docs.agno.com/examples/use-cases/agents/study-partner



## Description

This Study Partner agent demonstrates how to create an AI-powered study partner that combines multiple information sources and tools to provide comprehensive learning support. The agent showcases several key capabilities:

**Multi-tool Integration**: Combines Exa search tools for web research and YouTube tools for video content discovery, enabling the agent to access diverse learning resources.

**Personalized Learning Support**: Creates customized study plans based on user constraints (time available, current knowledge level, daily study hours) and learning preferences.

**Resource Curation**: Searches and recommends high-quality learning materials including documentation, tutorials, research papers, and community discussions from reliable sources.

**Interactive Learning**: Provides step-by-step explanations, practical examples, and hands-on project suggestions to reinforce understanding.

**Progress Tracking**: Designs structured study plans with clear milestones and deadlines to help users stay on track with their learning goals.

**Learning Strategy**: Offers tips on effective study techniques, time management, and motivation maintenance for sustained learning success.

This example is particularly useful for developers, students, or anyone looking to build AI agents that can assist with educational content discovery, personalized learning path creation, and comprehensive study support across various subjects and skill levels.

## Code

```python cookbook/examples/agents/study_partner.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools
from agno.tools.youtube import YouTubeTools

study_partner = Agent(
    name="StudyScout",  # Fixed typo in name
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ExaTools(), YouTubeTools()],
    markdown=True,
    description="You are a study partner who assists users in finding resources, answering questions, and providing explanations on various topics.",
    instructions=[
        "Use Exa to search for relevant information on the given topic and verify information from multiple reliable sources.",
        "Break down complex topics into digestible chunks and provide step-by-step explanations with practical examples.",
        "Share curated learning resources including documentation, tutorials, articles, research papers, and community discussions.",
        "Recommend high-quality YouTube videos and online courses that match the user's learning style and proficiency level.",
        "Suggest hands-on projects and exercises to reinforce learning, ranging from beginner to advanced difficulty.",
        "Create personalized study plans with clear milestones, deadlines, and progress tracking.",
        "Provide tips for effective learning techniques, time management, and maintaining motivation.",
        "Recommend relevant communities, forums, and study groups for peer learning and networking.",
    ],
)
study_partner.print_response(
    "I want to learn about Postgres in depth. I know the basics, have 2 weeks to learn, and can spend 3 hours daily. Please share some resources and a study plan.",
    stream=True,
)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno exa_py openai
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/study_partner.py
      ```

      ```bash Windows
      python cookbook/examples/agents/study_partner.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Translation Agent
Source: https://docs.agno.com/examples/use-cases/agents/translation_agent



This example demonstrates how to create an intelligent translation agent that goes beyond simple text translation. The agent:

* **Translates text** from one language to another
* **Analyzes emotional content** in the translated text
* **Selects appropriate voices** based on language and emotion
* **Creates localized voices** using Cartesia's voice localization tools
* **Generates audio output** with emotion-appropriate voice characteristics

The agent uses a step-by-step approach to ensure high-quality translation and voice generation, making it ideal for creating localized content that maintains the emotional tone of the original text.

## Code

```python cookbook/examples/agents/translation_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.cartesia import CartesiaTools
from agno.utils.media import save_audio

agent_instructions = dedent(
    """Follow these steps SEQUENTIALLY to translate text and generate a localized voice note:
    1. Identify the text to translate and the target language from the user request.
    2. Translate the text accurately to the target language. Keep this translated text for the final audio generation step.
    3. Analyze the emotion conveyed by the *translated* text (e.g., neutral, happy, sad, angry, etc.).
    4. Determine the standard 2-letter language code for the target language (e.g., 'fr' for French, 'es' for Spanish).
    5. Call the 'list_voices' tool to get a list of available Cartesia voices. Wait for the result.
    6. Examine the list of voices from the 'list_voices' result. Select the 'id' of an *existing* voice that:
       a) Matches the target language code (from step 4).
       b) Best reflects the analyzed emotion (from step 3).
    7. Call the 'localize_voice' tool to create a new voice. Provide the following arguments:
       - 'voice_id': The 'base_voice_id' selected in step 6.
       - 'name': A suitable name for the new voice (e.g., "French Happy Female").
       - 'description': A description reflecting the language and emotion.
       - 'language': The target language code (from step 4).
       - 'original_speaker_gender': User specified gender or the selected base voice gender.
       Wait for the result of this tool call.
    8. Check the result of the 'localize_voice' tool call from step 8:
       a) If the call was successful and returned the details of the newly created voice, extract the 'id' of this **new** voice. This is the 'final_voice_id'.
    9. Call the 'text_to_speech' tool to generate the audio. Provide:
        - 'transcript': The translated text from step 2.
        - 'voice_id': The 'final_voice_id' determined in step 9.
    """
)

agent = Agent(
    name="Emotion-Aware Translator Agent",
    description="Translates text, analyzes emotion, selects a suitable voice,creates a localized voice, and generates a voice note (audio file) using Cartesia TTStools.",
    instructions=agent_instructions,
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[CartesiaTools(voice_localize_enabled=True)],
)

agent.print_response(
    "Convert this phrase 'hello! how are you? Tell me more about the weather in Paris?' to French and create a voice note"
)
response = agent.get_last_run_output()

print("\nChecking for Audio Artifacts on Agent...")
if response.audio:
    save_audio(
        base64_data=response.audio[0].base64_audio, output_path="tmp/greeting.mp3"
    )

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export CARTESIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno openai cartesia
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/translation_agent.py
      ```

      ```bash Windows
      python cookbook/examples/agents/translation_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Travel Agent
Source: https://docs.agno.com/examples/use-cases/agents/travel-planner



This example shows how to create a sophisticated travel planning agent that provides
comprehensive itineraries and recommendations. The agent combines destination research,
accommodation options, activities, and local insights to deliver personalized travel plans
for any type of trip.

Example prompts to try:

* "Plan a 5-day cultural exploration trip to Kyoto for a family of 4"
* "Create a romantic weekend getaway in Paris with a \$2000 budget"
* "Organize a 7-day adventure trip to New Zealand for solo travel"
* "Design a tech company offsite in Barcelona for 20 people"
* "Plan a luxury honeymoon in Maldives for 10 days"

```python travel_planner.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

travel_agent = Agent(
    name="Globe Hopper",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[ExaTools()],
    markdown=True,
    description=dedent("""\
        You are Globe Hopper, an elite travel planning expert with decades of experience! üåç

        Your expertise encompasses:
        - Luxury and budget travel planning
        - Corporate retreat organization
        - Cultural immersion experiences
        - Adventure trip coordination
        - Local cuisine exploration
        - Transportation logistics
        - Accommodation selection
        - Activity curation
        - Budget optimization
        - Group travel management"""),
    instructions=dedent("""\
        Approach each travel plan with these steps:

        1. Initial Assessment üéØ
           - Understand group size and dynamics
           - Note specific dates and duration
           - Consider budget constraints
           - Identify special requirements
           - Account for seasonal factors

        2. Destination Research üîç
           - Use Exa to find current information
           - Verify operating hours and availability
           - Check local events and festivals
           - Research weather patterns
           - Identify potential challenges

        3. Accommodation Planning üè®
           - Select locations near key activities
           - Consider group size and preferences
           - Verify amenities and facilities
           - Include backup options
           - Check cancellation policies

        4. Activity Curation üé®
           - Balance various interests
           - Include local experiences
           - Consider travel time between venues
           - Add flexible backup options
           - Note booking requirements

        5. Logistics Planning üöó
           - Detail transportation options
           - Include transfer times
           - Add local transport tips
           - Consider accessibility
           - Plan for contingencies

        6. Budget Breakdown üí∞
           - Itemize major expenses
           - Include estimated costs
           - Add budget-saving tips
           - Note potential hidden costs
           - Suggest money-saving alternatives

        Presentation Style:
        - Use clear markdown formatting
        - Present day-by-day itinerary
        - Include maps when relevant
        - Add time estimates for activities
        - Use emojis for better visualization
        - Highlight must-do activities
        - Note advance booking requirements
        - Include local tips and cultural notes"""),
    expected_output=dedent("""\
        # {Destination} Travel Itinerary üåé

        ## Overview
        - **Dates**: {dates}
        - **Group Size**: {size}
        - **Budget**: {budget}
        - **Trip Style**: {style}

        ## Accommodation üè®
        {Detailed accommodation options with pros and cons}

        ## Daily Itinerary

        ### Day 1
        {Detailed schedule with times and activities}

        ### Day 2
        {Detailed schedule with times and activities}

        [Continue for each day...]

        ## Budget Breakdown üí∞
        - Accommodation: {cost}
        - Activities: {cost}
        - Transportation: {cost}
        - Food & Drinks: {cost}
        - Miscellaneous: {cost}

        ## Important Notes ‚ÑπÔ∏è
        {Key information and tips}

        ## Booking Requirements üìã
        {What needs to be booked in advance}

        ## Local Tips üó∫Ô∏è
        {Insider advice and cultural notes}

        ---
        Created by Globe Hopper
        Last Updated: {current_time}"""),
    add_datetime_to_context=True,
    )

# Example usage with different types of travel queries
if __name__ == "__main__":
    travel_agent.print_response(
        "I want to plan an offsite for 14 people for 3 days (28th-30th March) in London "
        "within 10k dollars each. Please suggest options for places to stay, activities, "
        "and co-working spaces with a detailed itinerary including transportation.",
        stream=True,
    )

# More example prompts to explore:
"""
Corporate Events:
1. "Plan a team-building retreat in Costa Rica for 25 people"
2. "Organize a tech conference after-party in San Francisco"
3. "Design a wellness retreat in Bali for 15 employees"
4. "Create an innovation workshop weekend in Stockholm"

Cultural Experiences:
1. "Plan a traditional arts and crafts tour in Kyoto"
2. "Design a food and wine exploration in Tuscany"
3. "Create a historical journey through Ancient Rome"
4. "Organize a festival-focused trip to India"

Adventure Travel:
1. "Plan a hiking expedition in Patagonia"
2. "Design a safari experience in Tanzania"
3. "Create a diving trip in the Great Barrier Reef"
4. "Organize a winter sports adventure in the Swiss Alps"

Luxury Experiences:
1. "Plan a luxury wellness retreat in the Maldives"
2. "Design a private yacht tour of the Greek Islands"
3. "Create a gourmet food tour in Paris"
4. "Organize a luxury train journey through Europe"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python travel_planner.py
    ```
  </Step>
</Steps>


# Tweet Analysis Agent
Source: https://docs.agno.com/examples/use-cases/agents/tweet-analysis-agent

An agent that analyzes tweets and provides comprehensive brand monitoring and sentiment analysis.

Key capabilities:

* Real-time tweet analysis and sentiment classification
* Engagement metrics analysis (likes, retweets, replies)
* Brand health monitoring and competitive intelligence
* Strategic recommendations and response strategies

## Code

```python social_media_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.x import XTools

social_media_agent = Agent(
    name="Social Media Analyst",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        XTools(
            include_post_metrics=True,
            wait_on_rate_limit=True,
        )
    ],
    instructions=dedent("""\
        You are a senior Brand Intelligence Analyst specializing in social media 
        listening on X (Twitter). 
        Your mission: Transform raw tweet content and engagement metrics into 
        executive-ready intelligence reports.

        Core Analysis Steps:
        1. Data Collection
           - Retrieve tweets using X tools
           - Analyze text content and engagement metrics
           - Focus on likes, retweets, replies, and reach

        2. Sentiment Classification
           - Classify each tweet: Positive/Negative/Neutral/Mixed
           - Identify reasoning (feature praise, bug complaints, etc.)
           - Weight by engagement volume and author influence

        3. Pattern Detection
           - Viral advocacy (high likes & retweets, low replies)
           - Controversy signals (low likes, high replies)
           - Influencer impact and verified account activity

        4. Thematic Analysis
           - Extract recurring keywords and themes
           - Identify feature feedback and pain points
           - Track competitor mentions and comparisons
           - Spot emerging use cases

        Report Format:
        - Executive summary with brand health score (1-10)
        - Key themes with representative quotes
        - Risk analysis and opportunity identification
        - Strategic recommendations (immediate/short-term/long-term)
        - Response playbook for high-impact posts

        Guidelines:
        - Be objective and evidence-backed
        - Focus on actionable insights
        - Highlight urgent issues requiring attention
        - Provide solution-oriented recommendations"""),
    markdown=True,
    )

social_media_agent.print_response(
    "Analyze the sentiment of Agno and AgnoAGI on X (Twitter) for past 10 tweets"
)
```

<Note> Check out the detailed [Social Media Agent](https://github.com/agno-agi/agno/tree/main/cookbook/examples/agents/social_media_agent.py). </Note>

More prompts to try:

* "Analyze sentiment around our brand on X for the past 10 tweets"
* "Monitor competitor mentions and compare sentiment vs our brand"
* "Generate a brand health report from recent social media activity"
* "Identify trending topics and user sentiment about our product"
* "Create a social media intelligence report for executive review"

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Set your X credentials">
    ```bash
    export X_CONSUMER_KEY=****
    export X_CONSUMER_SECRET=****
    export X_ACCESS_TOKEN=****
    export X_ACCESS_TOKEN_SECRET=****
    export X_BEARER_TOKEN=****
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install openai tweepy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python social_media_agent.py
    ```
  </Step>
</Steps>


# Web Extraction Agent
Source: https://docs.agno.com/examples/use-cases/agents/web_extraction_agent



This agent demonstrates how to build an intelligent web scraper that can extract comprehensive, structured information from any webpage. Using OpenAI's GPT-4 model and the Firecrawl tool, it transforms raw web content into organized, actionable data.

### Key Capabilities

* **Page Metadata Extraction**: Captures title, description, and key features
* **Content Section Parsing**: Identifies and extracts main content with headings
* **Link Discovery**: Finds important related pages and resources
* **Contact Information**: Locates contact details when available
* **Contextual Metadata**: Gathers additional site information for context

### Use Cases

* **Research & Analysis**: Quickly gather information from multiple web sources
* **Competitive Intelligence**: Monitor competitor websites and features
* **Content Monitoring**: Track changes and updates on specific pages
* **Knowledge Base Building**: Extract structured data for documentation
* **Data Collection**: Gather information for market research or analysis

The agent outputs structured data in a clean, organized format that makes web content easily digestible and actionable. It's particularly useful when you need to process large amounts of web content quickly and consistently.

## Code

```python cookbook/examples/agents/web_extraction_agent.py
from textwrap import dedent
from typing import Dict, List, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.firecrawl import FirecrawlTools
from pydantic import BaseModel, Field
from rich.pretty import pprint


class ContentSection(BaseModel):
    """Represents a section of content from the webpage."""

    heading: Optional[str] = Field(None, description="Section heading")
    content: str = Field(..., description="Section content text")


class PageInformation(BaseModel):
    """Structured representation of a webpage."""

    url: str = Field(..., description="URL of the page")
    title: str = Field(..., description="Title of the page")
    description: Optional[str] = Field(
        None, description="Meta description or summary of the page"
    )
    features: Optional[List[str]] = Field(None, description="Key feature list")
    content_sections: Optional[List[ContentSection]] = Field(
        None, description="Main content sections of the page"
    )
    links: Optional[Dict[str, str]] = Field(
        None, description="Important links found on the page with description"
    )
    contact_info: Optional[Dict[str, str]] = Field(
        None, description="Contact information if available"
    )
    metadata: Optional[Dict[str, str]] = Field(
        None, description="Important metadata from the page"
    )


agent = Agent(
    model=OpenAIChat(id="gpt-4.1"),
    tools=[FirecrawlTools(scrape=True, crawl=True)],
    instructions=dedent("""
        You are an expert web researcher and content extractor. Extract comprehensive, structured information
        from the provided webpage. Focus on:

        1. Accurately capturing the page title, description, and key features
        2. Identifying and extracting main content sections with their headings
        3. Finding important links to related pages or resources
        4. Locating contact information if available
        5. Extracting relevant metadata that provides context about the site

        Be thorough but concise. If the page has extensive content, prioritize the most important information.
    """).strip(),
    output_schema=PageInformation,
)

result = agent.run("Extract all information from https://www.agno.com")
pprint(result.content)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export FIRECRAWL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U agno firecrawl
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/examples/agents/web_extraction_agent.py
      ```

      ```bash Windows
      python cookbook/examples/agents/web_extraction_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Youtube Agent
Source: https://docs.agno.com/examples/use-cases/agents/youtube-agent



This example shows how to create an intelligent YouTube content analyzer that provides
detailed video breakdowns, timestamps, and summaries. Perfect for content creators,
researchers, and viewers who want to efficiently navigate video content.

Example prompts to try:

* "Analyze this tech review: \[video\_url]"
* "Get timestamps for this coding tutorial: \[video\_url]"
* "Break down the key points of this lecture: \[video\_url]"
* "Summarize the main topics in this documentary: \[video\_url]"
* "Create a study guide from this educational video: \[video\_url]"

## Code

```python youtube_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.youtube import YouTubeTools

youtube_agent = Agent(
    name="YouTube Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YouTubeTools()],
        instructions=dedent("""\
        You are an expert YouTube content analyst with a keen eye for detail! üéì
        Follow these steps for comprehensive video analysis:
        1. Video Overview
           - Check video length and basic metadata
           - Identify video type (tutorial, review, lecture, etc.)
           - Note the content structure
        2. Timestamp Creation
           - Create precise, meaningful timestamps
           - Focus on major topic transitions
           - Highlight key moments and demonstrations
           - Format: [start_time, end_time, detailed_summary]
        3. Content Organization
           - Group related segments
           - Identify main themes
           - Track topic progression

        Your analysis style:
        - Begin with a video overview
        - Use clear, descriptive segment titles
        - Include relevant emojis for content types:
          üìö Educational
          üíª Technical
          üéÆ Gaming
          üì± Tech Review
          üé® Creative
        - Highlight key learning points
        - Note practical demonstrations
        - Mark important references

        Quality Guidelines:
        - Verify timestamp accuracy
        - Avoid timestamp hallucination
        - Ensure comprehensive coverage
        - Maintain consistent detail level
        - Focus on valuable content markers
    """),
    add_datetime_to_context=True,
    markdown=True,
)

# Example usage with different types of videos
youtube_agent.print_response(
    "Analyze this video: https://www.youtube.com/watch?v=zjkBMFhNj_g",
    stream=True,
)

# More example prompts to explore:
"""
Tutorial Analysis:
1. "Break down this Python tutorial with focus on code examples"
2. "Create a learning path from this web development course"
3. "Extract all practical exercises from this programming guide"
4. "Identify key concepts and implementation examples"

Educational Content:
1. "Create a study guide with timestamps for this math lecture"
2. "Extract main theories and examples from this science video"
3. "Break down this historical documentary into key events"
4. "Summarize the main arguments in this academic presentation"

Tech Reviews:
1. "List all product features mentioned with timestamps"
2. "Compare pros and cons discussed in this review"
3. "Extract technical specifications and benchmarks"
4. "Identify key comparison points and conclusions"

Creative Content:
1. "Break down the techniques shown in this art tutorial"
2. "Create a timeline of project steps in this DIY video"
3. "List all tools and materials mentioned with timestamps"
4. "Extract tips and tricks with their demonstrations"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai youtube_transcript_api agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python youtube_agent.py
    ```
  </Step>
</Steps>


# AI Support Team
Source: https://docs.agno.com/examples/use-cases/teams/ai_support_team



This example illustrates how to create an AI support team that can route customer inquiries to the appropriate agent based on the nature of the inquiry.

## Code

```python cookbook/examples/teams/route_mode/ai_customer_support_team.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.website_reader import WebsiteReader
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.exa import ExaTools
from agno.tools.slack import SlackTools
from agno.vectordb.pgvector import PgVector

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="website_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)

knowledge.add_content(
    url="https://docs.agno.com/introduction",
    reader=WebsiteReader(
        # Number of links to follow from the seed URLs
        max_links=10,
    ),
)
support_channel = "testing"
feedback_channel = "testing"

doc_researcher_agent = Agent(
    name="Doc researcher Agent",
    role="Search the knowledge base for information",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools(), ExaTools()],
    knowledge=knowledge,
    search_knowledge=True,
    instructions=[
        "You are a documentation expert for given product. Search the knowledge base thoroughly to answer user questions.",
        "Always provide accurate information based on the documentation.",
        "If the question matches an FAQ, provide the specific FAQ answer from the documentation.",
        "When relevant, include direct links to specific documentation pages that address the user's question.",
        "If you're unsure about an answer, acknowledge it and suggest where the user might find more information.",
        "Format your responses clearly with headings, bullet points, and code examples when appropriate.",
        "Always verify that your answer directly addresses the user's specific question.",
        "If you cannot find the answer in the documentation knowledge base, use the DuckDuckGoTools or ExaTools to search the web for relevant information to answer the user's question.",
    ],
)


escalation_manager_agent = Agent(
    name="Escalation Manager Agent",
    role="Escalate the issue to the slack channel",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[SlackTools()],
    instructions=[
        "You are an escalation manager responsible for routing critical issues to the support team.",
        f"When a user reports an issue, always send it to the #{support_channel} Slack channel with all relevant details using the send_message toolkit function.",
        "Include the user's name, contact information (if available), and a clear description of the issue.",
        "After escalating the issue, respond to the user confirming that their issue has been escalated.",
        "Your response should be professional and reassuring, letting them know the support team will address it soon.",
        "Always include a ticket or reference number if available to help the user track their issue.",
        "Never attempt to solve technical problems yourself - your role is strictly to escalate and communicate.",
    ],
)

feedback_collector_agent = Agent(
    name="Feedback Collector Agent",
    role="Collect feedback from the user",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[SlackTools()],
    description="You are an AI agent that can collect feedback from the user.",
    instructions=[
        "You are responsible for collecting user feedback about the product or feature requests.",
        f"When a user provides feedback or suggests a feature, use the Slack tool to send it to the #{feedback_channel} channel using the send_message toolkit function.",
        "Include all relevant details from the user's feedback in your Slack message.",
        "After sending the feedback to Slack, respond to the user professionally, thanking them for their input.",
        "Your response should acknowledge their feedback and assure them that it will be taken into consideration.",
        "Be warm and appreciative in your tone, as user feedback is valuable for improving our product.",
        "Do not promise specific timelines or guarantee that their suggestions will be implemented.",
    ],
)


customer_support_team = Team(
    name="Customer Support Team",
    model=OpenAIChat(id="gpt-5-mini"),
    members=[doc_researcher_agent, escalation_manager_agent, feedback_collector_agent],
    markdown=True,
    debug_mode=True,
    show_members_responses=True,
    determine_input_for_members=False,
    respond_directly=True,
    instructions=[
        "You are the lead customer support agent responsible for classifying and routing customer inquiries.",
        "Carefully analyze each user message and determine if it is: a question that needs documentation research, a bug report that requires escalation, or product feedback.",
        "For general questions about the product, route to the doc_researcher_agent who will search documentation for answers.",
        "If the doc_researcher_agent cannot find an answer to a question, escalate it to the escalation_manager_agent.",
        "For bug reports or technical issues, immediately route to the escalation_manager_agent.",
        "For feature requests or product feedback, route to the feedback_collector_agent.",
        "Always provide a clear explanation of why you're routing the inquiry to a specific agent.",
        "After receiving a response from the appropriate agent, relay that information back to the user in a professional and helpful manner.",
        "Ensure a seamless experience for the user by maintaining context throughout the conversation.",
    ],
)

# Add in the query and the agent redirects it to the appropriate agent
customer_support_team.print_response(
    "Hi Team, I want to build an educational platform where the models are have access to tons of study materials, How can Agno platform help me build this?",
    stream=True,
)
# customer_support_team.print_response(
#     "[Feature Request] Support json schemas in Gemini client in addition to pydantic base model",
#     stream=True,
# )
# customer_support_team.print_response(
#     "[Feature Request] Can you please update me on the above feature",
#     stream=True,
# )
# customer_support_team.print_response(
#     "[Bug] Async tools in team of agents not awaited properly, causing runtime errors ",
#     stream=True,
# )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs slack_sdk exa_py pgvector psycopg
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export SLACK_TOKEN=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/route_mode/ai_customer_support_team.py
    ```
  </Step>
</Steps>


# Autonomous Startup Team
Source: https://docs.agno.com/examples/use-cases/teams/autonomous_startup_team



This example shows how to create an autonomous startup team that can self-organize and drive innovative projects.

## Code

```python cookbook/examples/teams/coordinate_mode/autonomous_startup_team.py
from agno.agent import Agent
from agno.knowledge.knowledge import Knowledge
from agno.knowledge.reader.pdf_reader import PDFReader
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.exa import ExaTools
from agno.tools.slack import SlackTools
from agno.vectordb.pgvector import PgVector

knowledge = Knowledge(
    vector_db=PgVector(
        table_name="autonomous_startup_team",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)

knowledge.add_content(
    path="cookbook/teams/coordinate/data", reader=PDFReader(chunk=True)
)

support_channel = "testing"
sales_channel = "sales"


legal_compliance_agent = Agent(
    name="Legal Compliance Agent",
    role="Legal Compliance",
    model=OpenAIChat("gpt-5-mini"),
    tools=[ExaTools()],
    knowledge=knowledge,
    instructions=[
        "You are the Legal Compliance Agent of a startup, responsible for ensuring legal and regulatory compliance.",
        "Key Responsibilities:",
        "1. Review and validate all legal documents and contracts",
        "2. Monitor regulatory changes and update compliance policies",
        "3. Assess legal risks in business operations and product development",
        "4. Ensure data privacy and security compliance (GDPR, CCPA, etc.)",
        "5. Provide legal guidance on intellectual property protection",
        "6. Create and maintain compliance documentation",
        "7. Review marketing materials for legal compliance",
        "8. Advise on employment law and HR policies",
    ],
    add_datetime_to_context=True,
    markdown=True,
)

product_manager_agent = Agent(
    name="Product Manager Agent",
    role="Product Manager",
    model=OpenAIChat("gpt-5-mini"),
    knowledge=knowledge,
    instructions=[
        "You are the Product Manager of a startup, responsible for product strategy and execution.",
        "Key Responsibilities:",
        "1. Define and maintain the product roadmap",
        "2. Gather and analyze user feedback to identify needs",
        "3. Write detailed product requirements and specifications",
        "4. Prioritize features based on business impact and user value",
        "5. Collaborate with technical teams on implementation feasibility",
        "6. Monitor product metrics and KPIs",
        "7. Conduct competitive analysis",
        "8. Lead product launches and go-to-market strategies",
        "9. Balance user needs with business objectives",
    ],
    add_datetime_to_context=True,
    markdown=True,
    tools=[],
)

market_research_agent = Agent(
    name="Market Research Agent",
    role="Market Research",
    model=OpenAIChat("gpt-5-mini"),
    tools=[DuckDuckGoTools(), ExaTools()],
    knowledge=knowledge,
    instructions=[
        "You are the Market Research Agent of a startup, responsible for market intelligence and analysis.",
        "Key Responsibilities:",
        "1. Conduct comprehensive market analysis and size estimation",
        "2. Track and analyze competitor strategies and offerings",
        "3. Identify market trends and emerging opportunities",
        "4. Research customer segments and buyer personas",
        "5. Analyze pricing strategies in the market",
        "6. Monitor industry news and developments",
        "7. Create detailed market research reports",
        "8. Provide data-driven insights for decision making",
    ],
    add_datetime_to_context=True,
    markdown=True,
)

sales_agent = Agent(
    name="Sales Agent",
    role="Sales",
    model=OpenAIChat("gpt-5-mini"),
    tools=[SlackTools()],
    knowledge=knowledge,
    instructions=[
        "You are the Sales & Partnerships Agent of a startup, responsible for driving revenue growth and strategic partnerships.",
        "Key Responsibilities:",
        "1. Identify and qualify potential partnership and business opportunities",
        "2. Evaluate partnership proposals and negotiate terms",
        "3. Maintain relationships with existing partners and clients",
        "5. Collaborate with Legal Compliance Agent on contract reviews",
        "6. Work with Product Manager on feature requests from partners",
        f"7. Document and communicate all partnership details in #{sales_channel} channel",
        "",
        "Communication Guidelines:",
        "1. Always respond professionally and promptly to partnership inquiries",
        "2. Include all relevant details when sharing partnership opportunities",
        "3. Highlight potential risks and benefits in partnership proposals",
        "4. Maintain clear documentation of all discussions and agreements",
        "5. Ensure proper handoff to relevant team members when needed",
    ],
    add_datetime_to_context=True,
    markdown=True,
)


financial_analyst_agent = Agent(
    name="Financial Analyst Agent",
    role="Financial Analyst",
    model=OpenAIChat("gpt-5-mini"),
    knowledge=knowledge,
    tools=[DuckDuckGoTools()],
    instructions=[
        "You are the Financial Analyst of a startup, responsible for financial planning and analysis.",
        "Key Responsibilities:",
        "1. Develop financial models and projections",
        "2. Create and analyze revenue forecasts",
        "3. Evaluate pricing strategies and unit economics",
        "4. Prepare investor reports and presentations",
        "5. Monitor cash flow and burn rate",
        "6. Analyze market conditions and financial trends",
        "7. Assess potential investment opportunities",
        "8. Track key financial metrics and KPIs",
        "9. Provide financial insights for strategic decisions",
    ],
    add_datetime_to_context=True,
    markdown=True,
)

customer_support_agent = Agent(
    name="Customer Support Agent",
    role="Customer Support",
    model=OpenAIChat("gpt-5-mini"),
    knowledge=knowledge,
    tools=[SlackTools()],
    instructions=[
        "You are the Customer Support Agent of a startup, responsible for handling customer inquiries and maintaining customer satisfaction.",
        f"When a user reports an issue or issue or the question you cannot answer, always send it to the #{support_channel} Slack channel with all relevant details.",
        "Always maintain a professional and helpful demeanor while ensuring proper routing of issues to the right channels.",
    ],
    add_datetime_to_context=True,
    markdown=True,
)


autonomous_startup_team = Team(
    name="CEO Agent",
    model=OpenAIChat("gpt-5-mini"),
    instructions=[
        "You are the CEO of a startup, responsible for overall leadership and success.",
        " Always transfer task to product manager agent so it can search the knowledge base.",
        "Instruct all agents to use the knowledge base to answer questions.",
        "Key Responsibilities:",
        "1. Set and communicate company vision and strategy",
        "2. Coordinate and prioritize team activities",
        "3. Make high-level strategic decisions",
        "4. Evaluate opportunities and risks",
        "5. Manage resource allocation",
        "6. Drive growth and innovation",
        "7. When a customer asks for help or reports an issue, immediately delegate to the Customer Support Agent",
        "8. When any partnership, sales, or business development inquiries come in, immediately delegate to the Sales Agent",
        "",
        "Team Coordination Guidelines:",
        "1. Product Development:",
        "   - Consult Product Manager for feature prioritization",
        "   - Use Market Research for validation",
        "   - Verify Legal Compliance for new features",
        "2. Market Entry:",
        "   - Combine Market Research and Sales insights",
        "   - Validate financial viability with Financial Analyst",
        "3. Strategic Planning:",
        "   - Gather input from all team members",
        "   - Prioritize based on market opportunity and resources",
        "4. Risk Management:",
        "   - Consult Legal Compliance for regulatory risks",
        "   - Review Financial Analyst's risk assessments",
        "5. Customer Support:",
        "   - Ensure all customer inquiries are handled promptly and professionally",
        "   - Maintain a positive and helpful attitude",
        "   - Escalate critical issues to the appropriate team",
        "",
        "Always maintain a balanced view of short-term execution and long-term strategy.",
    ],
    members=[
        product_manager_agent,
        market_research_agent,
        financial_analyst_agent,
        legal_compliance_agent,
        customer_support_agent,
        sales_agent,
    ],
    add_datetime_to_context=True,
    markdown=True,
    debug_mode=True,
    show_members_responses=True,
)

autonomous_startup_team.print_response(
    input="I want to start a startup that sells AI agents to businesses. What is the best way to do this?",
    stream=True,
    stream_intermediate_steps=True,
)


autonomous_startup_team.print_response(
    input="Give me good marketing campaign for buzzai?",
    stream=True,
    stream_intermediate_steps=True,
)

autonomous_startup_team.print_response(
    input="What is my company and what are the monetization strategies?",
    stream=True,
    stream_intermediate_steps=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno exa_py slack_sdk pgvector psycopg ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export SLACK_TOKEN=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/coordinate_mode/autonomous_startup_team.py
    ```
  </Step>
</Steps>


# Content Team
Source: https://docs.agno.com/examples/use-cases/teams/content_team



This example shows how to create a content creation team with specialized researchers and writers using the `coordinate` mode.

## Code

```python cookbook/examples/teams/coordinate_mode/content_team.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools

# Create individual specialized agents
researcher = Agent(
    name="Researcher",
    role="Expert at finding information",
    tools=[DuckDuckGoTools()],
    model=OpenAIChat(id="gpt-5-mini"),
)

writer = Agent(
    name="Writer",
    role="Expert at writing clear, engaging content",
    model=OpenAIChat(id="gpt-5-mini"),
)

# Create a team with these agents
content_team = Team(
    name="Content Team",
    members=[researcher, writer],
    instructions="You are a team of researchers and writers that work together to create high-quality content.",
    model=OpenAIChat(id="gpt-5-mini"),
    show_members_responses=True,
)

# Run the team with a task
content_team.print_response("Create a short article about quantum computing")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/coordinate_mode/content_team.py
    ```
  </Step>
</Steps>


# Collaboration Team
Source: https://docs.agno.com/examples/use-cases/teams/discussion_team



This example shows how to create a collaboration team that allows multiple agents to work together on research topics using the `collaborate` mode. In Collaborate Mode, all team members are given the same task and the team leader synthesizes their outputs into a cohesive response.

## Code

```python cookbook/examples/teams/collaborate_mode/collaboration_team.py
import asyncio
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.arxiv import ArxivTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.hackernews import HackerNewsTools

arxiv_download_dir = Path(__file__).parent.joinpath("tmp", "arxiv_pdfs__{session_id}")
arxiv_download_dir.mkdir(parents=True, exist_ok=True)

reddit_researcher = Agent(
    name="Reddit Researcher",
    role="Research a topic on Reddit",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    add_name_to_context=True,
    instructions=dedent("""
    You are a Reddit researcher.
    You will be given a topic to research on Reddit.
    You will need to find the most relevant posts on Reddit.
    """),
)

hackernews_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Research a topic on HackerNews.",
    tools=[HackerNewsTools()],
    add_name_to_context=True,
    instructions=dedent("""
    You are a HackerNews researcher.
    You will be given a topic to research on HackerNews.
    You will need to find the most relevant posts on HackerNews.
    """),
)

academic_paper_researcher = Agent(
    name="Academic Paper Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Research academic papers and scholarly content",
    tools=[GoogleSearchTools(), ArxivTools(download_dir=arxiv_download_dir)],
    add_name_to_context=True,
    instructions=dedent("""
    You are a academic paper researcher.
    You will be given a topic to research in academic literature.
    You will need to find relevant scholarly articles, papers, and academic discussions.
    Focus on peer-reviewed content and citations from reputable sources.
    Provide brief summaries of key findings and methodologies.
    """),
)

twitter_researcher = Agent(
    name="Twitter Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Research trending discussions and real-time updates",
    tools=[DuckDuckGoTools()],
    add_name_to_context=True,
    instructions=dedent("""
    You are a Twitter/X researcher.
    You will be given a topic to research on Twitter/X.
    You will need to find trending discussions, influential voices, and real-time updates.
    Focus on verified accounts and credible sources when possible.
    Track relevant hashtags and ongoing conversations.
    """),
)


agent_team = Team(
    name="Discussion Team",
    mode="collaborate",
    model=OpenAIChat("gpt-5-mini"),
    members=[
        reddit_researcher,
        hackernews_researcher,
        academic_paper_researcher,
        twitter_researcher,
    ],
    instructions=[
        "You are a discussion master.",
        "You have to stop the discussion when you think the team has reached a consensus.",
    ],
    markdown=True,
    show_members_responses=True,
)

if __name__ == "__main__":
    asyncio.run(
        agent_team.aprint_response(
            input="Start the discussion on the topic: 'What is the best way to learn to code?'",
            stream=True,
            stream_intermediate_steps=True,
        )
    )

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno arxiv pypdf pycountry 
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/collaborate_mode/collaboration_team.py
    ```
  </Step>
</Steps>


# HackerNews Team
Source: https://docs.agno.com/examples/use-cases/teams/hackernews_team



This example shows how to create a HackerNews team that can aggregate, curate, and discuss trending topics from HackerNews.

## Code

```python cookbook/examples/teams/coordinate_mode/hackernews_team.py
from typing import List

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.hackernews import HackerNewsTools
from agno.tools.newspaper4k import Newspaper4kTools
from pydantic import BaseModel


class Article(BaseModel):
    title: str
    summary: str
    reference_links: List[str]


hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-5-mini"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)

article_reader = Agent(
    name="Article Reader",
    role="Reads articles from URLs.",
    tools=[Newspaper4kTools()],
)


hn_team = Team(
    name="HackerNews Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[hn_researcher, web_searcher, article_reader],
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the article reader to read the links for the stories to get more information.",
        "Important: you must provide the article reader with the links to read.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    output_schema=Article,
    markdown=True,
    show_members_responses=True,
)

hn_team.print_response("Write an article about the top 2 stories on hackernews")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs newspaper4k lxml_html_clean
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/coordinate_mode/hackernews_team.py
    ```
  </Step>
</Steps>


# Multi Language Team
Source: https://docs.agno.com/examples/use-cases/teams/multi_language_team



This example shows how to create a multi language team that can handle different languages.

## Code

```python cookbook/examples/teams/route_mode/multi_language_team.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.deepseek import DeepSeek
from agno.models.mistral import MistralChat
from agno.models.openai import OpenAIChat
from agno.team import Team

japanese_agent = Agent(
    name="Japanese Agent",
    role="You only answer in Japanese",
    model=DeepSeek(id="deepseek-chat"),
)
chinese_agent = Agent(
    name="Chinese Agent",
    role="You only answer in Chinese",
    model=DeepSeek(id="deepseek-chat"),
)
spanish_agent = Agent(
    name="Spanish Agent",
    role="You only answer in Spanish",
    model=OpenAIChat(id="gpt-5-mini"),
)
french_agent = Agent(
    name="French Agent",
    role="You only answer in French",
    model=MistralChat(id="mistral-large-latest"),
)
german_agent = Agent(
    name="German Agent",
    role="You only answer in German",
    model=Claude("claude-3-5-sonnet-20241022"),
)
multi_language_team = Team(
    name="Multi Language Team",
    model=OpenAIChat("gpt-5-mini"),
    members=[
        spanish_agent,
        japanese_agent,
        french_agent,
        german_agent,
        chinese_agent,
    ],
    respond_directly=True,
    description="You are a language router that directs questions to the appropriate language agent.",
    instructions=[
        "Identify the language of the user's question and direct it to the appropriate language agent.",
        "Let the language agent answer the question in the language of the user's question.",
        "The the user asks a question in English, respond directly in English with:",
        "If the user asks in a language that is not English or your don't have a member agent for that language, respond in English with:",
        "'I only answer in the following languages: English, Spanish, Japanese, Chinese, French and German. Please ask your question in one of these languages.'",
        "Always check the language of the user's input before routing to an agent.",
        "For unsupported languages like Italian, respond in English with the above message.",
    ],
    markdown=True,
    show_members_responses=True,
)

if __name__ == "__main__":
    # Ask "How are you?" in all supported languages
    multi_language_team.print_response("Comment allez-vous?", stream=True)  # French
    multi_language_team.print_response("How are you?", stream=True)  # English
    multi_language_team.print_response("‰Ω†Â•ΩÂêóÔºü", stream=True)  # Chinese
    multi_language_team.print_response("„ÅäÂÖÉÊ∞ó„Åß„Åô„Åã?", stream=True)  # Japanese
    multi_language_team.print_response("Wie geht es Ihnen?", stream=True)  # German
    multi_language_team.print_response("Hola, ¬øc√≥mo est√°s?", stream=True)  # Spanish
    multi_language_team.print_response("Come stai?", stream=True)  # Italian
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno anthropic mistralai deepseek
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export DEEPSEEK_API_KEY=****
    export MISTRAL_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/route_mode/multi_language_team.py
    ```
  </Step>
</Steps>


# News Agency Team
Source: https://docs.agno.com/examples/use-cases/teams/news_agency_team



This example shows how to create a news agency team that can search the web, write an article, and edit it.

## Code

```python news_agency_team.py

from pathlib import Path

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools

urls_file = Path(__file__).parent.joinpath("tmp", "urls__{session_id}.md")
urls_file.parent.mkdir(parents=True, exist_ok=True)


searcher = Agent(
    name="Searcher",
    role="Searches the top URLs for a topic",
    instructions=[
        "Given a topic, first generate a list of 3 search terms related to that topic.",
        "For each search term, search the web and analyze the results.Return the 10 most relevant URLs to the topic.",
        "You are writing for the New York Times, so the quality of the sources is important.",
    ],
    tools=[DuckDuckGoTools()],
    add_datetime_to_context=True,
)
writer = Agent(
    name="Writer",
    role="Writes a high-quality article",
    description=(
        "You are a senior writer for the New York Times. Given a topic and a list of URLs, "
        "your goal is to write a high-quality NYT-worthy article on the topic."
    ),
    instructions=[
        "First read all urls using `read_article`."
        "Then write a high-quality NYT-worthy article on the topic."
        "The article should be well-structured, informative, engaging and catchy.",
        "Ensure the length is at least as long as a NYT cover story -- at a minimum, 15 paragraphs.",
        "Ensure you provide a nuanced and balanced opinion, quoting facts where possible.",
        "Focus on clarity, coherence, and overall quality.",
        "Never make up facts or plagiarize. Always provide proper attribution.",
        "Remember: you are writing for the New York Times, so the quality of the article is important.",
    ],
    tools=[Newspaper4kTools()],
    add_datetime_to_context=True,
)

editor = Team(
    name="Editor",
    model=OpenAIChat("gpt-5-mini"),
    members=[searcher, writer],
    description="You are a senior NYT editor. Given a topic, your goal is to write a NYT worthy article.",
    instructions=[
        "First ask the search journalist to search for the most relevant URLs for that topic.",
        "Then ask the writer to get an engaging draft of the article.",
        "Edit, proofread, and refine the article to ensure it meets the high standards of the New York Times.",
        "The article should be extremely articulate and well written. "
        "Focus on clarity, coherence, and overall quality.",
        "Remember: you are the final gatekeeper before the article is published, so make sure the article is perfect.",
    ],
    add_datetime_to_context=True,
    markdown=True,
    debug_mode=True,
    show_members_responses=True,
)
editor.print_response("Write an article about latest developments in AI.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install openai ddgs newspaper4k lxml_html_clean
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python news_agency_team.py
    ```
  </Step>
</Steps>


# Reasoning Team
Source: https://docs.agno.com/examples/use-cases/teams/reasoning_team



This example shows how to create a reasoning team that can handle complex queries involving web search and financial data using the `coordinate` mode with reasoning capabilities.

## Code

```python cookbook/examples/teams/coordinate_mode/reasoning_team.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.models.openai import OpenAIChat
from agno.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.reasoning import ReasoningTools
from agno.tools.exa import ExaTools

web_agent = Agent(
    name="Web Search Agent",
    role="Handle web search requests",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
)

finance_agent = Agent(
    name="Finance Agent",
    role="Handle financial data requests",
    model=OpenAIChat(id="gpt-5-mini"),  
    tools=[
        ExaTools(
            include_domains=["cnbc.com", "reuters.com", "bloomberg.com", "wsj.com"],
            show_results=True,
            text=False,
            highlights=False,
        )
    ],
    instructions=["Use tables to display data"],
)

team_leader = Team(
    name="Reasoning Team Leader",
    model=Claude(id="claude-3-7-sonnet-latest"),
    members=[
        web_agent,
        finance_agent,
    ],
    tools=[ReasoningTools(add_instructions=True)],
    markdown=True,
    show_members_responses=True,
)

team_leader.print_response(
    "Tell me 1 company in New York, 1 in San Francisco and 1 in Chicago and the stock price of each",
    stream=True,
    stream_intermediate_steps=True,
    show_full_reasoning=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno ddgs exa anthropic
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export ANTHROPIC_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python cookbook/examples/teams/coordinate_mode/reasoning_team.py
    ```
  </Step>
</Steps>


# Blog Post Generator
Source: https://docs.agno.com/examples/use-cases/workflows/blog-post-generator

This example demonstrates how to migrate from the similar workflows 1.0 example to workflows 2.0 structure.

This advanced example demonstrates how to build a sophisticated blog post generator that combines
web research capabilities with professional writing expertise. The workflow uses a multi-stage
approach:

1. Intelligent web research and source gathering
2. Content extraction and processing
3. Professional blog post writing with proper citations

Key capabilities:

* Advanced web research and source evaluation
* Content scraping and processing
* Professional writing with SEO optimization
* Automatic content caching for efficiency
* Source attribution and fact verification

Example blog topics to try:

* "The Rise of Artificial General Intelligence: Latest Breakthroughs"
* "How Quantum Computing is Revolutionizing Cybersecurity"
* "Sustainable Living in 2024: Practical Tips for Reducing Carbon Footprint"
* "The Future of Work: AI and Human Collaboration"
* "Space Tourism: From Science Fiction to Reality"
* "Mindfulness and Mental Health in the Digital Age"
* "The Evolution of Electric Vehicles: Current State and Future Trends"

Run `pip install openai ddgs newspaper4k lxml_html_clean sqlalchemy agno` to install dependencies.

```python blog_post_generator.py
"""üé® Blog Post Generator v2.0 - Your AI Content Creation Studio!

This advanced example demonstrates how to build a sophisticated blog post generator using
the new workflow v2.0 architecture. The workflow combines web research capabilities with
professional writing expertise using a multi-stage approach:

1. Intelligent web research and source gathering
2. Content extraction and processing
3. Professional blog post writing with proper citations

Key capabilities:
- Advanced web research and source evaluation
- Content scraping and processing
- Professional writing with SEO optimization
- Automatic content caching for efficiency
- Source attribution and fact verification
"""

import asyncio
import json
from textwrap import dedent
from typing import Dict, Optional

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow.workflow import Workflow
from pydantic import BaseModel, Field


# --- Response Models ---
class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )


class SearchResults(BaseModel):
    articles: list[NewsArticle]


class ScrapedArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )
    content: Optional[str] = Field(
        ...,
        description="Full article content in markdown format. None if content is unavailable.",
    )


# --- Agents ---
research_agent = Agent(
    name="Blog Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    description=dedent("""\
    You are BlogResearch-X, an elite research assistant specializing in discovering
    high-quality sources for compelling blog content. Your expertise includes:

    - Finding authoritative and trending sources
    - Evaluating content credibility and relevance
    - Identifying diverse perspectives and expert opinions
    - Discovering unique angles and insights
    - Ensuring comprehensive topic coverage
    """),
    instructions=dedent("""\
    1. Search Strategy üîç
       - Find 10-15 relevant sources and select the 5-7 best ones
       - Prioritize recent, authoritative content
       - Look for unique angles and expert insights
    2. Source Evaluation üìä
       - Verify source credibility and expertise
       - Check publication dates for timeliness
       - Assess content depth and uniqueness
    3. Diversity of Perspectives üåê
       - Include different viewpoints
       - Gather both mainstream and expert opinions
       - Find supporting data and statistics
    """),
    output_schema=SearchResults,
)

content_scraper_agent = Agent(
    name="Content Scraper Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[Newspaper4kTools()],
    description=dedent("""\
    You are ContentBot-X, a specialist in extracting and processing digital content
    for blog creation. Your expertise includes:

    - Efficient content extraction
    - Smart formatting and structuring
    - Key information identification
    - Quote and statistic preservation
    - Maintaining source attribution
    """),
    instructions=dedent("""\
    1. Content Extraction üìë
       - Extract content from the article
       - Preserve important quotes and statistics
       - Maintain proper attribution
       - Handle paywalls gracefully
    2. Content Processing üîÑ
       - Format text in clean markdown
       - Preserve key information
       - Structure content logically
    3. Quality Control ‚úÖ
       - Verify content relevance
       - Ensure accurate extraction
       - Maintain readability
    """),
    output_schema=ScrapedArticle,
)

blog_writer_agent = Agent(
    name="Blog Writer Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
    You are BlogMaster-X, an elite content creator combining journalistic excellence
    with digital marketing expertise. Your strengths include:

    - Crafting viral-worthy headlines
    - Writing engaging introductions
    - Structuring content for digital consumption
    - Incorporating research seamlessly
    - Optimizing for SEO while maintaining quality
    - Creating shareable conclusions
    """),
    instructions=dedent("""\
    1. Content Strategy üìù
       - Craft attention-grabbing headlines
       - Write compelling introductions
       - Structure content for engagement
       - Include relevant subheadings
    2. Writing Excellence ‚úçÔ∏è
       - Balance expertise with accessibility
       - Use clear, engaging language
       - Include relevant examples
       - Incorporate statistics naturally
    3. Source Integration üîç
       - Cite sources properly
       - Include expert quotes
       - Maintain factual accuracy
    4. Digital Optimization üíª
       - Structure for scanability
       - Include shareable takeaways
       - Optimize for SEO
       - Add engaging subheadings

    Format your blog post with this structure:
    # {Viral-Worthy Headline}

    ## Introduction
    {Engaging hook and context}

    ## {Compelling Section 1}
    {Key insights and analysis}
    {Expert quotes and statistics}

    ## {Engaging Section 2}
    {Deeper exploration}
    {Real-world examples}

    ## {Practical Section 3}
    {Actionable insights}
    {Expert recommendations}

    ## Key Takeaways
    - {Shareable insight 1}
    - {Practical takeaway 2}
    - {Notable finding 3}

    ## Sources
    {Properly attributed sources with links}
    """),
    markdown=True,
)


# --- Helper Functions ---
def get_cached_blog_post(session_state, topic: str) -> Optional[str]:
    """Get cached blog post from workflow session state"""
    logger.info("Checking if cached blog post exists")
    return session_state.get("blog_posts", {}).get(topic)


def cache_blog_post(session_state, topic: str, blog_post: str):
    """Cache blog post in workflow session state"""
    logger.info(f"Saving blog post for topic: {topic}")
    if "blog_posts" not in session_state:
        session_state["blog_posts"] = {}
    session_state["blog_posts"][topic] = blog_post


def get_cached_search_results(session_state, topic: str) -> Optional[SearchResults]:
    """Get cached search results from workflow session state"""
    logger.info("Checking if cached search results exist")
    search_results = session_state.get("search_results", {}).get(topic)
    if search_results and isinstance(search_results, dict):
        try:
            return SearchResults.model_validate(search_results)
        except Exception as e:
            logger.warning(f"Could not validate cached search results: {e}")
    return search_results if isinstance(search_results, SearchResults) else None


def cache_search_results(session_state, topic: str, search_results: SearchResults):
    """Cache search results in workflow session state"""
    logger.info(f"Saving search results for topic: {topic}")
    if "search_results" not in session_state:
        session_state["search_results"] = {}
    session_state["search_results"][topic] = search_results.model_dump()


def get_cached_scraped_articles(
    session_state, topic: str
) -> Optional[Dict[str, ScrapedArticle]]:
    """Get cached scraped articles from workflow session state"""
    logger.info("Checking if cached scraped articles exist")
    scraped_articles = session_state.get("scraped_articles", {}).get(topic)
    if scraped_articles and isinstance(scraped_articles, dict):
        try:
            return {
                url: ScrapedArticle.model_validate(article)
                for url, article in scraped_articles.items()
            }
        except Exception as e:
            logger.warning(f"Could not validate cached scraped articles: {e}")
    return scraped_articles if isinstance(scraped_articles, dict) else None


def cache_scraped_articles(
    session_state, topic: str, scraped_articles: Dict[str, ScrapedArticle]
):
    """Cache scraped articles in workflow session state"""
    logger.info(f"Saving scraped articles for topic: {topic}")
    if "scraped_articles" not in session_state:
        session_state["scraped_articles"] = {}
    session_state["scraped_articles"][topic] = {
        url: article.model_dump() for url, article in scraped_articles.items()
    }


async def get_search_results(
    session_state, topic: str, use_cache: bool = True, num_attempts: int = 3
) -> Optional[SearchResults]:
    """Get search results with caching support"""

    # Check cache first
    if use_cache:
        cached_results = get_cached_search_results(session_state, topic)
        if cached_results:
            logger.info(f"Found {len(cached_results.articles)} articles in cache.")
            return cached_results

    # Search for new results
    for attempt in range(num_attempts):
        try:
            print(
                f"üîç Searching for articles about: {topic} (attempt {attempt + 1}/{num_attempts})"
            )
            response = await research_agent.arun(topic)

            if (
                response
                and response.content
                and isinstance(response.content, SearchResults)
            ):
                article_count = len(response.content.articles)
                logger.info(f"Found {article_count} articles on attempt {attempt + 1}")
                print(f"‚úÖ Found {article_count} relevant articles")

                # Cache the results
                cache_search_results(session_state, topic, response.content)
                return response.content
            else:
                logger.warning(
                    f"Attempt {attempt + 1}/{num_attempts} failed: Invalid response type"
                )

        except Exception as e:
            logger.warning(f"Attempt {attempt + 1}/{num_attempts} failed: {str(e)}")

    logger.error(f"Failed to get search results after {num_attempts} attempts")
    return None


async def scrape_articles(
    session_state,
    topic: str,
    search_results: SearchResults,
    use_cache: bool = True,
) -> Dict[str, ScrapedArticle]:
    """Scrape articles with caching support"""

    # Check cache first
    if use_cache:
        cached_articles = get_cached_scraped_articles(session_state, topic)
        if cached_articles:
            logger.info(f"Found {len(cached_articles)} scraped articles in cache.")
            return cached_articles

    scraped_articles: Dict[str, ScrapedArticle] = {}

    print(f"üìÑ Scraping {len(search_results.articles)} articles...")

    for i, article in enumerate(search_results.articles, 1):
        try:
            print(
                f"üìñ Scraping article {i}/{len(search_results.articles)}: {article.title[:50]}..."
            )
            response = await content_scraper_agent.arun(article.url)

            if (
                response
                and response.content
                and isinstance(response.content, ScrapedArticle)
            ):
                scraped_articles[response.content.url] = response.content
                logger.info(f"Scraped article: {response.content.url}")
                print(f"‚úÖ Successfully scraped: {response.content.title[:50]}...")
            else:
                print(f"‚ùå Failed to scrape: {article.title[:50]}...")

        except Exception as e:
            logger.warning(f"Failed to scrape {article.url}: {str(e)}")
            print(f"‚ùå Error scraping: {article.title[:50]}...")

    # Cache the scraped articles
    cache_scraped_articles(session_state, topic, scraped_articles)
    return scraped_articles


# --- Main Execution Function ---
async def blog_generation_execution(
    session_state,
    topic: str = None,
    use_search_cache: bool = True,
    use_scrape_cache: bool = True,
    use_blog_cache: bool = True,
) -> str:
    """
    Blog post generation workflow execution function.

    Args:
        session_state: The shared session state
        topic: Blog post topic (if not provided, uses execution_input.input)
        use_search_cache: Whether to use cached search results
        use_scrape_cache: Whether to use cached scraped articles
        use_blog_cache: Whether to use cached blog posts
    """

    blog_topic = topic

    if not blog_topic:
        return "‚ùå No blog topic provided. Please specify a topic."

    print(f"üé® Generating blog post about: {blog_topic}")
    print("=" * 60)

    # Check for cached blog post first
    if use_blog_cache:
        cached_blog = get_cached_blog_post(session_state, blog_topic)
        if cached_blog:
            print("üìã Found cached blog post!")
            return cached_blog

    # Phase 1: Research and gather sources
    print("\nüîç PHASE 1: RESEARCH & SOURCE GATHERING")
    print("=" * 50)

    search_results = await get_search_results(
        session_state, blog_topic, use_search_cache
    )

    if not search_results or len(search_results.articles) == 0:
        return f"‚ùå Sorry, could not find any articles on the topic: {blog_topic}"

    print(f"üìä Found {len(search_results.articles)} relevant sources:")
    for i, article in enumerate(search_results.articles, 1):
        print(f"   {i}. {article.title[:60]}...")

    # Phase 2: Content extraction
    print("\nüìÑ PHASE 2: CONTENT EXTRACTION")
    print("=" * 50)

    scraped_articles = await scrape_articles(
        session_state, blog_topic, search_results, use_scrape_cache
    )

    if not scraped_articles:
        return f"‚ùå Could not extract content from any articles for topic: {blog_topic}"

    print(f"üìñ Successfully extracted content from {len(scraped_articles)} articles")

    # Phase 3: Blog post writing
    print("\n‚úçÔ∏è PHASE 3: BLOG POST CREATION")
    print("=" * 50)

    # Prepare input for the writer
    writer_input = {
        "topic": blog_topic,
        "articles": [article.model_dump() for article in scraped_articles.values()],
    }

    print("ü§ñ AI is crafting your blog post...")
    writer_response = await blog_writer_agent.arun(json.dumps(writer_input, indent=2))

    if not writer_response or not writer_response.content:
        return f"‚ùå Failed to generate blog post for topic: {blog_topic}"

    blog_post = writer_response.content

    # Cache the blog post
    cache_blog_post(session_state, blog_topic, blog_post)

    print("‚úÖ Blog post generated successfully!")
    print(f"üìù Length: {len(blog_post)} characters")
    print(f"üìö Sources: {len(scraped_articles)} articles")

    return blog_post


# --- Workflow Definition ---
blog_generator_workflow = Workflow(
    name="Blog Post Generator",
    description="Advanced blog post generator with research and content creation capabilities",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/blog_generator.db",
    ),
    steps=blog_generation_execution,
    session_state={},  # Initialize empty session state for caching
)


if __name__ == "__main__":
    import random

    async def main():
        # Fun example topics to showcase the generator's versatility
        example_topics = [
            "The Rise of Artificial General Intelligence: Latest Breakthroughs",
            "How Quantum Computing is Revolutionizing Cybersecurity",
            "Sustainable Living in 2024: Practical Tips for Reducing Carbon Footprint",
            "The Future of Work: AI and Human Collaboration",
            "Space Tourism: From Science Fiction to Reality",
            "Mindfulness and Mental Health in the Digital Age",
            "The Evolution of Electric Vehicles: Current State and Future Trends",
            "Why Cats Secretly Run the Internet",
            "The Science Behind Why Pizza Tastes Better at 2 AM",
            "How Rubber Ducks Revolutionized Software Development",
        ]

        # Test with a random topic
        topic = random.choice(example_topics)

        print("üß™ Testing Blog Post Generator v2.0")
        print("=" * 60)
        print(f"üìù Topic: {topic}")
        print()

        # Generate the blog post
        resp = await blog_generator_workflow.arun(
            topic=topic,
            use_search_cache=True,
            use_scrape_cache=True,
            use_blog_cache=True,
        )

        pprint_run_response(resp, markdown=True, show_time=True)

    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai ddgs newspaper4k lxml_html_clean sqlalchemy agno
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python blog_post_generator.py
    ```
  </Step>
</Steps>


# Company Description Workflow
Source: https://docs.agno.com/examples/use-cases/workflows/company-description

A workflow that generates comprehensive supplier profiles by gathering information from multiple sources and delivers them via email.

## Overview

This workflow combines web crawling, search engines, Wikipedia, and competitor analysis to create detailed supplier profiles. It processes company information through 4 specialized agents running in parallel, then generates a structured markdown report and sends it via email.

The workflow uses workflow session state management to cache analysis results. If the same supplier is analyzed again, it returns cached results instead of re-running the expensive analysis pipeline.

## Getting Started

### Prerequisites

* OpenAI API key
* Resend API key for emails \[[https://resend.com/api-keys](https://resend.com/api-keys)]
* Firecrawl API key for web crawling \[[https://www.firecrawl.dev/app/api-keys](https://www.firecrawl.dev/app/api-keys)]

### Quick Setup

```bash
export OPENAI_API_KEY="your-openai-key"
export RESEND_API_KEY="your-resend-key"
export FIRECRAWL_API_KEY="your-firecrawl-key"
```

Install dependencies

```
pip install agno openai firecrawl-py resend
```

## Code Structure

This company description workflow consists of three main files:

### 1. Agents (`agents.py`)

Specialized agents for gathering information from multiple sources:

```python agents.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.firecrawl import FirecrawlTools
from agno.tools.wikipedia import WikipediaTools
from prompts import (
    COMPETITOR_INSTRUCTIONS,
    CRAWLER_INSTRUCTIONS,
    SEARCH_INSTRUCTIONS,
    SUPPLIER_PROFILE_INSTRUCTIONS_GENERAL,
    WIKIPEDIA_INSTRUCTIONS,
)
from pydantic import BaseModel


class SupplierProfile(BaseModel):
    supplier_name: str
    supplier_homepage_url: str
    user_email: str


crawl_agent: Agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[FirecrawlTools(crawl=True, limit=5)],
    instructions=CRAWLER_INSTRUCTIONS,
)

search_agent: Agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=SEARCH_INSTRUCTIONS,
)

wikipedia_agent: Agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[WikipediaTools()],
    instructions=WIKIPEDIA_INSTRUCTIONS,
)

competitor_agent: Agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions=COMPETITOR_INSTRUCTIONS,
)

profile_agent: Agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=SUPPLIER_PROFILE_INSTRUCTIONS_GENERAL,
)
```

### 2. Prompts (`prompts.py`)

Detailed instructions for each specialized agent:

```python prompts.py
CRAWLER_INSTRUCTIONS = """
Your task is to crawl a website starting from the provided homepage URL. Follow these guidelines:

1. Initial Access: Begin by accessing the homepage URL.
2. Comprehensive Crawling: Recursively traverse the website to capture every accessible page and resource.
3. Data Extraction: Extract all available content, including text, images, metadata, and embedded resources, while preserving the original structure and context.
4. Detailed Reporting: Provide an extremely detailed and comprehensive response, including all extracted content without filtering or omissions.
5. Data Integrity: Ensure that the extracted content accurately reflects the website without any modifications.
"""

SEARCH_INSTRUCTIONS = """
You are tasked with searching the web for information about a supplier. Follow these guidelines:

1. Input: You will be provided with the name of the supplier.
2. Web Search: Perform comprehensive web searches to gather information about the supplier.
3. Latest News: Search for the most recent news and updates regarding the supplier.
4. Information Extraction: From the search results, extract all relevant details about the supplier.
5. Detailed Reporting: Provide an extremely verbose and detailed report that includes all relevant information without filtering or omissions.
"""

WIKIPEDIA_INSTRUCTIONS = """
You are tasked with searching Wikipedia for information about a supplier. Follow these guidelines:

1. Input: You will be provided with the name of the supplier.
2. Wikipedia Search: Use Wikipedia to find comprehensive information about the supplier.
3. Data Extraction: Extract all relevant details available on the supplier, including history, operations, products, and any other pertinent information.
4. Detailed Reporting: Provide an extremely verbose and detailed report that includes all extracted content without filtering or omissions.
"""

COMPETITOR_INSTRUCTIONS = """
You are tasked with finding competitors of a supplier. Follow these guidelines:

1. Input: You will be provided with the name of the supplier.
2. Competitor Search: Search the web for competitors of the supplier.
3. Data Extraction: Extract all relevant details about the competitors.
4. Detailed Reporting: Provide an extremely verbose and detailed report that includes all extracted content without filtering or omissions.
"""

SUPPLIER_PROFILE_INSTRUCTIONS_GENERAL = """
You are a supplier profile agent. You are given a supplier name, results from the supplier homepage and search results regarding the supplier, and Wikipedia results regarding the supplier. You need to be extremely verbose in your response. Do not filter out any content.

You are tasked with generating a segment of a supplier profile. The segment will be provided to you. Make sure to format it in markdown.

General format:

Title: [Title of the segment]

[Segment]

Formatting Guidelines:
1. Ensure the profile is structured, clear, and to the point.
2. Avoid assumptions‚Äîonly include verified details.
3. Use bullet points and short paragraphs for readability.
4. Cite sources where applicable for credibility.

Objective: This supplier profile should serve as a reliable reference document for businesses evaluating potential suppliers. The details should be extracted from official sources, search results, and any other reputable databases. The profile must provide an in-depth understanding of the supplier's operational, competitive, and financial position to support informed decision-making.

"""

SUPPLIER_PROFILE_DICT = {
    "1. Supplier Overview": """Company Name: [Supplier Name]
Industry: [Industry the supplier operates in]
Headquarters: [City, Country]
Year Founded: [Year]
Key Offerings: [Brief summary of main products or services]
Business Model: [Manufacturing, Wholesale, B2B/B2C, etc.]
Notable Clients & Partnerships: [List known customers or business partners]
Company Mission & Vision: [Summary of supplier's goals and commitments]""",
    #     "2. Website Content Summary": """Extract key details from the supplier's official website:
    # Website URL: [Supplier's official website link]
    # Products & Services Overview:
    #   - [List major product categories or services]
    #   - [Highlight any specialized offerings]
    # Certifications & Compliance: (e.g., ISO, FDA, CE, etc.)
    # Manufacturing & Supply Chain Information:
    #   - Factory locations, supply chain transparency, etc.
    # Sustainability & Corporate Social Responsibility (CSR):
    #   - Environmental impact, ethical sourcing, fair labor practices
    # Customer Support & After-Sales Services:
    #   - Warranty, return policies, support channels""",
    #     "3. Search Engine Insights": """Summarize search results to provide additional context on the supplier's market standing:
    # Latest News & Updates: [Any recent developments, funding rounds, expansions]
    # Industry Mentions: [Publications, blogs, or analyst reviews mentioning the supplier]
    # Regulatory Issues or Legal Disputes: [Any lawsuits, recalls, or compliance issues]
    # Competitive Positioning: [How the supplier compares to competitors in the market]""",
    #     "4. Key Contact Information": """Include publicly available contact details for business inquiries:
    # Email: [Customer support, sales, or partnership email]
    # Phone Number: [+XX-XXX-XXX-XXXX]
    # Office Address: [Headquarters or regional office locations]
    # LinkedIn Profile: [Supplier's LinkedIn page]
    # Other Business Directories: [Crunchbase, Alibaba, etc.]""",
    #     "5. Reputation & Reviews": """Analyze customer and partner feedback from multiple sources:
    # Customer Reviews & Testimonials: [Summarized from Trustpilot, Google Reviews, etc.]
    # Third-Party Ratings: [Any industry-recognized rankings or awards]
    # Complaints & Risks: [Potential risks, delays, quality issues, or fraud warnings]
    # Social Media Presence & Engagement: [Activity on LinkedIn, Twitter, etc.]""",
    #     "6. Additional Insights": """Pricing Model: [Wholesale, subscription, per-unit pricing, etc.]
    # MOQ (Minimum Order Quantity): [If applicable]
    # Return & Refund Policies: [Key policies for buyers]
    # Logistics & Shipping: [Lead times, global shipping capabilities]""",
    #     "7. Supplier Insight": """Provide a deep-dive analysis into the supplier's market positioning and business strategy:
    # Market Trends: [How current market trends impact the supplier]
    # Strategic Advantages: [Unique selling points or competitive edge]
    # Challenges & Risks: [Any operational or market-related challenges]
    # Future Outlook: [Predicted growth or strategic initiatives]""",
    #     "8. Supplier Profiles": """Create a comparative profile if multiple suppliers are being evaluated:
    # Comparative Metrics: [Key differentiators among suppliers]
    # Strengths & Weaknesses: [Side-by-side comparison details]
    # Strategic Fit: [How each supplier aligns with potential buyer needs]""",
    #     "9. Product Portfolio": """Detail the range and depth of the supplier's offerings:
    # Major Product Lines: [Detailed listing of core products or services]
    # Innovations & Specialized Solutions: [Highlight any innovative products or custom solutions]
    # Market Segments: [Industries or consumer segments served by the products]""",
    #     "10. Competitive Intelligence": """Summarize the supplier's competitive landscape:
    # Industry Competitors: [List of main competitors]
    # Market Share: [If available, indicate the supplier's market share]
    # Competitive Strategies: [Pricing, marketing, distribution, etc.]
    # Recent Competitor Moves: [Any recent competitive actions impacting the market]""",
    #     "11. Supplier Quadrant": """Position the supplier within a competitive quadrant analysis:
    # Quadrant Position: [Leader, Challenger, Niche Player, or Visionary]
    # Analysis Criteria: [Innovativeness, operational efficiency, market impact, etc.]
    # Visual Representation: [If applicable, describe or include a link to the quadrant chart]""",
    #     "12. SWOT Analysis": """Perform a comprehensive SWOT analysis:
    # Strengths: [Internal capabilities and competitive advantages]
    # Weaknesses: [Areas for improvement or potential vulnerabilities]
    # Opportunities: [External market opportunities or expansion potentials]
    # Threats: [External risks, competitive pressures, or regulatory challenges]""",
    #     "13. Financial Risk Summary": """Evaluate the financial stability and risk factors:
    # Financial Health: [Overview of revenue, profitability, and growth metrics]
    # Risk Factors: [Credit risk, market volatility, or liquidity issues]
    # Investment Attractiveness: [Analysis for potential investors or partners]""",
    #     "14. Financial Information": """Provide detailed financial data (where publicly available):
    # Revenue Figures: [Latest annual revenue, growth trends]
    # Profitability: [Net income, EBITDA, etc.]
    # Funding & Investment: [Details of any funding rounds, investor names]
    # Financial Reports: [Links or summaries of recent financial statements]
    # Credit Ratings: [If available, include credit ratings or financial stability indicators]""",
}
```

### 3. Workflow Implementation (`run_workflow.py`)

Complete workflow with parallel information gathering and email delivery:

```python run_workflow.py
import markdown
import resend
from agents import (
    SupplierProfile,
    competitor_agent,
    crawl_agent,
    search_agent,
    wikipedia_agent,
)
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.agent import RunOutput
from agno.utils.log import log_error, log_info
from agno.workflow import Parallel, Step, Workflow
from agno.workflow.types import StepInput, StepOutput
from prompts import SUPPLIER_PROFILE_DICT, SUPPLIER_PROFILE_INSTRUCTIONS_GENERAL

crawler_step = Step(
    name="Crawler",
    agent=crawl_agent,
    description="Crawl the supplier homepage for the supplier profile url",
)

search_step = Step(
    name="Search",
    agent=search_agent,
    description="Search for the supplier profile for the supplier name",
)

wikipedia_step = Step(
    name="Wikipedia",
    agent=wikipedia_agent,
    description="Search Wikipedia for the supplier profile for the supplier name",
)

competitor_step = Step(
    name="Competitor",
    agent=competitor_agent,
    description="Find competitors of the supplier name",
)


def generate_supplier_profile(step_input: StepInput) -> StepOutput:
    supplier_profile: SupplierProfile = step_input.input

    supplier_name: str = supplier_profile.supplier_name
    supplier_homepage_url: str = supplier_profile.supplier_homepage_url

    crawler_data: str = step_input.get_step_content("Gathering Information")["Crawler"]
    search_data: str = step_input.get_step_content("Gathering Information")["Search"]
    wikipedia_data: str = step_input.get_step_content("Gathering Information")[
        "Wikipedia"
    ]
    competitor_data: str = step_input.get_step_content("Gathering Information")[
        "Competitor"
    ]

    log_info(f"Crawler data: {crawler_data}")
    log_info(f"Search data: {search_data}")
    log_info(f"Wikipedia data: {wikipedia_data}")
    log_info(f"Competitor data: {competitor_data}")

    supplier_profile_prompt: str = f"Generate the supplier profile for the supplier name {supplier_name} and the supplier homepage url is {supplier_homepage_url}. The supplier homepage is {crawler_data} and the search results are {search_data} and the wikipedia results are {wikipedia_data} and the competitor results are {competitor_data}"

    supplier_profile_response: str = ""
    html_content: str = ""
    for key, value in SUPPLIER_PROFILE_DICT.items():
        agent = Agent(
            model=OpenAIChat(id="gpt-5-mini"),
            instructions="Instructions: "
            + SUPPLIER_PROFILE_INSTRUCTIONS_GENERAL
            + "Format to adhere to: "
            + value,
        )
        response: RunOutput = agent.run(
            "Write the response in markdown format for the title: "
            + key
            + " using the following information: "
            + supplier_profile_prompt
        )
        if response.content:
            html_content += markdown.markdown(response.content)
            supplier_profile_response += response.content

    log_info(f"Generated supplier profile for {html_content}")

    return StepOutput(
        content=html_content,
        success=True,
    )


generate_supplier_profile_step = Step(
    name="Generate Supplier Profile",
    executor=generate_supplier_profile,
    description="Generate the supplier profile for the supplier name",
)


def send_email(step_input: StepInput):
    supplier_profile: SupplierProfile = step_input.input
    supplier_name: str = supplier_profile.supplier_name
    user_email: str = supplier_profile.user_email

    html_content: str = step_input.get_step_content("Generate Supplier Profile")

    try:
        resend.Emails.send(
            {
                "from": "support@agno.com",
                "to": user_email,
                "subject": f"Supplier Profile for {supplier_name}",
                "html": html_content,
            }
        )
    except Exception as e:
        log_error(f"Error sending email: {e}")

    return StepOutput(
        content="Email sent successfully",
        success=True,
    )


send_email_step = Step(
    name="Send Email",
    executor=send_email,
    description="Send the email to the user",
)

company_description_workflow = Workflow(
    name="Company Description Workflow",
    description="A workflow to generate a company description for a supplier",
    steps=[
        Parallel(
            crawler_step,
            search_step,
            wikipedia_step,
            competitor_step,
            name="Gathering Information",
        ),
        generate_supplier_profile_step,
        send_email_step,
    ],
)

if __name__ == "__main__":
    supplier_profile_request = SupplierProfile(
        supplier_name="Agno",
        supplier_homepage_url="https://www.agno.com",
        user_email="yash@agno.com",
    )
    company_description_workflow.print_response(
        input=supplier_profile_request,
    )
```

## Key Features

* **üîÑ Parallel Processing**: Four agents gather information simultaneously for maximum efficiency
* **üåê Multi-Source Data**: Combines web crawling, search engines, Wikipedia, and competitor analysis
* **üìß Email Integration**: Automatically sends formatted reports via email using Resend
* **üìÑ Markdown Formatting**: Generates structured, readable reports in HTML format
* **üèóÔ∏è Modular Design**: Clean separation of agents, prompts, and workflow logic
* **‚ö° Efficient Execution**: Uses parallel steps to minimize execution time
* **üéØ Type Safety**: Pydantic models for structured data validation

## Usage Example

```python
# Create supplier profile request
supplier_request = SupplierProfile(
    supplier_name="Your Company Name",
    supplier_homepage_url="https://yourcompany.com",
    user_email="your.email@company.com",
)

# Run the workflow
company_description_workflow.print_response(
    input=supplier_request,
)
```

## Expected Output

The workflow will:

1. **Gather Information**: Simultaneously crawl the website, search the web, check Wikipedia, and find competitors
2. **Generate Profile**: Create a comprehensive supplier profile with detailed sections
3. **Send Email**: Deliver the formatted HTML report to the specified email address

The generated supplier profile includes:

* Company overview and basic information
* Detailed analysis from multiple data sources
* Structured markdown formatting for readability
* Professional email delivery with HTML formatting

Run the workflow with:

```bash
python run_workflow.py
```

**More Examples:**

* [Company Analysis](https://github.com/agno-agi/agno/tree/main/cookbook/examples/workflows/company_analysis)
* [Customer Support](https://github.com/agno-agi/agno/tree/main/cookbook/examples/workflows/customer_support)
* [Investment Analyst](https://github.com/agno-agi/agno/tree/main/cookbook/examples/workflows/investment_analyst)


# Employee Recruiter
Source: https://docs.agno.com/examples/use-cases/workflows/employee-recruiter

This example demonstrates how to migrate from the similar workflows 1.0 example to workflows 2.0 structure.

Employee Recruitment Workflow with Simulated Tools

This workflow automates the complete employee recruitment process from resume screening
to interview scheduling and email communication. It demonstrates a multi-agent system
working together to handle different aspects of the hiring pipeline.

Workflow Overview:

1. **Resume Screening**: Analyzes candidate resumes against job requirements and scores them
2. **Interview Scheduling**: Schedules interviews for qualified candidates (score >= 5.0)
3. **Email Communication**: Sends professional interview invitation emails

Key Features:

* **Multi-Agent Architecture**: Uses specialized agents for screening, scheduling, and email writing
* **Async Streaming**: Provides real-time feedback during execution
* **Simulated Tools**: Uses mock Zoom scheduling and email sending for demonstration
* **Resume Processing**: Extracts text from PDF resumes via URLs
* **Structured Responses**: Uses Pydantic models for type-safe data handling
* **Session State**: Caches resume content to avoid re-processing

Agents:

* **Screening Agent**: Evaluates candidates and provides scores/feedback
* **Scheduler Agent**: Creates interview appointments with realistic time slots
* **Email Writer Agent**: Composes professional interview invitation emails
* **Email Sender Agent**: Handles email delivery (simulated)

Usage:
python employee\_recruiter\_async\_stream.py

Input Parameters:

* message: Instructions for the recruitment process
* candidate\_resume\_urls: List of PDF resume URLs to process
* job\_description: The job posting requirements and details

Output:

* Streaming updates on each phase of the recruitment process
* Candidate screening results with scores and feedback
* Interview scheduling confirmations
* Email delivery confirmations

Note: This workflow uses simulated tools for Zoom scheduling and email sending
to demonstrate the concept, you can use the real tools in practice.

Run `pip install openai agno pypdf` to install dependencies.

```python employee_recruiter_async_stream.py

import asyncio
import io
import random
from datetime import datetime, timedelta
from typing import Any, List

import requests
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.workflow.types import WorkflowExecutionInput
from agno.workflow.workflow import Workflow
from pydantic import BaseModel
from pypdf import PdfReader


# --- Response models ---
class ScreeningResult(BaseModel):
    name: str
    email: str
    score: float
    feedback: str


class ScheduledCall(BaseModel):
    name: str
    email: str
    call_time: str
    url: str


class EmailContent(BaseModel):
    subject: str
    body: str


# --- PDF utility ---
def extract_text_from_pdf(url: str) -> str:
    try:
        resp = requests.get(url)
        resp.raise_for_status()
        reader = PdfReader(io.BytesIO(resp.content))
        return "\n".join(page.extract_text() or "" for page in reader.pages)
    except Exception as e:
        print(f"Error extracting PDF from {url}: {e}")
        return ""


# --- Simulation tools ---
def simulate_zoom_scheduling(
    agent: Agent, candidate_name: str, candidate_email: str
) -> str:
    """Simulate Zoom call scheduling"""
    # Generate a future time slot (1-7 days from now, between 10am-6pm IST)
    base_time = datetime.now() + timedelta(days=random.randint(1, 7))
    hour = random.randint(10, 17)  # 10am to 5pm
    scheduled_time = base_time.replace(hour=hour, minute=0, second=0, microsecond=0)

    # Generate fake Zoom URL
    meeting_id = random.randint(100000000, 999999999)
    zoom_url = f"https://zoom.us/j/{meeting_id}"

    result = "‚úÖ Zoom call scheduled successfully!\n"
    result += f"üìÖ Time: {scheduled_time.strftime('%Y-%m-%d %H:%M')} IST\n"
    result += f"üîó Meeting URL: {zoom_url}\n"
    result += f"üë§ Participant: {candidate_name} ({candidate_email})"

    return result


def simulate_email_sending(agent: Agent, to_email: str, subject: str, body: str) -> str:
    """Simulate email sending"""
    result = "üìß Email sent successfully!\n"
    result += f"üìÆ To: {to_email}\n"
    result += f"üìù Subject: {subject}\n"
    result += f"‚úâÔ∏è Body length: {len(body)} characters\n"
    result += f"üïê Sent at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

    return result


# --- Agents ---
screening_agent = Agent(
    name="Screening Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Screen candidate given resume text and job description.",
        "Provide a score from 0-10 based on how well they match the job requirements.",
        "Give specific feedback on strengths and areas of concern.",
        "Extract the candidate's name and email from the resume if available.",
    ],
    output_schema=ScreeningResult,
)

scheduler_agent = Agent(
    name="Scheduler Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        f"You are scheduling interview calls. Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} IST",
        "Schedule calls between 10am-6pm IST on weekdays.",
        "Use the simulate_zoom_scheduling tool to create the meeting.",
        "Provide realistic future dates and times.",
    ],
    tools=[simulate_zoom_scheduling],
    output_schema=ScheduledCall,
)

email_writer_agent = Agent(
    name="Email Writer Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Write professional, friendly interview invitation emails.",
        "Include congratulations, interview details, and next steps.",
        "Keep emails concise but warm and welcoming.",
        "Sign emails as 'John Doe, Senior Software Engineer' with email john@agno.com",
    ],
    output_schema=EmailContent,
)

email_sender_agent = Agent(
    name="Email Sender Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "You send emails using the simulate_email_sending tool.",
        "Always confirm successful delivery with details.",
    ],
    tools=[simulate_email_sending],
)


# --- Execution function ---
async def recruitment_execution(
    session_state,
    execution_input: WorkflowExecutionInput,
    job_description: str,
    **kwargs: Any,
):
    """Execute the complete recruitment workflow"""

    # Get inputs
    message: str = execution_input.input
    jd: str = job_description
    resumes: List[str] = kwargs.get("candidate_resume_urls", [])

    if not resumes:
        yield "‚ùå No candidate resume URLs provided"

    if not jd:
        yield "‚ùå No job description provided"

    print(f"üöÄ Starting recruitment process for {len(resumes)} candidates")
    print(f"üìã Job Description: {jd[:100]}{'...' if len(jd) > 100 else ''}")

    selected_candidates: List[ScreeningResult] = []

    # Phase 1: Screening
    print("\nüìä PHASE 1: CANDIDATE SCREENING")
    print("=" * 50)

    for i, url in enumerate(resumes, 1):
        print(f"\nüîç Processing candidate {i}/{len(resumes)}")

        # Extract resume text (with caching)
        if url not in session_state:
            print(f"üìÑ Extracting text from: {url}")
            session_state[url] = extract_text_from_pdf(url)
        else:
            print("üìã Using cached resume content")

        resume_text = session_state[url]

        if not resume_text:
            print("‚ùå Could not extract text from resume")
            continue

        # Screen the candidate
        screening_prompt = f"""
        {message}
        Please screen this candidate for the job position.

        RESUME:
        {resume_text}

        JOB DESCRIPTION:
        {jd}

        Evaluate how well this candidate matches the job requirements and provide a score from 0-10.
        """

        async for response in screening_agent.arun(
            screening_prompt, stream=True, stream_intermediate_steps=True
        ):
            if hasattr(response, "content") and response.content:
                candidate = response.content

        print(f"üë§ Candidate: {candidate.name}")
        print(f"üìß Email: {candidate.email}")
        print(f"‚≠ê Score: {candidate.score}/10")
        print(
            f"üí≠ Feedback: {candidate.feedback[:150]}{'...' if len(candidate.feedback) > 150 else ''}"
        )

        if candidate.score >= 5.0:
            selected_candidates.append(candidate)
            print("‚úÖ SELECTED for interview!")
        else:
            print("‚ùå Not selected (score below 5.0)")

    # Phase 2: Interview Scheduling & Email Communication
    if selected_candidates:
        print("\nüìÖ PHASE 2: INTERVIEW SCHEDULING")
        print("=" * 50)

        for i, candidate in enumerate(selected_candidates, 1):
            print(
                f"\nüóìÔ∏è Scheduling interview {i}/{len(selected_candidates)} for {candidate.name}"
            )

            # Schedule interview
            schedule_prompt = f"""
            Schedule a 1-hour interview call for:
            - Candidate: {candidate.name}
            - Email: {candidate.email}
            - Interviewer: Dirk Brand (dirk@phidata.com)
            Use the simulate_zoom_scheduling tool to create the meeting.
            """

            async for response in scheduler_agent.arun(
                schedule_prompt, stream=True, stream_intermediate_steps=True
            ):
                if hasattr(response, "content") and response.content:
                    scheduled_call = response.content

            print(f"üìÖ Scheduled for: {scheduled_call.call_time}")
            print(f"üîó Meeting URL: {scheduled_call.url}")

            # Write congratulatory email
            email_prompt = f"""
            Write a professional interview invitation email for:
            - Candidate: {candidate.name} ({candidate.email})
            - Interview time: {scheduled_call.call_time}
            - Meeting URL: {scheduled_call.url}
            - Congratulate them on being selected
            - Include next steps and what to expect
            """

            async for response in email_writer_agent.arun(
                email_prompt, stream=True, stream_intermediate_steps=True
            ):
                if hasattr(response, "content") and response.content:
                    email_content = response.content

            print(f"‚úèÔ∏è Email subject: {email_content.subject}")

            # Send email
            send_prompt = f"""
            Send the interview invitation email:
            - To: {candidate.email}
            - Subject: {email_content.subject}
            - Body: {email_content.body}
            Use the simulate_email_sending tool.
            """

            async for response in email_sender_agent.arun(
                send_prompt, stream=True, stream_intermediate_steps=True
            ):
                yield response


# --- Workflow definition ---
recruitment_workflow = Workflow(
    name="Employee Recruitment Workflow (Simulated)",
    description="Automated candidate screening with simulated scheduling and email",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflows.db",
    ),
    steps=recruitment_execution,
    session_state={},
)


if __name__ == "__main__":
    # Test with sample data
    print("üß™ Testing Employee Recruitment Workflow with Simulated Tools")
    print("=" * 60)

    asyncio.run(
        recruitment_workflow.aprint_response(
            input="Process candidates for backend engineer position",
            candidate_resume_urls=[
                "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/filters/cv_1.pdf",
                "https://agno-public.s3.us-east-1.amazonaws.com/demo_data/filters/cv_2.pdf",
            ],
            job_description="""
        We are hiring for backend and systems engineers!
        Join our team building the future of agentic software

        Requirements:
        üß† You know your way around Python, typescript, docker, and AWS.
        ‚öôÔ∏è Love to build in public and contribute to open source.
        üöÄ Are ok dealing with the pressure of an early-stage startup.
        üèÜ Want to be a part of the biggest technological shift since the internet.
        üåü Bonus: experience with infrastructure as code.
        üåü Bonus: starred Agno repo.
        """,
            stream=True,
            stream_intermediate_steps=True,
        )
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    openai agno pypdf
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python employee_recruiter_async_stream.py
    ```
  </Step>
</Steps>


# Investment Report Generator
Source: https://docs.agno.com/examples/use-cases/workflows/investment-report-generator

This example demonstrates how to build a sophisticated investment analysis system that combines market research, financial analysis, and portfolio management.

This advanced example demonstrates how to build a sophisticated investment analysis system that combines
market research, financial analysis, and portfolio management. The workflow uses a three-stage
approach:

1. Comprehensive stock analysis and market research
2. Investment potential evaluation and ranking
3. Strategic portfolio allocation recommendations

Key capabilities:

* Real-time market data analysis
* Professional financial research
* Investment risk assessment
* Portfolio allocation strategy
* Detailed investment rationale

Example companies to analyze:

* "AAPL, MSFT, GOOGL" (Tech Giants)
* "NVDA, AMD, INTC" (Semiconductor Leaders)
* "TSLA, F, GM" (Automotive Innovation)
* "JPM, BAC, GS" (Banking Sector)
* "AMZN, WMT, TGT" (Retail Competition)
* "PFE, JNJ, MRNA" (Healthcare Focus)
* "XOM, CVX, BP" (Energy Sector)

Run `pip install openai ddgs agno` to install dependencies.

```python investment_report_generator.py
"""üí∞ Investment Report Generator - Your AI Financial Analysis Studio!

This advanced example demonstrates how to build a sophisticated investment analysis system that combines
market research, financial analysis, and portfolio management. The workflow uses a three-stage
approach:
1. Comprehensive stock analysis and market research
2. Investment potential evaluation and ranking
3. Strategic portfolio allocation recommendations

Key capabilities:
- Real-time market data analysis
- Professional financial research
- Investment risk assessment
- Portfolio allocation strategy
- Detailed investment rationale

Example companies to analyze:
- "AAPL, MSFT, GOOGL" (Tech Giants)
- "NVDA, AMD, INTC" (Semiconductor Leaders)
- "TSLA, F, GM" (Automotive Innovation)
- "JPM, BAC, GS" (Banking Sector)
- "AMZN, WMT, TGT" (Retail Competition)
- "PFE, JNJ, MRNA" (Healthcare Focus)
- "XOM, CVX, BP" (Energy Sector)

Run `pip install openai ddgs agno` to install dependencies.
"""

import asyncio
import random
from pathlib import Path
from shutil import rmtree
from textwrap import dedent

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.pprint import pprint_run_response
from agno.workflow.types import WorkflowExecutionInput
from agno.workflow.workflow import Workflow
from pydantic import BaseModel


# --- Response models ---
class StockAnalysisResult(BaseModel):
    company_symbols: str
    market_analysis: str
    financial_metrics: str
    risk_assessment: str
    recommendations: str


class InvestmentRanking(BaseModel):
    ranked_companies: str
    investment_rationale: str
    risk_evaluation: str
    growth_potential: str


class PortfolioAllocation(BaseModel):
    allocation_strategy: str
    investment_thesis: str
    risk_management: str
    final_recommendations: str


# --- File management ---
reports_dir = Path(__file__).parent.joinpath("reports", "investment")
if reports_dir.is_dir():
    rmtree(path=reports_dir, ignore_errors=True)
reports_dir.mkdir(parents=True, exist_ok=True)

stock_analyst_report = str(reports_dir.joinpath("stock_analyst_report.md"))
research_analyst_report = str(reports_dir.joinpath("research_analyst_report.md"))
investment_report = str(reports_dir.joinpath("investment_report.md"))


# --- Agents ---
stock_analyst = Agent(
    name="Stock Analyst",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[
        DuckDuckGoTools(
            enable_search=True, enable_news=True
        )
    ],
    description=dedent("""\
    You are MarketMaster-X, an elite Senior Investment Analyst at Goldman Sachs with expertise in:

    - Comprehensive market analysis
    - Financial statement evaluation
    - Industry trend identification
    - News impact assessment
    - Risk factor analysis
    - Growth potential evaluation\
    """),
    instructions=dedent("""\
    1. Market Research üìä
       - Analyze company fundamentals and metrics
       - Review recent market performance
       - Evaluate competitive positioning
       - Assess industry trends and dynamics
    2. Financial Analysis üíπ
       - Examine key financial ratios
       - Review analyst recommendations
       - Analyze recent news impact
       - Identify growth catalysts
    3. Risk Assessment üéØ
       - Evaluate market risks
       - Assess company-specific challenges
       - Consider macroeconomic factors
       - Identify potential red flags
    Note: This analysis is for educational purposes only.\
    """),
    output_schema=StockAnalysisResult,
)

research_analyst = Agent(
    name="Research Analyst",
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
    You are ValuePro-X, an elite Senior Research Analyst at Goldman Sachs specializing in:

    - Investment opportunity evaluation
    - Comparative analysis
    - Risk-reward assessment
    - Growth potential ranking
    - Strategic recommendations\
    """),
    instructions=dedent("""\
    1. Investment Analysis üîç
       - Evaluate each company's potential
       - Compare relative valuations
       - Assess competitive advantages
       - Consider market positioning
    2. Risk Evaluation üìà
       - Analyze risk factors
       - Consider market conditions
       - Evaluate growth sustainability
       - Assess management capability
    3. Company Ranking üèÜ
       - Rank based on investment potential
       - Provide detailed rationale
       - Consider risk-adjusted returns
       - Explain competitive advantages\
    """),
    output_schema=InvestmentRanking,
)

investment_lead = Agent(
    name="Investment Lead",
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
    You are PortfolioSage-X, a distinguished Senior Investment Lead at Goldman Sachs expert in:

    - Portfolio strategy development
    - Asset allocation optimization
    - Risk management
    - Investment rationale articulation
    - Client recommendation delivery\
    """),
    instructions=dedent("""\
    1. Portfolio Strategy üíº
       - Develop allocation strategy
       - Optimize risk-reward balance
       - Consider diversification
       - Set investment timeframes
    2. Investment Rationale üìù
       - Explain allocation decisions
       - Support with analysis
       - Address potential concerns
       - Highlight growth catalysts
    3. Recommendation Delivery üìä
       - Present clear allocations
       - Explain investment thesis
       - Provide actionable insights
       - Include risk considerations\
    """),
    output_schema=PortfolioAllocation,
)


# --- Execution function ---
async def investment_analysis_execution(
    execution_input: WorkflowExecutionInput,
    companies: str,
) -> str:
    """Execute the complete investment analysis workflow"""

    # Get inputs
    message: str = execution_input.input
    company_symbols: str = companies

    if not company_symbols:
        return "‚ùå No company symbols provided"

    print(f"üöÄ Starting investment analysis for companies: {company_symbols}")
    print(f"üíº Analysis request: {message}")

    # Phase 1: Stock Analysis
    print("\nüìä PHASE 1: COMPREHENSIVE STOCK ANALYSIS")
    print("=" * 60)

    analysis_prompt = f"""
    {message}

    Please conduct a comprehensive analysis of the following companies: {company_symbols}

    For each company, provide:
    1. Current market position and financial metrics
    2. Recent performance and analyst recommendations
    3. Industry trends and competitive landscape
    4. Risk factors and growth potential
    5. News impact and market sentiment
    Companies to analyze: {company_symbols}
    """

    print("üîç Analyzing market data and fundamentals...")
    stock_analysis_result = await stock_analyst.arun(analysis_prompt)
    stock_analysis = stock_analysis_result.content

    # Save to file
    with open(stock_analyst_report, "w") as f:
        f.write("# Stock Analysis Report\n\n")
        f.write(f"**Companies:** {stock_analysis.company_symbols}\n\n")
        f.write(f"## Market Analysis\n{stock_analysis.market_analysis}\n\n")
        f.write(f"## Financial Metrics\n{stock_analysis.financial_metrics}\n\n")
        f.write(f"## Risk Assessment\n{stock_analysis.risk_assessment}\n\n")
        f.write(f"## Recommendations\n{stock_analysis.recommendations}\n")

    print(f"‚úÖ Stock analysis completed and saved to {stock_analyst_report}")

    # Phase 2: Investment Ranking
    print("\nüèÜ PHASE 2: INVESTMENT POTENTIAL RANKING")
    print("=" * 60)

    ranking_prompt = f"""
    Based on the comprehensive stock analysis below, please rank these companies by investment potential.
    STOCK ANALYSIS:
    - Market Analysis: {stock_analysis.market_analysis}
    - Financial Metrics: {stock_analysis.financial_metrics}
    - Risk Assessment: {stock_analysis.risk_assessment}
    - Initial Recommendations: {stock_analysis.recommendations}
    Please provide:
    1. Detailed ranking of companies from best to worst investment potential
    2. Investment rationale for each company
    3. Risk evaluation and mitigation strategies
    4. Growth potential assessment
    """

    print("üìà Ranking companies by investment potential...")
    ranking_result = await research_analyst.arun(ranking_prompt)
    ranking_analysis = ranking_result.content

    # Save to file
    with open(research_analyst_report, "w") as f:
        f.write("# Investment Ranking Report\n\n")
        f.write(f"## Company Rankings\n{ranking_analysis.ranked_companies}\n\n")
        f.write(f"## Investment Rationale\n{ranking_analysis.investment_rationale}\n\n")
        f.write(f"## Risk Evaluation\n{ranking_analysis.risk_evaluation}\n\n")
        f.write(f"## Growth Potential\n{ranking_analysis.growth_potential}\n")

    print(f"‚úÖ Investment ranking completed and saved to {research_analyst_report}")

    # Phase 3: Portfolio Allocation Strategy
    print("\nüíº PHASE 3: PORTFOLIO ALLOCATION STRATEGY")
    print("=" * 60)

    portfolio_prompt = f"""
    Based on the investment ranking and analysis below, create a strategic portfolio allocation.
    INVESTMENT RANKING:
    - Company Rankings: {ranking_analysis.ranked_companies}
    - Investment Rationale: {ranking_analysis.investment_rationale}
    - Risk Evaluation: {ranking_analysis.risk_evaluation}
    - Growth Potential: {ranking_analysis.growth_potential}
    Please provide:
    1. Specific allocation percentages for each company
    2. Investment thesis and strategic rationale
    3. Risk management approach
    4. Final actionable recommendations
    """

    print("üí∞ Developing portfolio allocation strategy...")
    portfolio_result = await investment_lead.arun(portfolio_prompt)
    portfolio_strategy = portfolio_result.content

    # Save to file
    with open(investment_report, "w") as f:
        f.write("# Investment Portfolio Report\n\n")
        f.write(f"## Allocation Strategy\n{portfolio_strategy.allocation_strategy}\n\n")
        f.write(f"## Investment Thesis\n{portfolio_strategy.investment_thesis}\n\n")
        f.write(f"## Risk Management\n{portfolio_strategy.risk_management}\n\n")
        f.write(
            f"## Final Recommendations\n{portfolio_strategy.final_recommendations}\n"
        )

    print(f"‚úÖ Portfolio strategy completed and saved to {investment_report}")

    # Final summary
    summary = f"""
    üéâ INVESTMENT ANALYSIS WORKFLOW COMPLETED!

    üìä Analysis Summary:
    ‚Ä¢ Companies Analyzed: {company_symbols}
    ‚Ä¢ Market Analysis: ‚úÖ Completed
    ‚Ä¢ Investment Ranking: ‚úÖ Completed
    ‚Ä¢ Portfolio Strategy: ‚úÖ Completed

    üìÅ Reports Generated:
    ‚Ä¢ Stock Analysis: {stock_analyst_report}
    ‚Ä¢ Investment Ranking: {research_analyst_report}
    ‚Ä¢ Portfolio Strategy: {investment_report}

    üí° Key Insights:
    {portfolio_strategy.allocation_strategy[:200]}...

    ‚ö†Ô∏è Disclaimer: This analysis is for educational purposes only and should not be considered as financial advice.
    """

    return summary


# --- Workflow definition ---
investment_workflow = Workflow(
    name="Investment Report Generator",
    description="Automated investment analysis with market research and portfolio allocation",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflows.db",
    ),
    steps=investment_analysis_execution,
    session_state={},  # Initialize empty workflow session state
)


if __name__ == "__main__":

    async def main():
        from rich.prompt import Prompt

        # Example investment scenarios to showcase the analyzer's capabilities
        example_scenarios = [
            "AAPL, MSFT, GOOGL",  # Tech Giants
            "NVDA, AMD, INTC",  # Semiconductor Leaders
            "TSLA, F, GM",  # Automotive Innovation
            "JPM, BAC, GS",  # Banking Sector
            "AMZN, WMT, TGT",  # Retail Competition
            "PFE, JNJ, MRNA",  # Healthcare Focus
            "XOM, CVX, BP",  # Energy Sector
        ]

        # Get companies from user with example suggestion
        companies = Prompt.ask(
            "[bold]Enter company symbols (comma-separated)[/bold] "
            "(or press Enter for a suggested portfolio)\n‚ú®",
            default=random.choice(example_scenarios),
        )

        print("üß™ Testing Investment Report Generator with New Workflow Structure")
        print("=" * 70)

        result = await investment_workflow.arun(
            input="Generate comprehensive investment analysis and portfolio allocation recommendations",
            companies=companies,
        )

        pprint_run_response(result, markdown=True)

    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    openai ddgs agno
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python investment_report_generator.py
    ```
  </Step>
</Steps>


# Startup Idea Validator
Source: https://docs.agno.com/examples/use-cases/workflows/startup-idea-validator

This example demonstrates how to migrate from the similar workflows 1.0 example to workflows 2.0 structure.

This workflow helps entrepreneurs validate their startup ideas by:

1. Clarifying and refining the core business concept
2. Evaluating originality compared to existing solutions
3. Defining clear mission and objectives
4. Conducting comprehensive market research and analysis

**Why is this helpful:**

* Get objective feedback on your startup idea before investing resources
* Understand your total addressable market and target segments
* Validate assumptions about market opportunity and competition
* Define clear mission and objectives to guide execution

**Example use cases:**

* New product/service validation
* Market opportunity assessment
* Competitive analysis
* Business model validation
* Target customer segmentation
* Mission/vision refinement

Run `pip install openai agno googlesearch-python` to install dependencies.

The workflow will guide you through validating your startup idea with AI-powered
analysis and research. Use the insights to refine your concept and business plan!

```python startup_idea_validator.py
"""
üöÄ Startup Idea Validator - Your Personal Business Validation Assistant!

This workflow helps entrepreneurs validate their startup ideas by:
1. Clarifying and refining the core business concept
2. Evaluating originality compared to existing solutions
3. Defining clear mission and objectives
4. Conducting comprehensive market research and analysis

Why is this helpful?
--------------------------------------------------------------------------------
‚Ä¢ Get objective feedback on your startup idea before investing resources
‚Ä¢ Understand your total addressable market and target segments
‚Ä¢ Validate assumptions about market opportunity and competition
‚Ä¢ Define clear mission and objectives to guide execution

Who should use this?
--------------------------------------------------------------------------------
‚Ä¢ Entrepreneurs and Startup Founders
‚Ä¢ Product Managers and Business Strategists
‚Ä¢ Innovation Teams
‚Ä¢ Angel Investors and VCs doing initial screening

Example use cases:
--------------------------------------------------------------------------------
‚Ä¢ New product/service validation
‚Ä¢ Market opportunity assessment
‚Ä¢ Competitive analysis
‚Ä¢ Business model validation
‚Ä¢ Target customer segmentation
‚Ä¢ Mission/vision refinement

Quick Start:
--------------------------------------------------------------------------------
1. Install dependencies:
   pip install openai agno

2. Set environment variables:
   - OPENAI_API_KEY

3. Run:
   python startup_idea_validator.py

The workflow will guide you through validating your startup idea with AI-powered
analysis and research. Use the insights to refine your concept and business plan!
"""

import asyncio
from typing import Any

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.googlesearch import GoogleSearchTools
from agno.utils.pprint import pprint_run_response
from agno.workflow.types import WorkflowExecutionInput
from agno.workflow.workflow import Workflow
from pydantic import BaseModel, Field


# --- Response models ---
class IdeaClarification(BaseModel):
    originality: str = Field(..., description="Originality of the idea.")
    mission: str = Field(..., description="Mission of the company.")
    objectives: str = Field(..., description="Objectives of the company.")


class MarketResearch(BaseModel):
    total_addressable_market: str = Field(
        ..., description="Total addressable market (TAM)."
    )
    serviceable_available_market: str = Field(
        ..., description="Serviceable available market (SAM)."
    )
    serviceable_obtainable_market: str = Field(
        ..., description="Serviceable obtainable market (SOM)."
    )
    target_customer_segments: str = Field(..., description="Target customer segments.")


class CompetitorAnalysis(BaseModel):
    competitors: str = Field(..., description="List of identified competitors.")
    swot_analysis: str = Field(..., description="SWOT analysis for each competitor.")
    positioning: str = Field(
        ..., description="Startup's potential positioning relative to competitors."
    )


class ValidationReport(BaseModel):
    executive_summary: str = Field(
        ..., description="Executive summary of the validation."
    )
    idea_assessment: str = Field(..., description="Assessment of the startup idea.")
    market_opportunity: str = Field(..., description="Market opportunity analysis.")
    competitive_landscape: str = Field(
        ..., description="Competitive landscape overview."
    )
    recommendations: str = Field(..., description="Strategic recommendations.")
    next_steps: str = Field(..., description="Recommended next steps.")


# --- Agents ---
idea_clarifier_agent = Agent(
    name="Idea Clarifier",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "Given a user's startup idea, your goal is to refine that idea.",
        "Evaluate the originality of the idea by comparing it with existing concepts.",
        "Define the mission and objectives of the startup.",
        "Provide clear, actionable insights about the core business concept.",
    ],
    add_history_to_context=True,
    add_datetime_to_context=True,
    output_schema=IdeaClarification,
    debug_mode=False,
)

market_research_agent = Agent(
    name="Market Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    instructions=[
        "You are provided with a startup idea and the company's mission and objectives.",
        "Estimate the total addressable market (TAM), serviceable available market (SAM), and serviceable obtainable market (SOM).",
        "Define target customer segments and their characteristics.",
        "Search the web for resources and data to support your analysis.",
        "Provide specific market size estimates with supporting data sources.",
    ],
    add_history_to_context=True,
    add_datetime_to_context=True,
    output_schema=MarketResearch,
)

competitor_analysis_agent = Agent(
    name="Competitor Analysis Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    instructions=[
        "You are provided with a startup idea and market research data.",
        "Identify existing competitors in the market.",
        "Perform Strengths, Weaknesses, Opportunities, and Threats (SWOT) analysis for each competitor.",
        "Assess the startup's potential positioning relative to competitors.",
        "Search for recent competitor information and market positioning.",
    ],
    add_history_to_context=True,
    add_datetime_to_context=True,
    output_schema=CompetitorAnalysis,
    debug_mode=False,
)

report_agent = Agent(
    name="Report Generator",
    model=OpenAIChat(id="gpt-5-mini"),
    instructions=[
        "You are provided with comprehensive data about a startup idea including clarification, market research, and competitor analysis.",
        "Synthesize all information into a comprehensive validation report.",
        "Provide clear executive summary, assessment, and actionable recommendations.",
        "Structure the report professionally with clear sections and insights.",
        "Include specific next steps for the entrepreneur.",
    ],
    add_history_to_context=True,
    add_datetime_to_context=True,
    output_schema=ValidationReport,
    debug_mode=False,
)


# --- Execution function ---
async def startup_validation_execution(
    workflow: Workflow,
    execution_input: WorkflowExecutionInput,
    startup_idea: str,
    **kwargs: Any,
) -> str:
    """Execute the complete startup idea validation workflow"""

    # Get inputs
    message: str = execution_input.input
    idea: str = startup_idea

    if not idea:
        return "‚ùå No startup idea provided"

    print(f"üöÄ Starting startup idea validation for: {idea}")
    print(f"üí° Validation request: {message}")

    # Phase 1: Idea Clarification
    print("\nüéØ PHASE 1: IDEA CLARIFICATION & REFINEMENT")
    print("=" * 60)

    clarification_prompt = f"""
    {message}

    Please analyze and refine the following startup idea:

    STARTUP IDEA: {idea}

    Evaluate:
    1. The originality of this idea compared to existing solutions
    2. Define a clear mission statement for this startup
    3. Outline specific, measurable objectives
    Provide insights on how to strengthen and focus the core concept.
    """

    print("üîç Analyzing and refining the startup concept...")

    try:
        clarification_result = await idea_clarifier_agent.arun(clarification_prompt)
        idea_clarification = clarification_result.content

        print("‚úÖ Idea clarification completed")
        print(f"üìù Mission: {idea_clarification.mission[:100]}...")

    except Exception as e:
        return f"‚ùå Failed to clarify idea: {str(e)}"

    # Phase 2: Market Research
    print("\nüìä PHASE 2: MARKET RESEARCH & ANALYSIS")
    print("=" * 60)

    market_research_prompt = f"""
    Based on the refined startup idea and clarification below, conduct comprehensive market research:
    STARTUP IDEA: {idea}
    ORIGINALITY: {idea_clarification.originality}
    MISSION: {idea_clarification.mission}
    OBJECTIVES: {idea_clarification.objectives}
    Please research and provide:
    1. Total Addressable Market (TAM) - overall market size
    2. Serviceable Available Market (SAM) - portion you could serve
    3. Serviceable Obtainable Market (SOM) - realistic market share
    4. Target customer segments with detailed characteristics
    Use web search to find current market data and trends.
    """

    print("üìà Researching market size and customer segments...")

    try:
        market_result = await market_research_agent.arun(market_research_prompt)
        market_research = market_result.content

        print("‚úÖ Market research completed")
        print(f"üéØ TAM: {market_research.total_addressable_market[:100]}...")

    except Exception as e:
        return f"‚ùå Failed to complete market research: {str(e)}"

    # Phase 3: Competitor Analysis
    print("\nüè¢ PHASE 3: COMPETITIVE LANDSCAPE ANALYSIS")
    print("=" * 60)

    competitor_prompt = f"""
    Based on the startup idea and market research below, analyze the competitive landscape:
    STARTUP IDEA: {idea}
    TAM: {market_research.total_addressable_market}
    SAM: {market_research.serviceable_available_market}
    SOM: {market_research.serviceable_obtainable_market}
    TARGET SEGMENTS: {market_research.target_customer_segments}
    Please research and provide:
    1. Identify direct and indirect competitors
    2. SWOT analysis for each major competitor
    3. Assessment of startup's potential competitive positioning
    4. Market gaps and opportunities
    Use web search to find current competitor information.
    """

    print("üîé Analyzing competitive landscape...")

    try:
        competitor_result = await competitor_analysis_agent.arun(competitor_prompt)
        competitor_analysis = competitor_result.content

        print("‚úÖ Competitor analysis completed")
        print(f"üèÜ Positioning: {competitor_analysis.positioning[:100]}...")

    except Exception as e:
        return f"‚ùå Failed to complete competitor analysis: {str(e)}"

    # Phase 4: Final Validation Report
    print("\nüìã PHASE 4: COMPREHENSIVE VALIDATION REPORT")
    print("=" * 60)

    report_prompt = f"""
    Synthesize all the research and analysis into a comprehensive startup validation report:

    STARTUP IDEA: {idea}

    IDEA CLARIFICATION:
    - Originality: {idea_clarification.originality}
    - Mission: {idea_clarification.mission}
    - Objectives: {idea_clarification.objectives}
    MARKET RESEARCH:
    - TAM: {market_research.total_addressable_market}
    - SAM: {market_research.serviceable_available_market}
    - SOM: {market_research.serviceable_obtainable_market}
    - Target Segments: {market_research.target_customer_segments}
    COMPETITOR ANALYSIS:
    - Competitors: {competitor_analysis.competitors}
    - SWOT: {competitor_analysis.swot_analysis}
    - Positioning: {competitor_analysis.positioning}
    Create a professional validation report with:
    1. Executive summary
    2. Idea assessment (strengths/weaknesses)
    3. Market opportunity analysis
    4. Competitive landscape overview
    5. Strategic recommendations
    6. Specific next steps for the entrepreneur
    """

    print("üìù Generating comprehensive validation report...")

    try:
        final_result = await report_agent.arun(report_prompt)
        validation_report = final_result.content

        print("‚úÖ Validation report completed")

    except Exception as e:
        return f"‚ùå Failed to generate final report: {str(e)}"

    # Final summary
    summary = f"""
    üéâ STARTUP IDEA VALIDATION COMPLETED!
    üìä Validation Summary:
    ‚Ä¢ Startup Idea: {idea}
    ‚Ä¢ Idea Clarification: ‚úÖ Completed
    ‚Ä¢ Market Research: ‚úÖ Completed
    ‚Ä¢ Competitor Analysis: ‚úÖ Completed
    ‚Ä¢ Final Report: ‚úÖ Generated

    üìà Key Market Insights:
    ‚Ä¢ TAM: {market_research.total_addressable_market[:150]}...
    ‚Ä¢ Target Segments: {market_research.target_customer_segments[:150]}...

    üèÜ Competitive Positioning:
    {competitor_analysis.positioning[:200]}...

    üìã COMPREHENSIVE VALIDATION REPORT:

    ## Executive Summary
    {validation_report.executive_summary}

    ## Idea Assessment
    {validation_report.idea_assessment}

    ## Market Opportunity
    {validation_report.market_opportunity}

    ## Competitive Landscape
    {validation_report.competitive_landscape}

    ## Strategic Recommendations
    {validation_report.recommendations}

    ## Next Steps
    {validation_report.next_steps}

    ‚ö†Ô∏è Disclaimer: This validation is for informational purposes only. Conduct additional due diligence before making investment decisions.
    """

    return summary


# --- Workflow definition ---
startup_validation_workflow = Workflow(
    name="Startup Idea Validator",
    description="Comprehensive startup idea validation with market research and competitive analysis",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/workflows.db",
    ),
    steps=startup_validation_execution,
    session_state={},  # Initialize empty workflow session state
)


if __name__ == "__main__":

    async def main():
        from rich.prompt import Prompt

        # Get idea from user
        idea = Prompt.ask(
            "[bold]What is your startup idea?[/bold]\n‚ú®",
            default="A marketplace for Christmas Ornaments made from leather",
        )

        print("üß™ Testing Startup Idea Validator with New Workflow Structure")
        print("=" * 70)

        result = await startup_validation_workflow.arun(
            input="Please validate this startup idea with comprehensive market research and competitive analysis",
            startup_idea=idea,
        )

        pprint_run_response(result, markdown=True)

    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    openai agno googlesearch-python
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python startup_idea_validator.py
    ```
  </Step>
</Steps>


# When to use a Workflow vs a Team in Agno
Source: https://docs.agno.com/faq/When-to-use-a-Workflow-vs-a-Team-in-Agno



Agno offers two powerful ways to build multi-agent systems: **Workflows** and **Teams**. Each is suited for different kinds of use-cases.

***

## Use a Workflow when:

You need **orchestrated, multi-step execution** with flexible control flow and a predictable outcome.

Workflows are ideal for:

* **Sequential processes** - Step-by-step agent executions with dependencies
* **Parallel execution** - Running independent tasks simultaneously
* **Conditional logic** - Dynamic routing based on content analysis
* **Quality assurance** - Iterative loops with end conditions
* **Complex pipelines** - Mixed components (agents, teams, functions) with branching
* **Structured processes** - Data transformation with predictable patterns

[Learn more about Workflows](/concepts/workflows/overview)

***

## Use an Agent Team when:

Your task requires reasoning, collaboration, or multi-tool decision-making.

Agent Teams are best for:

* Research and planning
* Tasks where agents divide responsibilities

[Learn more about Agent Teams](/concepts/teams/introduction)

***

## üí° Pro Tip

> Think of **Workflows** as assembly lines for known tasks,
> and **Agent Teams** as collaborative task forces for solving open-ended problems.


# AgentOS Connection Issues
Source: https://docs.agno.com/faq/agentos-connection



If you're experiencing connection issues with AgentOS, particularly when trying to connect to **local instances**, this guide will help you resolve them.

## Browser Compatibility

Some browsers have security restrictions that prevent connections to localhost domains due to mixed content security issues. Here's what you need to know about different browsers:

### Recommended Browsers

* **Chrome & Edge**: These browsers work well with local connections by default and are our recommended choices
* **Firefox**: Generally works well with local connections

### Browsers with Known Issues

* **Safari**: May block local connections due to its strict security policies
* **Brave**: Blocks local connections by default due to its shield feature

## Solutions

### For Brave Users

If you're using Brave browser, you can try these steps:

1. Click on the Brave shield icon in the address bar
2. Turn off the shield for the current site
3. Refresh the endpoint and try connecting again

<video autoPlay muted controls className="w-full aspect-video" src="https://mintcdn.com/agno-v2/Xj0hQoiFt0n7bXOq/videos/agentos-brave-issue.mp4?fit=max&auto=format&n=Xj0hQoiFt0n7bXOq&q=85&s=80ec713d1ca11cc06366c5460388fdd8" data-path="videos/agentos-brave-issue.mp4" />

### For Other Browsers

If you're using Safari or experiencing issues with other browsers, you can use one of these solutions:

#### 1. Use Chrome or Edge

The simplest solution is to use Chrome or Edge browsers which have better support for local connections.

#### 2. Use Tunneling Services

You can use tunneling services to expose your local endpoint to the internet:

##### Using ngrok

1. Install ngrok from [ngrok.com](https://ngrok.com)
2. Run your local server
3. Create a tunnel with ngrok:

```bash
ngrok http <your-local-port>
```

4. Use the provided ngrok URL on [AgentOS](https://os.agno.com).

##### Using Cloudflare Tunnel

1. Install Cloudflare Tunnel (cloudflared) from [Cloudflare's website](https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/install-and-setup/installation/)
2. Authenticate with Cloudflare
3. Create a tunnel:

```bash
cloudflared tunnel --url http://localhost:<your-local-port>
```

4. Use the provided Cloudflare URL on [AgentOS](https://os.agno.com).


# Connecting to Tableplus
Source: https://docs.agno.com/faq/connecting-to-tableplus



If you want to inspect your pgvector container to explore your storage or knowledge base, you can use TablePlus. Follow these steps:

## Step 1: Start Your `pgvector` Container

Run the following command to start a `pgvector` container locally:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

* `POSTGRES_DB=ai` sets the default database name.
* `POSTGRES_USER=ai` and `POSTGRES_PASSWORD=ai` define the database credentials.
* The container exposes port `5432` (mapped to `5532` on your local machine).

## Step 2: Configure TablePlus

1. **Open TablePlus**: Launch the TablePlus application.
2. **Create a New Connection**: Click on the `+` icon to add a new connection.
3. **Select `PostgreSQL`**: Choose PostgreSQL as the database type.

Fill in the following connection details:

* **Host**: `localhost`
* **Port**: `5532`
* **Database**: `ai`
* **User**: `ai`
* **Password**: `ai`

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=65f0ec170fdef92080bdc0e72feaacc4" data-og-width="492" width="492" data-og-height="386" height="386" data-path="images/tableplus.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=4c693a789381ec09ee8112a29a19a23f 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=83b7b78de5bb7e3e04337380be4a846a 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=a933eddefc5117323116e34eba956055 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=84a19124e98f325caa51ff1ee0032652 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=0a60723cf13d5771fcc8d9f89bb921f2 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tableplus.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=24d6892323098fdd654dcf4fcf579419 2500w" />


# Could Not Connect To Docker
Source: https://docs.agno.com/faq/could-not-connect-to-docker



If you have Docker up and running and get the following error, please read on:

```bash
ERROR    Could not connect to docker. Please confirm docker is installed and running
ERROR    Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
```

## Quick fix

Create the `/var/run/docker.sock` symlink using:

```shell
sudo ln -s "$HOME/.docker/run/docker.sock" /var/run/docker.sock
```

In 99% of the cases, this should work. If it doesnt, try:

```shell
sudo chown $USER /var/run/docker.sock
```

## Full details

Agno uses [docker-py](https://github.com/docker/docker-py) to run containers, and if the `/var/run/docker.sock` is missing or has incorrect permissions, it cannot connect to docker.

**To fix, please create the `/var/run/docker.sock` file using:**

```shell
sudo ln -s "$HOME/.docker/run/docker.sock" /var/run/docker.sock
```

If that does not work, check the permissions using `ls -l /var/run/docker.sock`.

If the `/var/run/docker.sock` does not exist, check if the `$HOME/.docker/run/docker.sock` file is missing. If its missing, please reinstall Docker.

**If none of this works and the `/var/run/docker.sock` exists:**

* Give your user permissions to the `/var/run/docker.sock` file:

```shell
sudo chown $USER /var/run/docker.sock
```

* Give your user permissions to the docker group:

```shell
sudo usermod -a -G docker $USER
```

## More info

* [Docker-py Issue](https://github.com/docker/docker-py/issues/3059#issuecomment-1294369344)
* [Stackoverflow answer](https://stackoverflow.com/questions/48568172/docker-sock-permission-denied/56592277#56592277)


# Setting Environment Variables
Source: https://docs.agno.com/faq/environment-variables



To configure your environment for applications, you may need to set environment variables. This guide provides instructions for setting environment variables in both macOS (Shell) and Windows (PowerShell and Windows Command Prompt).

## macOS

### Setting Environment Variables in Shell

#### Temporary Environment Variables

These environment variables will only be available in the current shell session.

```shell
export VARIABLE_NAME="value"
```

To display the environment variable:

```shell
echo $VARIABLE_NAME
```

#### Permanent Environment Variables

To make environment variables persist across sessions, add them to your shell configuration file (e.g., `.bashrc`, `.bash_profile`, `.zshrc`).

For Zsh:

```shell
echo 'export VARIABLE_NAME="value"' >> ~/.zshrc
source ~/.zshrc
```

To display the environment variable:

```shell
echo $VARIABLE_NAME
```

## Windows

### Setting Environment Variables in PowerShell

#### Temporary Environment Variables

These environment variables will only be available in the current PowerShell session.

```powershell
$env:VARIABLE_NAME = "value"
```

To display the environment variable:

```powershell
echo $env:VARIABLE_NAME
```

#### Permanent Environment Variables

To make environment variables persist across sessions, add them to your PowerShell profile script (e.g., `Microsoft.PowerShell_profile.ps1`).

```powershell
notepad $PROFILE
```

Add the following line to the profile script:

```powershell
$env:VARIABLE_NAME = "value"
```

Save and close the file, then reload the profile:

```powershell
. $PROFILE
```

To display the environment variable:

```powershell
echo $env:VARIABLE_NAME
```

### Setting Environment Variables in Windows Command Prompt

#### Temporary Environment Variables

These environment variables will only be available in the current Command Prompt session.

```cmd
set VARIABLE_NAME=value
```

To display the environment variable:

```cmd
echo %VARIABLE_NAME%
```

#### Permanent Environment Variables

To make environment variables persist across sessions, you can use the `setx` command:

```cmd
setx VARIABLE_NAME "value"
```

Note: After setting an environment variable using `setx`, you need to restart the Command Prompt or any applications that need to read the new environment variable.

To display the environment variable in a new Command Prompt session:

```cmd
echo %VARIABLE_NAME%
```

By following these steps, you can effectively set and display environment variables in macOS Shell, Windows Command Prompt, and PowerShell. This will ensure your environment is properly configured for your applications.


# OpenAI Key Request While Using Other Models
Source: https://docs.agno.com/faq/openai-key-request-for-other-models



If you see a request for an OpenAI API key but haven't explicitly configured OpenAI, it's because Agno uses OpenAI models by default in several places, including:

* The default model when unspecified in `Agent`
* The default embedder is OpenAIEmbedder with VectorDBs, unless specified

## Quick fix: Configure a Different Model

It is best to specify the model for the agent explicitly, otherwise it would default to `OpenAIChat`.

For example, to use Google's Gemini instead of OpenAI:

```python
from agno.agent import Agent, RunOutput
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-1.5-flash"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")
```

For more details on configuring different model providers, check our [models documentation](/concepts/models)

## Quick fix: Configure a Different Embedder

The same applies to embeddings. If you want to use a different embedder instead of `OpenAIEmbedder`, configure it explicitly.

For example, to use Google's Gemini as an embedder, use `GeminiEmbedder`:

```python
from agno.knowledge.knowledge import Knowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.google import GeminiEmbedder

# Embed sentence in database
embeddings = GeminiEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge = Knowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="gemini_embeddings",
        embedder=GeminiEmbedder(),
    ),
    max_results=2,
)
```

For more details on configuring different model providers, check our [Embeddings documentation](/concepts/knowledge/embedder/)


# Structured outputs
Source: https://docs.agno.com/faq/structured-outputs



## Structured Outputs vs. JSON Mode

When working with language models, generating responses that match a specific structure is crucial for building reliable applications. Agno Agents support two methods to achieve this: **Structured Outputs** and **JSON mode**.

***

### Structured Outputs (Default if supported)

"Structured Outputs" is the **preferred** and most **reliable** way to extract well-formed, schema-compliant responses from a Model. If a model class supports it, Agno Agents use Structured Outputs by default.

With structured outputs, we provide a schema to the model (using Pydantic or JSON Schema), and the model‚Äôs response is guaranteed to **strictly follow** that schema. This eliminates many common issues like missing fields, invalid enum values, or inconsistent formatting. Structured Outputs are ideal when you need high-confidence, well-structured responses‚Äîlike entity extraction, content generation for UI rendering, and more.

In this case, the response model is passed as a keyword argument to the model.

## Example

```python
from pydantic import BaseModel
from agno.agent import Agent
from agno.models.openai import OpenAIChat

class User(BaseModel):
    name: str
    age: int
    email: str

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You are a helpful assistant that can extract information from a user's profile.",
    output_schema=User,
)
```

In the example above, the model will generate a response that matches the `User` schema using structured outputs via OpenAI's `gpt-5-mini` model. The agent will then return the `User` object as-is.

***

### JSON Mode

Some model classes **do not support Structured Outputs**, or you may want to fall back to JSON mode even when the model supports both options. In such cases, you can enable **JSON mode** by setting `use_json_mode=True`.

JSON mode works by injecting a detailed description of the expected JSON structure into the system prompt. The model is then instructed to return a valid JSON object that follows this structure. Unlike Structured Outputs, the response is **not automatically validated** against the schema at the API level.

## Example

```python
from pydantic import BaseModel
from agno.agent import Agent
from agno.models.openai import OpenAIChat

class User(BaseModel):
    name: str
    age: int
    email: str

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You are a helpful assistant that can extract information from a user's profile.",
    output_schema=User,
    use_json_mode=True,
)

```

### When to use

Use **Structured Outputs** if the model supports it ‚Äî it‚Äôs reliable, clean, and validated automatically.

Use **JSON mode**:

* When the model doesn't support structured outputs. Agno agents do this by default on your behalf.
* When you need broader compatibility, but are okay validating manually.
* When the model does not support tools with structured outputs.


# Tokens-per-minute rate limiting
Source: https://docs.agno.com/faq/tpm-issues



<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=6c4a68b6662597c61b761f782dbe5f65" alt="Chat with pdf" data-og-width="698" width="698" data-og-height="179" height="179" data-path="images/tpm_issues.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=9d57cc77b1620f3ebc6ed5ac2348cd53 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=62e01716372bec142658c779175b6d1e 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=0840a597cda52c0c883f722e8f0cf13c 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=a3f1e2f454802a9143f82e893eb45af0 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=f5556252c255a94e36218a003e929a40 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/tpm_issues.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=ac5204f428d2ee70c268d6ec9e68b44b 2500w" />

If you face any problems with proprietary models (like OpenAI models) where you are rate limited, we provide the option to set `exponential_backoff=True` and to change `delay_between_retries` to a value in seconds (defaults to 1 second).

For example:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    description="You are an enthusiastic news reporter with a flair for storytelling!",
    markdown=True,
    exponential_backoff=True,
    delay_between_retries=2
)
agent.print_response("Tell me about a breaking news story from New York.", stream=True)
```

See our [models documentation](/concepts/models) for specific information about rate limiting.

In the case of OpenAI, they have tier based rate limits. See the [docs](https://platform.openai.com/docs/guides/rate-limits/usage-tiers) for more information.


# Contributing to Agno
Source: https://docs.agno.com/how-to/contribute

Learn how to contribute to Agno through our fork and pull request workflow.

Agno is an open-source project and we welcome contributions.

## üë©‚Äçüíª How to contribute

Please follow the [fork and pull request](https://docs.github.com/en/get-started/quickstart/contributing-to-projects) workflow:

* Fork the repository.
* Create a new branch for your feature.
* Add your feature or improvement.
* Send a pull request.
* We appreciate your support & input!

## Development setup

1. Clone the repository.
2. Create a virtual environment:
   * For Unix, use `./scripts/dev_setup.sh`.
   * This setup will:
     * Create a `.venv` virtual environment in the current directory.
     * Install the required packages.
     * Install the `agno` package in editable mode.
3. Activate the virtual environment:
   * On Unix: `source .venv/bin/activate`

> From here on you have to use `uv pip install` to install missing packages

## Formatting and validation

Ensure your code meets our quality standards by running the appropriate formatting and validation script before submitting a pull request:

* For Unix:
  * `./scripts/format.sh`
  * `./scripts/validate.sh`

These scripts will perform code formatting with `ruff` and static type checks with `mypy`.

Read more about the guidelines [here](https://github.com/agno-agi/agno/tree/main/CONTRIBUTING.md)

Message us on [Discord](https://discord.gg/4MtYHHrgA8) or post on [Discourse](https://community.agno.com/) if you have any questions or need help with credits.


# Install & Setup
Source: https://docs.agno.com/how-to/install



## Install `agno` SDK

We highly recommend:

* Installing `agno` using `pip` in a python virtual environment.

<Steps>
  <Step title="Create a virtual environment">
    <CodeGroup>
      ```bash Mac
      python3 -m venv ~/.venvs/agno
      source ~/.venvs/agno/bin/activate
      ```

      ```bash Windows
      python3 -m venv agnoenv
      agnoenv/scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install agno">
    Install `agno` using pip

    <CodeGroup>
      ```bash Mac
      pip install -U agno
      ```

      ```bash Windows
      pip install -U agno
      ```
    </CodeGroup>
  </Step>
</Steps>

<br />

<Note>
  If you encounter errors, try updating pip using `python -m pip install --upgrade pip`
</Note>

***

## Upgrade agno

To upgrade `agno`, run this in your virtual environment

```bash
pip install -U agno --no-cache-dir
```


# Agno v2.0 Changelog
Source: https://docs.agno.com/how-to/v2-changelog



<img height="200" src="https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=a2223b0ee329d32688b43f6ebe1b7174" data-og-width="323" data-og-height="320" data-path="images/changelogs/agent_os_stack.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?w=280&fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=ebcc3630f1f4c8482631fb06a7d29c91 280w, https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?w=560&fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=ee6bca0ef5c4acf434bd96854d698456 560w, https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?w=840&fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=b12920d3ed0141b7eae5364aeefb795f 840w, https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?w=1100&fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=7d8e536bad2a2e737c907296c9b550c3 1100w, https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?w=1650&fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=141013bcc891f080fe2e63188ce33e70 1650w, https://mintcdn.com/agno-v2/HVmF95GvYttNRl-5/images/changelogs/agent_os_stack.png?w=2500&fit=max&auto=format&n=HVmF95GvYttNRl-5&q=85&s=5424dcf79c186f18ec276e514bd0e932 2500w" />

This is a major release that introduces a completely new approach to building multi-agent systems. It also introduces the AgentOS, a runtime for agents.

This is a major rewrite of the Agno library and introduces various new concepts and updates to the existing ones.

Some of the major changes are:

* Agents, Teams and Workflows are now fully stateless.
* Knowledge is now a single solution that supports many forms of content.
* Storage of sessions, memories, evals, etc. has been simplified

## General Changes

<Accordion title="Repo Updates">
  * `/libs/agno` has been restructured to fit the new concepts in Agno and for better organization.
  * All code related to managing workspaces and agent deployment in Agno has been moved to a new package called `agno-infra`. This is a combination of the previous `agno-aws` and `agno-docker` packages, as well as the CLI and other tools.
  * `agno-aws` and `agno-docker` packages have been deprecated and will no-longer be maintained.
  * All code related to the Agno CLI (`ag`) has been moved to this new `agno-infra` package.
  * Added `AgentOS` to `agno` as a comprehensive API solution for building multi-agent systems. This also replaces `Playground` and other Apps. See details below.
  * Cookbook has been completely restructured, with new and more valuable READMEs, better coverage of concepts, and more examples.
</Accordion>

<Accordion title="AgentOS">
  * Introducing `AgentOS`, a system for hosting agents, teams and workflows as a production-ready API. See full details in the [AgentOS](/agent-os/introduction) section.
  * This adds routes for session management, memory management, knowledge management, evals management, and metrics.
  * This enables you to host agents, teams and workflows, and use the [Agent OS UI](https://os.agno.com) to manage them.
</Accordion>

<Accordion title="Apps Deprecations">
  * Removed `Playground`. Its functionality has been replaced by `AgentOS`.
  * Removed `AGUIApp` and replace with `AGUI` interface on `AgentOS`.
  * Removed `SlackApi` and replace with `Slack` interface on `AgentOS`.
  * Removed `WhatsappApi` and replace with `Whatsapp` interface on `AgentOS`.
  * Removed `FastAPIApp`. Its functionality has been replaced by `AgentOS`.
  * `DiscordClient` has been moved to `/integrations/discord`.
</Accordion>

## Session & Run State

* We have made significant changes to the innerworkings of `Agent`, `Team` and `Workflow` to make them completely stateless.
* This means that `agent_session`, `session_metrics`, `session_state`, etc. should not be seen as stateful variables that would be updated during the course of a run, but rather as "defaults" for the agent if they can be set on initialisation.
* `CustomEvent` is now supported and you can inherit from it to create your own custom events that can be yielded from your own tools. See the [documentation](/concepts/agents/run#custom-events) for more details.

<Accordion title="Updates to Run Objects">
  For agents:

  * `RunResponse` -> `RunOutput`
  * `RunResponseStartedEvent` -> `RunStartedEvent`
  * `RunResponseContentEvent` -> `RunContentEvent`
  * `RunResponseCompletedEvent` -> `RunCompletedEvent`
  * `IntermediateRunResponseContentEvent` -> `IntermediateRunContentEvent`
  * `RunResponseErrorEvent` -> `RunErrorEvent`
  * `RunResponseCancelledEvent` -> `RunCancelledEvent`

  For teams:

  * `TeamRunResponse` -> `TeamRunOutput`
  * `RunResponseStartedEvent` -> `RunStartedEvent`
  * `RunResponseContentEvent` -> `RunContentEvent`
  * `RunResponseCompletedEvent` -> `RunCompletedEvent`
  * `IntermediateRunResponseContentEvent` -> `IntermediateRunContentEvent`
  * `RunResponseErrorEvent` -> `RunErrorEvent`
  * `RunResponseCancelledEvent` -> `RunCancelledEvent`

  For workflows:

  * `WorkflowRunResponse` -> `WorkflowRunOutput`

  * `WorkflowRunResponseStartedEvent` -> `WorkflowRunStartedEvent`

  * `WorkflowRunResponseContentEvent` -> `WorkflowRunContentEvent`

  * `WorkflowRunResponseCompletedEvent` -> `WorkflowRunCompletedEvent`

  * `WorkflowRunResponseErrorEvent` -> `WorkflowRunErrorEvent`

  * `WorkflowRunResponseCancelledEvent` -> `WorkflowRunCancelledEvent`

  * The import location for `RunOutput` (and events) has been moved to `agno.run.agent`.

  * For `RunOutput`, `TeamRunOutput` and `WorkflowRunOutput` the `extra_data` attribute has been removed and the internal attributes are now top-level. This is `references`, `additional_input`, `reasoning_steps`, and `reasoning_messages`.

  * `metadata` added to `RunOutput`, `TeamRunOutput` and `WorkflowRunOutput`. This represents all the set metadata for the run.
</Accordion>

<Accordion title="Updates to Session Objects">
  * Session storage now stores `AgentSession`, `TeamSession` and `WorkflowSession` with new schemas. See full details in the [Session](/concepts/agents/sessions) section.
  * Session objects now have `runs` directly on it.
  * Session objects support new convenience methods:
    * `get_run` -> Get a specific run by ID.
    * `get_session_summary` -> Get the session summary.
    * `get_chat_history` -> Get an aggregated view of all messages for all runs in the session.
</Accordion>

<Accordion title="Updates to Metrics">
  * `SessionMetrics` and `MessageMetrics` have been unified as a single `Metrics` class.
  * `audio_tokens` has been renamed to `audio_total_tokens`.
  * `input_audio_tokens` has been renamed to `audio_input_tokens`.
  * `output_audio_tokens` has been renamed to `audio_output_tokens`.
  * `cached_tokens` has been renamed to `cache_read_tokens`.
  * `prompt_tokens` and `completion_tokens` have been removed (only `input_tokens` and `output_tokens` should be used)
  * `prompt_tokens_details` and `completion_tokens_details` have been removed. Instead `provider_metrics` captures any provider-specific metrics.
  * `time` has been renamed to `duration`.
</Accordion>

<Accordion title="Cancelling Runs">
  * You can now cancel a run by calling `cancel_run` on the `Agent`, `Team` or `Workflow`.
  * This will cancel the run and return a `RunCancelledEvent` during streaming, or set the `RunOutput.status` to `"cancelled"`.
</Accordion>

## Storage

* `Agent`, `Team`, `Workflow` and the various evals now all support a single `db` parameter. This is to enable storage for the instance of that class. This is required for persistence of sessions, memories, metrics, etc.
* `storage` and `memory` have been removed from `Agent`, `Team` and `Workflow`.

<Accordion title="Updates to Storage Classes">
  - This means all previous storage providers have been reworked. Also session storage, memory storage and eval storage are all a single solution now referred to as a "DB".
  - `PostgresStorage` -> `PostgresDb`
  - `SqliteStorage` -> `SqliteDb`
  - `MysqlStorage` -> `MysqlDb`
  - `RedisStorage` -> `RedisDb`
  - `MongoStorage` -> `MongoDb`
  - `DynamoDBStorage` -> `DynamoDb`
  - `SingleStoreStorage` -> `SingleStoreDb`
  - `InMemoryStorage` -> `InMemoryDb`
  - `JsonStorage` -> `JsonDb`
  - `GCSJsonStorage` -> `GCSJsonDb`
</Accordion>

## Memory

* With the above changes to storage, memory has been simplified.
* `memory` has been removed from `Agent` and `Team`. Instead memory is enabled with `enable_user_memories: bool` (like before) and persisted in the `db` instance.
* Changes to how memories are created can still be done by overriding the `MemoryManager` class on `Agent` or `Team`. E.g. `Agent(memory_manager=MyMemoryManager())`.
* `AgentMemory` and `TeamMemory` have been removed.

## Knowledge

* Knowledge has been completely reworked. See full details in the [Knowledge](/concepts/knowledge/) section.
* You now define a single `Knowledge` instance for all types of content. Files (PDF, CSV, etc.), URLs, and other.
* The agent can still use your knowledge base to search for information at runtime. All existing RAG implementations are still supported.
* Added **full `async` support** for embedding models and vector DBs. This has a significant impact on performance and is a major speed improvement when adding content to the knowledge base using `knowledge.add_content_async(...)`.
* `AgentKnowledge` and all other knowledge base classes have been removed.
* Import locations for `embedder`, `document`, `chunking`, `reranker` and `reader` have been moved to `agno.knowledge`. See [examples](/examples/concepts/knowledge) for more details.

## Tools updates

* General:
  * Since Agents and Teams are now stateless, using attributes from the agent/team object inside a function will give you access to the attributes set on initialisation of that agent/team. E.g. `agent.session_state` should not be used, instead `session_state` can now be directly accessed and would have the "current" state of the session.
  * A new flow allows images, audio and video files generated during tool execution to be passed back in a `FunctionExecutionResult` object and this will ensure these artifacts are made available to the model and agent as needed.
* All tools that handle media (e.g. image generation tools) now correctly add this generated media to the `RunOutput`, but also make it available for subsequent model calls.
* The interface of almost all the toolkits have been updated for a more consistent experience around switching specific tools on and off. The list of changes is too long to list here. We suggest you take a look at the toolkits you use specifically and how they have been updated.
* `show_results` is now `True` by default for all tools. If you just set `stop_after_tool_call=True` then `show_results` will be automatically set to `True`.
* `images`, `videos`, `audio` and `files` are now available as parameters to tools. See the [documentation](/concepts/tools/introduction) for more details.

## Media

#### Removals

* **Removed legacy artifact classes**: `ImageArtifact`, `VideoArtifact`, `AudioArtifact`, and `AudioResponse` classes have been completely removed in favor of unified media classes.

#### New Unified Media Architecture

* **Unified `Image` class**: Now serves all use cases (input, output, artifacts) with standardized `content: Optional[bytes]` field for raw image data
* **Unified `Audio` class**: Replaces both `AudioArtifact` and `AudioResponse` with consistent byte-based content storage and additional fields like `transcript`, `expires_at`, `sample_rate`, and `channels`
* **Unified `Video` class**: Updated to handle all video use cases with standardized content handling and metadata fields
* **Enhanced `File` class**: Updated to work seamlessly across agent, team, workflow, and toolkit contexts

#### New Methods and Features

* **`from_base64()` class method**: Added to `Image`, `Audio`, and `Video` classes for creating instances from base64-encoded content (automatically converts to raw bytes)
* **`get_content_bytes()` method**: Retrieves content as raw bytes, handling loading from URLs or file paths
* **`to_base64()` method**: Converts content to base64 string for transmission/storage
* **`to_dict()` method**: Enhanced serialization with optional base64 content inclusion

#### Content Standardization

* **Byte-based storage**: All media content is now stored as raw bytes (`Optional[bytes]`) instead of mixed string/bytes formats
* **Automatic validation**: Model validators ensure exactly one content source (`url`, `filepath`, or `content`) is provided
* **Auto-generated IDs**: Media objects automatically generate UUIDs when not provided

## Logging

* Added support for custom loggers. See the [documentation](/concepts/agents/custom-logger) for more details.

## Agent updates

<Accordion title="Updates to Agent Class">
  * `agent_id` -> `id` -> If `id` is not set, it is autogenerated using the `name` of the agent, or a random UUID if the `name` is not set.
  * `search_previous_sessions_history` -> `search_session_history`
  * `context` -> `dependencies`
  * `add_context` -> `add_dependencies_to_context`
  * `add_history_to_messages` -> `add_history_to_context`
  * `add_name_to_instructions` -> `add_name_to_context`
  * `add_datetime_to_instructions` -> `add_datetime_to_context`
  * `add_location_to_instructions` -> `add_location_to_context`
  * `add_messages` -> `additional_input`
  * `extra_data` -> `metadata`
  * `create_default_system_message` -> `build_context`
  * `create_default_user_message` -> `build_user_context`
  * Added `send_media_to_model` -> `True` by default. Set to False if you don't want to send media (image, audio, video, files) to the model.  This is useful if you only want media for tools.
  * Added `store_media` -> `True` by default. Set to False if you don't want to store any media in the `RunOutput` that is persisted with sessions.
  * `num_history_responses` -> `num_history_runs`
  * Removed `success_criteria` and `goal`
  * Removed `team_session_id` and `workflow_session_id`.
  * Removed `introduction`
  * Removed `show_tool_calls` -> This is now just always enabled.
  * Removed `team` and `team_data`
  * Removed `respond_directly`, `add_transfer_instructions`, `team_response_separator` and `team_session_id` (since team has been removed from `Agent`)
  * Removed all `team` functionality from inside `Agent` (i.e. the deprecated teams implementation has been removed)
  * Removed all `monitoring` from `Agent`. With the new AgentOS platform, monitoring is done using your own data. Go to [os.agno.com](https://os.agno.com) to get started.
</Accordion>

<Accordion title="Updates to Input & Output">
  * `response_model` -> `output_schema`
  * Added `input_schema` (a pydantic model) to validate the input to the agent.
  * Changed `message` to `input` (which also replaces `messages`). `input` can be of type `str`, `list`, `dict`, `Message`, `BaseModel`, or `list[Message]`.
  * If a `dict` and `input_schema` is provided, the dict will be validated against the schema.
  * If a `BaseModel` and `input_schema` is provided, the model will be validated against the schema.
  * `arun` and `acontinue_run` with `stream=True` now return an async iterator of `RunOutputEvent` directly and is not a coroutine anymore.
  * `debug_mode: bool` added to `run`, `arun`, `print_response` and `aprint_response` to enable debug mode for a specific run.
  * `add_history_to_context` added to `run`, `arun`, `print_response` and `aprint_response` to add the chat history to the context for the current run.
  * `dependencies` added to `run`, `arun`, `print_response` and `aprint_response` to add dependencies to the context for the current run.
  * `metadata` added to `run`, `arun`, `print_response` and `aprint_response` to set the metadata for the current run. This is merged with the metadata set on the `Team` object.
  * Added `get_run_output` and `get_last_run_output` to `Agent` to retrieve a run output by ID.
</Accordion>

<Accordion title="Updates to Metrics">
  * Metrics have been simplified and cleaned up.
  * There are now 3 levels of metrics:
    * `Message.metrics` -> Metrics for each message (assistant, tool, etc.).
    * `RunOutput.metrics` -> Aggregated metrics for the whole run.
    * `AgentSession.metrics` -> Aggregated metrics for the whole session.
</Accordion>

<Accordion title="Updates to Knowledge">
  * `knowledge` is now an instance of `Knowledge` instead of `AgentKnowledge`.
  * `retriever` -> `knowledge_retriever` -> For a custom retriever.
  * `add_references` -> `add_knowledge_to_context` -> To enable traditional RAG.
</Accordion>

<Accordion title="Updates to Memory">
  * `add_memory_references` -> `add_memories_to_context`
  * You can set a custom `memory_manager` to use when creating memories.
  * Added `get_user_memories` to retrieve the user memories.
</Accordion>

<Accordion title="Updates to Sessions">
  * `add_session_summary_references` -> `add_session_summary_to_context`
  * You can set a custom `session_summary_manager` to use when creating session summaries.
  * Removed `session_name` and replace with functions `get_session_name` and `rename_session`.
  * Added `get_session` to retrieve a session by ID.
  * Added `get_chat_history` to retrieve the chat history from a session.
  * Added `get_session_metrics` to retrieve the metrics for a session.
  * Added `get_session_state` to retrieve the session state from a session.
  * Added `get_session_summary` to retrieve the session summary from a session.
  * Because `Agent` is now stateless, `agent_session`, `session_metrics`, `run_id`, `run_input`, `run_messages` and `run_response` as "sticky" agent attributes have been removed.
  * Because `Agent` is now stateless, `images`, `videos`, `audio` are no longer available as agent attributes. Instead these can be accessed on the `RunOutput` for a particular run.
  * Removed `team_session_state` and `workflow_session_state`. Only `session_state` is used.
  * Added `enable_agentic_state` to `Agent` and `Team` to allow the agent to update the session state with a tool call.
</Accordion>

## Team updates

<Accordion title="Updates to Team Class">
  * Removed `mode` from `Team`. Instead there are attributes that can be used to control the behavior of the team:
    * `respond_directly` -> If True, the team leader won't process responses from the members and instead will return them directly
    * `delegate_task_to_all_members` -> If True, the team leader will delegate tasks to all members simultaneously, instead of one by one. When running async (using `arun`) members will run concurrently.
    * `determine_input_for_members` -> `True` by default. Set to False if you want to send the run input directly to the member agents without the team leader synthesizing its own input.
  * `team_id` -> `id` -> If `id` is not set, it is autogenerated using the `name` of the team, or a random UUID if the `name` is not set.
  * `search_previous_sessions_history` -> `search_session_history`
  * `context` -> `dependencies`
  * `add_context` -> `add_dependencies_to_context`
  * `add_history_to_messages` -> `add_history_to_context`
  * `add_name_to_instructions` -> `add_name_to_context`
  * `add_datetime_to_instructions` -> `add_datetime_to_context`
  * `add_location_to_instructions` -> `add_location_to_context`
  * `add_member_tools_to_system_message` -> `add_member_tools_to_context`
  * `extra_data` -> `metadata`
  * Added `additional_input` (works the same as for `Agent`)
  * Added `store_member_responses: bool` to optionally store the member responses on the team run output object.
  * Added `acli_app` to `Team` to enable the CLI app for the team in async mode.
  * Added `send_media_to_model` -> `True` by default. Set to False if you don't want to send media (image, audio, video, files) to the model.  This is useful if you only want media for tools.
  * Added `store_media` -> `True` by default. Set to False if you don't want to store any media in the `RunOutput` that is persisted with sessions.
  * `num_history_responses` -> `num_history_runs`
  * Removed `success_criteria`
  * Removed `team_session_id` and `workflow_session_id`.
  * Removed `enable_team_history`
  * Removed `num_of_interactions_from_history`
  * Removed `show_tool_calls` -> This is now just always enabled.
  * Removed `enable_agentic_context`. `session_state` and `enable_agentic_state` should rather be used to manage state shared between the team and the members.
  * Removed all `monitoring` from `Team`. With the new AgentOS platform, monitoring is done using your own data. Go to [os.agno.com](https://os.agno.com) to get started.
</Accordion>

<Accordion title="Updates to Input & Output">
  * `response_model` -> `output_schema`
  * Added `input_schema` (a pydantic model) to validate the input to the agent.
  * Changed `message` to `input` (which also replaces `messages`). `input` can be of type `str`, `list`, `dict`, `Message`, `BaseModel`, or `list[Message]`.
  * If a `dict` and `input_schema` is provided, the dict will be validated against the schema.
  * If a `BaseModel` and `input_schema` is provided, the model will be validated against the schema.
  * `arun` with `stream=True` now return an async iterator of `TeamRunOutputEvent` directly and is not a coroutine anymore.
  * `debug_mode: bool` added to `run`, `arun`, `print_response` and `aprint_response` to enable debug mode for a specific run.
  * `add_history_to_context` added to `run`, `arun`, `print_response` and `aprint_response` to add the chat history to the context for the current run.
  * `dependencies` added to `run`, `arun`, `print_response` and `aprint_response` to add dependencies to the context for the current run.
  * `metadata` added to `run`, `arun`, `print_response` and `aprint_response` to set the metadata for the current run. This is merged with the metadata set on the `Team` object.
  * Added `get_run_output` and `get_last_run_output` to `Team` to retrieve a run output by ID.
</Accordion>

<Accordion title="Updates to Metrics">
  * Metrics have been simplified and cleaned up.
  * There are now 3 levels of metrics:
    * `Message.metrics` -> Metrics for each message (assistant, tool, etc.).
    * `RunOutput.metrics` -> Aggregated metrics for the whole run.
    * `TeamSession.metrics` -> Aggregated metrics for the whole session.
</Accordion>

<Accordion title="Updates to Knowledge">
  * `knowledge` is now an instance of `Knowledge` instead of `AgentKnowledge`.
  * `retriever` -> `knowledge_retriever` -> For a custom retriever.
  * `add_references` -> `add_knowledge_to_context` -> To enable traditional RAG.
  * Added `update_knowledge` tool to update the knowledge base. Works the same as for `Agent`.
</Accordion>

<Accordion title="Updates to Memory">
  * `add_memory_references` -> `add_memories_to_context`
  * You can set a custom `memory_manager` to use when creating memories.
  * Added `get_user_memories` to retrieve the user memories.
</Accordion>

<Accordion title="Updates to Sessions">
  * `add_session_summary_references` -> `add_session_summary_to_context`
  * You can set a custom `session_summary_manager` to use when creating session summaries.
  * Removed `session_name` and replace with functions `get_session_name` and `rename_session`.
  * Added `get_session` to retrieve a session by ID.
  * Added `get_chat_history` to retrieve the chat history from a session.
  * Added `get_session_metrics` to retrieve the metrics for a session.
  * Added `get_session_state` to retrieve the session state from a session.
  * Added `get_session_summary` to retrieve the session summary from a session.
  * Because `Team` is now stateless, `team_session`, `session_metrics`, `run_id`, `run_input`, `run_messages` and `run_response` as "sticky" team attributes have been removed.
  * Because `Team` is now stateless, `images`, `videos`, `audio` are no longer available as team attributes. Instead these can be accessed on the `TeamRunOutput` for a particular run.
  * Removed `team_session_state` and `workflow_session_state`. Only `session_state` is used.
  * Added `enable_agentic_state` to `Team` to allow the agent to update the session state with a tool call.
</Accordion>

## Workflow updates

<Accordion title="Updates to Workflow Class">
  * `workflow_id` -> `id` -> If `id` is not set, it is autogenerated using the `name` of the workflow, or a random UUID if the `name` is not set.
  * Workflows "v1" has been completely removed and replaced with `Workflows v2`. See full details in the [Workflows](/concepts/workflows) section.
  * This means the import locations for "Workflows v2" is now `agno.workflows`.
  * `extra_data` -> `metadata`
  * Added `store_events` to `Workflow` to optionally store the events on the workflow run output object. Also added `events_to_skip` to skip certain events from being stored. This works the same as for `Agent` and `Team`.
  * Added `store_executor_outputs` to `Workflow` to optionally store the agent/team responses on the workflow run output object.
  * Added `input_schema` to `Workflow` to validate the input to the workflow.
  * Added support for websocket streaming of the workflow. This is appropriate for long-running workflows that need to be streamed to a client. This is only available for `arun`.
  * Removed all `monitoring` from `Workflow`. With the new AgentOS platform, monitoring is done using your own data. Go to [os.agno.com](https://os.agno.com) to get started.
</Accordion>

<Accordion title="Updates to Input & Output">
  * Changed `message` to `input` (which also replaces `messages`). `input` can be of type `str`, `list`, `dict`, or `BaseModel`.
  * If a `dict` and `input_schema` is provided, the dict will be validated against the schema.
  * If a `BaseModel` and `input_schema` is provided, the model will be validated against the schema.
  * `arun` with `stream=True` now return an async iterator of `WorkflowRunOutputEvent` directly and is not a coroutine anymore.
  * `debug_mode: bool` added to `run`, `arun`, `print_response` and `aprint_response` to enable debug mode for a specific run.
  * Added `get_run_output` and `get_last_run_output` to `Workflow` to retrieve a run output by ID.
</Accordion>

<Accordion title="Updates to Sessions">
  * Removed `session_name` and replace with functions `get_session_name` and `rename_session`.
  * Because `Workflow` is now stateless, `workflow_session`, `session_metrics`, `run_id`, `run_input`, `run_messages` and `run_response` as "sticky" workflow attributes have been removed.
  * Because `Workflow` is now stateless, `images`, `videos`, `audio` are no longer available as workflow attributes. Instead these can be accessed on the `WorkflowRunOutput` for a particular run.
  * Added `get_session` to retrieve a session by ID.
  * Added `get_session_metrics` to retrieve the metrics for a session.
  * Added `get_session_state` to retrieve the session state from a session.
  * Added `get_session_summary` to retrieve the session summary from a session.
</Accordion>


# Migrating to Agno v2.0
Source: https://docs.agno.com/how-to/v2-migration

Guide to migrate your Agno applications from v1 to v2.

If you have questions during your migration, we can help! Find us on [Discord](https://discord.gg/4MtYHHrgA8) or [Discourse](https://community.agno.com/).

<Tip>
  Reference the [v2.0 Changelog](/how-to/v2-changelog) for the full list of
  changes.
</Tip>

## Installing Agno v2

If you are already using Agno, you can upgrade to v2 by running:

```bash
pip install -U agno
```

Otherwise, you can install the latest version of Agno v2 by running:

```bash
pip install agno
```

## Migrating your Agno DB

If you used our `Storage` or `Memory` functionalities to store Agent sessions and memories in your database, you can start by migrating your tables.

Use our migration script: [`libs/agno/scripts/migrate_to_v2.py`](https://github.com/agno-agi/agno/blob/main/libs/agno/scripts/migrate_to_v2.py)

The script supports PostgreSQL, MySQL, SQLite, and MongoDB. Update the database connection settings, the batch size (useful if you are migrating large tables) in the script and run it.

Notice:

* The script won't cleanup the old tables, in case you still need them.
* The script is idempotent. If something goes wrong or if you stop it mid-run, you can run it again.
* Metrics are automatically converted from v1 to v2 format.

## Migrating your Agno code

Each section here covers a specific framework domain, with before and after examples and detailed explanations where needed.

### 1. Agents and Teams

[Agents](/concepts/agents/introduction) and [Teams](/concepts/teams/introduction) are the main building blocks in the Agno framework.

Below are some of the v2 updates we have made to the `Agent` and `Team` classes:

1.1. Streaming responses with `arun` now returns an `AsyncIterator`, not a coroutine. This is how you consume the resulting events now, when streaming a run:

```python v2_arun.py
async for event in agent.arun(...):
    ...
```

1.2. The `RunResponse` class is now `RunOutput`. This is the type of the results you get when running an Agent:

```python v2_run_output.py
from agno.run.agent import RunOutput

run_output: RunOutput = agent.run(...)
```

1.3. The events you get when streaming an Agent result have been renamed:

* `RunOutputStartedEvent` ‚Üí `RunStartedEvent`
* `RunOutputCompletedEvent` ‚Üí `RunCompletedEvent`
* `RunOutputErrorEvent` ‚Üí `RunErrorEvent`
* `RunOutputCancelledEvent` ‚Üí `RunCancelledEvent`
* `RunOutputContinuedEvent` ‚Üí `RunContinuedEvent`
* `RunOutputPausedEvent` ‚Üí `RunPausedEvent`
* `RunOutputContentEvent` ‚Üí `RunContentEvent`

1.4. Similarly, for Team output events:

* `TeamRunOutputStartedEvent` ‚Üí `TeamRunStartedEvent`
* `TeamRunOutputCompletedEvent` ‚Üí `TeamRunCompletedEvent`
* `TeamRunOutputErrorEvent` ‚Üí `TeamRunErrorEvent`
* `TeamRunOutputCancelledEvent` ‚Üí `TeamRunCancelledEvent`
* `TeamRunOutputContentEvent` ‚Üí `TeamRunContentEvent`

1.5. The `add_state_in_messages` parameter has been deprecated. Variables in instructions are now resolved automatically by default.
1.6. The `context` parameter has been renamed to `dependencies`.

This is how it looked like on v1:

```python v1_context.py
from agno.agent import Agent

agent = Agent(
    context={"top_stories": get_top_hackernews_stories},
    instructions="Here are the top stories: {top_stories}",
    add_state_in_messages=True,
)
```

This is how it looks like now, on v2:

```python v2_dependencies.py
from agno.agent import Agent

agent = Agent(
    dependencies={"top_stories": get_top_hackernews_stories},
    instructions="Here are the top stories: {top_stories}",
    # resolve_in_context=True by default - no need to set add_state_in_messages
)
```

<Tip>
  See the full list of changes in the [Agent
  Updates](/how-to/v2-changelog#agent-updates) section of the changelog.
</Tip>

### 2. Storage

Storage is used to persist Agent sessions, state and memories in a database.

This is how Storage looks like on v1:

```python v1_storage.py
from agno.agent import Agent
from agno.storage.sqlite import SqliteStorage

storage = SqliteStorage(table_name="agent_sessions", db_file="agno.db", mode="agent")

agent = Agent(storage=storage)
```

These are the changes we have made for v2:

2.1. The `Storage` classes have moved from `agno/storage` to `agno/db`. We will now refer to them as our `Db` classes.
2.2. The `mode` parameter has been deprecated. The same instance can now be used by Agents, Teams and Workflows.

```python v2_storage.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

db = SqliteDb(db_file="agno.db")

agent = Agent(db=db)
```

2.3. The `table_name` parameter has been deprecated. One instance now handles multiple tables, you can define their names individually.

```python v2_storage_table_names.py
db = SqliteDb(db_file="agno.db", sessions_table="your_sessions_table_name", ...)
```

These are all the supported tables, each used to persist data related to a specific domain:

```python v2_storage_all_tables.py
db = SqliteDb(
    db_file="agno.db",
    # Table to store your Agent, Team and Workflow sessions and runs
    session_table="your_session_table_name",
    # Table to store all user memories
    memory_table="your_memory_table_name",
    # Table to store all metrics aggregations
    metrics_table="your_metrics_table_name",
    # Table to store all your evaluation data
    eval_table="your_evals_table_name",
    # Table to store all your knowledge content
    knowledge_table="your_knowledge_table_name",
)
```

2.4. Previously running a `Team` would create a team session and sessions for every team member participating in the run. Now, only the `Team` session is created. The runs for the team leader and all members can be found in the `Team` session.

```python v2_storage_team_sessions.py
team.run(...)

team_session = team.get_latest_session()

# The runs for the team leader and all team members are here
team_session.runs
```

<Tip>
  See more changes in the [Storage Updates](/how-to/v2-changelog#storage)
  section of the changelog.
</Tip>

### 3. Memory

Memory gives an Agent the ability to recall relevant information.

This is how Memory looks like on V1:

```python v1_memory.py
from agno.agent import Agent
from agno.memory.v2.db.sqlite import SqliteMemoryDb
from agno.memory.v2.memory import Memory

memory_db = SqliteMemoryDb(table_name="memory", db_file="agno.db")
memory = Memory(db=memory_db)

agent = Agent(memory=memory)
```

These are the changes we have made for v2:

3.1. The `MemoryDb` classes have been deprecated. The main `Db` classes are to be used.
3.2. The `Memory` class has been deprecated. You now just need to set `enable_user_memories=True` on an Agent with a `db` for Memory to work.

```python v2_memory.py
from agno.agent import Agent
from agno.db.sqlite import SqliteDb

db = SqliteDb(db_file="agno.db")

agent = Agent(db=db, enable_user_memories=True)
```

3.3. The generated memories will be stored in the `memories_table`. By default, the `agno_memories` will be used. It will be created if needed. You can also set the memory table like this:

```python v2_memory_set_table.py
db = SqliteDb(db_file="agno.db", memory_table="your_memory_table_name")
```

3.4. The methods you previously had access to through the Memory class, are now direclty available on the relevant `db` object. For example:

```python v2_memory_db_methods.py
agent.get_user_memories(user_id="123")
```

You can find examples for other all other databases and advanced scenarios in the [examples](/examples/concepts/memory) section.

<Tip>
  See more changes in the [Memory Updates](/how-to/v2-changelog#memory)
  section of the changelog.
</Tip>

### 4. Knowledge

Knowledge gives an Agent the ability to search and retrieve relevant, domain-specific information from a knowledge base.

These are the changes we have made for v2:

4.1. `AgentKnowledge` has been deprecated in favor of the new `Knowledge` class.
Along with this, all of the child classes that used `AgentKnowledge` as a base have been removed. Their capabilities are now supported
by default in `Knowledge`. This also means that the correct reader for the content that you are adding is now selected automatically, with
the option to override it at any time.

4.2. The `load()` method and its variations have been replaced by `add_content()`. Content is the building block of any piece of knowledge originating
from any sources. For a full example of the usage, see the [Content Types](/concepts/knowledge/content_types) page.

4.3. `Knowledge` now supports a `contents_db`. This allows the storage and management of every piece of content that is added to your knowledge.
Furthermore, we now support deletion of individual vectors using the `remove_vectors_by_id()`, `remove_vectors_by_name()` and remove\_vectors by metadata()`methods.
You can also delete all vectors created by a specific piece of content using`remove\_content\_by\_id()\`.

4.4 In order to support the deletion mentioned above, VectorDB tables have been updated. Two new columns, `content_hash` and `content_id` have been added.

4.5. The `retriever` field has been renamed to `knowledge_retriever`.

4.6. The `add_references` method has been renamed to `add_knowledge_to_context`.

**Renamed**

* `retriever` -> `knowledge_retriever`
* `add_references` -> `add_knowledge_to_context`

<Tip>
  See more changes in the [Knowledge Updates](/how-to/v2-changelog#knowledge) section of the changelog.
</Tip>

### 5. Metrics

Metrics are used to understand the usage and consumption related to a Session, a Run or a Message.

These are the changes we have made for v2:

5.1. **Field name changes**:

* `time` ‚Üí `duration`
* `audio_tokens` ‚Üí `audio_total_tokens`
* `input_audio_tokens` ‚Üí `audio_input_tokens`
* `output_audio_tokens` ‚Üí `audio_output_tokens`
* `cached_tokens` ‚Üí `cache_read_tokens`

5.2. **Deprecated fields** (removed in v2):

* `prompt_tokens` and `completion_tokens` - replaced by `input_tokens` and `output_tokens`
* `prompt_tokens_details` and `completion_tokens_details` - detailed info moved to `provider_metrics`

5.3. **New structure**:

* Provider-specific metrics fields are now inside the `provider_metrics` field
* A new `additional_metrics` field has been added for custom metrics

<Tip>
  The migration script automatically converts all metrics from v1 to v2 format, including nested metrics in session data.
</Tip>

### 6. Teams

We have refactored the `Team` class to be more flexible and powerful.

The biggest changes is that the `mode` parameter has been deprecated. Instead there are attributes that can be used to control the behavior of the team:

* `respond_directly` -> If True, the team leader won't process responses from the members and instead will return them directly
* `delegate_task_to_all_members` -> If True, the team leader will delegate tasks to all members simultaneously, instead of one by one. When running async (using `arun`) members will run concurrently.
* `determine_input_for_members` -> `True` by default. Set to False if you want to send the run input directly to the member agents without the team leader synthesizing its own input. This is useful if you want to send pydantic model input directly to the member agents.

See the [Team updates](/how-to/v2-changelog#team-updates) section of the changelog for more details.

### 7. Workflows

We have heavily updated our Workflows, aiming to provide top-of-the-line tooling to build agentic systems.

<Tip>
  Make sure to check our [comprehensive migration guide for
  Workflows](/how-to/workflows-migration).
</Tip>

### 7. Apps -> Interfaces

The old "apps" system (`AGUIApp`, `SlackApi`, `WhatsappApi`) has been replaced with a unified interfaces system within AgentOS.

#### Before - Standalone Apps

```python
from agno.app.agui.app import AGUIApp

agui_app = AGUIApp(agent=agent)
app = agui_app.get_app()
agui_app.serve(port=8000)
```

#### After - Unified Interfaces

```python
from agno.os import AgentOS
from agno.os.interfaces.agui import AGUI

agent_os = AgentOS(agents=[agent], interfaces=[AGUI(agent=agent)])
app = agent_os.get_app()
agent_os.serve(port=8000)
```

#### Migration Steps

1. **Update imports**: Replace app imports with interface imports
2. **Use AgentOS**: Wrap agents with `AgentOS` and specify interfaces
3. **Update serving**: Use `agent_os.serve()` instead of `app.serve()`

### 8. Playground -> AgentOS

Our `Playground` has been deprecated. Our new [AgentOS](/agent-os/introduction) offering will substitute all usecases.

See [AgentOS](/agent-os/introduction) for more details!


# Migrating to Workflows 2.0
Source: https://docs.agno.com/how-to/workflows-migration

Learn how to migrate to Workflows 2.0.

## Migrating from Workflows 1.0

Workflows 2.0 is a completely new approach to agent automation, and requires an upgrade from the Workflows 1.0 implementation. It introduces a new, more flexible and powerful way to build workflows.

### Key Differences

| Workflows 1.0     | Workflows 2.0     | Migration Path                   |
| ----------------- | ----------------- | -------------------------------- |
| Linear only       | Multiple patterns | Add Parallel/Condition as needed |
| Agent-focused     | Mixed components  | Convert functions to Steps       |
| Limited branching | Smart routing     | Replace if/else with Router      |
| Manual loops      | Built-in Loop     | Use Loop component               |

### Migration Steps

1. **Assess current workflow**: Identify parallel opportunities
2. **Add conditions**: Convert if/else logic to Condition components
3. **Extract functions**: Move custom logic to function-based steps
4. **Enable streaming**: For event-based information
5. **Add state management**: Use `workflow_session_state` for data sharing

### Example of Blog Post Generator Workflow

Lets take an example that demonstrates how to build a sophisticated blog post generator that combines
web research capabilities with professional writing expertise. The workflow uses a multi-stage
approach:

1. Intelligent web research and source gathering
2. Content extraction and processing
3. Professional blog post writing with proper citations

Here's the code for the blog post generator in **Workflows 1.0**:

```python
import json
from textwrap import dedent
from typing import Dict, Iterator, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.run.workflow import WorkflowCompletedEvent
from agno.storage.sqlite import SqliteDb
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import RunOutput, Workflow
from pydantic import BaseModel, Field


class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )


class SearchResults(BaseModel):
    articles: list[NewsArticle]


class ScrapedArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )
    content: Optional[str] = Field(
        ...,
        description="Full article content in markdown format. None if content is unavailable.",
    )


class BlogPostGenerator(Workflow):
    """Advanced workflow for generating professional blog posts with proper research and citations."""

    description: str = dedent("""\
    An intelligent blog post generator that creates engaging, well-researched content.
    This workflow orchestrates multiple AI agents to research, analyze, and craft
    compelling blog posts that combine journalistic rigor with engaging storytelling.
    The system excels at creating content that is both informative and optimized for
    digital consumption.
    """)

    # Search Agent: Handles intelligent web searching and source gathering
    searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[DuckDuckGoTools()],
        description=dedent("""\
        You are BlogResearch-X, an elite research assistant specializing in discovering
        high-quality sources for compelling blog content. Your expertise includes:

        - Finding authoritative and trending sources
        - Evaluating content credibility and relevance
        - Identifying diverse perspectives and expert opinions
        - Discovering unique angles and insights
        - Ensuring comprehensive topic coverage\
        """),
        instructions=dedent("""\
        1. Search Strategy üîç
           - Find 10-15 relevant sources and select the 5-7 best ones
           - Prioritize recent, authoritative content
           - Look for unique angles and expert insights
        2. Source Evaluation üìä
           - Verify source credibility and expertise
           - Check publication dates for timeliness
           - Assess content depth and uniqueness
        3. Diversity of Perspectives üåê
           - Include different viewpoints
           - Gather both mainstream and expert opinions
           - Find supporting data and statistics\
        """),
        output_schema=SearchResults,
    )

    # Content Scraper: Extracts and processes article content
    article_scraper: Agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        tools=[Newspaper4kTools()],
        description=dedent("""\
        You are ContentBot-X, a specialist in extracting and processing digital content
        for blog creation. Your expertise includes:

        - Efficient content extraction
        - Smart formatting and structuring
        - Key information identification
        - Quote and statistic preservation
        - Maintaining source attribution\
        """),
        instructions=dedent("""\
        1. Content Extraction üìë
           - Extract content from the article
           - Preserve important quotes and statistics
           - Maintain proper attribution
           - Handle paywalls gracefully
        2. Content Processing üîÑ
           - Format text in clean markdown
           - Preserve key information
           - Structure content logically
        3. Quality Control ‚úÖ
           - Verify content relevance
           - Ensure accurate extraction
           - Maintain readability\
        """),
        output_schema=ScrapedArticle,
    )

    # Content Writer Agent: Crafts engaging blog posts from research
    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-5-mini"),
        description=dedent("""\
        You are BlogMaster-X, an elite content creator combining journalistic excellence
        with digital marketing expertise. Your strengths include:

        - Crafting viral-worthy headlines
        - Writing engaging introductions
        - Structuring content for digital consumption
        - Incorporating research seamlessly
        - Optimizing for SEO while maintaining quality
        - Creating shareable conclusions\
        """),
        instructions=dedent("""\
        1. Content Strategy üìù
           - Craft attention-grabbing headlines
           - Write compelling introductions
           - Structure content for engagement
           - Include relevant subheadings
        2. Writing Excellence ‚úçÔ∏è
           - Balance expertise with accessibility
           - Use clear, engaging language
           - Include relevant examples
           - Incorporate statistics naturally
        3. Source Integration üîç
           - Cite sources properly
           - Include expert quotes
           - Maintain factual accuracy
        4. Digital Optimization üíª
           - Structure for scanability
           - Include shareable takeaways
           - Optimize for SEO
           - Add engaging subheadings\
        """),
        expected_output=dedent("""\
        # {Viral-Worthy Headline}

        ## Introduction
        {Engaging hook and context}

        ## {Compelling Section 1}
        {Key insights and analysis}
        {Expert quotes and statistics}

        ## {Engaging Section 2}
        {Deeper exploration}
        {Real-world examples}

        ## {Practical Section 3}
        {Actionable insights}
        {Expert recommendations}

        ## Key Takeaways
        - {Shareable insight 1}
        - {Practical takeaway 2}
        - {Notable finding 3}

        ## Sources
        {Properly attributed sources with links}\
        """),
        markdown=True,
    )

    def run(
        self,
        topic: str,
        use_search_cache: bool = True,
        use_scrape_cache: bool = True,
        use_cached_report: bool = True,
    ) -> Iterator[RunOutputEvent]:
        logger.info(f"Generating a blog post on: {topic}")

        # Use the cached blog post if use_cache is True
        if use_cached_report:
            cached_blog_post = self.get_cached_blog_post(topic)
            if cached_blog_post:
                yield WorkflowCompletedEvent(
                    run_id=self.run_id,
                    content=cached_blog_post,
                )
                return

        # Search the web for articles on the topic
        search_results: Optional[SearchResults] = self.get_search_results(
            topic, use_search_cache
        )
        # If no search_results are found for the topic, end the workflow
        if search_results is None or len(search_results.articles) == 0:
            yield WorkflowCompletedEvent(
                run_id=self.run_id,
                content=f"Sorry, could not find any articles on the topic: {topic}",
            )
            return

        # Scrape the search results
        scraped_articles: Dict[str, ScrapedArticle] = self.scrape_articles(
            topic, search_results, use_scrape_cache
        )

        # Prepare the input for the writer
        writer_input = {
            "topic": topic,
            "articles": [v.model_dump() for v in scraped_articles.values()],
        }

        # Run the writer and yield the response
        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)

        # Save the blog post in the cache
        self.add_blog_post_to_cache(topic, self.writer.run_response.content)

    def get_cached_blog_post(self, topic: str) -> Optional[str]:
        logger.info("Checking if cached blog post exists")

        return self.session_state.get("blog_posts", {}).get(topic)

    def add_blog_post_to_cache(self, topic: str, blog_post: str):
        logger.info(f"Saving blog post for topic: {topic}")
        self.session_state.setdefault("blog_posts", {})
        self.session_state["blog_posts"][topic] = blog_post

    def get_cached_search_results(self, topic: str) -> Optional[SearchResults]:
        logger.info("Checking if cached search results exist")
        search_results = self.session_state.get("search_results", {}).get(topic)
        return (
            SearchResults.model_validate(search_results)
            if search_results and isinstance(search_results, dict)
            else search_results
        )

    def add_search_results_to_cache(self, topic: str, search_results: SearchResults):
        logger.info(f"Saving search results for topic: {topic}")
        self.session_state.setdefault("search_results", {})
        self.session_state["search_results"][topic] = search_results

    def get_cached_scraped_articles(
        self, topic: str
    ) -> Optional[Dict[str, ScrapedArticle]]:
        logger.info("Checking if cached scraped articles exist")
        scraped_articles = self.session_state.get("scraped_articles", {}).get(topic)
        return (
            ScrapedArticle.model_validate(scraped_articles)
            if scraped_articles and isinstance(scraped_articles, dict)
            else scraped_articles
        )

    def add_scraped_articles_to_cache(
        self, topic: str, scraped_articles: Dict[str, ScrapedArticle]
    ):
        logger.info(f"Saving scraped articles for topic: {topic}")
        self.session_state.setdefault("scraped_articles", {})
        self.session_state["scraped_articles"][topic] = scraped_articles

    def get_search_results(
        self, topic: str, use_search_cache: bool, num_attempts: int = 3
    ) -> Optional[SearchResults]:
        # Get cached search_results from the session state if use_search_cache is True
        if use_search_cache:
            try:
                search_results_from_cache = self.get_cached_search_results(topic)
                if search_results_from_cache is not None:
                    search_results = SearchResults.model_validate(
                        search_results_from_cache
                    )
                    logger.info(
                        f"Found {len(search_results.articles)} articles in cache."
                    )
                    return search_results
            except Exception as e:
                logger.warning(f"Could not read search results from cache: {e}")

        # If there are no cached search_results, use the searcher to find the latest articles
        for attempt in range(num_attempts):
            try:
                searcher_response: RunOutput = self.searcher.run(topic)
                if (
                    searcher_response is not None
                    and searcher_response.content is not None
                    and isinstance(searcher_response.content, SearchResults)
                ):
                    article_count = len(searcher_response.content.articles)
                    logger.info(
                        f"Found {article_count} articles on attempt {attempt + 1}"
                    )
                    # Cache the search results
                    self.add_search_results_to_cache(topic, searcher_response.content)
                    return searcher_response.content
                else:
                    logger.warning(
                        f"Attempt {attempt + 1}/{num_attempts} failed: Invalid response type"
                    )
            except Exception as e:
                logger.warning(f"Attempt {attempt + 1}/{num_attempts} failed: {str(e)}")

        logger.error(f"Failed to get search results after {num_attempts} attempts")
        return None

    def scrape_articles(
        self, topic: str, search_results: SearchResults, use_scrape_cache: bool
    ) -> Dict[str, ScrapedArticle]:
        scraped_articles: Dict[str, ScrapedArticle] = {}

        # Get cached scraped_articles from the session state if use_scrape_cache is True
        if use_scrape_cache:
            try:
                scraped_articles_from_cache = self.get_cached_scraped_articles(topic)
                if scraped_articles_from_cache is not None:
                    scraped_articles = scraped_articles_from_cache
                    logger.info(
                        f"Found {len(scraped_articles)} scraped articles in cache."
                    )
                    return scraped_articles
            except Exception as e:
                logger.warning(f"Could not read scraped articles from cache: {e}")

        # Scrape the articles that are not in the cache
        for article in search_results.articles:
            if article.url in scraped_articles:
                logger.info(f"Found scraped article in cache: {article.url}")
                continue

            article_scraper_response: RunOutput = self.article_scraper.run(
                article.url
            )
            if (
                article_scraper_response is not None
                and article_scraper_response.content is not None
                and isinstance(article_scraper_response.content, ScrapedArticle)
            ):
                scraped_articles[article_scraper_response.content.url] = (
                    article_scraper_response.content
                )
                logger.info(f"Scraped article: {article_scraper_response.content.url}")

        # Save the scraped articles in the session state
        self.add_scraped_articles_to_cache(topic, scraped_articles)
        return scraped_articles


# Run the workflow if the script is executed directly
if __name__ == "__main__":
    import random

    from rich.prompt import Prompt

    # Fun example prompts to showcase the generator's versatility
    example_prompts = [
        "Why Cats Secretly Run the Internet",
        "The Science Behind Why Pizza Tastes Better at 2 AM",
        "Time Travelers' Guide to Modern Social Media",
        "How Rubber Ducks Revolutionized Software Development",
        "The Secret Society of Office Plants: A Survival Guide",
        "Why Dogs Think We're Bad at Smelling Things",
        "The Underground Economy of Coffee Shop WiFi Passwords",
        "A Historical Analysis of Dad Jokes Through the Ages",
    ]

    # Get topic from user
    topic = Prompt.ask(
        "[bold]Enter a blog post topic[/bold] (or press Enter for a random example)\n‚ú®",
        default=random.choice(example_prompts),
    )

    # Convert the topic to a URL-safe string for use in session_id
    url_safe_topic = topic.lower().replace(" ", "-")

    # Initialize the blog post generator workflow
    # - Creates a unique session ID based on the topic
    # - Sets up SQLite storage for caching results
    generate_blog_post = BlogPostGenerator(
        session_id=f"generate-blog-post-on-{url_safe_topic}",
        db=SqliteDb(
            db_file="tmp/agno_workflows.db",
        ),
        debug_mode=True,
    )

    # Execute the workflow with caching enabled
    # Returns an iterator of RunOutput objects containing the generated content
    blog_post: Iterator[RunOutputEvent] = generate_blog_post.run(
        topic=topic,
        use_search_cache=True,
        use_scrape_cache=True,
        use_cached_report=True,
    )

    # Print the response
    pprint_run_response(blog_post, markdown=True)
```

To convert this into **Workflows 2.0** structure, either we can break down the workflow into smaller steps and follow the [development guide](/concepts/workflows/types_of_workflows).
Or for simplicity we can directly replace the run method to a single custom function executor as mentioned [here](/concepts/workflows/types_of_workflows#2-fully-python-workflow).

It will look like this:

```python
import asyncio
import json
from textwrap import dedent
from typing import Dict, Optional

from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.openai import OpenAIChat
from agno.tools.googlesearch import GoogleSearchTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow.workflow import Workflow
from pydantic import BaseModel, Field


# --- Response Models ---
class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )


class SearchResults(BaseModel):
    articles: list[NewsArticle]


class ScrapedArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )
    content: Optional[str] = Field(
        ...,
        description="Full article content in markdown format. None if content is unavailable.",
    )


# --- Agents ---
research_agent = Agent(
    name="Blog Research Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[GoogleSearchTools()],
    description=dedent("""\
    You are BlogResearch-X, an elite research assistant specializing in discovering
    high-quality sources for compelling blog content. Your expertise includes:

    - Finding authoritative and trending sources
    - Evaluating content credibility and relevance
    - Identifying diverse perspectives and expert opinions
    - Discovering unique angles and insights
    - Ensuring comprehensive topic coverage
    """),
    instructions=dedent("""\
    1. Search Strategy üîç
       - Find 10-15 relevant sources and select the 5-7 best ones
       - Prioritize recent, authoritative content
       - Look for unique angles and expert insights
    2. Source Evaluation üìä
       - Verify source credibility and expertise
       - Check publication dates for timeliness
       - Assess content depth and uniqueness
    3. Diversity of Perspectives üåê
       - Include different viewpoints
       - Gather both mainstream and expert opinions
       - Find supporting data and statistics
    """),
    output_schema=SearchResults,
)

content_scraper_agent = Agent(
    name="Content Scraper Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[Newspaper4kTools()],
    description=dedent("""\
    You are ContentBot-X, a specialist in extracting and processing digital content
    for blog creation. Your expertise includes:

    - Efficient content extraction
    - Smart formatting and structuring
    - Key information identification
    - Quote and statistic preservation
    - Maintaining source attribution
    """),
    instructions=dedent("""\
    1. Content Extraction üìë
       - Extract content from the article
       - Preserve important quotes and statistics
       - Maintain proper attribution
       - Handle paywalls gracefully
    2. Content Processing üîÑ
       - Format text in clean markdown
       - Preserve key information
       - Structure content logically
    3. Quality Control ‚úÖ
       - Verify content relevance
       - Ensure accurate extraction
       - Maintain readability
    """),
    output_schema=ScrapedArticle,
)

blog_writer_agent = Agent(
    name="Blog Writer Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    description=dedent("""\
    You are BlogMaster-X, an elite content creator combining journalistic excellence
    with digital marketing expertise. Your strengths include:

    - Crafting viral-worthy headlines
    - Writing engaging introductions
    - Structuring content for digital consumption
    - Incorporating research seamlessly
    - Optimizing for SEO while maintaining quality
    - Creating shareable conclusions
    """),
    instructions=dedent("""\
    1. Content Strategy üìù
       - Craft attention-grabbing headlines
       - Write compelling introductions
       - Structure content for engagement
       - Include relevant subheadings
    2. Writing Excellence ‚úçÔ∏è
       - Balance expertise with accessibility
       - Use clear, engaging language
       - Include relevant examples
       - Incorporate statistics naturally
    3. Source Integration üîç
       - Cite sources properly
       - Include expert quotes
       - Maintain factual accuracy
    4. Digital Optimization üíª
       - Structure for scanability
       - Include shareable takeaways
       - Optimize for SEO
       - Add engaging subheadings

    Format your blog post with this structure:
    # {Viral-Worthy Headline}

    ## Introduction
    {Engaging hook and context}

    ## {Compelling Section 1}
    {Key insights and analysis}
    {Expert quotes and statistics}

    ## {Engaging Section 2}
    {Deeper exploration}
    {Real-world examples}

    ## {Practical Section 3}
    {Actionable insights}
    {Expert recommendations}

    ## Key Takeaways
    - {Shareable insight 1}
    - {Practical takeaway 2}
    - {Notable finding 3}

    ## Sources
    {Properly attributed sources with links}
    """),
    markdown=True,
)


# --- Helper Functions ---
def get_cached_blog_post(session_state, topic: str) -> Optional[str]:
    """Get cached blog post from workflow session state"""
    logger.info("Checking if cached blog post exists")
    return session_state.get("blog_posts", {}).get(topic)


def cache_blog_post(session_state, topic: str, blog_post: str):
    """Cache blog post in workflow session state"""
    logger.info(f"Saving blog post for topic: {topic}")
    if "blog_posts" not in session_state:
        session_state["blog_posts"] = {}
    session_state["blog_posts"][topic] = blog_post


def get_cached_search_results(session_state, topic: str) -> Optional[SearchResults]:
    """Get cached search results from workflow session state"""
    logger.info("Checking if cached search results exist")
    search_results = session_state.get("search_results", {}).get(topic)
    if search_results and isinstance(search_results, dict):
        try:
            return SearchResults.model_validate(search_results)
        except Exception as e:
            logger.warning(f"Could not validate cached search results: {e}")
    return search_results if isinstance(search_results, SearchResults) else None


def cache_search_results(session_state, topic: str, search_results: SearchResults):
    """Cache search results in workflow session state"""
    logger.info(f"Saving search results for topic: {topic}")
    if "search_results" not in session_state:
        session_state["search_results"] = {}
    session_state["search_results"][topic] = search_results.model_dump()


def get_cached_scraped_articles(
    session_state, topic: str
) -> Optional[Dict[str, ScrapedArticle]]:
    """Get cached scraped articles from workflow session state"""
    logger.info("Checking if cached scraped articles exist")
    scraped_articles = session_state.get("scraped_articles", {}).get(topic)
    if scraped_articles and isinstance(scraped_articles, dict):
        try:
            return {
                url: ScrapedArticle.model_validate(article)
                for url, article in scraped_articles.items()
            }
        except Exception as e:
            logger.warning(f"Could not validate cached scraped articles: {e}")
    return scraped_articles if isinstance(scraped_articles, dict) else None


def cache_scraped_articles(
    session_state, topic: str, scraped_articles: Dict[str, ScrapedArticle]
):
    """Cache scraped articles in workflow session state"""
    logger.info(f"Saving scraped articles for topic: {topic}")
    if "scraped_articles" not in session_state:
        session_state["scraped_articles"] = {}
    session_state["scraped_articles"][topic] = {
        url: article.model_dump() for url, article in scraped_articles.items()
    }


async def get_search_results(
    session_state, topic: str, use_cache: bool = True, num_attempts: int = 3
) -> Optional[SearchResults]:
    """Get search results with caching support"""

    # Check cache first
    if use_cache:
        cached_results = get_cached_search_results(session_state, topic)
        if cached_results:
            logger.info(f"Found {len(cached_results.articles)} articles in cache.")
            return cached_results

    # Search for new results
    for attempt in range(num_attempts):
        try:
            print(
                f"üîç Searching for articles about: {topic} (attempt {attempt + 1}/{num_attempts})"
            )
            response = await research_agent.arun(topic)

            if (
                response
                and response.content
                and isinstance(response.content, SearchResults)
            ):
                article_count = len(response.content.articles)
                logger.info(f"Found {article_count} articles on attempt {attempt + 1}")
                print(f"‚úÖ Found {article_count} relevant articles")

                # Cache the results
                cache_search_results(session_state, topic, response.content)
                return response.content
            else:
                logger.warning(
                    f"Attempt {attempt + 1}/{num_attempts} failed: Invalid response type"
                )

        except Exception as e:
            logger.warning(f"Attempt {attempt + 1}/{num_attempts} failed: {str(e)}")

    logger.error(f"Failed to get search results after {num_attempts} attempts")
    return None


async def scrape_articles(
    session_state,
    topic: str,
    search_results: SearchResults,
    use_cache: bool = True,
) -> Dict[str, ScrapedArticle]:
    """Scrape articles with caching support"""

    # Check cache first
    if use_cache:
        cached_articles = get_cached_scraped_articles(session_state, topic)
        if cached_articles:
            logger.info(f"Found {len(cached_articles)} scraped articles in cache.")
            return cached_articles

    scraped_articles: Dict[str, ScrapedArticle] = {}

    print(f"üìÑ Scraping {len(search_results.articles)} articles...")

    for i, article in enumerate(search_results.articles, 1):
        try:
            print(
                f"üìñ Scraping article {i}/{len(search_results.articles)}: {article.title[:50]}..."
            )
            response = await content_scraper_agent.arun(article.url)

            if (
                response
                and response.content
                and isinstance(response.content, ScrapedArticle)
            ):
                scraped_articles[response.content.url] = response.content
                logger.info(f"Scraped article: {response.content.url}")
                print(f"‚úÖ Successfully scraped: {response.content.title[:50]}...")
            else:
                print(f"‚ùå Failed to scrape: {article.title[:50]}...")

        except Exception as e:
            logger.warning(f"Failed to scrape {article.url}: {str(e)}")
            print(f"‚ùå Error scraping: {article.title[:50]}...")

    # Cache the scraped articles
    cache_scraped_articles(session_state, topic, scraped_articles)
    return scraped_articles


# --- Main Execution Function ---
async def blog_generation_execution(
    session_state,
    topic: str = None,
    use_search_cache: bool = True,
    use_scrape_cache: bool = True,
    use_blog_cache: bool = True,
) -> str:
    """
    Blog post generation workflow execution function.

    Args:
        session_state: The shared session state
        topic: Blog post topic (if not provided, uses execution_input.input)
        use_search_cache: Whether to use cached search results
        use_scrape_cache: Whether to use cached scraped articles
        use_blog_cache: Whether to use cached blog posts
    """

    blog_topic = topic

    if not blog_topic:
        return "‚ùå No blog topic provided. Please specify a topic."

    print(f"üé® Generating blog post about: {blog_topic}")
    print("=" * 60)

    # Check for cached blog post first
    if use_blog_cache:
        cached_blog = get_cached_blog_post(session_state, blog_topic)
        if cached_blog:
            print("üìã Found cached blog post!")
            return cached_blog

    # Phase 1: Research and gather sources
    print("\nüîç PHASE 1: RESEARCH & SOURCE GATHERING")
    print("=" * 50)

    search_results = await get_search_results(
        session_state, blog_topic, use_search_cache
    )

    if not search_results or len(search_results.articles) == 0:
        return f"‚ùå Sorry, could not find any articles on the topic: {blog_topic}"

    print(f"üìä Found {len(search_results.articles)} relevant sources:")
    for i, article in enumerate(search_results.articles, 1):
        print(f"   {i}. {article.title[:60]}...")

    # Phase 2: Content extraction
    print("\nüìÑ PHASE 2: CONTENT EXTRACTION")
    print("=" * 50)

    scraped_articles = await scrape_articles(
        session_state, blog_topic, search_results, use_scrape_cache
    )

    if not scraped_articles:
        return f"‚ùå Could not extract content from any articles for topic: {blog_topic}"

    print(f"üìñ Successfully extracted content from {len(scraped_articles)} articles")

    # Phase 3: Blog post writing
    print("\n‚úçÔ∏è PHASE 3: BLOG POST CREATION")
    print("=" * 50)

    # Prepare input for the writer
    writer_input = {
        "topic": blog_topic,
        "articles": [article.model_dump() for article in scraped_articles.values()],
    }

    print("ü§ñ AI is crafting your blog post...")
    writer_response = await blog_writer_agent.arun(json.dumps(writer_input, indent=2))

    if not writer_response or not writer_response.content:
        return f"‚ùå Failed to generate blog post for topic: {blog_topic}"

    blog_post = writer_response.content

    # Cache the blog post
    cache_blog_post(session_state, blog_topic, blog_post)

    print("‚úÖ Blog post generated successfully!")
    print(f"üìù Length: {len(blog_post)} characters")
    print(f"üìö Sources: {len(scraped_articles)} articles")

    return blog_post


# --- Workflow Definition ---
blog_generator_workflow = Workflow(
    name="Blog Post Generator",
    description="Advanced blog post generator with research and content creation capabilities",
    db=SqliteDb(
        session_table="workflow_session",
        db_file="tmp/blog_generator.db",
    ),
    steps=blog_generation_execution,
    session_state={},  # Initialize empty session state for caching
)


if __name__ == "__main__":
    import random

    async def main():
        # Fun example topics to showcase the generator's versatility
        example_topics = [
            "The Rise of Artificial General Intelligence: Latest Breakthroughs",
            "How Quantum Computing is Revolutionizing Cybersecurity",
            "Sustainable Living in 2024: Practical Tips for Reducing Carbon Footprint",
            "The Future of Work: AI and Human Collaboration",
            "Space Tourism: From Science Fiction to Reality",
            "Mindfulness and Mental Health in the Digital Age",
            "The Evolution of Electric Vehicles: Current State and Future Trends",
            "Why Cats Secretly Run the Internet",
            "The Science Behind Why Pizza Tastes Better at 2 AM",
            "How Rubber Ducks Revolutionized Software Development",
        ]

        # Test with a random topic
        topic = random.choice(example_topics)

        print("üß™ Testing Blog Post Generator v2.0")
        print("=" * 60)
        print(f"üìù Topic: {topic}")
        print()

        # Generate the blog post
        resp = await blog_generator_workflow.arun(
            topic=topic,
            use_search_cache=True,
            use_scrape_cache=True,
            use_blog_cache=True,
        )

        pprint_run_response(resp, markdown=True, show_time=True)

    asyncio.run(main())
```

For more examples and advanced patterns, see [here](/examples/concepts/workflows/01-basic-workflows). Each file demonstrates a specific pattern with detailed comments and real-world use cases.


# Discord Bot
Source: https://docs.agno.com/integrations/discord/introduction

Host agents as Discord Bots.

The Discord Bot integration allows you to serve Agents or Teams via Discord, using the discord.py library to handle Discord events and send messages.

## Setup Steps

<Snippet file="setup-discord-app.mdx" />

### Example Usage

Create an agent, wrap it with `DiscordClient`, and run it:

```python
from agno.agent import Agent
from agno.integrations.discord import DiscordClient
from agno.models.openai import OpenAIChat

basic_agent = Agent(
    name="Basic Agent",
    model=OpenAIChat(id="gpt-5-mini"), 
    add_history_to_context=True,
    num_history_runs=3,
    add_datetime_to_context=True,
)

discord_agent = DiscordClient(basic_agent)
if __name__ == "__main__":
    discord_agent.serve()
```

## Core Components

* `DiscordClient`: Wraps Agno agents/teams for Discord integration using discord.py.
* `DiscordClient.serve`: Starts the Discord bot client with the provided token.

## `DiscordClient` Class

Main entry point for Agno Discord bot applications.

### Initialization Parameters

| Parameter | Type              | Default | Description            |
| --------- | ----------------- | ------- | ---------------------- |
| `agent`   | `Optional[Agent]` | `None`  | Agno `Agent` instance. |
| `team`    | `Optional[Team]`  | `None`  | Agno `Team` instance.  |

*Provide `agent` or `team`, not both.*

## Event Handling

The Discord bot automatically handles various Discord events:

### Message Events

* **Description**: Processes all incoming messages from users
* **Media Support**: Handles images, videos, audio files, and documents
* **Threading**: Automatically creates threads for conversations
* **Features**:
  * Automatic thread creation for each conversation
  * Media processing and forwarding to agents
  * Message splitting for responses longer than 1500 characters
  * Support for reasoning content display
  * Context enrichment with username and message URL

### Supported Media Types

* **Images**: Direct URL processing for image analysis
* **Videos**: Downloads and processes video content
* **Audio**: URL-based audio processing
* **Files**: Downloads and processes document attachments

## Environment Variables

Ensure the following environment variable is set:

```bash
export DISCORD_BOT_TOKEN="your-discord-bot-token"
```

## Message Processing

The bot processes messages with the following workflow:

1. **Message Reception**: Receives messages from Discord channels
2. **Media Processing**: Downloads and processes any attached media
3. **Thread Management**: Creates or uses existing threads for conversations
4. **Agent/Team Execution**: Forwards the message and media to the configured agent or team
5. **Response Handling**: Sends the response back to Discord, splitting long messages if necessary
6. **Reasoning Display**: Shows reasoning content in italics if available

## Features

### Automatic Thread Creation

* Creates a new thread for each user's first message
* Maintains conversation context within threads
* Uses the format: `{username}'s thread`

### Media Support

* **Images**: Passed as `Image` objects with URLs
* **Videos**: Downloaded and passed as `Video` objects with content
* **Audio**: Passed as `Audio` objects with URLs
* **Files**: Downloaded and passed as `File` objects with content

### Message Formatting

* Long messages (>1500 characters) are automatically split
* Reasoning content is displayed in italics
* Batch numbering for split messages: `[1/3] message content`

## Testing the Integration

1. Set up your Discord bot token: `export DISCORD_BOT_TOKEN="your-token"`
2. Run your application: `python your_discord_bot.py`
3. Invite the bot to your Discord server
4. Send a message in any channel where the bot has access
5. The bot will automatically create a thread and respond


# AgentOps
Source: https://docs.agno.com/integrations/observability/agentops

Integrate Agno with AgentOps to send traces and logs to a centralized observability platform.

## Integrating Agno with AgentOps

[AgentOps](https://app.agentops.ai/) provides automatic instrumentation for your Agno agents to track all operations including agent interactions, team coordination, tool usage, and workflow execution.

## Prerequisites

1. **Install AgentOps**

   Ensure you have the AgentOps package installed:

   ```bash
   pip install agentops
   ```

2. **Authentication**
   Go to [AgentOps](https://app.agentops.ai/) and copy your API key
   ```bash
   export AGENTOPS_API_KEY=<your-api-key>
   ```

## Logging Model Calls with AgentOps

This example demonstrates how to use AgentOps to log model calls.

```python
import agentops
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Initialize AgentOps
agentops.init()

# Create and run an agent
agent = Agent(model=OpenAIChat(id="gpt-5-mini"))
response = agent.run("Share a 2 sentence horror story")

# Print the response
print(response.content)
```

## Notes

* **Environment Variables**: Ensure your environment variable is correctly set for the AgentOps API key.
* **Initialization**: Call `agentops.init()` to initialize AgentOps.
* **AgentOps Docs**: [AgentOps Docs](https://docs.agentops.ai/v2/integrations/agno)

Following these steps will integrate Agno with AgentOps, providing comprehensive logging and visualization for your AI agents‚Äô model calls.


# Arize
Source: https://docs.agno.com/integrations/observability/arize

Integrate Agno with Arize Phoenix to send traces and gain insights into your agent's performance.

## Integrating Agno with Arize Phoenix

[Arize Phoenix](https://phoenix.arize.com/) is a powerful platform for monitoring and analyzing AI models. By integrating Agno with Arize Phoenix, you can leverage OpenInference to send traces and gain insights into your agent's performance.

## Prerequisites

1. **Install Dependencies**

   Ensure you have the necessary packages installed:

   ```bash
   pip install arize-phoenix openai openinference-instrumentation-agno opentelemetry-sdk opentelemetry-exporter-otlp
   ```

2. **Setup Arize Phoenix Account**

   * Create an account at [Arize Phoenix](https://phoenix.arize.com/).
   * Obtain your API key from the Arize Phoenix dashboard.

3. **Set Environment Variables**

   Configure your environment with the Arize Phoenix API key:

   ```bash
   export ARIZE_PHOENIX_API_KEY=<your-key>
   ```

## Sending Traces to Arize Phoenix

* ### Example: Using Arize Phoenix with OpenInference

This example demonstrates how to instrument your Agno agent with OpenInference and send traces to Arize Phoenix.

```python
import asyncio
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from phoenix.otel import register

# Set environment variables for Arize Phoenix
os.environ["PHOENIX_CLIENT_HEADERS"] = f"api_key={os.getenv('ARIZE_PHOENIX_API_KEY')}"
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "https://app.phoenix.arize.com"

# Configure the Phoenix tracer
tracer_provider = register(
    project_name="agno-stock-price-agent",  # Default is 'default'
    auto_instrument=True,  # Automatically use the installed OpenInference instrumentation
)

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What is the current price of Tesla?")
```

Now go to the [phoenix cloud](https://app.phoenix.arize.com) and view the traces created by your agent. You can visualize the execution flow, monitor performance, and debug issues directly from the Arize Phoenix dashboard.

<Frame caption="Arize Phoenix Trace">
  <img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=4cf3e72fb6ccbcb4e888180f8697edd2" style={{ borderRadius: '10px', width: '100%', maxWidth: '800px' }} alt="arize-agno observability" data-og-width="2160" width="2160" data-og-height="1239" height="1239" data-path="images/arize-phoenix-trace.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=45a468f95e21528368f9e756386d7db0 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7094e80a2c0ca54769d664e76a7d4cad 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=8fafca5315b18a0277f14d720aa49e60 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=4d5df2fb5e6f0642fd339f90e9885eb6 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=b57cff98e108efdf5c5e5bebdac43e73 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/arize-phoenix-trace.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=57dc5c8addbb1396dc08e4c8ced0d67d 2500w" />
</Frame>

* ### Example: Local Collector Setup

For local development, you can run a local collector using

```bash
phoenix serve
```

```python
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from phoenix.otel import register

# Set the local collector endpoint
os.environ["PHOENIX_COLLECTOR_ENDPOINT"] = "http://localhost:6006"

# Configure the Phoenix tracer
tracer_provider = register(
    project_name="agno-stock-price-agent",  # Default is 'default'
    auto_instrument=True,  # Automatically use the installed OpenInference instrumentation
)

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What is the current price of Tesla?")
```

## Notes

* **Environment Variables**: Ensure your environment variables are correctly set for the API key and collector endpoint.
* **Local Development**: Use `phoenix serve` to start a local collector for development purposes.

By following these steps, you can effectively integrate Agno with Arize Phoenix, enabling comprehensive observability and monitoring of your AI agents.


# Atla
Source: https://docs.agno.com/integrations/observability/atla

Integrate `Atla` with Agno for real-time monitoring, automated evaluation, and performance analytics of your AI agents.

[Atla](https://www.atla-ai.com/) is an advanced observability platform designed specifically for AI agent monitoring and evaluation.
This integration provides comprehensive insights into agent performance, automated quality assessment, and detailed analytics for production AI systems.

## Prerequisites

* **API Key**: Obtain your API key from the [Atla dashboard](https://app.atla-ai.com)

Install the Atla Insights SDK with Agno support:

```bash
pip install "atla-insights"
```

## Configuration

Configure your API key as an environment variable:

```bash
export ATLA_API_KEY="your_api_key_from_atla_dashboard"
```

## Example

```python
from os import getenv
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from atla_insights import configure, instrument_agno

# Step 1: Configure Atla
configure(token=getenv("ATLA_API_KEY"))

# Step 2: Create your Agno agent
agent = Agent(
    name="Market Analysis Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    instructions="Provide professional market analysis with data-driven insights.",
    debug_mode=True,
)

# Step 3: Instrument and execute
with instrument_agno("openai"):
    response = agent.run("Retrieve the latest news about the stock market.")
    print(response.content)
```

Now go to the [Atla dashboard](https://app.atla-ai.com/app/) and view the traces created by your agent. You can visualize the execution flow, monitor performance, and debug issues directly from the Atla dashboard.

<Frame caption="Atla Agent run trace">
  <img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=83334fabbdbc6d69fd6c322568a79910" style={{ borderRadius: '10px', width: '100%', maxWidth: '800px' }} alt="atla-trace" data-og-width="1482" width="1482" data-og-height="853" height="853" data-path="images/atla-trace-summary.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c16251e3e7934ba377fcc96c87fb9c94 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=30b4c98898ac04641de69533b0e9b2b3 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=846aa70151fd7874c52b08db17fb25ac 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0ddcdd1f24323b0cfe1f38af5bc56b03 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=6f8a77a8d026dfc3533084b788e3caf0 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/atla-trace-summary.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=e9e30bd974ffc954415f1a9e0a5931d3 2500w" />
</Frame>


# OpenTelemetry
Source: https://docs.agno.com/integrations/observability/introduction

Agno supports observability through OpenTelemetry, integrating seamlessly with popular tracing and monitoring platforms.

Observability helps us understand, debug, and improve AI agents. Agno supports observability through [OpenTelemetry](https://opentelemetry.io/), integrating seamlessly with popular tracing and monitoring platforms.

## Key Benefits

* **Trace**: Visualize and analyze agent execution flows.
* **Monitor**: Track performance, errors, and usage.
* **Debug**: Quickly identify and resolve issues.

## OpenTelemetry Support

Agno offers first-class support for OpenTelemetry, the industry standard for distributed tracing and observability.

* **Auto-Instrumentation**: Automatically instrument your agents and tools.
* **Flexible Export**: Send traces to any OpenTelemetry-compatible backend.
* **Custom Tracing**: Extend or customize tracing as needed.

<Note>
  OpenTelemetry-compatible backends including Arize Phoenix, Langfuse, Langsmith, Langtrace, Maxim and Weave are supported by Agno out of the box.
</Note>

## Developer Resources

* [Cookbooks](https://github.com/agno-agi/agno/tree/main/cookbook/observability)


# LangDB
Source: https://docs.agno.com/integrations/observability/langdb

Integrate Agno with LangDB to trace agent execution, tool calls, and gain comprehensive observability into your agent's performance.

## Integrating Agno with LangDB

[LangDB](https://langdb.ai/) provides an AI Gateway platform for comprehensive observability and tracing of AI agents and LLM interactions. By integrating Agno with LangDB, you can gain full visibility into your agent's operations, including agent runs, tool calls, team interactions, and performance metrics.

For detailed integration instructions, see the [LangDB Agno documentation](https://docs.langdb.ai/getting-started/working-with-agent-frameworks/working-with-agno).

<Frame caption="LangDB Finance Team Trace">
  <img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=12aaf8fd6e3e9ce0dcca4e7bd0da9c43" style={{ borderRadius: '10px', width: '100%', maxWidth: '800px' }} alt="langdb-agno finance team observability" data-og-width="1623" width="1623" data-og-height="900" height="900" data-path="images/langdb-finance-trace.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=44bb9cf4c423a327b5459917cd3562cb 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a2589678cacdac15c3b5c8dc21903189 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=b3aeeed6a9e129f4465d41d2e9e75929 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=d803a20ad4a20d1871212d0c23156624 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=3f5eb5fa7780f3c740331550747b190b 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-trace.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a397f1a8bb1d2e1ef366866ec6484a04 2500w" />
</Frame>

## Prerequisites

1. **Install Dependencies**

   Ensure you have the necessary packages installed:

   ```bash
   pip install agno 'pylangdb[agno]'
   ```

2. **Setup LangDB Account**

   * Sign up for an account at [LangDB](https://app.langdb.ai/signup)
   * Create a new project in the LangDB dashboard
   * Obtain your API key and Project ID from the project settings

3. **Set Environment Variables**

   Configure your environment with the LangDB credentials:

   ```bash
   export LANGDB_API_KEY="<your_langdb_api_key>"
   export LANGDB_PROJECT_ID="<your_langdb_project_id>"
   ```

## Sending Traces to LangDB

### Example: Basic Agent Setup

This example demonstrates how to instrument your Agno agent with LangDB tracing.

```python
from pylangdb.agno import init

# Initialize LangDB tracing - must be called before creating agents
init()

from agno.agent import Agent
from agno.models.langdb import LangDB
from agno.tools.duckduckgo import DuckDuckGoTools

# Create agent with LangDB model (uses environment variables automatically)
agent = Agent(
    name="Web Research Agent",
    model=LangDB(id="openai/gpt-4.1"),
    tools=[DuckDuckGoTools()],
    instructions="Answer questions using web search and provide comprehensive information"
)

# Use the agent
response = agent.run("What are the latest developments in AI agents?")
print(response)
```

### Example: Multi-Agent Team Coordination

For more complex workflows, you can use Agno's `Team` class with LangDB tracing:

```python
from pylangdb.agno import init
init()

from agno.agent import Agent
from agno.team import Team
from agno.models.langdb import LangDB
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

# Research Agent
web_agent = Agent(
    name="Market Research Agent",
    model=LangDB(id="openai/gpt-4.1"),
    tools=[DuckDuckGoTools()],
    instructions="Research current market conditions and news"
)

# Financial Analysis Agent
finance_agent = Agent(
    name="Financial Analyst",
    model=LangDB(id="xai/grok-4"),
    tools=[YFinanceTools(stock_price=True, company_info=True)],
    instructions="Perform quantitative financial analysis"
)

# Coordinated Team
reasoning_team = Team(
    name="Finance Reasoning Team",
    model=LangDB(id="xai/grok-4"),
    members=[web_agent, finance_agent],
    instructions=[
        "Collaborate to provide comprehensive financial insights",
        "Consider both fundamental analysis and market sentiment"
    ]
)

# Execute team workflow
reasoning_team.print_response("Analyze Apple (AAPL) investment potential")
```

## Sample Trace

View a complete example trace in the LangDB dashboard: [Finance Reasoning Team Trace](https://app.langdb.ai/sharing/threads/73c91c58-eab7-4c6b-afe1-5ab6324f1ada)

<Frame caption="LangDB Finance Team Thread">
  <img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=177481792ff1b6fcdc03d464b62f7711" style={{ borderRadius: '10px', width: '100%', maxWidth: '800px' }} alt="langdb-agno finance team observability" data-og-width="1241" width="1241" data-og-height="916" height="916" data-path="images/langdb-finance-thread.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=13536f1cb8949e0e540505a137e8c978 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2783572ef55c1d8645c2f9dc34c31809 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=d08349da04673fd7f1f358f0201cfd55 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=b13d7216f599fef647e6f1f705198368 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0124f22d2915636b0086f19f628515f3 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/langdb-finance-thread.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0470d1883900d3fc2e0e4d2515417291 2500w" />
</Frame>

## Advanced Features

### LangDB Capabilities

* **Virtual Models**: Save, share, and reuse model configurations‚Äîcombining prompts, parameters, tools, and routing logic into a single named unit for consistent behavior across apps
* **MCP Support**: Enhanced tool capabilities through Model Context Protocol servers
* **Multi-Provider**: Support for OpenAI, Anthropic, Google, xAI, and other providers

## Notes

* **Initialization Order**: Always call `init()` before creating any Agno agents or teams
* **Environment Variables**: With `LANGDB_API_KEY` and `LANGDB_PROJECT_ID` set, you can create models with just `LangDB(id="model_name")`

## Resources

* [LangDB Documentation](https://docs.langdb.ai/)
* [Building a Reasoning Finance Team Guide](https://docs.langdb.ai/guides/building-agents/building-a-reasoning-finance-team-with-agno)
* [LangDB GitHub Samples](https://github.com/langdb/langdb-samples/tree/main/examples/agno)
* [LangDB Dashboard](https://app.langdb.ai/)

By following these steps, you can effectively integrate Agno with LangDB, enabling comprehensive observability and monitoring of your AI agents.


# Langfuse
Source: https://docs.agno.com/integrations/observability/langfuse

Integrate Agno with Langfuse to send traces and gain insights into your agent's performance.

## Integrating Agno with Langfuse

Langfuse provides a robust platform for tracing and monitoring AI model calls. By integrating Agno with Langfuse, you can utilize OpenInference and OpenLIT to send traces and gain insights into your agent's performance.

## Prerequisites

1. **Install Dependencies**

   Ensure you have the necessary packages installed:

   ```bash
   pip install agno openai langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
   ```

2. **Setup Langfuse Account**

   * Either self-host or sign up for an account at [Langfuse](https://us.cloud.langfuse.com).
   * Obtain your public and secret API keys from the Langfuse dashboard.

3. **Set Environment Variables**

   Configure your environment with the Langfuse API keys:

   ```bash
   export LANGFUSE_PUBLIC_KEY=<your-public-key>
   export LANGFUSE_SECRET_KEY=<your-secret-key>
   ```

## Sending Traces to Langfuse

* ### Example: Using Langfuse with OpenInference

This example demonstrates how to instrument your Agno agent with OpenInference and send traces to Langfuse.

```python
import base64
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

# Set environment variables for Langfuse
LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://us.cloud.langfuse.com/api/public/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

# Configure the tracer provider
tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What is the current price of Tesla?")
```

* ### Example: Using Langfuse with OpenLIT

This example demonstrates how to use Langfuse via OpenLIT to trace model calls.

```python
import base64
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from opentelemetry import trace

# Set environment variables for Langfuse
LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://us.cloud.langfuse.com/api/public/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

# Configure the tracer provider
trace_provider = TracerProvider()
trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace.set_tracer_provider(trace_provider)

# Initialize OpenLIT instrumentation
import openlit
openlit.init(tracer=trace.get_tracer(__name__), disable_batch=True)

# Create and configure the agent
agent = Agent(
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
    debug_mode=True,
)

# Use the agent
agent.print_response("What is currently trending on Twitter?")
```

## Notes

* **Environment Variables**: Ensure your environment variables are correctly set for the API keys and OTLP endpoint.
* **Data Regions**: Adjust the `OTEL_EXPORTER_OTLP_ENDPOINT` for your data region or local deployment as needed. Available regions include:
  * `https://us.cloud.langfuse.com/api/public/otel` for the US region
  * `https://eu.cloud.langfuse.com/api/public/otel` for the EU region
  * `http://localhost:3000/api/public/otel` for local deployment

By following these steps, you can effectively integrate Agno with Langfuse, enabling comprehensive observability and monitoring of your AI agents.


# LangSmith
Source: https://docs.agno.com/integrations/observability/langsmith

Integrate Agno with LangSmith to send traces and gain insights into your agent's performance.

## Integrating Agno with LangSmith

LangSmith offers a comprehensive platform for tracing and monitoring AI model calls. By integrating Agno with LangSmith, you can utilize OpenInference to send traces and gain insights into your agent's performance.

## Prerequisites

1. **Create a LangSmith Account**

   * Sign up for an account at [LangSmith](https://smith.langchain.com).
   * Obtain your API key from the LangSmith dashboard.

2. **Set Environment Variables**

   Configure your environment with the LangSmith API key and other necessary settings:

   ```bash
   export LANGSMITH_API_KEY=<your-key>
   export LANGSMITH_TRACING=true
   export LANGSMITH_ENDPOINT=https://eu.api.smith.langchain.com  # or https://api.smith.langchain.com for US
   export LANGSMITH_PROJECT=<your-project-name>
   ```

3. **Install Dependencies**

   Ensure you have the necessary packages installed:

   ```bash
   pip install openai openinference-instrumentation-agno opentelemetry-sdk opentelemetry-exporter-otlp
   ```

## Sending Traces to LangSmith

This example demonstrates how to instrument your Agno agent with OpenInference and send traces to LangSmith.

```python
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

# Set the endpoint and headers for LangSmith
endpoint = "https://eu.api.smith.langchain.com/otel/v1/traces"
headers = {
    "x-api-key": os.getenv("LANGSMITH_API_KEY"),
    "Langsmith-Project": os.getenv("LANGSMITH_PROJECT"),
}

# Configure the tracer provider
tracer_provider = TracerProvider()
tracer_provider.add_span_processor(
    SimpleSpanProcessor(OTLPSpanExporter(endpoint=endpoint, headers=headers))
)
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Start instrumenting agno
AgnoInstrumentor().instrument()

# Create and configure the agent
agent = Agent(
    name="Stock Market Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
    debug_mode=True,
)

# Use the agent
agent.print_response("What is news on the stock market?")
```

## Notes

* **Environment Variables**: Ensure your environment variables are correctly set for the API key, endpoint, and project name.
* **Data Regions**: Choose the appropriate `LANGSMITH_ENDPOINT` based on your data region.

By following these steps, you can effectively integrate Agno with LangSmith, enabling comprehensive observability and monitoring of your AI agents.


# Langtrace
Source: https://docs.agno.com/integrations/observability/langtrace

Integrate Agno with Langtrace to send traces and gain insights into your agent's performance.

## Integrating Agno with Langtrace

Langtrace provides a powerful platform for tracing and monitoring AI model calls. By integrating Agno with Langtrace, you can gain insights into your agent's performance and behavior.

## Prerequisites

1. **Install Dependencies**

   Ensure you have the necessary package installed:

   ```bash
   pip install langtrace-python-sdk
   ```

2. **Create a Langtrace Account**

   * Sign up for an account at [Langtrace](https://app.langtrace.ai/).
   * Obtain your API key from the Langtrace dashboard.

3. **Set Environment Variables**

   Configure your environment with the Langtrace API key:

   ```bash
   export LANGTRACE_API_KEY=<your-key>
   ```

## Sending Traces to Langtrace

This example demonstrates how to instrument your Agno agent with Langtrace.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from langtrace_python_sdk import langtrace
from langtrace_python_sdk.utils.with_root_span import with_langtrace_root_span

# Initialize Langtrace
langtrace.init()

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-5-mini"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    debug_mode=True,
)

# Use the agent
agent.print_response("What is the current price of Tesla?")
```

## Notes

* **Environment Variables**: Ensure your environment variable is correctly set for the API key.
* **Initialization**: Call `langtrace.init()` to initialize Langtrace before using the agent.

By following these steps, you can effectively integrate Agno with Langtrace, enabling comprehensive observability and monitoring of your AI agents.


# Maxim
Source: https://docs.agno.com/integrations/observability/maxim

Connect Agno with Maxim to monitor, trace, and evaluate your agent's activity and performance.

## Integrating Agno with Maxim

Maxim AI provides comprehensive agent monitoring, evaluation, and observability for your Agno applications. With Maxim's one-line integration, you can easily trace and analyse agent interactions, performance metrics, and more.

## Prerequisites

1. **Install Dependencies**

   Ensure you have the necessary packages installed:

   ```bash
   pip install agno openai maxim-py
   ```

   Or install Maxim separately:

   ```bash
   pip install maxim-py
   ```

2. **Setup Maxim Account**

   * Sign up for an account at [Maxim](https://getmaxim.ai/).
   * Generate your API key from the Maxim dashboard.
   * Create a repository to store your traces.

3. **Set Environment Variables**

   Configure your environment with the Maxim API key:

   ```bash
   export MAXIM_API_KEY=<your-api-key>
   export MAXIM_LOG_REPO_ID=<your-repo-id>
   export OPENAI_API_KEY=<your-openai-api-key>
   ```

## Sending Traces to Maxim

### Example: Basic Maxim Integration

This example demonstrates how to instrument your Agno agent with Maxim and send traces for monitoring and evaluation.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

try:
    from maxim import Maxim
    from maxim.logger.agno import instrument_agno
except ImportError:
    raise ImportError(
        "`maxim` not installed. Please install using `pip install maxim-py`"
    )

# Instrument Agno with Maxim for automatic tracing and logging
instrument_agno(Maxim().logger())

# Create and configure the agent
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    show_tool_calls=True,
    markdown=True,
)

# Use the agent
response = agent.run("What is the current price of Tesla?")
print(response.content)
```

### Example: Multi-Agent System with Maxim

This example demonstrates how to set up a multi-agent system with comprehensive Maxim tracing using the Team class.

```python
"""
This example shows how to use Maxim to log agent calls and traces.

Steps to get started with Maxim:
1. Install Maxim: pip install maxim-py
2. Add instrument_agno(Maxim().logger()) to initialize tracing
3. Authentication:
 - Go to https://getmaxim.ai and create an account
 - Generate your API key from the settings
 - Export your API key as an environment variable:
    - export MAXIM_API_KEY=<your-api-key>
    - export MAXIM_LOG_REPO_ID=<your-repo-id>
4. All agent interactions will be automatically traced and logged to Maxim
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.team.team import Team
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

try:
    from maxim import Maxim
    from maxim.logger.agno import instrument_agno
except ImportError:
    raise ImportError(
        "`maxim` not installed. Please install using `pip install maxim-py`"
    )

# Instrument Agno with Maxim for automatic tracing and logging
instrument_agno(Maxim().logger())

# Web Search Agent: Fetches financial information from the web
web_search_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    markdown=True,
)

# Finance Agent: Gets financial data using YFinance tools
finance_agent = Agent(
    name="Finance Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[YFinanceTools()],
    instructions="Use tables to display data",
    markdown=True,
)

# Aggregate both agents into a multi-agent system
multi_ai_team = Team(
    members=[web_search_agent, finance_agent],
    model=OpenAIChat(id="gpt-4o"),
    instructions="You are a helpful financial assistant. Answer user questions about stocks, companies, and financial data.",
    markdown=True,
)

if __name__ == "__main__":
    print("Welcome to the Financial Conversational Agent! Type 'exit' to quit.")
    messages = []
    while True:
        print("********************************")
        user_input = input("You: ")
        if user_input.strip().lower() in ["exit", "quit"]:
            print("Goodbye!")
            break
        messages.append({"role": "user", "content": user_input})
        conversation = "\n".join(
            [
                ("User: " + m["content"])
                if m["role"] == "user"
                else ("Agent: " + m["content"])
                for m in messages
            ]
        )
        response = multi_ai_team.run(
            f"Conversation so far:\n{conversation}\n\nRespond to the latest user message."
        )
        agent_reply = getattr(response, "content", response)
        print("---------------------------------")
        print("Agent:", agent_reply)
        messages.append({"role": "agent", "content": str(agent_reply)})
```

<img src="https://mintcdn.com/agno-v2/7E-fsqZkCqV5M6b3/images/maxim.gif?s=2269ee92857eb7024d3a8fe6f836fa54" alt="agno.gif" data-og-width="1280" width="1280" data-og-height="720" height="720" data-path="images/maxim.gif" data-optimize="true" data-opv="2" />

## Features

### Observability & Tracing

Maxim provides comprehensive observability for your Agno agents:

* **Agent Tracing**: Track your agent's complete lifecycle, including tool calls, agent trajectories, and decision flows
* **Token Usage**: Monitor prompt and completion token consumption
* **Model Information**: Track which models are being used and their performance
* **Tool Calls**: Detailed logging of all tool executions and their results
* **Performance Metrics**: Latency, cost, and error rate tracking

### Evaluation & Analytics

* **Auto Evaluations**: Automatically evaluate captured logs based on filters and sampling
* **Human Evaluations**: Use human evaluation or rating to assess log quality
* **Node Level Evaluations**: Evaluate any component of your trace for detailed insights
* **Dashboards**: Visualize traces over time, usage metrics, latency & error rates

### Alerting

Set thresholds on error rates, cost, token usage, user feedback, and latency to get real-time alerts via Slack or PagerDuty.

## Notes

* **Environment Variables**: Ensure your environment variables are correctly set for the API key and repository ID.
* **Instrumentation Order**: Call `instrument_agno()` **before** creating or executing any agents to ensure proper tracing.
* **Debug Mode**: Enable debug mode to see detailed logging information:

  ```python
  instrument_agno(Maxim().logger(), {"debug" : True})
  ```
* **Maxim Docs**: For more information on Maxim's features and capabilities, refer to the [Maxim documentation](https://getmaxim.ai/docs).

By following these steps, you can effectively integrate Agno with Maxim, enabling comprehensive observability, evaluation, and monitoring of your AI agents.


# Weave
Source: https://docs.agno.com/integrations/observability/weave

Integrate Agno with Weave by WandB to send traces and gain insights into your agent's performance.

## Integrating Agno with Weave by WandB

[Weave by Weights & Biases (WandB)](https://weave-docs.wandb.ai/) provides a powerful platform for logging and visualizing model calls. By integrating Agno with Weave, you can track and analyze your agent's performance and behavior.

## Prerequisites

1. **Install Weave**

   Ensure you have the Weave package installed:

   ```bash
   pip install weave
   ```

2. **Authentication**
   Go to [WandB](https://wandb.ai) and copy your API key
   ```bash
   export WANDB_API_KEY=<your-api-key>
   ```

## Logging Model Calls with Weave

This example demonstrates how to use Weave to log model calls.

```python
import weave
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Initialize Weave with your project name
weave.init("agno")

# Create and configure the agent
agent = Agent(model=OpenAIChat(id="gpt-5-mini"), markdown=True, debug_mode=True)

# Define a function to run the agent, decorated with weave.op()
@weave.op()
def run(content: str):
    return agent.run(content)

# Use the function to log a model call
run("Share a 2 sentence horror story")
```

## Notes

* **Environment Variables**: Ensure your environment variable is correctly set for the WandB API key.
* **Initialization**: Call `weave.init("project-name")` to initialize Weave with your project name.
* **Decorators**: Use `@weave.op()` to decorate functions you want to log with Weave.

By following these steps, you can effectively integrate Agno with Weave, enabling comprehensive logging and visualization of your AI agents' model calls.


# Scenario Testing
Source: https://docs.agno.com/integrations/testing/scenario-testing



This example demonstrates how to use the [Scenario](https://github.com/langwatch/scenario) framework for agentic simulation-based testing. Scenario enables you to simulate conversations between agents, user simulators, and judges, making it easy to test and evaluate agent behaviors in a controlled environment.

> **Tip:** For a more advanced scenario testing example, check out the [customer support scenario](https://github.com/langwatch/create-agent-app/tree/main/agno_example) for a more complex agent, including tool calls and advanced scenario features.

## Basic Scenario Testing

```python cookbook/agent_concepts/other/scenario_testing.py
import pytest
import scenario
from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Configure Scenario defaults (model for user simulator and judge)
scenario.configure(default_model="openai/gpt-4.1-mini")

@pytest.mark.agent_test
@pytest.mark.asyncio
async def test_vegetarian_recipe_agent() -> None:
    # 1. Define an AgentAdapter to wrap your agent
    class VegetarianRecipeAgentAdapter(scenario.AgentAdapter):
        agent: Agent

        def __init__(self) -> None:
            self.agent = Agent(
                model=OpenAIChat(id="gpt-4.1-mini"),
                markdown=True,
                debug_mode=True,
                instructions="You are a vegetarian recipe agent.",
            )

        async def call(self, input: scenario.AgentInput) -> scenario.AgentReturnTypes:
            response = self.agent.run(
                message=input.last_new_user_message_str(), # Pass only the last user message
                session_id=input.thread_id, # Pass the thread id, this allows the agent to track history
            )
            return response.content

    # 2. Run the scenario simulation
    result = await scenario.run(
        name="dinner recipe request",
        description="User is looking for a vegetarian dinner idea.",
        agents=[
            VegetarianRecipeAgentAdapter(),
            scenario.UserSimulatorAgent(),
            scenario.JudgeAgent(
                criteria=[
                    "Agent should not ask more than two follow-up questions",
                    "Agent should generate a recipe",
                    "Recipe should include a list of ingredients",
                    "Recipe should include step-by-step cooking instructions",
                    "Recipe should be vegetarian and not include any sort of meat",
                ]
            ),
        ],
    )

    # 3. Assert and inspect the result
    assert result.success
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export LANGWATCH_API_KEY=xxx # Optional, required for Simulation monitoring
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno langwatch-scenario pytest pytest-asyncio
    # or
    uv add agno langwatch-scenario openai pytest
    ```
  </Step>

  <Step title="Run Agent">
    ```bash
    pytest cookbook/agent_concepts/other/scenario_testing.py
    ```
  </Step>
</Steps>


# What is Agno?
Source: https://docs.agno.com/introduction

**Agno is a high-performance runtime for multi-agent systems. Use it to build, run and manage secure multi-agent systems in your cloud.**

Agno gives you the fastest framework for building agents with session management, memory, knowledge, human in the loop and MCP support. You can put agents together as autonomous multi-agent teams, or build step-based agentic workflows for full control over complex multi-step processes.

But the real advantage of Agno is its [AgentOS](/agent-os/introduction) runtime:

1. You get a pre-built FastAPI app for running your agentic system, meaning you start building your product on day one. This is a remarkable advantage over other solutions or rolling your own.
2. You also get a control plane which connects directly to your AgentOS for testing, monitoring and managing your system. This gives you unmatched visibility and control over your system.
3. Your AgentOS runs in your cloud and you get complete data privacy because no data ever leaves your system. This is incredible for security conscious enterprises that can't send traces to external services.

For organizations building agents, Agno provides the complete solution. You get the fastest framework for building agents (speed of development and execution), a pre-built FastAPI app that lets you build your product on day one, and a control plane for managing your system.

We bring a novel architecture that no other framework provides, your AgentOS runs securely in your cloud, and the control plane connects directly to it from your browser. You don't need to send data to external services or pay retention costs, you get complete privacy and control.

## Getting started

If you're new to Agno, follow our [quickstart](/introduction/quickstart) to build your first Agent and run it using the AgentOS.

After that, checkout the [examples gallery](/examples/introduction) and build real-world applications with Agno.

<Tip>
  If you're looking for Agno 1.0 docs, please visit [docs-v1.agno.com](https://docs-v1.agno.com). We also have a [migration guide](/how-to/v2-migration) for those coming from Agno 1.0.
</Tip>


# Getting Help
Source: https://docs.agno.com/introduction/getting-help

Connect with builders, get support, and explore Agent Engineering.

## Need help?

Head over to our [community forum](https://agno.link/community) for help and insights from the team.

## Building with Agno?

Share what you're building on [X](https://agno.link/x), [LinkedIn](https://www.linkedin.com/company/agno-agi) or join our [Discord](https://agno.link/discord) to connect with other builders.

## Looking for dedicated support?

We've helped many companies turn ideas into AI products. [Book a call](https://cal.com/team/agno/intro) to get started.


# Quickstart
Source: https://docs.agno.com/introduction/quickstart

Build and run your first Agent using Agno.

**Agents are AI programs where a language model controls the flow of execution.**

In 10 lines of code, we can build an Agent that takes action based on user input and available tools. This agent will fetch the top stories from HackerNews and summarize them.

```python hackernews_agent.py lines
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    model=Claude(id="claude-sonnet-4-0"),
    tools=[HackerNewsTools()],
    markdown=True,
)
agent.print_response("Summarize the top 5 stories on hackernews", stream=True)
```

## Build your first Agent

Instead of a toy demo, let's build an Agent that your can extend and build upon. We'll connect our agent to Agno's documentation via an MCP server, and give it a database to store conversation history and state.

**This is a simple yet complete example that you can extend by connecting to any MCP server**.

```python agno_agent.py lines
from agno.agent import Agent
from agno.db.sqlite import SqliteDb
from agno.models.anthropic import Claude
from agno.os import AgentOS
from agno.tools.mcp import MCPTools

# Create the Agent
agno_agent = Agent(
    name="Agno Agent",
    model=Claude(id="claude-sonnet-4-0"),
    # Add a database to the Agent
    db=SqliteDb(db_file="agno.db"),
    # Add the Agno MCP server to the Agent
    tools=[MCPTools(transport="streamable-http", url="https://docs.agno.com/mcp")],
    # Add the previous session history to the context
    add_history_to_context=True,
    markdown=True,
)


# Create the AgentOS
agent_os = AgentOS(agents=[agno_agent])
# Get the FastAPI app for the AgentOS
app = agent_os.get_app()
```

<Check>
  There is an incredible amount of alpha in these 25 lines of code.

  You get a fully functional Agent with memory and state that can access any MCP server. It's served via a FastAPI app with pre-built endpoints that you can use to build your product.
</Check>

## Run your AgentOS

The AgentOS gives us a FastAPI application with ready-to-use API endpoints for serving, monitoring and managing our Agents. Let's run it.

<Steps>
  <Step title="Setup your virtual environment">
    <CodeGroup>
      ```bash Mac
      uv venv --python 3.12
      source .venv/bin/activate
      ```

      ```bash Windows
      uv venv --python 3.12
      .venv/Scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install dependencies">
    <CodeGroup>
      ```bash Mac
      uv pip install -U agno anthropic mcp 'fastapi[standard]' sqlalchemy
      ```

      ```bash Windows
      uv pip install -U agno anthropic mcp 'fastapi[standard]' sqlalchemy
      ```
    </CodeGroup>
  </Step>

  <Step title="Export your Anthropic API key">
    <CodeGroup>
      ```bash Mac
      export ANTHROPIC_API_KEY=sk-***
      ```

      ```bash Windows
      setx ANTHROPIC_API_KEY sk-***
      ```
    </CodeGroup>
  </Step>

  <Step title="Run your AgentOS">
    ```shell
    fastapi dev agno_agent.py
    ```

    This will start your AgentOS on `http://localhost:8000`
  </Step>
</Steps>

## Connect your AgentOS

Agno provides a web interface that connects to your AgentOS, use it to monitor, manage and test your agentic system. Open [os.agno.com](https://os.agno.com) and sign in to your account.

1. Click on **"Add new OS"** in the top navigation bar.
2. Select **"Local"** to connect to a local AgentOS running on your machine.
3. Enter the endpoint URL of your AgentOS. The default is `http://localhost:8000`.
4. Give your AgentOS a descriptive name like "Development OS" or "Local 8000".
5. Click **"Connect"**.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/aEfJPs-hg36UsUPO/videos/agent-os-connect-1.mp4?fit=max&auto=format&n=aEfJPs-hg36UsUPO&q=85&s=907888debf7f055f14e0f84405ba5749" type="video/mp4" data-path="videos/agent-os-connect-1.mp4" />
  </video>
</Frame>

Once connected, you'll see your new OS with a live status indicator.

## Chat with your Agent

Next, let's chat with our Agent, go to the `Chat` section in the sidebar and select your Agent.

* Ask ‚ÄúWhat is Agno?‚Äù and the Agent will answer using the Agno MCP server.
* Agents keep their own history, tools, and instructions; switching users won‚Äôt mix context.

<Frame>
  <video autoPlay muted loop playsInline style={{ borderRadius: "0.5rem", width: "100%", height: "auto" }}>
    <source src="https://mintcdn.com/agno-v2/aEfJPs-hg36UsUPO/videos/agno-agent-chat.mp4?fit=max&auto=format&n=aEfJPs-hg36UsUPO&q=85&s=b8ac56bfb2e9436799299fcafa746d4a" type="video/mp4" data-path="videos/agno-agent-chat.mp4" />
  </video>
</Frame>

<Tip>
  Click on Sessions to view your Agent's conversations. This data is stored in your Agent's database, so no need for external tracing services.
</Tip>

## Pre-built API endpoints

The FastAPI app generated by your AgentOS comes with pre-built SSE-compatible API endpoints that you can use to build your product. You can always add your own routes, middleware or any other FastAPI feature, but this is such a great starting point.

Checkout the API endpoints at `/docs` of your AgentOS url, e.g. [http://localhost:8000/docs](http://localhost:8000/docs).

## Next

After running your AgentOS, dive into [core concepts](/concepts/agents/introduction) and extend your Agents with more capabilities.

Happy building!


# AgentOS API Overview
Source: https://docs.agno.com/reference-api/overview

Complete API reference for interacting with AgentOS programmatically

Welcome to the comprehensive API reference for the Agno AgentOS API. This RESTful API enables you to programmatically interact with your AgentOS instance, manage agents, teams, and workflows, and integrate AgentOS capabilities into your applications.

## Authentication

AgentOS supports bearer-token authentication via a single Security Key.

* When `OS_SECURITY_KEY` environment variable is set on the server, all routes require:

```bash
Authorization: Bearer <OS_SECURITY_KEY>
```

* When `OS_SECURITY_KEY` is not set, authentication is disabled for that instance.

See the dedicated guide: [Secure your AgentOS with a Security Key](/agent-os/security).

## Core Resources

The AgentOS API is organized around several key resources:

<CardGroup cols={2}>
  <Card title="Agents" icon="robot" href="/reference-api/schema/agents/list-all-agents">
    Create, manage, and execute individual agent runs with tools and knowledge
  </Card>

  <Card title="Teams" icon="users" href="/reference-api/schema/teams/list-all-teams">
    Orchestrate multiple agents working together on complex tasks
  </Card>

  <Card title="Workflows" icon="diagram-project" href="/reference-api/schema/workflows/list-all-workflows">
    Define and execute multi-step automated processes
  </Card>

  <Card title="Sessions" icon="clock" href="/reference-api/schema/sessions/list-sessions">
    Track conversation history and maintain context across interactions
  </Card>

  <Card title="Memory" icon="brain" href="/reference-api/schema/memory/list-memories">
    Store and retrieve persistent memories for personalized interactions
  </Card>

  <Card title="Knowledge" icon="book" href="/reference-api/schema/knowledge/list-content">
    Upload, manage, and query knowledge bases for your agents
  </Card>

  <Card title="Evals" icon="chart-bar" href="/reference-api/schema/evals/list-evaluation-runs">
    Run evaluations and track performance metrics for your agents
  </Card>
</CardGroup>


# Cancel Agent Run
Source: https://docs.agno.com/reference-api/schema/agents/cancel-agent-run

post /agents/{agent_id}/runs/{run_id}/cancel
Cancel a currently executing agent run. This will attempt to stop the agent's execution gracefully.

**Note:** Cancellation may not be immediate for all operations.



# Continue Agent Run
Source: https://docs.agno.com/reference-api/schema/agents/continue-agent-run

post /agents/{agent_id}/runs/{run_id}/continue
Continue a paused or incomplete agent run with updated tool results.

**Use Cases:**
- Resume execution after tool approval/rejection
- Provide manual tool execution results

**Tools Parameter:**
JSON string containing array of tool execution objects with results.



# Create Agent Run
Source: https://docs.agno.com/reference-api/schema/agents/create-agent-run

post /agents/{agent_id}/runs
Execute an agent with a message and optional media files. Supports both streaming and non-streaming responses.

**Features:**
- Text message input with optional session management
- Multi-media support: images (PNG, JPEG, WebP), audio (WAV, MP3), video (MP4, WebM, etc.)
- Document processing: PDF, CSV, DOCX, TXT, JSON
- Real-time streaming responses with Server-Sent Events (SSE)
- User and session context preservation

**Streaming Response:**
When `stream=true`, returns SSE events with `event` and `data` fields.



# Get Agent Details
Source: https://docs.agno.com/reference-api/schema/agents/get-agent-details

get /agents/{agent_id}
Retrieve detailed configuration and capabilities of a specific agent.

**Returns comprehensive agent information including:**
- Model configuration and provider details
- Complete tool inventory and configurations
- Session management settings
- Knowledge base and memory configurations
- Reasoning capabilities and settings
- System prompts and response formatting options



# List All Agents
Source: https://docs.agno.com/reference-api/schema/agents/list-all-agents

get /agents
Retrieve a comprehensive list of all agents configured in this OS instance.

**Returns:**
- Agent metadata (ID, name, description)
- Model configuration and capabilities
- Available tools and their configurations
- Session, knowledge, memory, and reasoning settings
- Only meaningful (non-default) configurations are included



# Get OS Configuration
Source: https://docs.agno.com/reference-api/schema/core/get-os-configuration

get /config
Retrieve the complete configuration of the AgentOS instance, including:

- Available models and databases
- Registered agents, teams, and workflows
- Chat, session, memory, knowledge, and evaluation configurations
- Available interfaces and their routes



# Delete Evaluation Runs
Source: https://docs.agno.com/reference-api/schema/evals/delete-evaluation-runs

delete /eval-runs
Delete multiple evaluation runs by their IDs. This action cannot be undone.



# Execute Evaluation
Source: https://docs.agno.com/reference-api/schema/evals/execute-evaluation

post /eval-runs
Run evaluation tests on agents or teams. Supports accuracy, performance, and reliability evaluations. Requires either agent_id or team_id, but not both.



# Get Evaluation Run
Source: https://docs.agno.com/reference-api/schema/evals/get-evaluation-run

get /eval-runs/{eval_run_id}
Retrieve detailed results and metrics for a specific evaluation run.



# List Evaluation Runs
Source: https://docs.agno.com/reference-api/schema/evals/list-evaluation-runs

get /eval-runs
Retrieve paginated evaluation runs with filtering and sorting options. Filter by agent, team, workflow, model, or evaluation type.



# Update Evaluation Run
Source: https://docs.agno.com/reference-api/schema/evals/update-evaluation-run

patch /eval-runs/{eval_run_id}
Update the name or other properties of an existing evaluation run.



# Delete All Content
Source: https://docs.agno.com/reference-api/schema/knowledge/delete-all-content

delete /knowledge/content
Permanently remove all content from the knowledge base. This is a destructive operation that cannot be undone. Use with extreme caution.



# Delete Content by ID
Source: https://docs.agno.com/reference-api/schema/knowledge/delete-content-by-id

delete /knowledge/content/{content_id}
Permanently remove a specific content item from the knowledge base. This action cannot be undone.



# Get Content by ID
Source: https://docs.agno.com/reference-api/schema/knowledge/get-content-by-id

get /knowledge/content/{content_id}
Retrieve detailed information about a specific content item including processing status and metadata.



# Get Content Status
Source: https://docs.agno.com/reference-api/schema/knowledge/get-content-status

get /knowledge/content/{content_id}/status
Retrieve the current processing status of a content item. Useful for monitoring asynchronous content processing progress and identifying any processing errors.



# List Content
Source: https://docs.agno.com/reference-api/schema/knowledge/list-content

get /knowledge/content
Retrieve paginated list of all content in the knowledge base with filtering and sorting options. Filter by status, content type, or metadata properties.



# Update Content
Source: https://docs.agno.com/reference-api/schema/knowledge/update-content

patch /knowledge/content/{content_id}
Update content properties such as name, description, metadata, or processing configuration. Allows modification of existing content without re-uploading.



# Upload Content
Source: https://docs.agno.com/reference-api/schema/knowledge/upload-content

post /knowledge/content
Upload content to the knowledge base. Supports file uploads, text content, or URLs. Content is processed asynchronously in the background. Supports custom readers and chunking strategies.



# Create Memory
Source: https://docs.agno.com/reference-api/schema/memory/create-memory

post /memories
Create a new user memory with content and associated topics. Memories are used to store contextual information for users across conversations.



# Delete Memory
Source: https://docs.agno.com/reference-api/schema/memory/delete-memory

delete /memories/{memory_id}
Permanently delete a specific user memory. This action cannot be undone.



# Delete Multiple Memories
Source: https://docs.agno.com/reference-api/schema/memory/delete-multiple-memories

delete /memories
Delete multiple user memories by their IDs in a single operation. This action cannot be undone and all specified memories will be permanently removed.



# Get Memory by ID
Source: https://docs.agno.com/reference-api/schema/memory/get-memory-by-id

get /memories/{memory_id}
Retrieve detailed information about a specific user memory by its ID.



# Get Memory Topics
Source: https://docs.agno.com/reference-api/schema/memory/get-memory-topics

get /memory_topics
Retrieve all unique topics associated with memories in the system. Useful for filtering and categorizing memories by topic.



# Get User Memory Statistics
Source: https://docs.agno.com/reference-api/schema/memory/get-user-memory-statistics

get /user_memory_stats
Retrieve paginated statistics about memory usage by user. Provides insights into user engagement and memory distribution across users.



# List Memories
Source: https://docs.agno.com/reference-api/schema/memory/list-memories

get /memories
Retrieve paginated list of user memories with filtering and search capabilities. Filter by user, agent, team, topics, or search within memory content.



# Update Memory
Source: https://docs.agno.com/reference-api/schema/memory/update-memory

patch /memories/{memory_id}
Update an existing user memory's content and topics. Replaces the entire memory content and topic list with the provided values.



# Get AgentOS Metrics
Source: https://docs.agno.com/reference-api/schema/metrics/get-agentos-metrics

get /metrics
Retrieve AgentOS metrics and analytics data for a specified date range. If no date range is specified, returns all available metrics.



# Refresh Metrics
Source: https://docs.agno.com/reference-api/schema/metrics/refresh-metrics

post /metrics/refresh
Manually trigger recalculation of system metrics from raw data. This operation analyzes system activity logs and regenerates aggregated metrics. Useful for ensuring metrics are up-to-date or after system maintenance.



# Delete Multiple Sessions
Source: https://docs.agno.com/reference-api/schema/sessions/delete-multiple-sessions

delete /sessions
Delete multiple sessions by their IDs in a single operation. This action cannot be undone and will permanently remove all specified sessions and their runs.



# Delete Session
Source: https://docs.agno.com/reference-api/schema/sessions/delete-session

delete /sessions/{session_id}
Permanently delete a specific session and all its associated runs. This action cannot be undone and will remove all conversation history.



# Get Session by ID
Source: https://docs.agno.com/reference-api/schema/sessions/get-session-by-id

get /sessions/{session_id}
Retrieve detailed information about a specific session including metadata, configuration, and run history. Response schema varies based on session type (agent, team, or workflow).



# Get Session Runs
Source: https://docs.agno.com/reference-api/schema/sessions/get-session-runs

get /sessions/{session_id}/runs
Retrieve all runs (executions) for a specific session. Runs represent individual interactions or executions within a session. Response schema varies based on session type.



# List Sessions
Source: https://docs.agno.com/reference-api/schema/sessions/list-sessions

get /sessions
Retrieve paginated list of sessions with filtering and sorting options. Supports filtering by session type (agent, team, workflow), component, user, and name. Sessions represent conversation histories and execution contexts.



# Rename Session
Source: https://docs.agno.com/reference-api/schema/sessions/rename-session

post /sessions/{session_id}/rename
Update the name of an existing session. Useful for organizing and categorizing sessions with meaningful names for better identification and management.



# Cancel Team Run
Source: https://docs.agno.com/reference-api/schema/teams/cancel-team-run

post /teams/{team_id}/runs/{run_id}/cancel
Cancel a currently executing team run. This will attempt to stop the team's execution gracefully.

**Note:** Cancellation may not be immediate for all operations.



# Create Team Run
Source: https://docs.agno.com/reference-api/schema/teams/create-team-run

post /teams/{team_id}/runs
Execute a team collaboration with multiple agents working together on a task.

**Features:**
- Text message input with optional session management
- Multi-media support: images (PNG, JPEG, WebP), audio (WAV, MP3), video (MP4, WebM, etc.)
- Document processing: PDF, CSV, DOCX, TXT, JSON
- Real-time streaming responses with Server-Sent Events (SSE)
- User and session context preservation

**Streaming Response:**
When `stream=true`, returns SSE events with `event` and `data` fields.



# Get Team Details
Source: https://docs.agno.com/reference-api/schema/teams/get-team-details

get /teams/{team_id}
Retrieve detailed configuration and member information for a specific team.



# List All Teams
Source: https://docs.agno.com/reference-api/schema/teams/list-all-teams

get /teams
Retrieve a comprehensive list of all teams configured in this OS instance.

**Returns team information including:**
- Team metadata (ID, name, description, execution mode)
- Model configuration for team coordination
- Team member roster with roles and capabilities
- Knowledge sharing and memory configurations



# Cancel Workflow Run
Source: https://docs.agno.com/reference-api/schema/workflows/cancel-workflow-run

post /workflows/{workflow_id}/runs/{run_id}/cancel
Cancel a currently executing workflow run, stopping all active steps and cleanup.
**Note:** Complex workflows with multiple parallel steps may take time to fully cancel.



# Execute Workflow
Source: https://docs.agno.com/reference-api/schema/workflows/execute-workflow

post /workflows/{workflow_id}/runs
Execute a workflow with the provided input data. Workflows can run in streaming or batch mode.

**Execution Modes:**
- **Streaming (`stream=true`)**: Real-time step-by-step execution updates via SSE
- **Non-Streaming (`stream=false`)**: Complete workflow execution with final result

**Workflow Execution Process:**
1. Input validation against workflow schema
2. Sequential or parallel step execution based on workflow design
3. Data flow between steps with transformation
4. Error handling and automatic retries where configured
5. Final result compilation and response

**Session Management:**
Workflows support session continuity for stateful execution across multiple runs.



# Get Workflow Details
Source: https://docs.agno.com/reference-api/schema/workflows/get-workflow-details

get /workflows/{workflow_id}
Retrieve detailed configuration and step information for a specific workflow.



# List All Workflows
Source: https://docs.agno.com/reference-api/schema/workflows/list-all-workflows

get /workflows
Retrieve a comprehensive list of all workflows configured in this OS instance.

**Return Information:**
- Workflow metadata (ID, name, description)
- Input schema requirements
- Step sequence and execution flow
- Associated agents and teams



# AgentOS
Source: https://docs.agno.com/reference/agent-os/agent-os



## Parameters

| Parameter        | Type                                  | Default            | Description                                                                                                                                                                                                       |
| ---------------- | ------------------------------------- | ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `os_id`          | `Optional[str]`                       | Autogenerated UUID | AgentOS ID                                                                                                                                                                                                        |
| `name`           | `Optional[str]`                       | `None`             | AgentOS name                                                                                                                                                                                                      |
| `description`    | `Optional[str]`                       | `None`             | AgentOS description                                                                                                                                                                                               |
| `version`        | `Optional[str]`                       | `None`             | AgentOS version                                                                                                                                                                                                   |
| `agents`         | `Optional[List[Agent]]`               | `None`             | List of agents available in the AgentOS                                                                                                                                                                           |
| `teams`          | `Optional[List[Team]]`                | `None`             | List of teams available in the AgentOS                                                                                                                                                                            |
| `workflows`      | `Optional[List[Workflow]]`            | `None`             | List of workflows available in the AgentOS                                                                                                                                                                        |
| `interfaces`     | `Optional[List[BaseInterface]]`       | `None`             | List of interfaces available in the AgentOS                                                                                                                                                                       |
| `config`         | `Optional[Union[str, AgentOSConfig]]` | `None`             | User-provided configuration for the AgentOS. Either a path to a YAML file or an `AgentOSConfig` instance.                                                                                                         |
| `settings`       | `Optional[AgnoAPISettings]`           | `None`             | Settings for the AgentOS API                                                                                                                                                                                      |
| `fastapi_app`    | `Optional[FastAPI]`                   | `None`             | Custom FastAPI APP to use for the AgentOS                                                                                                                                                                         |
| `lifespan`       | `Optional[Any]`                       | `None`             | Lifespan context manager for the FastAPI app                                                                                                                                                                      |
| `enable_mcp`     | `bool`                                | `False`            | Whether to enable MCP (Model Context Protocol)                                                                                                                                                                    |
| `replace_routes` | `bool`                                | `True`             | If False and using a custom fastapi\_app, skip AgentOS routes that conflict with existing routes, preferring the user's custom routes. If True (default), AgentOS routes will override conflicting custom routes. |
| `telemetry`      | `bool`                                | `True`             | Log minimal telemetry for analytics                                                                                                                                                                               |

## Functions

### `get_app`

Get the FastAPI APP configured for the AgentOS.

### `get_routes`

Get the routes configured for the AgentOS.

### `serve`

Run the app, effectively starting the AgentOS.

**Parameters:**

* `app` (Union\[str, FastAPI]): FastAPI APP instance
* `host` (str): Host to bind. Defaults to `localhost`
* `port` (int): Port to bind. Defaults to `7777`
* `workers` (Optional\[int]): Number of workers to use. Defaults to `None`
* `reload` (bool): Enable auto-reload for development. Defaults to `False`


# AgentOSConfig
Source: https://docs.agno.com/reference/agent-os/configuration



<Snippet file="agent-os-configuration-reference.mdx" />

## Using a YAML Configuration File

You can also provide your AgentOS configuration via a YAML file.

You can define all the previously mentioned configuration options in the file:

```yaml
# List of models available in the AgentOS
available_models:
  - <MODEL_STRING>
  ...

# Configuration for the Chat page
chat:
  quick_prompts:
    <AGENT_ID>:
      - <PROMPT_1>
      - <PROMPT_2>
      - <PROMPT_3>
      ...
    ...


# Configuration for the Evals page
evals:
  available_models:
    - <MODEL_STRING>
    ...
  display_name: <DISPLAY_NAME>
  dbs:
    - <DB_ID>
      domain_config:
        available_models:
          - <MODEL_STRING>
          ...
        display_name: <DISPLAY_NAME>
    ...


# Configuration for the Knowledge page
knowledge:
  display_name: <DISPLAY_NAME>
  dbs:
    - <DB_ID>
      domain_config:
        display_name: <DISPLAY_NAME>
    ...

# Configuration for the Memory page
memory:
  display_name: <DISPLAY_NAME>
  dbs:
    - <DB_ID>
      domain_config:
        display_name: <DISPLAY_NAME>
    ...

# Configuration for the Session page
session:
  display_name: <DISPLAY_NAME>
  dbs:
    - <DB_ID>
      domain_config:
        display_name: <DISPLAY_NAME>
    ...

# Configuration for the Metrics page
metrics:
  display_name: <DISPLAY_NAME>
  dbs:
    - <DB_ID>
      domain_config:
        display_name: <DISPLAY_NAME>
    ...
```


# Agent
Source: https://docs.agno.com/reference/agents/agent



## Parameters

| Parameter                          | Type                                                        | Default    | Description                                                                                                                                                                                                                      |
| ---------------------------------- | ----------------------------------------------------------- | ---------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `model`                            | `Optional[Model]`                                           | `None`     | Model to use for this Agent                                                                                                                                                                                                      |
| `name`                             | `Optional[str]`                                             | `None`     | Agent name                                                                                                                                                                                                                       |
| `id`                               | `Optional[str]`                                             | `None`     | Agent ID (autogenerated UUID if not set)                                                                                                                                                                                         |
| `user_id`                          | `Optional[str]`                                             | `None`     | Default user\_id to use for this agent                                                                                                                                                                                           |
| `session_id`                       | `Optional[str]`                                             | `None`     | Default session\_id to use for this agent (autogenerated if not set)                                                                                                                                                             |
| `session_state`                    | `Optional[Dict[str, Any]]`                                  | `None`     | Default session state (stored in the database to persist across runs)                                                                                                                                                            |
| `add_session_state_to_context`     | `bool`                                                      | `False`    | Set to True to add the session\_state to the context                                                                                                                                                                             |
| `enable_agentic_state`             | `bool`                                                      | `False`    | Set to True to give the agent tools to update the session\_state dynamically                                                                                                                                                     |
| `cache_session`                    | `bool`                                                      | `False`    | If True, cache the current Agent session in memory for faster access                                                                                                                                                             |
| `search_session_history`           | `Optional[bool]`                                            | `False`    | Set this to `True` to allow searching through previous sessions.                                                                                                                                                                 |
| `num_history_sessions`             | `Optional[int]`                                             | `None`     | Specify the number of past sessions to include in the search. It's advisable to keep this number to 2 or 3 for now, as a larger number might fill up the context length of the model, potentially leading to performance issues. |
| `dependencies`                     | `Optional[Dict[str, Any]]`                                  | `None`     | Dependencies available for tools and prompt functions                                                                                                                                                                            |
| `add_dependencies_to_context`      | `bool`                                                      | `False`    | If True, add the dependencies to the user prompt                                                                                                                                                                                 |
| `db`                               | `Optional[BaseDb]`                                          | `None`     | Database to use for this agent                                                                                                                                                                                                   |
| `memory_manager`                   | `Optional[MemoryManager]`                                   | `None`     | Memory manager to use for this agent                                                                                                                                                                                             |
| `enable_agentic_memory`            | `bool`                                                      | `False`    | Enable the agent to manage memories of the user                                                                                                                                                                                  |
| `enable_user_memories`             | `bool`                                                      | `False`    | If True, the agent creates/updates user memories at the end of runs                                                                                                                                                              |
| `add_memories_to_context`          | `Optional[bool]`                                            | `None`     | If True, the agent adds a reference to the user memories in the response                                                                                                                                                         |
| `enable_session_summaries`         | `bool`                                                      | `False`    | If True, the agent creates/updates session summaries at the end of runs                                                                                                                                                          |
| `add_session_summary_to_context`   | `Optional[bool]`                                            | `None`     | If True, the agent adds session summaries to the context                                                                                                                                                                         |
| `session_summary_manager`          | `Optional[SessionSummaryManager]`                           | `None`     | Session summary manager                                                                                                                                                                                                          |
| `add_history_to_context`           | `bool`                                                      | `False`    | Add the chat history of the current session to the messages sent to the Model                                                                                                                                                    |
| `num_history_runs`                 | `int`                                                       | `3`        | Number of historical runs to include in the messages.                                                                                                                                                                            |
| `knowledge`                        | `Optional[Knowledge]`                                       | `None`     | Agent Knowledge                                                                                                                                                                                                                  |
| `knowledge_filters`                | `Optional[Dict[str, Any]]`                                  | `None`     | Knowledge filters to apply to the knowledge base                                                                                                                                                                                 |
| `enable_agentic_knowledge_filters` | `Optional[bool]`                                            | `None`     | Let the agent choose the knowledge filters                                                                                                                                                                                       |
| `add_knowledge_to_context`         | `bool`                                                      | `False`    | Enable RAG by adding references from Knowledge to the user prompt                                                                                                                                                                |
| `knowledge_retriever`              | `Optional[Callable[..., Optional[List[Union[Dict, str]]]]]` | `None`     | Function to get references to add to the user\_message                                                                                                                                                                           |
| `references_format`                | `Literal["json", "yaml"]`                                   | `"json"`   | Format of the references                                                                                                                                                                                                         |
| `metadata`                         | `Optional[Dict[str, Any]]`                                  | `None`     | Metadata stored with this agent                                                                                                                                                                                                  |
| `tools`                            | `Optional[List[Union[Toolkit, Callable, Function, Dict]]]`  | `None`     | A list of tools provided to the Model                                                                                                                                                                                            |
| `tool_call_limit`                  | `Optional[int]`                                             | `None`     | Maximum number of tool calls allowed for a single run                                                                                                                                                                            |
| `tool_choice`                      | `Optional[Union[str, Dict[str, Any]]]`                      | `None`     | Controls which (if any) tool is called by the model                                                                                                                                                                              |
| `tool_hooks`                       | `Optional[List[Callable]]`                                  | `None`     | Functions that will run between tool calls                                                                                                                                                                                       |
| `reasoning`                        | `bool`                                                      | `False`    | Enable reasoning by working through the problem step by step                                                                                                                                                                     |
| `reasoning_model`                  | `Optional[Model]`                                           | `None`     | Model to use for reasoning                                                                                                                                                                                                       |
| `reasoning_agent`                  | `Optional[Agent]`                                           | `None`     | Agent to use for reasoning                                                                                                                                                                                                       |
| `reasoning_min_steps`              | `int`                                                       | `1`        | Minimum number of reasoning steps                                                                                                                                                                                                |
| `reasoning_max_steps`              | `int`                                                       | `10`       | Maximum number of reasoning steps                                                                                                                                                                                                |
| `read_chat_history`                | `bool`                                                      | `False`    | Add a tool that allows the Model to read the chat history                                                                                                                                                                        |
| `search_knowledge`                 | `bool`                                                      | `True`     | Add a tool that allows the Model to search the knowledge base                                                                                                                                                                    |
| `update_knowledge`                 | `bool`                                                      | `False`    | Add a tool that allows the Model to update the knowledge base                                                                                                                                                                    |
| `read_tool_call_history`           | `bool`                                                      | `False`    | Add a tool that allows the Model to get the tool call history                                                                                                                                                                    |
| `send_media_to_model`              | `bool`                                                      | `True`     | If False, media (images, videos, audio, files) is only available to tools and not sent to the LLM                                                                                                                                |
| `store_media`                      | `bool`                                                      | `True`     | If True, store media in run output                                                                                                                                                                                               |
| `system_message`                   | `Optional[Union[str, Callable, Message]]`                   | `None`     | Provide the system message as a string or function                                                                                                                                                                               |
| `system_message_role`              | `str`                                                       | `"system"` | Role for the system message                                                                                                                                                                                                      |
| `build_context`                    | `bool`                                                      | `True`     | Set to False to skip context building                                                                                                                                                                                            |
| `description`                      | `Optional[str]`                                             | `None`     | A description of the Agent that is added to the start of the system message                                                                                                                                                      |
| `instructions`                     | `Optional[Union[str, List[str], Callable]]`                 | `None`     | List of instructions for the agent                                                                                                                                                                                               |
| `expected_output`                  | `Optional[str]`                                             | `None`     | Provide the expected output from the Agent                                                                                                                                                                                       |
| `additional_context`               | `Optional[str]`                                             | `None`     | Additional context added to the end of the system message                                                                                                                                                                        |
| `markdown`                         | `bool`                                                      | `False`    | If markdown=true, add instructions to format the output using markdown                                                                                                                                                           |
| `add_name_to_context`              | `bool`                                                      | `False`    | If True, add the agent name to the instructions                                                                                                                                                                                  |
| `add_datetime_to_context`          | `bool`                                                      | `False`    | If True, add the current datetime to the instructions to give the agent a sense of time                                                                                                                                          |
| `add_location_to_context`          | `bool`                                                      | `False`    | If True, add the current location to the instructions to give the agent a sense of place                                                                                                                                         |
| `timezone_identifier`              | `Optional[str]`                                             | `None`     | Allows for custom timezone for datetime instructions following the TZ Database format (e.g. "Etc/UTC")                                                                                                                           |
| `resolve_in_context`               | `bool`                                                      | `True`     | If True, resolve session\_state, dependencies, and metadata in the user and system messages                                                                                                                                      |
| `additional_input`                 | `Optional[List[Union[str, Dict, BaseModel, Message]]]`      | `None`     | A list of extra messages added after the system message and before the user message                                                                                                                                              |
| `user_message_role`                | `str`                                                       | `"user"`   | Role for the user message                                                                                                                                                                                                        |
| `build_user_context`               | `bool`                                                      | `True`     | Set to False to skip building the user context                                                                                                                                                                                   |
| `retries`                          | `int`                                                       | `0`        | Number of retries to attempt                                                                                                                                                                                                     |
| `delay_between_retries`            | `int`                                                       | `1`        | Delay between retries (in seconds)                                                                                                                                                                                               |
| `exponential_backoff`              | `bool`                                                      | `False`    | If True, the delay between retries is doubled each time                                                                                                                                                                          |
| `input_schema`                     | `Optional[Type[BaseModel]]`                                 | `None`     | Provide an input schema to validate the input                                                                                                                                                                                    |
| `output_schema`                    | `Optional[Type[BaseModel]]`                                 | `None`     | Provide a response model to get the response as a Pydantic model                                                                                                                                                                 |
| `parser_model`                     | `Optional[Model]`                                           | `None`     | Provide a secondary model to parse the response from the primary model                                                                                                                                                           |
| `parser_model_prompt`              | `Optional[str]`                                             | `None`     | Provide a prompt for the parser model                                                                                                                                                                                            |
| `output_model`                     | `Optional[Model]`                                           | `None`     | Provide an output model to structure the response from the main model                                                                                                                                                            |
| `output_model_prompt`              | `Optional[str]`                                             | `None`     | Provide a prompt for the output model                                                                                                                                                                                            |
| `parse_response`                   | `bool`                                                      | `True`     | If True, the response from the Model is converted into the output\_schema                                                                                                                                                        |
| `structured_outputs`               | `Optional[bool]`                                            | `None`     | Use model enforced structured\_outputs if supported (e.g. OpenAIChat)                                                                                                                                                            |
| `use_json_mode`                    | `bool`                                                      | `False`    | If `output_schema` is set, sets the response mode of the model, i.e. if the model should explicitly respond with a JSON object instead of a Pydantic model                                                                       |
| `save_response_to_file`            | `Optional[str]`                                             | `None`     | Save the response to a file                                                                                                                                                                                                      |
| `stream`                           | `Optional[bool]`                                            | `None`     | Stream the response from the Agent                                                                                                                                                                                               |
| `stream_intermediate_steps`        | `bool`                                                      | `False`    | Stream the intermediate steps from the Agent                                                                                                                                                                                     |
| `store_events`                     | `bool`                                                      | `False`    | Persist the events on the run response                                                                                                                                                                                           |
| `events_to_skip`                   | `Optional[List[RunEvent]]`                                  | `None`     | Specify which event types to skip when storing events on the RunOutput                                                                                                                                                           |
| `role`                             | `Optional[str]`                                             | `None`     | If this Agent is part of a team, this is the role of the agent in the team                                                                                                                                                       |
| `debug_mode`                       | `bool`                                                      | `False`    | Enable debug logs                                                                                                                                                                                                                |
| `debug_level`                      | `Literal[1, 2]`                                             | `1`        | Debug level for logging                                                                                                                                                                                                          |
| `telemetry`                        | `bool`                                                      | `True`     | Log minimal telemetry for analytics                                                                                                                                                                                              |

## Functions

### `run`

Run the agent.

**Parameters:**

* `input` (Union\[str, List, Dict, Message, BaseModel, List\[Message]]): The input to send to the agent
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `retries` (Optional\[int]): Number of retries to attempt
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

### `arun`

Run the agent asynchronously.

**Parameters:**

* `input` (Union\[str, List, Dict, Message, BaseModel, List\[Message]]): The input to send to the agent
* `stream` (Optional\[bool]): Whether to stream the response
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `retries` (Optional\[int]): Number of retries to attempt
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

**Returns:**

* `Union[RunOutput, AsyncIterator[RunOutputEvent]]`: Either a RunOutput or an iterator of RunOutputEvents, depending on the `stream` parameter

### `continue_run`

Continue a run.

**Parameters:**

* `run_response` (Optional\[RunOutput]): The run response to continue
* `run_id` (Optional\[str]): The run ID to continue
* `updated_tools` (Optional\[List\[ToolExecution]]): Updated tools to use, required if the run is resumed using `run_id`
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `retries` (Optional\[int]): Number of retries to attempt
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

**Returns:**

* `Union[RunOutput, Iterator[RunOutputEvent]]`: Either a RunOutput or an iterator of RunOutputEvents, depending on the `stream` parameter

### `acontinue_run`

Continue a run asynchronously.

**Parameters:**

* `run_response` (Optional\[RunOutput]): The run response to continue
* `run_id` (Optional\[str]): The run ID to continue
* `updated_tools` (Optional\[List\[ToolExecution]]): Updated tools to use, required if the run is resumed using `run_id`
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `retries` (Optional\[int]): Number of retries to attempt
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

**Returns:**

* `Union[RunOutput, AsyncIterator[Union[RunOutputEvent, RunOutput]]]`: Either a RunOutput or an iterator of RunOutputEvents, depending on the `stream` parameter

### `print_response`

Run the agent and print the response.

**Parameters:**

* `input` (Union\[List, Dict, str, Message, BaseModel, List\[Message]]): The input to send to the agent
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `user_id` (Optional\[str]): User ID to use
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `markdown` (Optional\[bool]): Whether to format output as markdown
* `show_message` (bool): Whether to show the input message
* `show_reasoning` (bool): Whether to show reasoning steps
* `show_full_reasoning` (bool): Whether to show full reasoning information
* `console` (Optional\[Any]): Console to use for output
* `tags_to_include_in_markdown` (Optional\[Set\[str]]): Tags to include in markdown content
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

### `aprint_response`

Run the agent and print the response asynchronously.

**Parameters:**

* `input` (Union\[List, Dict, str, Message, BaseModel, List\[Message]]): The input to send to the agent
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `user_id` (Optional\[str]): User ID to use
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `markdown` (Optional\[bool]): Whether to format output as markdown
* `show_message` (bool): Whether to show the message
* `show_reasoning` (bool): Whether to show reasoning
* `show_full_reasoning` (bool): Whether to show full reasoning
* `console` (Optional\[Any]): Console to use for output
* `tags_to_include_in_markdown` (Optional\[Set\[str]]): Tags to include in markdown content
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

### `cli_app`

Run an interactive command-line interface to interact with the agent.

**Parameters:**

* `input` (Optional\[str]): The input to send to the agent
* `session_id` (Optional\[str]): Session ID to use
* `user_id` (Optional\[str]): User ID to use
* `user` (str): Name for the user (default: "User")
* `emoji` (str): Emoji for the user (default: ":sunglasses:")
* `stream` (bool): Whether to stream the response (default: False)
* `markdown` (bool): Whether to format output as markdown (default: False)
* `exit_on` (Optional\[List\[str]]): List of commands to exit the CLI
* `**kwargs`: Additional keyword arguments

### `acli_app`

Run an interactive command-line interface to interact with the agent asynchronously.

**Parameters:**

* `input` (Optional\[str]): The input to send to the agent
* `session_id` (Optional\[str]): Session ID to use
* `user_id` (Optional\[str]): User ID to use
* `user` (str): Name for the user (default: "User")
* `emoji` (str): Emoji for the user (default: ":sunglasses:")
* `stream` (bool): Whether to stream the response (default: False)
* `markdown` (bool): Whether to format output as markdown (default: False)
* `exit_on` (Optional\[List\[str]]): List of commands to exit the CLI
* `**kwargs`: Additional keyword arguments

### cancel\_run

Cancel a run by run ID.

**Parameters:**

* `run_id` (str): The run ID to cancel

**Returns:**

* `bool`: True if the run was successfully cancelled

### get\_run\_output

Get the run output for the given run ID.

**Parameters:**

* `run_id` (str): The run ID
* `session_id` (str): Session ID to use

**Returns:**

* `Optional[RunOutput]`: The run output

### get\_last\_run\_output

Get the last run output for the session.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `Optional[RunOutput]`: The last run output

### get\_session

Get the session for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `Optional[AgentSession]`: The agent session

### get\_session\_summary

Get the session summary for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* Session summary for the given session

### get\_user\_memories

Get the user memories for the given user ID.

**Parameters:**

* `user_id` (str): User ID to use

**Returns:**

* `List[UserMemory]`: The user memories

### get\_session\_state

Get the session state for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `Dict[str, Any]`: The session state

### get\_session\_metrics

Get the session metrics for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `Optional[Metrics]`: The session metrics

### delete\_session

Delete a session.

**Parameters:**

* `session_id` (str): Session ID to delete

### save\_session

Save a session to the database.

**Parameters:**

* `session` (AgentSession): The session to save

### rename

Rename the agent and update the session.

**Parameters:**

* `name` (str): The new name for the agent
* `session_id` (str): Session ID to use

### get\_session\_name

Get the session name for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `str`: The session name

### set\_session\_name

Set the session name.

**Parameters:**

* `session_id` (str): Session ID to use
* `autogenerate` (bool): Whether to autogenerate the name
* `session_name` (Optional\[str]): The name to set

**Returns:**

* `AgentSession`: The updated session

### get\_messages\_for\_session

Get the messages for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `List[Message]`: The messages for the session

### get\_chat\_history

Get the chat history for the given session ID.

**Parameters:**

* `session_id` (str): Session ID to use

**Returns:**

* `List[Message]`: The chat history

### add\_tool

Add a tool to the agent.

**Parameters:**

* `tool` (Union\[Toolkit, Callable, Function, Dict]): The tool to add

### set\_tools

Replace the tools of the agent.

**Parameters:**

* `tools` (List\[Union\[Toolkit, Callable, Function, Dict]]): The tools to set


# RunOutput
Source: https://docs.agno.com/reference/agents/run-response



## RunOutput Attributes

| Attribute             | Type                                | Default             | Description                                                      |
| --------------------- | ----------------------------------- | ------------------- | ---------------------------------------------------------------- |
| `run_id`              | `Optional[str]`                     | `None`              | Run ID                                                           |
| `agent_id`            | `Optional[str]`                     | `None`              | Agent ID for the run                                             |
| `agent_name`          | `Optional[str]`                     | `None`              | Agent name for the run                                           |
| `session_id`          | `Optional[str]`                     | `None`              | Session ID for the run                                           |
| `parent_run_id`       | `Optional[str]`                     | `None`              | Parent run ID                                                    |
| `workflow_id`         | `Optional[str]`                     | `None`              | Workflow ID if this run is part of a workflow                    |
| `user_id`             | `Optional[str]`                     | `None`              | User ID associated with the run                                  |
| `content`             | `Optional[Any]`                     | `None`              | Content of the response                                          |
| `content_type`        | `str`                               | `"str"`             | Specifies the data type of the content                           |
| `reasoning_content`   | `Optional[str]`                     | `None`              | Any reasoning content the model produced                         |
| `reasoning_steps`     | `Optional[List[ReasoningStep]]`     | `None`              | List of reasoning steps                                          |
| `reasoning_messages`  | `Optional[List[Message]]`           | `None`              | List of reasoning messages                                       |
| `model`               | `Optional[str]`                     | `None`              | The model used in the run                                        |
| `model_provider`      | `Optional[str]`                     | `None`              | The model provider used in the run                               |
| `messages`            | `Optional[List[Message]]`           | `None`              | A list of messages included in the response                      |
| `metrics`             | `Optional[Metrics]`                 | `None`              | Usage metrics of the run                                         |
| `additional_input`    | `Optional[List[Message]]`           | `None`              | Additional input messages                                        |
| `tools`               | `Optional[List[ToolExecution]]`     | `None`              | List of tool executions                                          |
| `images`              | `Optional[List[Image]]`             | `None`              | List of images attached to the response                          |
| `videos`              | `Optional[List[Video]]`             | `None`              | List of videos attached to the response                          |
| `audio`               | `Optional[List[Audio]]`             | `None`              | List of audio snippets attached to the response                  |
| `response_audio`      | `Optional[Audio]`                   | `None`              | The model's raw response in audio                                |
| `input`               | `Optional[RunInput]`                | `None`              | Input media and messages from user                               |
| `citations`           | `Optional[Citations]`               | `None`              | Any citations used in the response                               |
| `model_provider_data` | `Optional[Any]`                     | `None`              | Model provider specific metadata                                 |
| `references`          | `Optional[List[MessageReferences]]` | `None`              | References used in the response                                  |
| `metadata`            | `Optional[Dict[str, Any]]`          | `None`              | Metadata associated with the run                                 |
| `created_at`          | `int`                               | Current timestamp   | Unix timestamp of the response creation                          |
| `events`              | `Optional[List[RunOutputEvent]]`    | `None`              | List of events that occurred during the run                      |
| `status`              | `RunStatus`                         | `RunStatus.running` | Status of the run (running, completed, paused, cancelled, error) |
| `workflow_step_id`    | `Optional[str]`                     | `None`              | Workflow step ID (foreign key relationship)                      |

## RunOutputEvent Types and Attributes

### Base RunOutputEvent Attributes

All events inherit from `BaseAgentRunEvent` which provides these common attributes:

| Attribute         | Type                            | Default           | Description                                      |
| ----------------- | ------------------------------- | ----------------- | ------------------------------------------------ |
| `created_at`      | `int`                           | Current timestamp | Unix timestamp of the event creation             |
| `event`           | `str`                           | Event type value  | The type of event                                |
| `agent_id`        | `str`                           | `""`              | ID of the agent generating the event             |
| `agent_name`      | `str`                           | `""`              | Name of the agent generating the event           |
| `run_id`          | `Optional[str]`                 | `None`            | ID of the current run                            |
| `session_id`      | `Optional[str]`                 | `None`            | ID of the current session                        |
| `workflow_id`     | `Optional[str]`                 | `None`            | ID of the workflow if part of workflow execution |
| `workflow_run_id` | `Optional[str]`                 | `None`            | ID of the workflow run                           |
| `step_id`         | `Optional[str]`                 | `None`            | ID of the workflow step                          |
| `step_name`       | `Optional[str]`                 | `None`            | Name of the workflow step                        |
| `step_index`      | `Optional[int]`                 | `None`            | Index of the workflow step                       |
| `tools`           | `Optional[List[ToolExecution]]` | `None`            | Tools associated with this event                 |
| `content`         | `Optional[Any]`                 | `None`            | For backwards compatibility                      |

### RunStartedEvent

| Attribute        | Type  | Default        | Description               |
| ---------------- | ----- | -------------- | ------------------------- |
| `event`          | `str` | `"RunStarted"` | Event type                |
| `model`          | `str` | `""`           | The model being used      |
| `model_provider` | `str` | `""`           | The provider of the model |

### RunContentEvent

| Attribute             | Type                                | Default        | Description                      |
| --------------------- | ----------------------------------- | -------------- | -------------------------------- |
| `event`               | `str`                               | `"RunContent"` | Event type                       |
| `content`             | `Optional[Any]`                     | `None`         | The content of the response      |
| `content_type`        | `str`                               | `"str"`        | Type of the content              |
| `reasoning_content`   | `Optional[str]`                     | `None`         | Reasoning content produced       |
| `citations`           | `Optional[Citations]`               | `None`         | Citations used in the response   |
| `model_provider_data` | `Optional[Any]`                     | `None`         | Model provider specific metadata |
| `response_audio`      | `Optional[Audio]`                   | `None`         | Model's audio response           |
| `image`               | `Optional[Image]`                   | `None`         | Image attached to the response   |
| `references`          | `Optional[List[MessageReferences]]` | `None`         | References used in the response  |
| `additional_input`    | `Optional[List[Message]]`           | `None`         | Additional input messages        |
| `reasoning_steps`     | `Optional[List[ReasoningStep]]`     | `None`         | Reasoning steps                  |
| `reasoning_messages`  | `Optional[List[Message]]`           | `None`         | Reasoning messages               |

### IntermediateRunContentEvent

| Attribute      | Type            | Default                    | Description                          |
| -------------- | --------------- | -------------------------- | ------------------------------------ |
| `event`        | `str`           | `"RunIntermediateContent"` | Event type                           |
| `content`      | `Optional[Any]` | `None`                     | Intermediate content of the response |
| `content_type` | `str`           | `"str"`                    | Type of the content                  |

### RunCompletedEvent

| Attribute             | Type                                | Default          | Description                             |
| --------------------- | ----------------------------------- | ---------------- | --------------------------------------- |
| `event`               | `str`                               | `"RunCompleted"` | Event type                              |
| `content`             | `Optional[Any]`                     | `None`           | Final content of the response           |
| `content_type`        | `str`                               | `"str"`          | Type of the content                     |
| `reasoning_content`   | `Optional[str]`                     | `None`           | Reasoning content produced              |
| `citations`           | `Optional[Citations]`               | `None`           | Citations used in the response          |
| `model_provider_data` | `Optional[Any]`                     | `None`           | Model provider specific metadata        |
| `images`              | `Optional[List[Image]]`             | `None`           | Images attached to the response         |
| `videos`              | `Optional[List[Video]]`             | `None`           | Videos attached to the response         |
| `audio`               | `Optional[List[Audio]]`             | `None`           | Audio snippets attached to the response |
| `response_audio`      | `Optional[Audio]`                   | `None`           | Model's audio response                  |
| `references`          | `Optional[List[MessageReferences]]` | `None`           | References used in the response         |
| `additional_input`    | `Optional[List[Message]]`           | `None`           | Additional input messages               |
| `reasoning_steps`     | `Optional[List[ReasoningStep]]`     | `None`           | Reasoning steps                         |
| `reasoning_messages`  | `Optional[List[Message]]`           | `None`           | Reasoning messages                      |
| `metadata`            | `Optional[Dict[str, Any]]`          | `None`           | Additional metadata                     |
| `metrics`             | `Optional[Metrics]`                 | `None`           | Usage metrics                           |

### RunPausedEvent

| Attribute | Type                            | Default       | Description                     |
| --------- | ------------------------------- | ------------- | ------------------------------- |
| `event`   | `str`                           | `"RunPaused"` | Event type                      |
| `tools`   | `Optional[List[ToolExecution]]` | `None`        | Tools that require confirmation |

### RunContinuedEvent

| Attribute | Type  | Default          | Description |
| --------- | ----- | ---------------- | ----------- |
| `event`   | `str` | `"RunContinued"` | Event type  |

### RunErrorEvent

| Attribute | Type            | Default      | Description   |
| --------- | --------------- | ------------ | ------------- |
| `event`   | `str`           | `"RunError"` | Event type    |
| `content` | `Optional[str]` | `None`       | Error message |

### RunCancelledEvent

| Attribute | Type            | Default          | Description             |
| --------- | --------------- | ---------------- | ----------------------- |
| `event`   | `str`           | `"RunCancelled"` | Event type              |
| `reason`  | `Optional[str]` | `None`           | Reason for cancellation |

### ReasoningStartedEvent

| Attribute | Type  | Default              | Description |
| --------- | ----- | -------------------- | ----------- |
| `event`   | `str` | `"ReasoningStarted"` | Event type  |

### ReasoningStepEvent

| Attribute           | Type            | Default           | Description                   |
| ------------------- | --------------- | ----------------- | ----------------------------- |
| `event`             | `str`           | `"ReasoningStep"` | Event type                    |
| `content`           | `Optional[Any]` | `None`            | Content of the reasoning step |
| `content_type`      | `str`           | `"str"`           | Type of the content           |
| `reasoning_content` | `str`           | `""`              | Detailed reasoning content    |

### ReasoningCompletedEvent

| Attribute      | Type            | Default                | Description                   |
| -------------- | --------------- | ---------------------- | ----------------------------- |
| `event`        | `str`           | `"ReasoningCompleted"` | Event type                    |
| `content`      | `Optional[Any]` | `None`                 | Content of the reasoning step |
| `content_type` | `str`           | `"str"`                | Type of the content           |

### ToolCallStartedEvent

| Attribute | Type                      | Default             | Description           |
| --------- | ------------------------- | ------------------- | --------------------- |
| `event`   | `str`                     | `"ToolCallStarted"` | Event type            |
| `tool`    | `Optional[ToolExecution]` | `None`              | The tool being called |

### ToolCallCompletedEvent

| Attribute | Type                      | Default               | Description                 |
| --------- | ------------------------- | --------------------- | --------------------------- |
| `event`   | `str`                     | `"ToolCallCompleted"` | Event type                  |
| `tool`    | `Optional[ToolExecution]` | `None`                | The tool that was called    |
| `content` | `Optional[Any]`           | `None`                | Result of the tool call     |
| `images`  | `Optional[List[Image]]`   | `None`                | Images produced by the tool |
| `videos`  | `Optional[List[Video]]`   | `None`                | Videos produced by the tool |
| `audio`   | `Optional[List[Audio]]`   | `None`                | Audio produced by the tool  |

### MemoryUpdateStartedEvent

| Attribute | Type  | Default                 | Description |
| --------- | ----- | ----------------------- | ----------- |
| `event`   | `str` | `"MemoryUpdateStarted"` | Event type  |

### MemoryUpdateCompletedEvent

| Attribute | Type  | Default                   | Description |
| --------- | ----- | ------------------------- | ----------- |
| `event`   | `str` | `"MemoryUpdateCompleted"` | Event type  |

### ParserModelResponseStartedEvent

| Attribute | Type  | Default                        | Description |
| --------- | ----- | ------------------------------ | ----------- |
| `event`   | `str` | `"ParserModelResponseStarted"` | Event type  |

### ParserModelResponseCompletedEvent

| Attribute | Type  | Default                          | Description |
| --------- | ----- | -------------------------------- | ----------- |
| `event`   | `str` | `"ParserModelResponseCompleted"` | Event type  |

### OutputModelResponseStartedEvent

| Attribute | Type  | Default                        | Description |
| --------- | ----- | ------------------------------ | ----------- |
| `event`   | `str` | `"OutputModelResponseStarted"` | Event type  |

### OutputModelResponseCompletedEvent

| Attribute | Type  | Default                          | Description |
| --------- | ----- | -------------------------------- | ----------- |
| `event`   | `str` | `"OutputModelResponseCompleted"` | Event type  |

### CustomEvent

| Attribute | Type  | Default         | Description |
| --------- | ----- | --------------- | ----------- |
| `event`   | `str` | `"CustomEvent"` | Event type  |


# AgentSession
Source: https://docs.agno.com/reference/agents/session



## AgentSession Attributes

| Parameter      | Type                        | Default  | Description                                                        |
| -------------- | --------------------------- | -------- | ------------------------------------------------------------------ |
| `session_id`   | `str`                       | Required | Session UUID                                                       |
| `agent_id`     | `Optional[str]`             | `None`   | ID of the agent that this session is associated with               |
| `team_id`      | `Optional[str]`             | `None`   | ID of the team that this session is associated with                |
| `user_id`      | `Optional[str]`             | `None`   | ID of the user interacting with this agent                         |
| `workflow_id`  | `Optional[str]`             | `None`   | ID of the workflow that this session is associated with            |
| `session_data` | `Optional[Dict[str, Any]]`  | `None`   | Session Data: session\_name, session\_state, images, videos, audio |
| `metadata`     | `Optional[Dict[str, Any]]`  | `None`   | Metadata stored with this agent                                    |
| `agent_data`   | `Optional[Dict[str, Any]]`  | `None`   | Agent Data: agent\_id, name and model                              |
| `runs`         | `Optional[List[RunOutput]]` | `None`   | List of all runs in the session                                    |
| `summary`      | `Optional[SessionSummary]`  | `None`   | Summary of the session                                             |
| `created_at`   | `Optional[int]`             | `None`   | The unix timestamp when this session was created                   |
| `updated_at`   | `Optional[int]`             | `None`   | The unix timestamp when this session was last updated              |

## AgentSession Methods

### `upsert_run(run: RunOutput)`

Adds a RunOutput to the runs list. If a run with the same `run_id` already exists, it updates the existing run.

### `get_run(run_id: str) -> Optional[RunOutput]`

Retrieves a specific run by its `run_id`.

### `get_messages_from_last_n_runs(...) -> List[Message]`

Gets messages from the last N runs with various filtering options:

* `agent_id`: Filter by agent ID
* `team_id`: Filter by team ID
* `last_n`: Number of recent runs to include
* `skip_role`: Skip messages with specific role
* `skip_status`: Skip runs with specific statuses
* `skip_history_messages`: Whether to skip history messages

### `get_session_summary() -> Optional[SessionSummary]`

Get the session summary for the session

### `get_chat_history() -> List[Message]`

Get the chat history for the session


# Agentic Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/agentic



Agentic chunking is an intelligent method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text.
Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

<Snippet file="chunking-agentic.mdx" />


# CSV Row Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/csv-row



CSV row chunking is a method of splitting CSV files into smaller chunks based on the number of rows, rather than character count. This approach is particularly useful for structured data where you want to process CSV files in manageable row-based chunks while preserving the integrity of individual records.

<Snippet file="chunking-csv-row.mdx" />


# Document Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/document



Document chunking is a method of splitting documents into smaller chunks based on document structure like paragraphs and sections.
It analyzes natural document boundaries rather than splitting at fixed character counts. This is useful when you want to process large documents while preserving semantic meaning and context.

<Snippet file="chunking-document.mdx" />


# Fixed Size Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/fixed-size



Fixed size chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks.
This is useful when you want to process large documents in smaller, manageable pieces.

<Snippet file="chunking-fixed-size.mdx" />


# Markdown Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/markdown



Markdown chunking is a method of splitting markdown based on structure like headers, paragraphs and sections.
This is useful when you want to process large markdown documents in smaller, manageable pieces.

<Snippet file="chunking-markdown.mdx" />


# Recursive Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/recursive



Recursive chunking is a method of splitting documents into smaller chunks by recursively applying a chunking strategy.
This is useful when you want to process large documents in smaller, manageable pieces.

<Snippet file="chunking-recursive.mdx" />


# Semantic Chunking
Source: https://docs.agno.com/reference/knowledge/chunking/semantic



Semantic chunking is a method of splitting documents into smaller chunks by analyzing semantic similarity between text segments using embeddings.
It uses the chonkie library to identify natural breakpoints where the semantic meaning changes significantly, based on a configurable similarity threshold.
This helps preserve context and meaning better than fixed-size chunking by ensuring semantically related content stays together in the same chunk, while splitting occurs at meaningful topic transitions.

<Snippet file="chunking-semantic.mdx" />


# Azure OpenAI
Source: https://docs.agno.com/reference/knowledge/embedder/azure_openai



Azure OpenAI Embedder is a class that allows you to embed documents using Azure OpenAI.

<Snippet file="embedder-azure-openai-reference.mdx" />


# Cohere
Source: https://docs.agno.com/reference/knowledge/embedder/cohere



Cohere Embedder is a class that allows you to embed documents using Cohere's embedding models.

<Snippet file="embedder-cohere-reference.mdx" />


# FastEmbed
Source: https://docs.agno.com/reference/knowledge/embedder/fastembed



FastEmbed Embedder is a class that allows you to embed documents using FastEmbed's efficient embedding models, with BAAI/bge-small-en-v1.5 as the default model.

<Snippet file="embedder-fastembed-reference.mdx" />


# Fireworks
Source: https://docs.agno.com/reference/knowledge/embedder/fireworks



Fireworks Embedder is a class that allows you to embed documents using Fireworks.ai's embedding models. It extends the OpenAI Embedder class and uses a compatible API interface.

<Snippet file="embedder-fireworks-reference.mdx" />


# Gemini
Source: https://docs.agno.com/reference/knowledge/embedder/gemini



Gemini Embedder is a class that allows you to embed documents using Google's Gemini embedding models through the Google Generative AI API.

<Snippet file="embedder-gemini-reference.mdx" />


# Hugging Face
Source: https://docs.agno.com/reference/knowledge/embedder/huggingface



Hugging Face Embedder is a class that allows you to embed documents using any embedding model hosted on HuggingFace's Inference API.

<Snippet file="embedder-huggingface-reference.mdx" />


# Mistral
Source: https://docs.agno.com/reference/knowledge/embedder/mistral



Mistral Embedder is a class that allows you to embed documents using Mistral AI's embedding models.

<Snippet file="embedder-mistral-reference.mdx" />


# Ollama
Source: https://docs.agno.com/reference/knowledge/embedder/ollama



Ollama Embedder is a class that allows you to embed documents using locally hosted Ollama models. This embedder provides integration with Ollama's API for generating embeddings from various open-source models.

<Snippet file="embedder-ollama-reference.mdx" />


# OpenAI
Source: https://docs.agno.com/reference/knowledge/embedder/openai



OpenAI Embedder is a class that allows you to embed documents using OpenAI's embedding models, including the latest text-embedding-3 series.

<Snippet file="embedder-openai-reference.mdx" />


# Sentence Transformer
Source: https://docs.agno.com/reference/knowledge/embedder/sentence-transformer



Sentence Transformer Embedder is a class that allows you to embed documents using Hugging Face's sentence-transformers library, providing access to a wide range of open-source embedding models that can run locally.

<Snippet file="embedder-sentence-transformer-reference.mdx" />


# Together
Source: https://docs.agno.com/reference/knowledge/embedder/together



Together Embedder is a class that allows you to embed documents using Together AI's embedding models. It extends the OpenAI Embedder class and uses a compatible API interface.

<Snippet file="embedder-together-reference.mdx" />


# VoyageAI
Source: https://docs.agno.com/reference/knowledge/embedder/voyageai



VoyageAI Embedder is a class that allows you to embed documents using VoyageAI's embedding models, which are specifically designed for high-performance text embeddings.

<Snippet file="embedder-voyageai-reference.mdx" />


# Knowledge
Source: https://docs.agno.com/reference/knowledge/knowledge



Knowledge is a class that manages knowledge bases for AI agents. It provides comprehensive knowledge management capabilities including adding new content to the knowledge base, searching the knowledge base and deleting content from the knowledge base.

<Snippet file="knowledge-reference.mdx" />


# Arxiv Reader
Source: https://docs.agno.com/reference/knowledge/reader/arxiv



ArxivReader is a reader class that allows you to read papers from the Arxiv API.

<Snippet file="arxiv-reader-reference.mdx" />


# Reader
Source: https://docs.agno.com/reference/knowledge/reader/base



Reader is the base class for all reader classes in Agno.

<Snippet file="base-reader-reference.mdx" />


# CSV Reader
Source: https://docs.agno.com/reference/knowledge/reader/csv



CSVReader is a reader class that allows you to read data from CSV files.

<Snippet file="csv-reader-reference.mdx" />


# Docx Reader
Source: https://docs.agno.com/reference/knowledge/reader/docx



DocxReader is a reader class that allows you to read data from Docx files.

<Snippet file="docx-reader-reference.mdx" />


# FireCrawl Reader
Source: https://docs.agno.com/reference/knowledge/reader/firecrawl



FireCrawlReader is a reader class that allows you to read data from websites using Firecrawl.

<Snippet file="firecrawl-reader-reference.mdx" />


# JSON Reader
Source: https://docs.agno.com/reference/knowledge/reader/json



JSONReader is a reader class that allows you to read data from JSON files.

<Snippet file="json-reader-reference.mdx" />


# PDF Reader
Source: https://docs.agno.com/reference/knowledge/reader/pdf



PDFReader is a reader class that allows you to read data from PDF files.

<Snippet file="pdf-reader-reference.mdx" />


# Text Reader
Source: https://docs.agno.com/reference/knowledge/reader/text



TextReader is a reader class that allows you to read data from text files.

<Snippet file="text-reader-reference.mdx" />


# Web Search Reader
Source: https://docs.agno.com/reference/knowledge/reader/web-search



WebSearchReader is a reader class that allows you to read data from web search results.

<Snippet file="web-search-reader-reference.mdx" />


# Website Reader
Source: https://docs.agno.com/reference/knowledge/reader/website



WebsiteReader is a reader class that allows you to read data from websites.

<Snippet file="website-reader-reference.mdx" />


# Wikipedia Reader
Source: https://docs.agno.com/reference/knowledge/reader/wikipedia



WikipediaReader is a reader class that allows you to read Wikipedia articles.

<Snippet file="wikipedia-reader-reference.mdx" />


# YouTube Reader
Source: https://docs.agno.com/reference/knowledge/reader/youtube



YouTubeReader is a reader class that allows you to read transcript from YouTube videos.

<Snippet file="youtube-reader-reference.mdx" />


# GCS Content
Source: https://docs.agno.com/reference/knowledge/remote-content/gcs-content



GCSContent is a class that allows you to add content from a GCS bucket to the knowledge base.

<Snippet file="gcs-remote-content-params.mdx" />


# S3 Content
Source: https://docs.agno.com/reference/knowledge/remote-content/s3-content



S3Content is a class that allows you to add content from a S3 bucket to the knowledge base.

<Snippet file="s3-remote-content-params.mdx" />


# Cohere Reranker
Source: https://docs.agno.com/reference/knowledge/reranker/cohere



<Snippet file="reranker-cohere-params.mdx" />


# Memory Manager
Source: https://docs.agno.com/reference/memory/memory



Memory is a class that manages conversation history, session summaries, and long-term user memories for AI agents. It provides comprehensive memory management capabilities including adding new memories, searching memories, and deleting memories.

<Snippet file="memory-manager-reference.mdx" />


# AI/ML API
Source: https://docs.agno.com/reference/models/aimlapi



The **AI/ML API** provider gives unified access to over **300+ AI models**, including **Deepseek**, **Gemini**, **ChatGPT**, and others, via a single standardized interface.

The models run with **enterprise-grade rate limits and uptime**, and are ideal for production use.

You can sign up at [aimlapi.com](https://aimlapi.com/?utm_source=agno\&utm_medium=integration\&utm_campaign=aimlapi) and view full provider documentation at [docs.aimlapi.com](https://docs.aimlapi.com/?utm_source=agno\&utm_medium=github\&utm_campaign=integration).

<Snippet file="model-aimlapi-params.mdx" />


# Claude
Source: https://docs.agno.com/reference/models/anthropic



The Claude model provides access to Anthropic's Claude models.

<Snippet file="model-claude-params.mdx" />


# Azure AI Foundry
Source: https://docs.agno.com/reference/models/azure



The Azure AI Foundry model provides access to Azure-hosted AI Foundry models.

<Snippet file="model-azure-ai-foundry-params.mdx" />


# Azure OpenAI
Source: https://docs.agno.com/reference/models/azure_open_ai



The AzureOpenAI model provides access to Azure-hosted OpenAI models.

<Snippet file="model-azure-openaiparams.mdx" />


# AWS Bedrock
Source: https://docs.agno.com/reference/models/bedrock

Learn how to use AWS Bedrock models in Agno.

The AWS Bedrock model provides access to models hosted on AWS Bedrock.

<Snippet file="model-aws-params.mdx" />


# AWS Bedrock Claude
Source: https://docs.agno.com/reference/models/bedrock_claude



The AWS Bedrock Claude model provides access to Anthropic's Claude models hosted on AWS Bedrock.

<Snippet file="model-aws-claude-params.mdx" />


# Cohere
Source: https://docs.agno.com/reference/models/cohere



The Cohere model provides access to Cohere's language models.

<Snippet file="model-cohere-params.mdx" />


# DeepInfra
Source: https://docs.agno.com/reference/models/deepinfra



The DeepInfra model provides access to DeepInfra's hosted language models.

<Snippet file="model-deepinfra-params.mdx" />


# DeepSeek
Source: https://docs.agno.com/reference/models/deepseek



The DeepSeek model provides access to DeepSeek's language models.

<Snippet file="model-deepseek-params.mdx" />


# Fireworks
Source: https://docs.agno.com/reference/models/fireworks



The Fireworks model provides access to Fireworks' language models.

<Snippet file="model-fireworks-params.mdx" />


# Gemini
Source: https://docs.agno.com/reference/models/gemini



The Gemini model provides access to Google's Gemini models.

<Snippet file="model-google-params.mdx" />


# Groq
Source: https://docs.agno.com/reference/models/groq



The Groq model provides access to Groq's high-performance language models.

<Snippet file="model-groq-params.mdx" />


# HuggingFace
Source: https://docs.agno.com/reference/models/huggingface



The HuggingFace model provides access to models hosted on the HuggingFace Hub.

<Snippet file="model-hf-params.mdx" />


# IBM WatsonX
Source: https://docs.agno.com/reference/models/ibm-watsonx



The IBM WatsonX model provides access to IBM's language models.

<Snippet file="model-ibm-watsonx-params.mdx" />


# InternLM
Source: https://docs.agno.com/reference/models/internlm



The InternLM model provides access to the InternLM model.

<Snippet file="model-internlm-params.mdx" />


# Meta
Source: https://docs.agno.com/reference/models/meta



The Meta model provides access to Meta's language models.

<Snippet file="model-meta-params.mdx" />


# Mistral
Source: https://docs.agno.com/reference/models/mistral



The Mistral model provides access to Mistral's language models.

<Snippet file="model-mistral-params.mdx" />


# Model
Source: https://docs.agno.com/reference/models/model



The Model class is the base class for all models in Agno. It provides common functionality and parameters that are inherited by specific model implementations like OpenAIChat, Claude, etc.

<Snippet file="model-base-params.mdx" />


# Nebius
Source: https://docs.agno.com/reference/models/nebius



The Nebius model provides access to Nebius's text and image models.

<Snippet file="model-nebius-params.mdx" />


# Nvidia
Source: https://docs.agno.com/reference/models/nvidia



The Nvidia model provides access to Nvidia's language models.

<Snippet file="model-nvidia-params.mdx" />


# Ollama
Source: https://docs.agno.com/reference/models/ollama



The Ollama model provides access to open source models, both locally-hosted and via **Ollama Cloud**.

**Local Usage**: Run models on your own hardware using the Ollama client. Perfect for development, privacy-sensitive workloads, and when you want full control over your infrastructure.

**Cloud Usage**: Access cloud-hosted models via [Ollama Cloud](https://ollama.com) with an API key for scalable, production-ready deployments. No local setup required - simply set your `OLLAMA_API_KEY` and start using powerful models instantly.

## Key Features

* **Dual Deployment Options**: Choose between local hosting for privacy and control, or cloud hosting for scalability
* **Seamless Switching**: Easy transition between local and cloud deployments with minimal code changes
* **Auto-configuration**: When using an API key, the host automatically defaults to Ollama Cloud
* **Wide Model Support**: Access to extensive library of open-source models including GPT-OSS, Llama, Qwen, DeepSeek, and Phi models

<Snippet file="model-ollama-params.mdx" />


# Ollama Tools
Source: https://docs.agno.com/reference/models/ollama_tools



The Ollama Tools model provides access to the Ollama models and passes tools in XML format to the model.

<Snippet file="model-ollama-tools-params.mdx" />


# OpenAI
Source: https://docs.agno.com/reference/models/openai



The OpenAIChat model provides access to OpenAI models like GPT-4o.

<Snippet file="model-openai-params.mdx" />


# OpenAI Like
Source: https://docs.agno.com/reference/models/openai_like



The OpenAI Like model works as a wrapper for the OpenAILike models.

<Snippet file="model-openai-like-params.mdx" />


# OpenRouter
Source: https://docs.agno.com/reference/models/openrouter



The OpenRouter model provides unified access to various language models through OpenRouter.

<Snippet file="model-openrouter-params.mdx" />


# Perplexity
Source: https://docs.agno.com/reference/models/perplexity



The Perplexity model provides access to Perplexity's language models.

<Snippet file="model-perplexity-params.mdx" />


# Sambanova
Source: https://docs.agno.com/reference/models/sambanova



The Sambanova model provides access to Sambanova's language models.

<Snippet file="model-sambanova-params.mdx" />


# Together
Source: https://docs.agno.com/reference/models/together



The Together model provides access to Together's language models.

<Snippet file="model-together-params.mdx" />


# Vercel v0
Source: https://docs.agno.com/reference/models/vercel



The Vercel v0 model provides access to Vercel's language models.

<Snippet file="model-v0-params.mdx" />


# xAI
Source: https://docs.agno.com/reference/models/xai



The xAI model provides access to xAI's language models.

<Snippet file="model-xai-params.mdx" />


# DynamoDB
Source: https://docs.agno.com/reference/storage/dynamodb



DynamoDB is a class that implements the Db interface using Amazon DynamoDB as the backend storage system. It provides scalable, managed storage for agent sessions with support for indexing and efficient querying.

<Snippet file="db-dynamodb-params.mdx" />


# FirestoreDb
Source: https://docs.agno.com/reference/storage/firestore



`FirestoreDb` is a class that implements the Db interface using Google Firestore as the backend storage system. It provides high-performance, distributed storage for agent sessions with support for JSON data types and schema versioning.

<Snippet file="db-firestore-params.mdx" />


# GcsJsonDb
Source: https://docs.agno.com/reference/storage/gcs



`GcsJsonDb` is a class that implements the Db interface using Google Cloud Storage as a database using JSON files. It provides high-performance, distributed storage for agent sessions with support for JSON data types and schema versioning.

<Snippet file="db-gcs-params.mdx" />


# InMemoryDb
Source: https://docs.agno.com/reference/storage/in_memory



`InMemoryDb` is a class that implements the Db interface using an in-memory database. It provides lightweight, in-memory storage for agent/team sessions.

<Snippet file="db-in-memory-params.mdx" />


# JsonDb
Source: https://docs.agno.com/reference/storage/json



`JsonDb` is a class that implements the Db interface using JSON files as the backend storage system. It provides a simple, file-based storage solution for agent sessions with each session stored in a separate JSON file.

<Snippet file="db-json-params.mdx" />


# MongoDB
Source: https://docs.agno.com/reference/storage/mongodb



`MongoDb` is a class that implements the Db interface using MongoDB as the backend storage system. It provides scalable, document-based storage for agent sessions with support for indexing and efficient querying.

<Snippet file="db-mongodb-params.mdx" />


# MySQLDb
Source: https://docs.agno.com/reference/storage/mysql



`MySQLDb` is a class that implements the Db interface using MySQL as the backend storage system. It provides robust, relational storage for agent sessions with support for JSONB data types, schema versioning, and efficient querying.

<Snippet file="db-mysql-params.mdx" />


# PostgresDb
Source: https://docs.agno.com/reference/storage/postgres



`PostgresDb` is a class that implements the Db interface using PostgreSQL as the backend storage system. It provides robust, relational storage for agent sessions with support for JSONB data types, schema versioning, and efficient querying.

<Snippet file="db-postgres-params.mdx" />


# RedisDb
Source: https://docs.agno.com/reference/storage/redis



`RedisDb` is a class that implements the Db interface using Redis as the backend storage system. It provides high-performance, distributed storage for agent sessions with support for JSON data types and schema versioning.

<Snippet file="db-redis-params.mdx" />


# SingleStoreDb
Source: https://docs.agno.com/reference/storage/singlestore



`SingleStoreDb` is a class that implements the Db interface using SingleStore  as the backend storage system. It provides high-performance, distributed storage for agent sessions with support for JSON data types and schema versioning.

<Snippet file="db-singlestore-params.mdx" />


# SqliteDb
Source: https://docs.agno.com/reference/storage/sqlite



`SqliteDb` is a class that implements the Db interface using SQLite as the backend storage system. It provides lightweight, file-based storage for agent sessions with support for JSON data types and schema versioning.

<Snippet file="db-sqlite-params.mdx" />


# Team Session
Source: https://docs.agno.com/reference/teams/session



## TeamSession Attributes

| Parameter      | Type                                              | Default  | Description                                             |
| -------------- | ------------------------------------------------- | -------- | ------------------------------------------------------- |
| `session_id`   | `str`                                             | Required | Session UUID                                            |
| `team_id`      | `Optional[str]`                                   | `None`   | ID of the team that this session is associated with     |
| `user_id`      | `Optional[str]`                                   | `None`   | ID of the user interacting with this team               |
| `workflow_id`  | `Optional[str]`                                   | `None`   | ID of the workflow that this session is associated with |
| `team_data`    | `Optional[Dict[str, Any]]`                        | `None`   | Team Data: name, team\_id, model, and mode              |
| `session_data` | `Optional[Dict[str, Any]]`                        | `None`   | Session Data: session\_state, images, videos, audio     |
| `metadata`     | `Optional[Dict[str, Any]]`                        | `None`   | Metadata stored with this team                          |
| `runs`         | `Optional[List[Union[TeamRunOutput, RunOutput]]]` | `None`   | List of all runs in the session                         |
| `summary`      | `Optional[SessionSummary]`                        | `None`   | Summary of the session                                  |
| `created_at`   | `Optional[int]`                                   | `None`   | The unix timestamp when this session was created        |
| `updated_at`   | `Optional[int]`                                   | `None`   | The unix timestamp when this session was last updated   |

## TeamSession Methods

### `upsert_run(run: TeamRunOutput)`

Adds a TeamRunOutput to the runs list. If a run with the same `run_id` already exists, it updates the existing run.

### `get_run(run_id: str) -> Optional[RunOutput]`

Retrieves a specific run by its `run_id`.

### `get_messages_from_last_n_runs(...) -> List[Message]`

Gets messages from the last N runs with various filtering options:

* `agent_id`: Filter by agent ID
* `team_id`: Filter by team ID
* `last_n`: Number of recent runs to include
* `skip_role`: Skip messages with specific role
* `skip_status`: Skip runs with specific statuses
* `skip_history_messages`: Whether to skip history messages

### `get_session_summary() -> Optional[SessionSummary]`

Get the session summary for the session

### `get_chat_history() -> List[Message]`

Get the chat history for the session


# Team
Source: https://docs.agno.com/reference/teams/team



## Parameters

| Parameter                          | Type                                                        | Default    | Description                                                                                                          |
| ---------------------------------- | ----------------------------------------------------------- | ---------- | -------------------------------------------------------------------------------------------------------------------- |
| `members`                          | `List[Union[Agent, Team]]`                                  | -          | List of agents or teams that make up this team                                                                       |
| `id`                               | `Optional[str]`                                             | `None`     | Team UUID (autogenerated if not set)                                                                                 |
| `model`                            | `Optional[Model]`                                           | `None`     | Model to use for the team                                                                                            |
| `name`                             | `Optional[str]`                                             | `None`     | Name of the team                                                                                                     |
| `role`                             | `Optional[str]`                                             | `None`     | Role of the team within its parent team                                                                              |
| `respond_directly`                 | `bool`                                                      | `False`    | If True, the team leader won't process responses from the members and instead will return them directly              |
| `determine_input_for_members`      | `bool`                                                      | `True`     | Set to False if you want to send the run input directly to the member agents                                         |
| `delegate_task_to_all_members`     | `bool`                                                      | `False`    | If True, the team leader will delegate tasks to all members automatically, without any decision from the team leader |
| `user_id`                          | `Optional[str]`                                             | `None`     | Default user ID for this team                                                                                        |
| `session_id`                       | `Optional[str]`                                             | `None`     | Default session ID for this team (autogenerated if not set)                                                          |
| `session_state`                    | `Optional[Dict[str, Any]]`                                  | `None`     | Session state (stored in the database to persist across runs)                                                        |
| `add_session_state_to_context`     | `bool`                                                      | `False`    | Set to True to add the session\_state to the context                                                                 |
| `enable_agentic_state`             | `bool`                                                      | `False`    | Set to True to give the team tools to update the session\_state dynamically                                          |
| `cache_session`                    | `bool`                                                      | `False`    | If True, cache the current Team session in memory for faster access                                                  |
| `resolve_in_context`               | `bool`                                                      | `True`     | If True, resolve the session\_state, dependencies, and metadata in the user and system messages                      |
| `description`                      | `Optional[str]`                                             | `None`     | A description of the Team that is added to the start of the system message                                           |
| `instructions`                     | `Optional[Union[str, List[str], Callable]]`                 | `None`     | List of instructions for the team                                                                                    |
| `expected_output`                  | `Optional[str]`                                             | `None`     | Provide the expected output from the Team                                                                            |
| `additional_context`               | `Optional[str]`                                             | `None`     | Additional context added to the end of the system message                                                            |
| `markdown`                         | `bool`                                                      | `False`    | If markdown=true, add instructions to format the output using markdown                                               |
| `add_datetime_to_context`          | `bool`                                                      | `False`    | If True, add the current datetime to the instructions to give the team a sense of time                               |
| `add_location_to_context`          | `bool`                                                      | `False`    | If True, add the current location to the instructions to give the team a sense of location                           |
| `timezone_identifier`              | `Optional[str]`                                             | `None`     | Allows for custom timezone for datetime instructions following the TZ Database format                                |
| `add_name_to_context`              | `bool`                                                      | `False`    | If True, add the team name to the instructions                                                                       |
| `add_member_tools_to_context`      | `bool`                                                      | `True`     | If True, add the tools available to team members to the context                                                      |
| `system_message`                   | `Optional[Union[str, Callable, Message]]`                   | `None`     | Provide the system message as a string or function                                                                   |
| `system_message_role`              | `str`                                                       | `"system"` | Role for the system message                                                                                          |
| `additional_input`                 | `Optional[List[Union[str, Dict, BaseModel, Message]]]`      | `None`     | A list of extra messages added after the system message and before the user message                                  |
| `db`                               | `Optional[BaseDb]`                                          | `None`     | Database to use for this team                                                                                        |
| `memory_manager`                   | `Optional[MemoryManager]`                                   | `None`     | Memory manager to use for this team                                                                                  |
| `dependencies`                     | `Optional[Dict[str, Any]]`                                  | `None`     | User provided dependencies                                                                                           |
| `add_dependencies_to_context`      | `bool`                                                      | `False`    | If True, add the dependencies to the user prompt                                                                     |
| `knowledge`                        | `Optional[Knowledge]`                                       | `None`     | Add a knowledge base to the team                                                                                     |
| `knowledge_filters`                | `Optional[Dict[str, Any]]`                                  | `None`     | Filters to apply to knowledge base searches                                                                          |
| `enable_agentic_knowledge_filters` | `Optional[bool]`                                            | `False`    | Let the team choose the knowledge filters                                                                            |
| `update_knowledge`                 | `bool`                                                      | `False`    | Add a tool that allows the Team to update Knowledge                                                                  |
| `add_knowledge_to_context`         | `bool`                                                      | `False`    | If True, add references to the user prompt                                                                           |
| `knowledge_retriever`              | `Optional[Callable[..., Optional[List[Union[Dict, str]]]]]` | `None`     | Retrieval function to get references                                                                                 |
| `references_format`                | `Literal["json", "yaml"]`                                   | `"json"`   | Format of the references                                                                                             |
| `share_member_interactions`        | `bool`                                                      | `False`    | If True, send all previous member interactions to members                                                            |
| `get_member_information_tool`      | `bool`                                                      | `False`    | If True, add a tool to get information about the team members                                                        |
| `search_knowledge`                 | `bool`                                                      | `True`     | Add a tool to search the knowledge base (aka Agentic RAG)                                                            |
| `read_team_history`                | `bool`                                                      | `False`    | If True, read the team history                                                                                       |
| `send_media_to_model`              | `bool`                                                      | `True`     | If False, media (images, videos, audio, files) is only available to tools and not sent to the LLM                    |
| `store_media`                      | `bool`                                                      | `True`     | If True, store media in run output                                                                                   |
| `tools`                            | `Optional[List[Union[Toolkit, Callable, Function, Dict]]]`  | `None`     | A list of tools provided to the Model                                                                                |
| `tool_choice`                      | `Optional[Union[str, Dict[str, Any]]]`                      | `None`     | Controls which (if any) tool is called by the team model                                                             |
| `tool_call_limit`                  | `Optional[int]`                                             | `None`     | Maximum number of tool calls allowed                                                                                 |
| `tool_hooks`                       | `Optional[List[Callable]]`                                  | `None`     | A list of hooks to be called before and after the tool call                                                          |
| `input_schema`                     | `Optional[Type[BaseModel]]`                                 | `None`     | Input schema for validating input                                                                                    |
| `output_schema`                    | `Optional[Type[BaseModel]]`                                 | `None`     | Output schema for the team response                                                                                  |
| `parser_model`                     | `Optional[Model]`                                           | `None`     | Provide a secondary model to parse the response from the primary model                                               |
| `parser_model_prompt`              | `Optional[str]`                                             | `None`     | Provide a prompt for the parser model                                                                                |
| `output_model`                     | `Optional[Model]`                                           | `None`     | Provide an output model to parse the response from the team                                                          |
| `output_model_prompt`              | `Optional[str]`                                             | `None`     | Provide a prompt for the output model                                                                                |
| `use_json_mode`                    | `bool`                                                      | `False`    | If `output_schema` is set, sets the response mode of the model                                                       |
| `parse_response`                   | `bool`                                                      | `True`     | If True, parse the response                                                                                          |
| `enable_agentic_memory`            | `bool`                                                      | `False`    | Enable the team to manage memories of the user                                                                       |
| `enable_user_memories`             | `bool`                                                      | `False`    | If True, the team creates/updates user memories at the end of runs                                                   |
| `add_memories_to_context`          | `Optional[bool]`                                            | `None`     | If True, the team adds a reference to the user memories in the response                                              |
| `enable_session_summaries`         | `bool`                                                      | `False`    | If True, the team creates/updates session summaries at the end of runs                                               |
| `session_summary_manager`          | `Optional[SessionSummaryManager]`                           | `None`     | Session summary manager                                                                                              |
| `add_session_summary_to_context`   | `Optional[bool]`                                            | `None`     | If True, the team adds session summaries to the context                                                              |
| `add_history_to_context`           | `bool`                                                      | `False`    | Add messages from the chat history to the messages list sent to the Model                                            |
| `num_history_runs`                 | `int`                                                       | `3`        | Number of historical runs to include in the messages                                                                 |
| `metadata`                         | `Optional[Dict[str, Any]]`                                  | `None`     | Metadata stored with this team                                                                                       |
| `reasoning`                        | `bool`                                                      | `False`    | Enable reasoning for the team                                                                                        |
| `reasoning_model`                  | `Optional[Model]`                                           | `None`     | Model to use for reasoning                                                                                           |
| `reasoning_agent`                  | `Optional[Agent]`                                           | `None`     | Agent to use for reasoning                                                                                           |
| `reasoning_min_steps`              | `int`                                                       | `1`        | Minimum number of reasoning steps                                                                                    |
| `reasoning_max_steps`              | `int`                                                       | `10`       | Maximum number of reasoning steps                                                                                    |
| `stream`                           | `Optional[bool]`                                            | `None`     | Stream the response from the Team                                                                                    |
| `stream_intermediate_steps`        | `bool`                                                      | `False`    | Stream the intermediate steps from the Team                                                                          |
| `stream_member_events`             | `bool`                                                      | `True`     | Stream the member events from the Team members                                                                       |
| `store_events`                     | `bool`                                                      | `False`    | Store the events from the Team                                                                                       |
| `events_to_skip`                   | `Optional[List[Union[RunEvent, TeamRunEvent]]]`             | `None`     | List of events to skip from the Team                                                                                 |
| `store_member_responses`           | `bool`                                                      | `False`    | Store member agent runs inside the team's RunOutput                                                                  |
| `debug_mode`                       | `bool`                                                      | `False`    | Enable debug logs                                                                                                    |
| `debug_level`                      | `Literal[1, 2]`                                             | `1`        | Debug level: 1 = basic, 2 = detailed                                                                                 |
| `show_members_responses`           | `bool`                                                      | `False`    | Enable member logs - Sets the debug\_mode for team and members                                                       |
| `retries`                          | `int`                                                       | `0`        | Number of retries to attempt                                                                                         |
| `delay_between_retries`            | `int`                                                       | `1`        | Delay between retries (in seconds)                                                                                   |
| `exponential_backoff`              | `bool`                                                      | `False`    | Exponential backoff: if True, the delay between retries is doubled each time                                         |
| `telemetry`                        | `bool`                                                      | `True`     | Log minimal telemetry for analytics                                                                                  |

## Functions

### `run`

Run the team.

**Parameters:**

* `input` (Union\[str, List, Dict, Message, BaseModel, List\[Message]]): The input to send to the team
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `user_id` (Optional\[str]): User ID to use
* `retries` (Optional\[int]): Number of retries to attempt
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode
* `yield_run_response` (bool): Whether to yield the run response (only for streaming)

**Returns:**

* `Union[TeamRunOutput, Iterator[Union[RunOutputEvent, TeamRunOutputEvent]]]`: Either a TeamRunOutput or an iterator of events, depending on the `stream` parameter

### `arun`

Run the team asynchronously.

**Parameters:**

* `input` (Union\[str, List, Dict, Message, BaseModel, List\[Message]]): The input to send to the team
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `user_id` (Optional\[str]): User ID to use
* `retries` (Optional\[int]): Number of retries to attempt
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode
* `yield_run_response` (bool): Whether to yield the run response (only for streaming)

**Returns:**

* `Union[TeamRunOutput, AsyncIterator[Union[RunOutputEvent, TeamRunOutputEvent]]]`: Either a TeamRunOutput or an async iterator of events, depending on the `stream` parameter

### `print_response`

Run the team and print the response.

**Parameters:**

* `input` (Union\[List, Dict, str, Message, BaseModel, List\[Message]]): The input to send to the team
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `user_id` (Optional\[str]): User ID to use
* `show_message` (bool): Whether to show the message (default: True)
* `show_reasoning` (bool): Whether to show reasoning (default: True)
* `show_full_reasoning` (bool): Whether to show full reasoning (default: False)
* `console` (Optional\[Any]): Console to use for output
* `tags_to_include_in_markdown` (Optional\[Set\[str]]): Tags to include in markdown content
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `markdown` (Optional\[bool]): Whether to format output as markdown
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

### `aprint_response`

Run the team and print the response asynchronously.

**Parameters:**

* `input` (Union\[List, Dict, str, Message, BaseModel, List\[Message]]): The input to send to the team
* `stream` (Optional\[bool]): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `user_id` (Optional\[str]): User ID to use
* `show_message` (bool): Whether to show the message (default: True)
* `show_reasoning` (bool): Whether to show reasoning (default: True)
* `show_full_reasoning` (bool): Whether to show full reasoning (default: False)
* `console` (Optional\[Any]): Console to use for output
* `tags_to_include_in_markdown` (Optional\[Set\[str]]): Tags to include in markdown content
* `audio` (Optional\[Sequence\[Audio]]): Audio files to include
* `images` (Optional\[Sequence\[Image]]): Image files to include
* `videos` (Optional\[Sequence\[Video]]): Video files to include
* `files` (Optional\[Sequence\[File]]): Files to include
* `markdown` (Optional\[bool]): Whether to format output as markdown
* `knowledge_filters` (Optional\[Dict\[str, Any]]): Knowledge filters to apply
* `add_history_to_context` (Optional\[bool]): Whether to add history to context
* `dependencies` (Optional\[Dict\[str, Any]]): Dependencies to use for this run
* `add_dependencies_to_context` (Optional\[bool]): Whether to add dependencies to context
* `add_session_state_to_context` (Optional\[bool]): Whether to add session state to context
* `metadata` (Optional\[Dict\[str, Any]]): Metadata to use for this run
* `debug_mode` (Optional\[bool]): Whether to enable debug mode

### `cli_app`

Run an interactive command-line interface to interact with the team.

**Parameters:**

* `input` (Optional\[str]): The input to send to the team
* `user` (str): Name for the user (default: "User")
* `emoji` (str): Emoji for the user (default: ":sunglasses:")
* `stream` (bool): Whether to stream the response (default: False)
* `markdown` (bool): Whether to format output as markdown (default: False)
* `exit_on` (Optional\[List\[str]]): List of commands to exit the CLI
* `**kwargs`: Additional keyword arguments

### `acli_app`

Run an interactive command-line interface to interact with the team asynchronously.

**Parameters:**

* `input` (Optional\[str]): The input to send to the team
* `session_id` (Optional\[str]): Session ID to use
* `user_id` (Optional\[str]): User ID to use
* `user` (str): Name for the user (default: "User")
* `emoji` (str): Emoji for the user (default: ":sunglasses:")
* `stream` (bool): Whether to stream the response (default: False)
* `markdown` (bool): Whether to format output as markdown (default: False)
* `exit_on` (Optional\[List\[str]]): List of commands to exit the CLI
* `**kwargs`: Additional keyword arguments

### `get_session_summary`

Get the session summary for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* Session summary for the given session

### `get_user_memories`

Get the user memories for the given user ID.

**Parameters:**

* `user_id` (Optional\[str]): User ID to use (if not provided, the current user is used)

**Returns:**

* `Optional[List[UserMemory]]`: The user memories

### `add_tool`

Add a tool to the team.

**Parameters:**

* `tool` (Union\[Toolkit, Callable, Function, Dict]): The tool to add

### `set_tools`

Replace the tools of the team.

**Parameters:**

* `tools` (List\[Union\[Toolkit, Callable, Function, Dict]]): The tools to set

### `cancel_run`

Cancel a run by run ID.

**Parameters:**

* `run_id` (str): The run ID to cancel

**Returns:**

* `bool`: True if the run was successfully cancelled

### `get_run_output`

Get the run output for the given run ID.

**Parameters:**

* `run_id` (str): The run ID
* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `Optional[Union[TeamRunOutput, RunOutput]]`: The run output

### `get_last_run_output`

Get the last run output for the session.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `Optional[TeamRunOutput]`: The last run output

### `get_session`

Get the session for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `Optional[TeamSession]`: The team session

### `save_session`

Save a session to the database.

**Parameters:**

* `session` (TeamSession): The session to save

### `delete_session`

Delete a session.

**Parameters:**

* `session_id` (str): Session ID to delete

### `get_session_name`

Get the session name for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `str`: The session name

### `set_session_name`

Set the session name.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)
* `autogenerate` (bool): Whether to autogenerate the name
* `session_name` (Optional\[str]): The name to set

**Returns:**

* `TeamSession`: The updated session

### `get_session_state`

Get the session state for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `Dict[str, Any]`: The session state

### `get_session_metrics`

Get the session metrics for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `Optional[Metrics]`: The session metrics

### `get_chat_history`

Get the chat history for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `List[Message]`: The chat history

### `get_messages_for_session`

Get the messages for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use (if not provided, the current session is used)

**Returns:**

* `List[Message]`: The messages for the session


# TeamRunOutput
Source: https://docs.agno.com/reference/teams/team-response



The `TeamRunOutput` class represents the response from a team run, containing both the team's overall response and individual member responses. It supports streaming and provides real-time events throughout the execution of a team.

## TeamRunOutput Attributes

| Attribute             | Type                                              | Default             | Description                                 |
| --------------------- | ------------------------------------------------- | ------------------- | ------------------------------------------- |
| `content`             | `Any`                                             | `None`              | Content of the response                     |
| `content_type`        | `str`                                             | `"str"`             | Specifies the data type of the content      |
| `messages`            | `List[Message]`                                   | `None`              | A list of messages included in the response |
| `metrics`             | `Metrics`                                         | `None`              | Usage metrics of the run                    |
| `model`               | `str`                                             | `None`              | The model used in the run                   |
| `model_provider`      | `str`                                             | `None`              | The model provider used in the run          |
| `member_responses`    | `List[Union[TeamRunOutput, RunOutput]]`           | `[]`                | Responses from individual team members      |
| `run_id`              | `str`                                             | `None`              | Run Id                                      |
| `team_id`             | `str`                                             | `None`              | Team Id for the run                         |
| `team_name`           | `str`                                             | `None`              | Name of the team                            |
| `session_id`          | `str`                                             | `None`              | Session Id for the run                      |
| `parent_run_id`       | `str`                                             | `None`              | Parent run ID if this is a nested run       |
| `tools`               | `List[ToolExecution]`                             | `None`              | List of tools provided to the model         |
| `images`              | `List[Image]`                                     | `None`              | List of images from member runs             |
| `videos`              | `List[Video]`                                     | `None`              | List of videos from member runs             |
| `audio`               | `List[Audio]`                                     | `None`              | List of audio snippets from member runs     |
| `response_audio`      | `Audio`                                           | `None`              | The model's raw response in audio           |
| `input`               | `TeamRunInput`                                    | `None`              | Input media and messages from user          |
| `reasoning_content`   | `str`                                             | `None`              | Any reasoning content the model produced    |
| `citations`           | `Citations`                                       | `None`              | Any citations used in the response          |
| `model_provider_data` | `Any`                                             | `None`              | Model provider specific metadata            |
| `metadata`            | `Dict[str, Any]`                                  | `None`              | Additional metadata for the run             |
| `references`          | `List[MessageReferences]`                         | `None`              | Message references                          |
| `additional_input`    | `List[Message]`                                   | `None`              | Additional input messages                   |
| `reasoning_steps`     | `List[ReasoningStep]`                             | `None`              | Reasoning steps taken during execution      |
| `reasoning_messages`  | `List[Message]`                                   | `None`              | Messages related to reasoning               |
| `created_at`          | `int`                                             | Current timestamp   | Unix timestamp of the response creation     |
| `events`              | `List[Union[RunOutputEvent, TeamRunOutputEvent]]` | `None`              | List of events that occurred during the run |
| `status`              | `RunStatus`                                       | `RunStatus.running` | Current status of the run                   |
| `workflow_step_id`    | `str`                                             | `None`              | FK: Points to StepOutput.step\_id           |

## TeamRunOutputEvent Types

The following events are sent by the `Team.run()` function depending on the team's configuration:

### Core Events

| Event Type                   | Description                                             |
| ---------------------------- | ------------------------------------------------------- |
| `TeamRunStarted`             | Indicates the start of a team run                       |
| `TeamRunContent`             | Contains the model's response text as individual chunks |
| `TeamRunIntermediateContent` | Contains intermediate content during the run            |
| `TeamRunCompleted`           | Signals successful completion of the team run           |
| `TeamRunError`               | Indicates an error occurred during the team run         |
| `TeamRunCancelled`           | Signals that the team run was cancelled                 |

### Tool Events

| Event Type              | Description                                                    |
| ----------------------- | -------------------------------------------------------------- |
| `TeamToolCallStarted`   | Indicates the start of a tool call                             |
| `TeamToolCallCompleted` | Signals completion of a tool call, including tool call results |

### Reasoning Events

| Event Type               | Description                                         |
| ------------------------ | --------------------------------------------------- |
| `TeamReasoningStarted`   | Indicates the start of the team's reasoning process |
| `TeamReasoningStep`      | Contains a single step in the reasoning process     |
| `TeamReasoningCompleted` | Signals completion of the reasoning process         |

### Memory Events

| Event Type                  | Description                                    |
| --------------------------- | ---------------------------------------------- |
| `TeamMemoryUpdateStarted`   | Indicates that the team is updating its memory |
| `TeamMemoryUpdateCompleted` | Signals completion of a memory update          |

## Event Attributes

### Base TeamRunOutputEvent

All events inherit from `BaseTeamRunEvent` which provides these common attributes:

| Attribute         | Type            | Default           | Description                           |
| ----------------- | --------------- | ----------------- | ------------------------------------- |
| `created_at`      | `int`           | Current timestamp | Unix timestamp of the event creation  |
| `event`           | `str`           | `""`              | The type of event                     |
| `team_id`         | `str`           | `""`              | ID of the team generating the event   |
| `team_name`       | `str`           | `""`              | Name of the team generating the event |
| `run_id`          | `Optional[str]` | `None`            | ID of the current run                 |
| `session_id`      | `Optional[str]` | `None`            | ID of the current session             |
| `workflow_id`     | `Optional[str]` | `None`            | ID of the workflow                    |
| `workflow_run_id` | `Optional[str]` | `None`            | ID of the workflow's run              |
| `step_id`         | `Optional[str]` | `None`            | ID of the workflow step               |
| `step_name`       | `Optional[str]` | `None`            | Name of the workflow step             |
| `step_index`      | `Optional[int]` | `None`            | Index of the workflow step            |
| `content`         | `Optional[Any]` | `None`            | For backwards compatibility           |

### RunStartedEvent

| Attribute        | Type  | Default            | Description               |
| ---------------- | ----- | ------------------ | ------------------------- |
| `event`          | `str` | `"TeamRunStarted"` | Event type                |
| `model`          | `str` | `""`               | The model being used      |
| `model_provider` | `str` | `""`               | The provider of the model |

### IntermediateRunContentEvent

| Attribute      | Type            | Default                        | Description                          |
| -------------- | --------------- | ------------------------------ | ------------------------------------ |
| `event`        | `str`           | `"TeamRunIntermediateContent"` | Event type                           |
| `content`      | `Optional[Any]` | `None`                         | Intermediate content of the response |
| `content_type` | `str`           | `"str"`                        | Type of the content                  |

### RunContentEvent

| Attribute             | Type                                | Default            | Description                      |
| --------------------- | ----------------------------------- | ------------------ | -------------------------------- |
| `event`               | `str`                               | `"TeamRunContent"` | Event type                       |
| `content`             | `Optional[Any]`                     | `None`             | The content of the response      |
| `content_type`        | `str`                               | `"str"`            | Type of the content              |
| `reasoning_content`   | `Optional[str]`                     | `None`             | Reasoning content produced       |
| `citations`           | `Optional[Citations]`               | `None`             | Citations used in the response   |
| `model_provider_data` | `Optional[Any]`                     | `None`             | Model provider specific metadata |
| `response_audio`      | `Optional[Audio]`                   | `None`             | Model's audio response           |
| `image`               | `Optional[Image]`                   | `None`             | Image attached to the response   |
| `references`          | `Optional[List[MessageReferences]]` | `None`             | Message references               |
| `additional_input`    | `Optional[List[Message]]`           | `None`             | Additional input messages        |
| `reasoning_steps`     | `Optional[List[ReasoningStep]]`     | `None`             | Reasoning steps                  |
| `reasoning_messages`  | `Optional[List[Message]]`           | `None`             | Reasoning messages               |

### RunCompletedEvent

| Attribute             | Type                                    | Default              | Description                             |
| --------------------- | --------------------------------------- | -------------------- | --------------------------------------- |
| `event`               | `str`                                   | `"TeamRunCompleted"` | Event type                              |
| `content`             | `Optional[Any]`                         | `None`               | Final content of the response           |
| `content_type`        | `str`                                   | `"str"`              | Type of the content                     |
| `reasoning_content`   | `Optional[str]`                         | `None`               | Reasoning content produced              |
| `citations`           | `Optional[Citations]`                   | `None`               | Citations used in the response          |
| `model_provider_data` | `Optional[Any]`                         | `None`               | Model provider specific metadata        |
| `images`              | `Optional[List[Image]]`                 | `None`               | Images attached to the response         |
| `videos`              | `Optional[List[Video]]`                 | `None`               | Videos attached to the response         |
| `audio`               | `Optional[List[Audio]]`                 | `None`               | Audio snippets attached to the response |
| `response_audio`      | `Optional[Audio]`                       | `None`               | Model's audio response                  |
| `references`          | `Optional[List[MessageReferences]]`     | `None`               | Message references                      |
| `additional_input`    | `Optional[List[Message]]`               | `None`               | Additional input messages               |
| `reasoning_steps`     | `Optional[List[ReasoningStep]]`         | `None`               | Reasoning steps                         |
| `reasoning_messages`  | `Optional[List[Message]]`               | `None`               | Reasoning messages                      |
| `member_responses`    | `List[Union[TeamRunOutput, RunOutput]]` | `[]`                 | Responses from individual team members  |
| `metadata`            | `Optional[Dict[str, Any]]`              | `None`               | Additional metadata                     |
| `metrics`             | `Optional[Metrics]`                     | `None`               | Usage metrics                           |

### RunErrorEvent

| Attribute | Type            | Default          | Description   |
| --------- | --------------- | ---------------- | ------------- |
| `event`   | `str`           | `"TeamRunError"` | Event type    |
| `content` | `Optional[str]` | `None`           | Error message |

### RunCancelledEvent

| Attribute | Type            | Default              | Description             |
| --------- | --------------- | -------------------- | ----------------------- |
| `event`   | `str`           | `"TeamRunCancelled"` | Event type              |
| `reason`  | `Optional[str]` | `None`               | Reason for cancellation |

### ToolCallStartedEvent

| Attribute | Type                      | Default                 | Description           |
| --------- | ------------------------- | ----------------------- | --------------------- |
| `event`   | `str`                     | `"TeamToolCallStarted"` | Event type            |
| `tool`    | `Optional[ToolExecution]` | `None`                  | The tool being called |

### ToolCallCompletedEvent

| Attribute | Type                      | Default                   | Description                 |
| --------- | ------------------------- | ------------------------- | --------------------------- |
| `event`   | `str`                     | `"TeamToolCallCompleted"` | Event type                  |
| `tool`    | `Optional[ToolExecution]` | `None`                    | The tool that was called    |
| `content` | `Optional[Any]`           | `None`                    | Result of the tool call     |
| `images`  | `Optional[List[Image]]`   | `None`                    | Images produced by the tool |
| `videos`  | `Optional[List[Video]]`   | `None`                    | Videos produced by the tool |
| `audio`   | `Optional[List[Audio]]`   | `None`                    | Audio produced by the tool  |

### ReasoningStartedEvent

| Attribute | Type  | Default                  | Description |
| --------- | ----- | ------------------------ | ----------- |
| `event`   | `str` | `"TeamReasoningStarted"` | Event type  |

### ReasoningStepEvent

| Attribute           | Type            | Default               | Description                   |
| ------------------- | --------------- | --------------------- | ----------------------------- |
| `event`             | `str`           | `"TeamReasoningStep"` | Event type                    |
| `content`           | `Optional[Any]` | `None`                | Content of the reasoning step |
| `content_type`      | `str`           | `"str"`               | Type of the content           |
| `reasoning_content` | `str`           | `""`                  | Detailed reasoning content    |

### ReasoningCompletedEvent

| Attribute      | Type            | Default                    | Description                   |
| -------------- | --------------- | -------------------------- | ----------------------------- |
| `event`        | `str`           | `"TeamReasoningCompleted"` | Event type                    |
| `content`      | `Optional[Any]` | `None`                     | Content of the reasoning step |
| `content_type` | `str`           | `"str"`                    | Type of the content           |

### MemoryUpdateStartedEvent

| Attribute | Type  | Default                     | Description |
| --------- | ----- | --------------------------- | ----------- |
| `event`   | `str` | `"TeamMemoryUpdateStarted"` | Event type  |

### MemoryUpdateCompletedEvent

| Attribute | Type  | Default                       | Description |
| --------- | ----- | ----------------------------- | ----------- |
| `event`   | `str` | `"TeamMemoryUpdateCompleted"` | Event type  |

### ParserModelResponseStartedEvent

| Attribute | Type  | Default                            | Description |
| --------- | ----- | ---------------------------------- | ----------- |
| `event`   | `str` | `"TeamParserModelResponseStarted"` | Event type  |

### ParserModelResponseCompletedEvent

| Attribute | Type  | Default                              | Description |
| --------- | ----- | ------------------------------------ | ----------- |
| `event`   | `str` | `"TeamParserModelResponseCompleted"` | Event type  |

### OutputModelResponseStartedEvent

| Attribute | Type  | Default                            | Description |
| --------- | ----- | ---------------------------------- | ----------- |
| `event`   | `str` | `"TeamOutputModelResponseStarted"` | Event type  |

### OutputModelResponseCompletedEvent

| Attribute | Type  | Default                              | Description |
| --------- | ----- | ------------------------------------ | ----------- |
| `event`   | `str` | `"TeamOutputModelResponseCompleted"` | Event type  |

### CustomEvent

| Attribute | Type  | Default         | Description |
| --------- | ----- | --------------- | ----------- |
| `event`   | `str` | `"CustomEvent"` | Event type  |


# Cassandra
Source: https://docs.agno.com/reference/vector_db/cassandra



<Snippet file="vector-db-cassandra-reference.mdx" />


# ChromaDb
Source: https://docs.agno.com/reference/vector_db/chromadb



<Snippet file="vector-db-chromadb-reference.mdx" />


# Clickhouse
Source: https://docs.agno.com/reference/vector_db/clickhouse



<Snippet file="vector-db-clickhouse-reference.mdx" />


# Couchbase
Source: https://docs.agno.com/reference/vector_db/couchbase



<Snippet file="vector-db-couchbase-reference.mdx" />


# LanceDb
Source: https://docs.agno.com/reference/vector_db/lancedb



<Snippet file="vector-db-lancedb-reference.mdx" />


# Milvus
Source: https://docs.agno.com/reference/vector_db/milvus



<Snippet file="vector-db-milvus-reference.mdx" />


# MongoDb
Source: https://docs.agno.com/reference/vector_db/mongodb



<Snippet file="vector-db-mongodb-reference.mdx" />


# PgVector
Source: https://docs.agno.com/reference/vector_db/pgvector



<Snippet file="vector-db-pgvector-reference.mdx" />


# Pinecone
Source: https://docs.agno.com/reference/vector_db/pinecone



<Snippet file="vector-db-pinecone-reference.mdx" />


# Qdrant
Source: https://docs.agno.com/reference/vector_db/qdrant



<Snippet file="vector-db-qdrant-reference.mdx" />


# SingleStore
Source: https://docs.agno.com/reference/vector_db/singlestore



<Snippet file="vector-db-singlestore-reference.mdx" />


# SurrealDB
Source: https://docs.agno.com/reference/vector_db/surrealdb



<Snippet file="vector_db_surrealdb_params.mdx" />


# Weaviate
Source: https://docs.agno.com/reference/vector_db/weaviate



<Snippet file="vector-db-weaviate-reference.mdx" />


# Conditional Steps
Source: https://docs.agno.com/reference/workflows/conditional-steps



| Parameter     | Type                                                                               | Default  | Description                                   |
| ------------- | ---------------------------------------------------------------------------------- | -------- | --------------------------------------------- |
| `evaluator`   | `Union[Callable[[StepInput], bool], Callable[[StepInput], Awaitable[bool]], bool]` | Required | Function or boolean to evaluate the condition |
| `steps`       | `WorkflowSteps`                                                                    | Required | Steps to execute if the condition is met      |
| `name`        | `Optional[str]`                                                                    | `None`   | Name of the condition step                    |
| `description` | `Optional[str]`                                                                    | `None`   | Description of the condition step             |


# Loop Steps
Source: https://docs.agno.com/reference/workflows/loop-steps



| Parameter        | Type                                                                                                 | Default  | Description                                 |
| ---------------- | ---------------------------------------------------------------------------------------------------- | -------- | ------------------------------------------- |
| `steps`          | `WorkflowSteps`                                                                                      | Required | Steps to execute in each loop iteration     |
| `name`           | `Optional[str]`                                                                                      | `None`   | Name of the loop step                       |
| `description`    | `Optional[str]`                                                                                      | `None`   | Description of the loop step                |
| `max_iterations` | `int`                                                                                                | `3`      | Maximum number of iterations for the loop   |
| `end_condition`  | `Optional[Union[Callable[[List[StepOutput]], bool], Callable[[List[StepOutput]], Awaitable[bool]]]]` | `None`   | Function to evaluate if the loop should end |


# Parallel Steps
Source: https://docs.agno.com/reference/workflows/parallel-steps



| Parameter     | Type             | Default  | Description                                     |
| ------------- | ---------------- | -------- | ----------------------------------------------- |
| `*steps`      | `*WorkflowSteps` | Required | Variable number of steps to execute in parallel |
| `name`        | `Optional[str]`  | `None`   | Name of the parallel execution block            |
| `description` | `Optional[str]`  | `None`   | Description of the parallel execution           |


# Router Steps
Source: https://docs.agno.com/reference/workflows/router-steps



| Parameter     | Type                                                                                                                                                   | Default  | Description                                                                   |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | -------- | ----------------------------------------------------------------------------- |
| `selector`    | `Union[Callable[[StepInput], Union[WorkflowSteps, List[WorkflowSteps]]], Callable[[StepInput], Awaitable[Union[WorkflowSteps, List[WorkflowSteps]]]]]` | Required | Function to select steps dynamically (supports both sync and async functions) |
| `choices`     | `WorkflowSteps`                                                                                                                                        | Required | Available steps for selection                                                 |
| `name`        | `Optional[str]`                                                                                                                                        | `None`   | Name of the router step                                                       |
| `description` | `Optional[str]`                                                                                                                                        | `None`   | Description of the router step                                                |


# Step
Source: https://docs.agno.com/reference/workflows/step



| Parameter         | Type                     | Default | Description                                                     |
| ----------------- | ------------------------ | ------- | --------------------------------------------------------------- |
| `name`            | `Optional[str]`          | `None`  | Name of the step for identification                             |
| `agent`           | `Optional[Agent]`        | `None`  | Agent to execute for this step                                  |
| `team`            | `Optional[Team]`         | `None`  | Team to execute for this step                                   |
| `executor`        | `Optional[StepExecutor]` | `None`  | Custom function to execute for this step                        |
| `step_id`         | `Optional[str]`          | `None`  | Unique identifier for the step (auto-generated if not provided) |
| `description`     | `Optional[str]`          | `None`  | Description of the step's purpose                               |
| `max_retries`     | `int`                    | `3`     | Maximum number of retry attempts on failure                     |
| `timeout_seconds` | `Optional[int]`          | `None`  | Timeout for step execution in seconds                           |
| `skip_on_failure` | `bool`                   | `False` | Whether to skip this step if it fails after all retries         |


# StepInput
Source: https://docs.agno.com/reference/workflows/step_input



| Parameter               | Type                                                         | Description                                                                |
| ----------------------- | ------------------------------------------------------------ | -------------------------------------------------------------------------- |
| `input`                 | `Optional[Union[str, Dict[str, Any], List[Any], BaseModel]]` | Primary input message (can be any format)                                  |
| `previous_step_content` | `Optional[Any]`                                              | Content from the last step                                                 |
| `previous_step_outputs` | `Optional[Dict[str, StepOutput]]`                            | All previous step outputs by name                                          |
| `additional_data`       | `Optional[Dict[str, Any]]`                                   | Additional context data                                                    |
| `images`                | `Optional[List[Image]]`                                      | Media inputs - images (accumulated from workflow input and previous steps) |
| `videos`                | `Optional[List[Video]]`                                      | Media inputs - videos (accumulated from workflow input and previous steps) |
| `audio`                 | `Optional[List[Audio]]`                                      | Media inputs - audio (accumulated from workflow input and previous steps)  |
| `files`                 | `Optional[List[File]]`                                       | File inputs (accumulated from workflow input and previous steps)           |

## Helper Functions

| Method                             | Return Type                            | Description                                                     |
| ---------------------------------- | -------------------------------------- | --------------------------------------------------------------- |
| `get_step_output(step_name: str)`  | `Optional[StepOutput]`                 | Get the complete StepOutput object from a specific step by name |
| `get_step_content(step_name: str)` | `Optional[Union[str, Dict[str, str]]]` | Get content from a specific step by name                        |
| `get_all_previous_content()`       | `str`                                  | Get all previous step content combined                          |
| `get_last_step_content()`          | `Optional[str]`                        | Get content from the immediate previous step                    |


# StepOutput
Source: https://docs.agno.com/reference/workflows/step_output



| Parameter       | Type                                                              | Default | Description                                                     |
| --------------- | ----------------------------------------------------------------- | ------- | --------------------------------------------------------------- |
| `step_name`     | `Optional[str]`                                                   | `None`  | Step identification name                                        |
| `step_id`       | `Optional[str]`                                                   | `None`  | Unique step identifier                                          |
| `step_type`     | `Optional[str]`                                                   | `None`  | Type of step (e.g., "Loop", "Condition", "Parallel")            |
| `executor_type` | `Optional[str]`                                                   | `None`  | Type of executor: "agent", "team", or "function"                |
| `executor_name` | `Optional[str]`                                                   | `None`  | Name of the executor                                            |
| `content`       | `Optional[Union[str, Dict[str, Any], List[Any], BaseModel, Any]]` | `None`  | Primary output (can be any format)                              |
| `step_run_id`   | `Optional[str]`                                                   | `None`  | Link to the run ID of the step execution                        |
| `images`        | `Optional[List[Image]]`                                           | `None`  | Media outputs - images (new or passed-through)                  |
| `videos`        | `Optional[List[Video]]`                                           | `None`  | Media outputs - videos (new or passed-through)                  |
| `audio`         | `Optional[List[Audio]]`                                           | `None`  | Media outputs - audio (new or passed-through)                   |
| `files`         | `Optional[List[File]]`                                            | `None`  | File outputs (new or passed-through)                            |
| `metrics`       | `Optional[Metrics]`                                               | `None`  | Execution metrics and metadata                                  |
| `success`       | `bool`                                                            | `True`  | Execution success status                                        |
| `error`         | `Optional[str]`                                                   | `None`  | Error message if execution failed                               |
| `stop`          | `bool`                                                            | `False` | Request early workflow termination                              |
| `steps`         | `Optional[List[StepOutput]]`                                      | `None`  | Nested step outputs for composite steps (Loop, Condition, etc.) |


# Steps
Source: https://docs.agno.com/reference/workflows/steps-step



| Parameter     | Type                  | Default | Description                                                        |
| ------------- | --------------------- | ------- | ------------------------------------------------------------------ |
| `name`        | `Optional[str]`       | `None`  | Name of the steps group for identification                         |
| `description` | `Optional[str]`       | `None`  | Description of the steps group's purpose                           |
| `steps`       | `Optional[List[Any]]` | `[]`    | List of steps to execute sequentially (empty list if not provided) |


# Workflow
Source: https://docs.agno.com/reference/workflows/workflow



## Parameters

| Parameter                   | Type                                                              | Default | Description                                                                          |
| --------------------------- | ----------------------------------------------------------------- | ------- | ------------------------------------------------------------------------------------ |
| `name`                      | `Optional[str]`                                                   | `None`  | Workflow name                                                                        |
| `id`                        | `Optional[str]`                                                   | `None`  | Workflow ID (autogenerated if not set)                                               |
| `description`               | `Optional[str]`                                                   | `None`  | Workflow description                                                                 |
| `steps`                     | `Optional[WorkflowSteps]`                                         | `None`  | Workflow steps - can be a callable function, Steps object, or list of steps          |
| `db`                        | `Optional[BaseDb]`                                                | `None`  | Database to use for this workflow                                                    |
| `session_id`                | `Optional[str]`                                                   | `None`  | Default session\_id to use for this workflow (autogenerated if not set)              |
| `user_id`                   | `Optional[str]`                                                   | `None`  | Default user\_id to use for this workflow                                            |
| `session_state`             | `Optional[Dict[str, Any]]`                                        | `None`  | Default session state (stored in the database to persist across runs)                |
| `debug_mode`                | `Optional[bool]`                                                  | `False` | If True, the workflow runs in debug mode                                             |
| `stream`                    | `Optional[bool]`                                                  | `None`  | Stream the response from the Workflow                                                |
| `stream_intermediate_steps` | `bool`                                                            | `False` | Stream the intermediate steps from the Workflow                                      |
| `store_events`              | `bool`                                                            | `False` | Persist the events on the run response                                               |
| `events_to_skip`            | `Optional[List[Union[WorkflowRunEvent, RunEvent, TeamRunEvent]]]` | `None`  | Events to skip when persisting the events on the run response                        |
| `store_executor_outputs`    | `bool`                                                            | `True`  | Control whether to store executor responses (agent/team responses) in flattened runs |
| `websocket_handler`         | `Optional[WebSocketHandler]`                                      | `None`  | WebSocket handler for real-time communication                                        |
| `input_schema`              | `Optional[Type[BaseModel]]`                                       | `None`  | Input schema to validate the input to the workflow                                   |
| `metadata`                  | `Optional[Dict[str, Any]]`                                        | `None`  | Metadata stored with this workflow                                                   |
| `cache_session`             | `bool`                                                            | `False` | If True, cache the current workflow session in memory for faster access              |
| `telemetry`                 | `bool`                                                            | `True`  | Log minimal telemetry for analytics                                                  |

## Functions

### `run`

Execute the workflow synchronously with optional streaming.

**Parameters:**

* `input` (Optional\[Union\[str, Dict\[str, Any], List\[Any], BaseModel]]): The input to send to the workflow
* `additional_data` (Optional\[Dict\[str, Any]]): Additional data to include with the input
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `audio` (Optional\[List\[Audio]]): Audio files to include
* `images` (Optional\[List\[Image]]): Image files to include
* `videos` (Optional\[List\[Video]]): Video files to include
* `files` (Optional\[List\[File]]): Files to include
* `stream` (bool): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps

**Returns:**

* `Union[WorkflowRunOutput, Iterator[WorkflowRunOutputEvent]]`: Either a WorkflowRunOutput or an iterator of WorkflowRunOutputEvents, depending on the `stream` parameter

### `arun`

Execute the workflow asynchronously with optional streaming.

**Parameters:**

* `input` (Optional\[Union\[str, Dict\[str, Any], List\[Any], BaseModel, List\[Message]]]): The input to send to the workflow
* `additional_data` (Optional\[Dict\[str, Any]]): Additional data to include with the input
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `session_state` (Optional\[Dict\[str, Any]]): Session state to use
* `audio` (Optional\[List\[Audio]]): Audio files to include
* `images` (Optional\[List\[Image]]): Image files to include
* `videos` (Optional\[List\[Video]]): Video files to include
* `files` (Optional\[List\[File]]): Files to include
* `stream` (bool): Whether to stream the response
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `background` (Optional\[bool]): Whether to run in background
* `websocket` (Optional\[WebSocket]): WebSocket for real-time communication

**Returns:**

* `Union[WorkflowRunOutput, AsyncIterator[WorkflowRunOutputEvent]]`: Either a WorkflowRunOutput or an iterator of WorkflowRunOutputEvents, depending on the `stream` parameter

### `print_response`

Print workflow execution with rich formatting and optional streaming.

**Parameters:**

* `input` (Union\[str, Dict\[str, Any], List\[Any], BaseModel, List\[Message]]): The input to send to the workflow
* `additional_data` (Optional\[Dict\[str, Any]]): Additional data to include with the input
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `audio` (Optional\[List\[Audio]]): Audio files to include
* `images` (Optional\[List\[Image]]): Image files to include
* `videos` (Optional\[List\[Video]]): Video files to include
* `files` (Optional\[List\[File]]): Files to include
* `stream` (Optional\[bool]): Whether to stream the response content
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `markdown` (bool): Whether to render content as markdown
* `show_time` (bool): Whether to show execution time
* `show_step_details` (bool): Whether to show individual step outputs
* `console` (Optional\[Any]): Rich console instance (optional)

### `aprint_response`

Print workflow execution with rich formatting and optional streaming asynchronously.

**Parameters:**

* `input` (Union\[str, Dict\[str, Any], List\[Any], BaseModel, List\[Message]]): The input to send to the workflow
* `additional_data` (Optional\[Dict\[str, Any]]): Additional data to include with the input
* `user_id` (Optional\[str]): User ID to use
* `session_id` (Optional\[str]): Session ID to use
* `audio` (Optional\[List\[Audio]]): Audio files to include
* `images` (Optional\[List\[Image]]): Image files to include
* `videos` (Optional\[List\[Video]]): Video files to include
* `files` (Optional\[List\[File]]): Files to include
* `stream` (Optional\[bool]): Whether to stream the response content
* `stream_intermediate_steps` (Optional\[bool]): Whether to stream intermediate steps
* `markdown` (bool): Whether to render content as markdown
* `show_time` (bool): Whether to show execution time
* `show_step_details` (bool): Whether to show individual step outputs
* `console` (Optional\[Any]): Rich console instance (optional)

### `cancel_run`

Cancel a running workflow execution.

**Parameters:**

* `run_id` (str): The run\_id to cancel

**Returns:**

* `bool`: True if the run was found and marked for cancellation, False otherwise

### `get_run`

Get the status and details of a background workflow run.

**Parameters:**

* `run_id` (str): The run ID to get

**Returns:**

* `Optional[WorkflowRunOutput]`: The workflow run output if found

### `get_run_output`

Get a WorkflowRunOutput from the database.

**Parameters:**

* `run_id` (str): The run ID
* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `Optional[WorkflowRunOutput]`: The run output

### `get_last_run_output`

Get the last run response from the database for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `Optional[WorkflowRunOutput]`: The last run output

### `get_session`

Get the session for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `Optional[WorkflowSession]`: The workflow session

### `get_session_state`

Get the session state for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `Dict[str, Any]`: The session state

### `get_session_name`

Get the session name for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `str`: The session name

### `set_session_name`

Set the session name and save to storage.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use
* `autogenerate` (bool): Whether to autogenerate the name
* `session_name` (Optional\[str]): The name to set

**Returns:**

* `WorkflowSession`: The updated session

### `get_session_metrics`

Get the session metrics for the given session ID.

**Parameters:**

* `session_id` (Optional\[str]): Session ID to use

**Returns:**

* `Optional[Metrics]`: The session metrics

### `delete_session`

Delete a session.

**Parameters:**

* `session_id` (str): Session ID to delete

### `save_session`

Save the WorkflowSession to storage.

**Parameters:**

* `session` (WorkflowSession): The session to save

### `to_dict`

Convert workflow to dictionary representation.

**Returns:**

* `Dict[str, Any]`: Dictionary representation of the workflow


# WorkflowRunOutput
Source: https://docs.agno.com/reference/workflows/workflow_run_output



## WorkflowRunOutput Attributes

| Parameter            | Type                                                              | Default             | Description                                                           |
| -------------------- | ----------------------------------------------------------------- | ------------------- | --------------------------------------------------------------------- |
| `content`            | `Optional[Union[str, Dict[str, Any], List[Any], BaseModel, Any]]` | `None`              | Main content/output from the workflow execution                       |
| `content_type`       | `str`                                                             | `"str"`             | Type of the content (e.g., "str", "json", etc.)                       |
| `workflow_id`        | `Optional[str]`                                                   | `None`              | Unique identifier of the executed workflow                            |
| `workflow_name`      | `Optional[str]`                                                   | `None`              | Name of the executed workflow                                         |
| `run_id`             | `Optional[str]`                                                   | `None`              | Unique identifier for this specific run                               |
| `session_id`         | `Optional[str]`                                                   | `None`              | Session UUID associated with this run                                 |
| `images`             | `Optional[List[Image]]`                                           | `None`              | List of image artifacts generated                                     |
| `videos`             | `Optional[List[Video]]`                                           | `None`              | List of video artifacts generated                                     |
| `audio`              | `Optional[List[Audio]]`                                           | `None`              | List of audio artifacts generated                                     |
| `response_audio`     | `Optional[Audio]`                                                 | `None`              | Audio response from the workflow                                      |
| `step_results`       | `List[Union[StepOutput, List[StepOutput]]]`                       | `[]`                | Actual step execution results as StepOutput objects                   |
| `step_executor_runs` | `Optional[List[Union[RunOutput, TeamRunOutput]]]`                 | `None`              | Store agent/team responses separately with parent\_run\_id references |
| `events`             | `Optional[List[WorkflowRunOutputEvent]]`                          | `None`              | Events captured during workflow execution                             |
| `metrics`            | `Optional[WorkflowMetrics]`                                       | `None`              | Workflow metrics aggregated from all steps                            |
| `metadata`           | `Optional[Dict[str, Any]]`                                        | `None`              | Additional metadata stored with the response                          |
| `created_at`         | `int`                                                             | `int(time())`       | Unix timestamp when the response was created                          |
| `status`             | `RunStatus`                                                       | `RunStatus.pending` | Current status of the workflow run                                    |

## WorkflowRunOutputEvent Types and Attributes

### BaseWorkflowRunOutputEvent Attributes

| Parameter        | Type            | Default       | Description                                              |
| ---------------- | --------------- | ------------- | -------------------------------------------------------- |
| `created_at`     | `int`           | `int(time())` | Unix timestamp when the event was created                |
| `event`          | `str`           | `""`          | Type of the event (e.g., "WorkflowStarted")              |
| `workflow_id`    | `Optional[str]` | `None`        | Unique identifier of the workflow                        |
| `workflow_name`  | `Optional[str]` | `None`        | Name of the workflow                                     |
| `session_id`     | `Optional[str]` | `None`        | Session UUID associated with the workflow                |
| `run_id`         | `Optional[str]` | `None`        | Unique identifier for the workflow run                   |
| `step_id`        | `Optional[str]` | `None`        | Unique identifier for the current step                   |
| `parent_step_id` | `Optional[str]` | `None`        | Unique identifier for the parent step (for nested steps) |

### WorkflowStartedEvent Attributes

| Parameter                                               | Type  | Default                                   | Description           |
| ------------------------------------------------------- | ----- | ----------------------------------------- | --------------------- |
| `event`                                                 | `str` | `WorkflowRunEvent.workflow_started.value` | Event type identifier |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |       |                                           |                       |

### WorkflowCompletedEvent Attributes

<Snippet file="workflow-completed-event.mdx" />

### WorkflowCancelledEvent Attributes

| Parameter                                               | Type                       | Default                                     | Description                                 |
| ------------------------------------------------------- | -------------------------- | ------------------------------------------- | ------------------------------------------- |
| `event`                                                 | `str`                      | `WorkflowRunEvent.workflow_completed.value` | Event type identifier                       |
| `content`                                               | `Optional[Any]`            | `None`                                      | Final output content from the workflow      |
| `content_type`                                          | `str`                      | `"str"`                                     | Type of the content                         |
| `step_results`                                          | `List[StepOutput]`         | `[]`                                        | List of all step execution results          |
| `metadata`                                              | `Optional[Dict[str, Any]]` | `None`                                      | Additional metadata from workflow execution |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                            |                                             |                                             |

### StepStartedEvent Attributes

| Parameter                                               | Type                          | Default                               | Description                    |
| ------------------------------------------------------- | ----------------------------- | ------------------------------------- | ------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.step_started.value` | Event type identifier          |
| `step_name`                                             | `Optional[str]`               | `None`                                | Name of the step being started |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                | Index or position of the step  |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                       |                                |

### StepCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                 | Description                           |
| ------------------------------------------------------- | ----------------------------- | --------------------------------------- | ------------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.step_completed.value` | Event type identifier                 |
| `step_name`                                             | `Optional[str]`               | `None`                                  | Name of the step that completed       |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                  | Index or position of the step         |
| `content`                                               | `Optional[Any]`               | `None`                                  | Content output from the step          |
| `content_type`                                          | `str`                         | `"str"`                                 | Type of the content                   |
| `images`                                                | `Optional[List[Image]]`       | `None`                                  | Image artifacts from the step         |
| `videos`                                                | `Optional[List[Video]]`       | `None`                                  | Video artifacts from the step         |
| `audio`                                                 | `Optional[List[Audio]]`       | `None`                                  | Audio artifacts from the step         |
| `response_audio`                                        | `Optional[Audio]`             | `None`                                  | Audio response from the step          |
| `step_response`                                         | `Optional[StepOutput]`        | `None`                                  | Complete step execution result object |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                         |                                       |

### ConditionExecutionStartedEvent Attributes

| Parameter                                               | Type                          | Default                                              | Description                        |
| ------------------------------------------------------- | ----------------------------- | ---------------------------------------------------- | ---------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.condition_execution_started.value` | Event type identifier              |
| `step_name`                                             | `Optional[str]`               | `None`                                               | Name of the condition step         |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                               | Index or position of the condition |
| `condition_result`                                      | `Optional[bool]`              | `None`                                               | Result of the condition evaluation |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                      |                                    |

### ConditionExecutionCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                                | Description                                 |
| ------------------------------------------------------- | ----------------------------- | ------------------------------------------------------ | ------------------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.condition_execution_completed.value` | Event type identifier                       |
| `step_name`                                             | `Optional[str]`               | `None`                                                 | Name of the condition step                  |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                                 | Index or position of the condition          |
| `condition_result`                                      | `Optional[bool]`              | `None`                                                 | Result of the condition evaluation          |
| `executed_steps`                                        | `Optional[int]`               | `None`                                                 | Number of steps executed based on condition |
| `step_results`                                          | `List[StepOutput]`            | `[]`                                                   | Results from executed steps                 |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                        |                                             |

### ParallelExecutionStartedEvent Attributes

| Parameter                                               | Type                          | Default                                             | Description                            |
| ------------------------------------------------------- | ----------------------------- | --------------------------------------------------- | -------------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.parallel_execution_started.value` | Event type identifier                  |
| `step_name`                                             | `Optional[str]`               | `None`                                              | Name of the parallel step              |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                              | Index or position of the parallel step |
| `parallel_step_count`                                   | `Optional[int]`               | `None`                                              | Number of steps to execute in parallel |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                     |                                        |

### ParallelExecutionCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                               | Description                            |
| ------------------------------------------------------- | ----------------------------- | ----------------------------------------------------- | -------------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.parallel_execution_completed.value` | Event type identifier                  |
| `step_name`                                             | `Optional[str]`               | `None`                                                | Name of the parallel step              |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                                | Index or position of the parallel step |
| `parallel_step_count`                                   | `Optional[int]`               | `None`                                                | Number of steps executed in parallel   |
| `step_results`                                          | `List[StepOutput]`            | `field(default_factory=list)`                         | Results from all parallel steps        |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                       |                                        |

### LoopExecutionStartedEvent Attributes

| Parameter                                               | Type                          | Default                                         | Description                          |
| ------------------------------------------------------- | ----------------------------- | ----------------------------------------------- | ------------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.loop_execution_started.value` | Event type identifier                |
| `step_name`                                             | `Optional[str]`               | `None`                                          | Name of the loop step                |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                          | Index or position of the loop        |
| `max_iterations`                                        | `Optional[int]`               | `None`                                          | Maximum number of iterations allowed |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                 |                                      |

### LoopIterationStartedEvent Attributes

| Parameter                                               | Type                          | Default                                         | Description                          |
| ------------------------------------------------------- | ----------------------------- | ----------------------------------------------- | ------------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.loop_iteration_started.value` | Event type identifier                |
| `step_name`                                             | `Optional[str]`               | `None`                                          | Name of the loop step                |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                          | Index or position of the loop        |
| `iteration`                                             | `int`                         | `0`                                             | Current iteration number             |
| `max_iterations`                                        | `Optional[int]`               | `None`                                          | Maximum number of iterations allowed |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                 |                                      |

### LoopIterationCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                           | Description                          |
| ------------------------------------------------------- | ----------------------------- | ------------------------------------------------- | ------------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.loop_iteration_completed.value` | Event type identifier                |
| `step_name`                                             | `Optional[str]`               | `None`                                            | Name of the loop step                |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                            | Index or position of the loop        |
| `iteration`                                             | `int`                         | `0`                                               | Current iteration number             |
| `max_iterations`                                        | `Optional[int]`               | `None`                                            | Maximum number of iterations allowed |
| `iteration_results`                                     | `List[StepOutput]`            | `[]`                                              | Results from this iteration          |
| `should_continue`                                       | `bool`                        | `True`                                            | Whether the loop should continue     |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                   |                                      |

### LoopExecutionCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                           | Description                          |
| ------------------------------------------------------- | ----------------------------- | ------------------------------------------------- | ------------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.loop_execution_completed.value` | Event type identifier                |
| `step_name`                                             | `Optional[str]`               | `None`                                            | Name of the loop step                |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                            | Index or position of the loop        |
| `total_iterations`                                      | `int`                         | `0`                                               | Total number of iterations completed |
| `max_iterations`                                        | `Optional[int]`               | `None`                                            | Maximum number of iterations allowed |
| `all_results`                                           | `List[List[StepOutput]]`      | `[]`                                              | Results from all iterations          |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                   |                                      |

### RouterExecutionStartedEvent Attributes

| Parameter                                               | Type                          | Default                                           | Description                           |
| ------------------------------------------------------- | ----------------------------- | ------------------------------------------------- | ------------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.router_execution_started.value` | Event type identifier                 |
| `step_name`                                             | `Optional[str]`               | `None`                                            | Name of the router step               |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                            | Index or position of the router       |
| `selected_steps`                                        | `List[str]`                   | `field(default_factory=list)`                     | Names of steps selected by the router |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                   |                                       |

### RouterExecutionCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                             | Description                       |
| ------------------------------------------------------- | ----------------------------- | --------------------------------------------------- | --------------------------------- |
| `event`                                                 | `str`                         | `WorkflowRunEvent.router_execution_completed.value` | Event type identifier             |
| `step_name`                                             | `Optional[str]`               | `None`                                              | Name of the router step           |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                              | Index or position of the router   |
| `selected_steps`                                        | `List[str]`                   | `field(default_factory=list)`                       | Names of steps that were selected |
| `executed_steps`                                        | `Optional[int]`               | `None`                                              | Number of steps executed          |
| `step_results`                                          | `List[StepOutput]`            | `field(default_factory=list)`                       | Results from executed steps       |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                     |                                   |

### StepsExecutionStartedEvent Attributes

| Parameter                                               | Type                          | Default                                          | Description                          |
| ------------------------------------------------------- | ----------------------------- | ------------------------------------------------ | ------------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.steps_execution_started.value` | Event type identifier                |
| `step_name`                                             | `Optional[str]`               | `None`                                           | Name of the steps group              |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                           | Index or position of the steps group |
| `steps_count`                                           | `Optional[int]`               | `None`                                           | Number of steps in the group         |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                  |                                      |

### StepsExecutionCompletedEvent Attributes

| Parameter                                               | Type                          | Default                                            | Description                          |
| ------------------------------------------------------- | ----------------------------- | -------------------------------------------------- | ------------------------------------ |
| `event`                                                 | `str`                         | `WorkflowRunEvent.steps_execution_completed.value` | Event type identifier                |
| `step_name`                                             | `Optional[str]`               | `None`                                             | Name of the steps group              |
| `step_index`                                            | `Optional[Union[int, tuple]]` | `None`                                             | Index or position of the steps group |
| `steps_count`                                           | `Optional[int]`               | `None`                                             | Number of steps in the group         |
| `executed_steps`                                        | `Optional[int]`               | `None`                                             | Number of steps actually executed    |
| `step_results`                                          | `List[StepOutput]`            | `field(default_factory=list)`                      | Results from all executed steps      |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                               |                                                    |                                      |

### StepOutputEvent Attributes

| Parameter                                               | Type                                                              | Default        | Description                                  |
| ------------------------------------------------------- | ----------------------------------------------------------------- | -------------- | -------------------------------------------- |
| `event`                                                 | `str`                                                             | `"StepOutput"` | Event type identifier                        |
| `step_name`                                             | `Optional[str]`                                                   | `None`         | Name of the step that produced output        |
| `step_index`                                            | `Optional[Union[int, tuple]]`                                     | `None`         | Index or position of the step                |
| `step_output`                                           | `Optional[StepOutput]`                                            | `None`         | Complete step execution result               |
| *Inherits all fields from `BaseWorkflowRunOutputEvent`* |                                                                   |                |                                              |
| **Properties (read-only):**                             |                                                                   |                |                                              |
| `content`                                               | `Optional[Union[str, Dict[str, Any], List[Any], BaseModel, Any]]` | -              | Content from the step output                 |
| `images`                                                | `Optional[List[Image]]`                                           | -              | Images from the step output                  |
| `videos`                                                | `Optional[List[Video]]`                                           | -              | Videos from the step output                  |
| `audio`                                                 | `Optional[List[Audio]]`                                           | -              | Audio from the step output                   |
| `success`                                               | `bool`                                                            | -              | Whether the step succeeded                   |
| `error`                                                 | `Optional[str]`                                                   | -              | Error message if step failed                 |
| `stop`                                                  | `bool`                                                            | -              | Whether the step requested early termination |


# Agent Infra AWS
Source: https://docs.agno.com/templates/agent-infra-aws/introduction



The Agent Infra AWS template provides a simple AWS infrastructure for running AgentOS. It contains:

* An AgentOS instance, serving Agents, Teams, Workflows and utilities using FastAPI.
* A PostgreSQL database for storing sessions, memories and knowledge.

You can run your Agent Infra AWS locally as well as on AWS. This guide goes over the local setup first.

<Snippet file="setup.mdx" />

<Snippet file="create-agent-infra-aws-codebase.mdx" />

<Snippet file="run-agent-infra-aws-local.mdx" />

## Next

Congratulations on running your Agent Infra AWS locally. Next Steps:

* [Run your Agent API on AWS](/workspaces/agent-api/aws)
* Read how to [update workspace settings](/workspaces/workspace-management/workspace-settings)
* Read how to [create a git repository for your workspace](/workspaces/workspace-management/git-repo)
* Read how to [manage the development application](/workspaces/workspace-management/development-app)
* Read how to [format and validate your code](/workspaces/workspace-management/format-and-validate)
* Read how to [add python libraries](/workspaces/workspace-management/install)
* Chat with us on [discord](https://agno.link/discord)


# Agent Infra Docker
Source: https://docs.agno.com/templates/agent-infra-docker/introduction



The Agent Infra Docker template provides a simple Docker Compose file for running AgentOS. It contains:

* An AgentOS instance, serving Agents, Teams, Workflows and utilities using FastAPI.
* A PostgreSQL database for storing sessions, memories and knowledge.

<Snippet file="setup.mdx" />

<Snippet file="create-agent-infra-docker-codebase.mdx" />

<Snippet file="run-agent-infra-docker-local.mdx" />


# CI/CD
Source: https://docs.agno.com/templates/infra-management/ci-cd



Agno templates come pre-configured with [Github Actions](https://docs.github.com/en/actions) for CI/CD. We can

1. [Test and Validate on every PR](#test-and-validate-on-every-pr)
2. [Build Docker Images with Github Releases](#build-docker-images-with-github-releases)
3. [Build ECR Images with Github Releases](#build-ecr-images-with-github-releases)

## Test and Validate on every PR

Whenever a PR is opened against the `main` branch, a validate script runs that ensures

1. The changes are formatted using ruff
2. All unit-tests pass
3. The changes don't have any typing or linting errors.

Checkout the `.github/workflows/validate.yml` file for more information.

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=01d9c697e3f87a8248fa8daa6fac3922" alt="validate-cicd" data-og-width="940" width="940" data-og-height="353" height="353" data-path="images/validate-cicd.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=e8bf732e3895a4377b65766816624fc5 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=5dd89160c72ebf2f088d75bd8dfe52dc 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=8a27817ed129343cad278184145eb5ee 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=eb51747558d308ee09444057ba4f7f85 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=57ed9ba5331f3170a62cdfe304d9c05d 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/validate-cicd.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=6b995305ffe38e39b14bbe7ef18ce4ba 2500w" />

## Build Docker Images with Github Releases

If you're using [Dockerhub](https://hub.docker.com/) for images, you can buld and push the images throug a Github Release. This action is defined in the `.github/workflows/docker-images.yml` file.

1. Create a [Docker Access Token](https://hub.docker.com/settings/security) for Github Actions

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=870118e1906c093108643eceaaf577e6" alt="docker-access-token" data-og-width="742" width="742" data-og-height="568" height="568" data-path="images/docker-access-token.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=44ecd6f45c24f63b65c47d63d5dda04e 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7010dc82d6907e7a0e4c9b727a5b1f14 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=f35b57f4d86867cd143d00861e9a188d 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=ae91c75b8692c79f3f67b7c949a87305 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=ce6d88dc5073bcbb6ec943c2ff9f1750 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/docker-access-token.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c730143dfa3232d2daffbe8f04b77eb1 2500w" />

2. Create secret variables `DOCKERHUB_REPO`, `DOCKERHUB_TOKEN` and `DOCKERHUB_USERNAME` in your github repo. These variables are used by the action in `.github/workflows/docker-images.yml`

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=70015ffb61a3816c45806f85c8c44877" alt="github-actions-docker-secrets" data-og-width="1143" width="1143" data-og-height="822" height="822" data-path="images/github-actions-docker-secrets.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=98a34ba0df0ee5fa4ad3ed51852978d1 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=025950971a2df62fd409c74a6bf265df 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=fdb266b2ef9b01200bbf0704a607af87 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=3a78c11b5d5fe0e1294bdea54fd03004 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=e37288626fd82e5fa083c0bc48cf00c9 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-docker-secrets.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=f854830e5040e368d1154389162e173e 2500w" />

3. Run workflow using a Github Release

This workflow is configured to run when a release is created. Create a new release using:

<Note>
  Confirm the image name in the `.github/workflows/docker-images.yml` file before running
</Note>

<CodeGroup>
  ```bash Mac
  gh release create v0.1.0 --title "v0.1.0" -n ""
  ```

  ```bash Windows
  gh release create v0.1.0 --title "v0.1.0" -n ""
  ```
</CodeGroup>

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2f96812f7b12f8e1f9d831152556c5d7" alt="github-actions-build-docker" data-og-width="1042" width="1042" data-og-height="732" height="732" data-path="images/github-actions-build-docker.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=ec6400a97ff55a3a44da52d9e53473ca 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=6568fab440d3f4794aecce651f2a3a0e 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c88fbcfbeb5e647b45e56d064c8066b6 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c7d8bc7f1d25a8167dcbe7920bfca3e6 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=ab0a319474f8e5380c2dc9740715b916 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-docker.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0a29ea2ec1f152a8142a2988768316da 2500w" />

<Note>
  You can also run the workflow using `gh workflow run`
</Note>

## Build ECR Images with Github Releases

If you're using ECR for images, you can buld and push the images through a Github Release. This action is defined in the `.github/workflows/ecr-images.yml` file and uses the new OpenID Connect (OIDC) approach to request the access token, without using IAM access keys.

We will follow this [guide](https://aws.amazon.com/blogs/security/use-iam-roles-to-connect-github-actions-to-actions-in-aws/) to create an IAM role which will be used by the github action.

1. Open the IAM console.
2. In the left navigation menu, choose Identity providers.
3. In the Identity providers pane, choose Add provider.
4. For Provider type, choose OpenID Connect.
5. For Provider URL, enter the URL of the GitHub OIDC IdP: [https://token.actions.githubusercontent.com](https://token.actions.githubusercontent.com)
6. Get thumbprint to verify the server certificate
7. For Audience, enter sts.amazonaws.com.

Verify the information matches the screenshot below and Add provider

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=3eda54501351859a9afc8a041dc82139" alt="github-oidc-provider" data-og-width="1125" width="1125" data-og-height="799" height="799" data-path="images/github-oidc-provider.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=4c8f4ac0f7afae5f6c02d105fb827306 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2e714e3b3ef8993d0d0db50b9975eb12 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=96bbb52cb5fd2bd262fcb1d2eb2caf66 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=69a06894592bebeefa2170cdf776f424 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7cf6268657b4073faa5671f6710dcbff 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=ff74cc7bd14c9412ff7f9ef72d069e15 2500w" />

8. Assign a Role to the provider.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=dbd84c74dc15c2dd74311e69afd6a6cd" alt="github-oidc-provider-assign-role" data-og-width="1347" width="1347" data-og-height="587" height="587" data-path="images/github-oidc-provider-assign-role.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=fc0720d26b0176b03192881e0d00d4c7 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=305275efad18dd80e182f7442bfcb292 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0dc5facedf7d84a8e35ad5faa29409e7 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7723cea354fe2bc26fed0bccdf406853 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=9038f7189b3752d863fdb6772d34ceae 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-assign-role.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=e0e20507f59fa7b57970bdd1b187072e 2500w" />

9. Create a new role.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=e7b3d4a069f97ba3dbfe8bc08e8a534f" alt="github-oidc-provider-create-new-role" data-og-width="604" width="604" data-og-height="278" height="278" data-path="images/github-oidc-provider-create-new-role.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=0b0bbe7da72790aeaa23eca25e846e12 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7536bf15de67ff8826aaaaa336d3b2ff 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=65907ad9152fa24dcd1fe791d6a1980d 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7396e3e8f50462a000d5cd3131cf7e94 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=cd64cc43cbf45bf06a66f40db3976251 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-create-new-role.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c8037ba2ea7bfc3e8f03dcb19ed66c9f 2500w" />

10. Confirm that Web identity is already selected as the trusted entity and the Identity provider field is populated with the IdP. In the Audience list, select sts.amazonaws.com, and then select Next.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=3fe69db526ec7276382189d8d063561f" alt="github-oidc-provider-trusted-entity" data-og-width="1300" width="1300" data-og-height="934" height="934" data-path="images/github-oidc-provider-trusted-entity.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=1eb0d8ae46efdbb4f0ce072de01a4287 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a54123b0b191d9587345115f28a5c2e2 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=74e9c6b7764f1ee331fc692808e898d0 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a8d61a562ca252b89940f25c67e94c4c 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c2904811b03b257358ba3578dc0a4c8e 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-provider-trusted-entity.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=cd5780393d9adde78a009499ef3ba6bf 2500w" />

11. Add the `AmazonEC2ContainerRegistryPowerUser` permission to this role.

12. Create the role with the name `GithubActionsRole`.

13. Find the role `GithubActionsRole` and copy the ARN.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=ff1efeba61931aa435c13062d91a8f0b" alt="github-oidc-role" data-og-width="1389" width="1389" data-og-height="710" height="710" data-path="images/github-oidc-role.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=1c1afadf6e661558e3cc861e2353a38d 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2231af7fff49341e8393eb7b49b610b1 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=43d85fdcd8f72dbe0ed7948a95793d38 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=f05dc967abe03969118e755451c43a4a 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=b5e1b433d11d461a5fc24c8b14e6bc91 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-oidc-role.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=8b7072639f56d42f00d00b8b735cb375 2500w" />

14. Create the ECR Repositories: `llm` and `jupyter-llm` which are built by the workflow.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c68ceb3a9b6784fd519cc04b0e38caf1" alt="create-ecr-image" data-og-width="1389" width="1389" data-og-height="408" height="408" data-path="images/create-ecr-image.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2ce02d48da7e53a6c335736a17ebec6e 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=f0b4d1687849a637c0a595c4a8d0690a 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=26b1f13eb8b6f9b09a06b9e6bb1eeb27 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=e53f084201341a7c92738fa62efdb64c 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c9e2477e1befaf12f81d4d345dac5a26 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a22af7830053ba9139cfb6d0d4017d4a 2500w" />

15. Update the workflow with the `GithubActionsRole` ARN and ECR Repository.

```yaml .github/workflows/ecr-images.yml
name: Build ECR Images

on:
  release:
    types: [published]

permissions:
  # For AWS OIDC Token access as per https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services#updating-your-github-actions-workflow
  id-token: write # This is required for requesting the JWT
  contents: read # This is required for actions/checkout

env:
  ECR_REPO: [YOUR_ECR_REPO]
  # Create role using https://aws.amazon.com/blogs/security/use-iam-roles-to-connect-github-actions-to-actions-in-aws/
  AWS_ROLE: [GITHUB_ACTIONS_ROLE_ARN]
  AWS_REGION: us-east-1
```

16. Update the `docker-images` workflow to **NOT** run on a release

```yaml .github/workflows/docker-images.yml
name: Build Docker Images

on: workflow_dispatch
```

17. Run workflow using a Github Release

<CodeGroup>
  ```bash Mac
  gh release create v0.2.0 --title "v0.2.0" -n ""
  ```

  ```bash Windows
  gh release create v0.2.0 --title "v0.2.0" -n ""
  ```
</CodeGroup>

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=aff1bdde8baea8591770b0f6b5ac036b" alt="github-actions-build-ecr" data-og-width="1389" width="1389" data-og-height="710" height="710" data-path="images/github-actions-build-ecr.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=7440b9e93662a242501bdf7eb37f0620 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a62d3057b07926a447999d1b75a092dd 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=494393ce11efce791ab0d62f19b1b1fb 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2a85f548629bf8dc605f9964f99329fc 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=27878c2ccf71bb63426dc120b9233cd3 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/github-actions-build-ecr.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=9116b3c2eb2bf07b4e8f4c5070e3c1fa 2500w" />

<Note>
  You can also run the workflow using `gh workflow run`
</Note>


# Database Tables
Source: https://docs.agno.com/templates/infra-management/database-tables



Agno templates come pre-configured with [SqlAlchemy](https://www.sqlalchemy.org/) and [alembic](https://alembic.sqlalchemy.org/en/latest/) to manage databases. The general workflow to add a table is:

1. Add table definition to the `db/tables` directory.
2. Import the table class in the `db/tables/__init__.py` file.
3. Create a database migration.
4. Run database migration.

## Table Definition

Let's create a `UsersTable`, copy the following code to `db/tables/user.py`

```python db/tables/user.py
from datetime import datetime
from typing import Optional

from sqlalchemy.orm import Mapped, mapped_column
from sqlalchemy.sql.expression import text
from sqlalchemy.types import BigInteger, DateTime, String

from db.tables.base import Base


class UsersTable(Base):
    """Table for storing user data."""

    __tablename__ = "dim_users"

    id_user: Mapped[int] = mapped_column(
        BigInteger, primary_key=True, autoincrement=True, nullable=False, index=True
    )
    email: Mapped[str] = mapped_column(String)
    is_active: Mapped[bool] = mapped_column(default=True)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=text("now()")
    )
    updated_at: Mapped[Optional[datetime]] = mapped_column(
        DateTime(timezone=True), onupdate=text("now()")
    )
```

Update the `db/tables/__init__.py` file:

```python db/tables/__init__.py
from db.tables.base import Base
from db.tables.user import UsersTable
```

## Creat a database revision

Run the alembic command to create a database migration in the dev container:

```bash
docker exec -it ai-api alembic -c db/alembic.ini revision --autogenerate -m "Initialize DB"
```

## Migrate dev database

Run the alembic command to migrate the dev database:

```bash
docker exec -it ai-api alembic -c db/alembic.ini upgrade head
```

### Optional: Add test user

Now lets's add a test user. Copy the following code to `db/tables/test_add_user.py`

```python db/tables/test_add_user.py
from typing import Optional
from sqlalchemy.orm import Session

from db.session import SessionLocal
from db.tables.user import UsersTable
from utils.log import logger


def create_user(db_session: Session, email: str) -> UsersTable:
    """Create a new user."""
    new_user = UsersTable(email=email)
    db_session.add(new_user)
    return new_user


def get_user(db_session: Session, email: str) -> Optional[UsersTable]:
    """Get a user by email."""
    return db_session.query(UsersTable).filter(UsersTable.email == email).first()


if __name__ == "__main__":
    test_user_email = "test@test.com"
    with SessionLocal() as sess, sess.begin():
        logger.info(f"Creating user: {test_user_email}")
        create_user(db_session=sess, email=test_user_email)
        logger.info(f"Getting user: {test_user_email}")
        user = get_user(db_session=sess, email=test_user_email)
        if user:
            logger.info(f"User created: {user.id_user}")
        else:
            logger.info(f"User not found: {test_user_email}")

```

Run the script to add a test adding a user:

```bash
docker exec -it ai-api python db/tables/test_add_user.py
```

## Migrate production database

We recommended migrating the production database by setting the environment variable `MIGRATE_DB = True` and restarting the production service. This runs `alembic -c db/alembic.ini upgrade head` from the entrypoint script at container startup.

### Update the `workspace/prd_resources.py` file

```python workspace/prd_resources.py
...
# -*- Build container environment
container_env = {
    ...
    # Migrate database on startup using alembic
    "MIGRATE_DB": ws_settings.prd_db_enabled,
}
...
```

### Update the ECS Task Definition

Because we updated the Environment Variables, we need to update the Task Definition:

<CodeGroup>
  ```bash terminal
  ag ws patch --env prd --infra aws --name td
  ```

  ```bash shorthand
  ag ws patch -e prd -i aws -n td
  ```
</CodeGroup>

### Update the ECS Service

After updating the task definition, redeploy the production application:

<CodeGroup>
  ```bash terminal
  ag ws patch --env prd --infra aws --name service
  ```

  ```bash shorthand
  ag ws patch -e prd -i aws -n service
  ```
</CodeGroup>

## Manually migrate prodution database

Another approach is to SSH into the production container to run the migration manually. Your ECS tasks are already enabled with SSH access. Run the alembic command to migrate the production database:

```bash
ECS_CLUSTER=ai-app-prd-cluster
TASK_ARN=$(aws ecs list-tasks --cluster ai-app-prd-cluster --query "taskArns[0]" --output text)
CONTAINER_NAME=ai-api-prd

aws ecs execute-command --cluster $ECS_CLUSTER \
    --task $TASK_ARN \
    --container $CONTAINER_NAME \
    --interactive \
    --command "alembic -c db/alembic.ini upgrade head"
```

***

## How the migrations directory was created

<Note>
  These commands have been run and are described for completeness
</Note>

The migrations directory was created using:

```bash
docker exec -it ai-api cd db && alembic init migrations
```

* After running the above command, the `db/migrations` directory should be created.
* Update `alembic.ini`
  * set `script_location = db/migrations`
  * uncomment `black` hook in `[post_write_hooks]`
* Update `db/migrations/env.py` file following [this link](https://alembic.sqlalchemy.org/en/latest/autogenerate.html)
* Add the following function to `configure` to only include tables in the target\_metadata

```python db/migrations/env.py
# -*- Only include tables that are in the target_metadata
def include_name(name, type_, parent_names):
    if type_ == "table":
        return name in target_metadata.tables
    else:
        return True
...
```


# Development Application
Source: https://docs.agno.com/templates/infra-management/development-app



Your development application runs locally on docker and its resources are defined in the `infra/dev_resources.py` file. This guide shows how to:

1. [Build a development image](#build-your-development-image)
2. [Restart all docker containers](#restart-all-containers)
3. [Recreate development resources](#recreate-development-resources)

## Infra Settings

The `InfraSettings` object in the `infra/settings.py` file defines common settings used by your Agno Infra apps and resources.

## Build your development image

Your application uses the `agno` docker images by default. To use your own image:

* Open `infra/settings.py` file
* Update the `image_repo` to your image repository
* Set `build_images=True`

```python infra/settings.py
infra_settings = InfraSettings(
    ...
    # -*- Image Settings
    # Repository for images
    image_repo="local",
    # Build images locally
    build_images=True,
)
```

### Build a new image

Build the development image using:

<CodeGroup>
  ```bash terminal
  ag infra up --env dev --infra docker --type image
  ```

  ```bash short options
  ag infra up -e dev -i docker -t image
  ```
</CodeGroup>

To `force` rebuild images, use the `--force` or `-f` flag

<CodeGroup>
  ```bash terminal
  ag infra up --env dev --infra docker --type image --force
  ```

  ```bash short options
  ag infra up -e dev -i docker -t image -f
  ```
</CodeGroup>

***

## Restart all containers

Restart all docker containers using:

<CodeGroup>
  ```bash terminal
  ag infra restart --env dev --infra docker --type container
  ```

  ```bash short options
  ag infra restart -e dev -c docker -t container
  ```
</CodeGroup>

***

## Recreate development resources

To recreate all dev resources, use the `--force` flag:

<CodeGroup>
  ```bash terminal
  ag infra up -f
  ```

  ```bash full options
  ag infra up --env dev --infra docker --force
  ```

  ```bash shorthand
  ag infra up dev:docker -f
  ```

  ```bash short options
  ag infra up -e dev -i docker -f
  ```
</CodeGroup>


# Use Custom Domain and HTTPS
Source: https://docs.agno.com/templates/infra-management/domain-https



## Use a custom domain

1. Register your domain with [Route 53](https://us-east-1.console.aws.amazon.com/route53/).
2. Point the domain to the loadbalancer DNS.

### Custom domain for your Streamlit App

Create a record in the Route53 console to point `app.[YOUR_DOMAIN]` to the Streamlit App.

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=2387492f4fa89cab98e2a603da83535b" alt="llm-app-aidev-run" data-og-width="1081" width="1081" data-og-height="569" height="569" data-path="images/llm-app-aidev-run.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=1d9004362958e21665a9deb78811a4dd 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=16e4a3f99f355b484c3bfc0ff98ec7c9 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=d2659746f0b009a8e84c7fe1528cac65 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=1b3b6f7c9a098578bcc4cf88f5802588 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=d1e8a2a0a23ce16cbaf50ebe0fce0fba 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-aidev-run.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=4c1c3fbd924321ecfe7aabedc3d9ad1e 2500w" />

You can visit the app at [http://app.aidev.run](http://app.aidev.run)

<Note>Note the `http` in the domain name.</Note>

### Custom domain for your FastAPI App

Create a record in the Route53 console to point `api.[YOUR_DOMAIN]` to the FastAPI App.

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=a22989f1a3cc440bd90cb8d3ea96d9f9" alt="llm-api-aidev-run" data-og-width="1081" width="1081" data-og-height="569" height="569" data-path="images/llm-api-aidev-run.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=b46a06510a2604def1c407120ec2acb6 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=52a498dd427ddfda840161aef0581ed3 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=42ee55ee9564e53bdfe1b77e58c47970 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=2bc60300004304b16a6e5e19756278bd 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=1a9a223d0f703808451a027be044e49b 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-api-aidev-run.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=47ce9b2510136e42b24538842b20bd40 2500w" />

You can access the api at [http://api.aidev.run](http://api.aidev.run)

<Note>Note the `http` in the domain name.</Note>

## Add HTTPS

To add HTTPS:

1. Create a certificate using [AWS ACM](https://us-east-1.console.aws.amazon.com/acm). Request a certificat for `*.[YOUR_DOMAIN]`

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=15b580029369ef5c8039bddfad4be52d" alt="llm-app-request-cert" data-og-width="1105" width="1105" data-og-height="581" height="581" data-path="images/llm-app-request-cert.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=05442b5b3ac14b98d42e885488be4ede 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=9ce2e4e86b46e10e984aa1b1ab9939a7 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=85149f2d24287108d22bd604f7014dc3 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=dbb81c8a8e8df3c85eaed02a097a89b1 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=6c804f2e99c3881f52cabd5566b54802 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-request-cert.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=b9534df74f2df9325cdeae0448e25bfd 2500w" />

2. Creating records in Route 53.

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=4291826e3abd20126daf4e1bbd42c0a3" alt="llm-app-validate-cert" data-og-width="1322" width="1322" data-og-height="566" height="566" data-path="images/llm-app-validate-cert.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=c7813e664032c848f1b2c5a51953f8eb 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=b98c005abf74fc4a7b7c75678cf8b0f6 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=b25347bff02d1684a44906d860b51a98 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=f7a1bafd43f582f40f13513ea64daa32 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=179c892f6141685a69e521865a7c4d28 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/llm-app-validate-cert.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=051a273f486a1f576ee0cedd97c24c69 2500w" />

3. Add the certificate ARN to Apps

<Note>Make sure the certificate is `Issued` before adding it to your Apps</Note>

Update the `llm-app/workspace/prd_resources.py` file and add the `load_balancer_certificate_arn` to the `FastAPI` and `Streamlit` Apps.

```python workspace/prd_resources.py

# -*- Streamlit running on ECS
prd_streamlit = Streamlit(
    ...
    # To enable HTTPS, create an ACM certificate and add the ARN below:
    load_balancer_enable_https=True,
    load_balancer_certificate_arn="arn:aws:acm:us-east-1:497891874516:certificate/6598c24a-d4fc-4f17-8ee0-0d3906eb705f",
    ...
)

# -*- FastAPI running on ECS
prd_fastapi = FastApi(
    ...
    # To enable HTTPS, create an ACM certificate and add the ARN below:
    load_balancer_enable_https=True,
    load_balancer_certificate_arn="arn:aws:acm:us-east-1:497891874516:certificate/6598c24a-d4fc-4f17-8ee0-0d3906eb705f",
    ...
)
```

4. Create new Loadbalancer Listeners

Create new listeners for the loadbalancer to pickup the HTTPs configuration.

<CodeGroup>
  ```bash terminal
  ag ws up --env prd --infra aws --name listener
  ```

  ```bash shorthand
  ag ws up -e prd -i aws -n listener
  ```
</CodeGroup>

<Note>The certificate should be `Issued` before applying it.</Note>

After this, `https` should be working on your custom domain.

5. Update existing listeners to redirect HTTP to HTTPS

<CodeGroup>
  ```bash terminal
  ag ws patch --env prd --infra aws --name listener
  ```

  ```bash shorthand
  ag ws patch -e prd -i aws -n listener
  ```
</CodeGroup>

After this, all HTTP requests should redirect to HTTPS automatically.


# Environment variables
Source: https://docs.agno.com/templates/infra-management/env-vars



Environment variables can be added to resources using the `env_vars` parameter or the `env_file` parameter pointing to a `yaml` file. Examples

```python dev_resources.py
dev_fastapi = FastApi(
    ...
    env_vars={
        "RUNTIME_ENV": "dev",
        # Get the OpenAI API key from the local environment
        "OPENAI_API_KEY": getenv("OPENAI_API_KEY"),
        # Database configuration
        "DB_HOST": dev_db.get_db_host(),
        "DB_PORT": dev_db.get_db_port(),
        "DB_USER": dev_db.get_db_user(),
        "DB_PASS": dev_db.get_db_password(),
        "DB_DATABASE": dev_db.get_db_database(),
        # Wait for database to be available before starting the application
        "WAIT_FOR_DB": ws_settings.dev_db_enabled,
        # Migrate database on startup using alembic
        # "MIGRATE_DB": ws_settings.prd_db_enabled,
    },
    ...
)
```

```python prd_resources.py
prd_fastapi = FastApi(
    ...
    env_vars={
        "RUNTIME_ENV": "prd",
        # Get the OpenAI API key from the local environment
        "OPENAI_API_KEY": getenv("OPENAI_API_KEY"),
        # Database configuration
        "DB_HOST": AwsReference(prd_db.get_db_endpoint),
        "DB_PORT": AwsReference(prd_db.get_db_port),
        "DB_USER": AwsReference(prd_db.get_master_username),
        "DB_PASS": AwsReference(prd_db.get_master_user_password),
        "DB_DATABASE": AwsReference(prd_db.get_db_name),
        # Wait for database to be available before starting the application
        "WAIT_FOR_DB": ws_settings.prd_db_enabled,
        # Migrate database on startup using alembic
        # "MIGRATE_DB": ws_settings.prd_db_enabled,
    },
    ...
)
```

The apps in your templates are already configured to read environment variables.


# Format & Validate
Source: https://docs.agno.com/templates/infra-management/format-and-validate



## Format

Formatting the codebase using a set standard saves us time and mental energy. Agno templates are pre-configured with [ruff](https://docs.astral.sh/ruff/) that you can run using a helper script or directly.

<CodeGroup>
  ```bash terminal
  ./scripts/format.sh
  ```

  ```bash ruff
  ruff format .
  ```
</CodeGroup>

## Validate

Linting and Type Checking add an extra layer of protection to the codebase. We highly recommending running the validate script before pushing any changes.

Agno templates are pre-configured with [ruff](https://docs.astral.sh/ruff/) and [mypy](https://mypy.readthedocs.io/en/stable/) that you can run using a helper script or directly. Checkout the `pyproject.toml` file for the configuration.

<CodeGroup>
  ```bash terminal
  ./scripts/validate.sh
  ```

  ```bash ruff
  ruff check .
  ```

  ```bash mypy
  mypy .
  ```
</CodeGroup>


# Create Git Repo
Source: https://docs.agno.com/templates/infra-management/git-repo



Create a git repository to share your application with your team.

<Steps>
  <Step title="Create a git repository">
    Create a new [git repository](https://github.com/new).
  </Step>

  <Step title="Push your code">
    Push your code to the git repository.

    ```bash terminal
    git init
    git add .
    git commit -m "Init LLM App"
    git branch -M main
    git remote add origin https://github.com/[YOUR_GIT_REPO].git
    git push -u origin main
    ```
  </Step>

  <Step title="Ask your team to join">
    Ask your team to follow the [setup steps for new users](/workspaces/workspace-management/new-users) to use this workspace.
  </Step>
</Steps>


# Infra Settings
Source: https://docs.agno.com/templates/infra-management/infra-settings



The `InfraSettings` object in the `infra/settings.py` file defines common settings used by your apps and resources. Here are the settings we recommend updating:

```python infra/settings.py
infra_settings = InfraSettings(
    # Update this to your project name
    infra_name="ai",
    # Add your AWS subnets
    subnet_ids=["subnet-xyz", "subnet-xyz"],
    # Add your image repository
    image_repo="[ACCOUNT_ID].dkr.ecr.us-east-1.amazonaws.com",
    # Set to True to build images locally
    build_images=True,
    # Set to True to push images after building
    push_images=True,
)
```

<Note>
  `InfraSettings` can also be updated using environment variables or the `.env` file.

  Checkout the `example.env` file for an example.
</Note>

### Infra Name

The `infra_name` is used to name your apps and resources. Change it to your project or team name, for example:

* `infra_name="booking-ai"`
* `infra_name="reddit-ai"`
* `infra_name="vantage-ai"`

The `infra_name` is used to name:

* The image for your application
* Apps like db, streamlit app and FastAPI server
* Resources like buckets, secrets and loadbalancers

Checkout the `infra/dev_resources.py` and `infra/prd_resources.py` file to see how its used.

## Image Repository

The `image_repo` defines the repo for your image.

* If using dockerhub it would be something like `agno`.
* If using ECR it would be something like `[ACCOUNT_ID].dkr.ecr.us-east-1.amazonaws.com`

Checkout the `dev_image` in `infra/dev_resources.py` and `prd_image` in `infra/prd_resources.py` to see how its used.

## Build Images

Setting `build_images=True` will build images locally when running `ag infra up dev:docker` or `ag infra up prd:docker`.

Checkout the `dev_image` in `infra/dev_resources.py` and `prd_image` in `infra/prd_resources.py` to see how its used.

Read more about:

* [Building your development image](/workspaces/workspace-management/development-app#build-your-development-image)
* [Building your production image](/workspaces/workspace-management/production-app#build-your-production-image)

## Push Images

Setting `push_images=True` will push images after building when running `ag infra up dev:docker` or `ag infra up prd:docker`.

Checkout the `dev_image` in `infra/dev_resources.py` and `prd_image` in `infra/prd_resources.py` to see how its used.

Read more about:

* [Building your development image](/workspaces/workspace-management/development-app#build-your-development-image)
* [Building your production image](/workspaces/workspace-management/production-app#build-your-production-image)

## AWS Settings

The `aws_region` and `subnet_ids` provide values used for creating production resources. Checkout the `infra/prd_resources.py` file to see how its used.


# Install & Setup
Source: https://docs.agno.com/templates/infra-management/install



## Install Agno

We highly recommend:

* Installing `agno` using `pip` in a python virtual environment.
* Creating an `ai` directory for your ai infra

<Steps>
  <Step title="Create a virtual environment">
    Open the `Terminal` and create an `ai` directory with a python virtual environment.

    <CodeGroup>
      ```bash Mac
      mkdir ai && cd ai

      python3 -m venv aienv
      source aienv/bin/activate
      ```

      ```bash Windows
      mkdir ai; cd ai

      python3 -m venv aienv
      aienv/scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install Agno">
    Install `agno` using pip

    <CodeGroup>
      ```bash Mac
      pip install -U agno
      ```

      ```bash Windows
      pip install -U agno
      ```
    </CodeGroup>
  </Step>

  <Step title="Install Docker">
    Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) to run apps locally
  </Step>
</Steps>

<br />

<Note>
  If you encounter errors, try updating pip using `python -m pip install --upgrade pip`
</Note>

***

## Upgrade Agno

To upgrade `agno`, run this in your virtual environment

```bash
pip install -U agno --no-cache-dir
```

***

## Reset Agno infra

\#TODO: Look into reset command

To reset the agno config, run

```bash
ag init -r
```

<Note>
  This does not delete any physical data
</Note>


# Introduction
Source: https://docs.agno.com/templates/infra-management/introduction



**Agno Infra** provides a standard for codebases of Agentic Systems. It uses [AgentOS](/agent-os/introduction) locally using Docker and cloud deployment environments in production. It allows you to manager your Agentic System as Python code.

<img src="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=cf53d931a9d952a92835b273aaf123b2" alt="workspace" data-og-width="3034" width="3034" data-og-height="2610" height="2610" data-path="images/workspace.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?w=280&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=c3fed495254a0c287d049d780adced9c 280w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?w=560&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=83f902e68e266da8dee08f0f95a64451 560w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?w=840&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=6a3ae8e9feea160bdb44d52e7c15a0c9 840w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?w=1100&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=4abb2e5f4cfa54098f2ee179c93662ec 1100w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?w=1650&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=72c4058fd198ea4aa026146c67189942 1650w, https://mintcdn.com/agno-v2/yeT29TzCG5roT0hQ/images/workspace.png?w=2500&fit=max&auto=format&n=yeT29TzCG5roT0hQ&q=85&s=f93ab351c6bf977d784b8e59563a2e91 2500w" />

## Create a new Agno Infra project

Run `ag infra create` to create a new infra project, the command will ask your for a starter template and infra project name.

<CodeGroup>
  ```bash Create Infra Project
  ag infra create
  ```

  ```bash Create Agent App
  ag infra create -t agent-app-aws -n agent-app
  ```

  ```bash Create Agent API
  ag infra create -t agent-api-aws -n agent-api
  ```
</CodeGroup>

## Start infra resources

Run `ag infra up` to start i.e. create infra resources

<CodeGroup>
  ```bash terminal
  ag infra up
  ```

  ```bash shorthand
  ag infra up dev:docker
  ```

  ```bash full options
  ag infra up --env dev --infra docker
  ```

  ```bash short options
  ag infra up -e dev -i docker
  ```
</CodeGroup>

## Stop infra resources

Run `ag infra down` to stop i.e. delete infra resources

<CodeGroup>
  ```bash terminal
  ag infra down
  ```

  ```bash shorthand
  ag infra down dev:docker
  ```

  ```bash full options
  ag infra down --env dev --infra docker
  ```

  ```bash short options
  ag infra down -e dev -i docker
  ```
</CodeGroup>

## Patch infra resources

Run `ag infra patch` to patch i.e. update infra resources

<CodeGroup>
  ```bash terminal
  ag infra patch
  ```

  ```bash shorthand
  ag infra patch dev:docker
  ```

  ```bash full options
  ag infra patch --env dev --infra docker
  ```

  ```bash short options
  ag infra patch -e dev -i docker
  ```
</CodeGroup>

<br />

<Note>
  The `patch` command in under development for some resources. Use `restart` if needed
</Note>

## Restart infra

Run `ag infra restart` to stop resources and start them again

<CodeGroup>
  ```bash terminal
  ag infra restart
  ```

  ```bash shorthand
  ag infra restart dev:docker
  ```

  ```bash full options
  ag infra restart --env dev --infra docker
  ```

  ```bash short options
  ag infra restart -e dev -i docker
  ```
</CodeGroup>

## Setup existing infra

If you clone the codebase directly (eg: if your coworker created it) - run `ag infra setup` to set it up locally

<CodeGroup>
  ```bash terminal
  ag infra setup
  ```

  ```bash with debug logs
  ag infra setup -d
  ```
</CodeGroup>

## Command Options

<Note>Run `ag infra up --help` to view all options</Note>

### Environment (`--env`)

Use the `--env` or `-e` flag to filter the environment (dev/prd)

<CodeGroup>
  ```bash flag
  ag infra up --env dev
  ```

  ```bash shorthand
  ag infra up dev
  ```

  ```bash short options
  ag infra up -e dev
  ```
</CodeGroup>

### Infra (`--infra`)

Use the `--infra` or `-i` flag to filter the infra (docker/aws/k8s)

<CodeGroup>
  ```bash flag
  ag infra up --infra docker
  ```

  ```bash shorthand
  ag infra up :docker
  ```

  ```bash short options
  ag infra up -i docker
  ```
</CodeGroup>

### Group (`--group`)

Use the `--group` or `-g` flag to filter by resource group.

<CodeGroup>
  ```bash flag
  ag infra up --group app
  ```

  ```bash full options
  ag infra up \
    --env dev \
    --infra docker \
    --group app
  ```

  ```bash shorthand
  ag infra up dev:docker:app
  ```

  ```bash short options
  ag infra up \
    -e dev \
    -i docker \
    -g app
  ```
</CodeGroup>

### Name (`--name`)

Use the `--name` or `-n` flag to filter by resource name

<CodeGroup>
  ```bash flag
  ag infra up --name app
  ```

  ```bash full options
  ag infra up \
    --env dev \
    --infra docker \
    --name app
  ```

  ```bash shorthand
  ag infra up dev:docker::app
  ```

  ```bash short options
  ag infra up \
    -e dev \
    -i docker \
    -n app
  ```
</CodeGroup>

### Type (`--type`)

Use the `--type` or `-t` flag to filter by resource type.

<CodeGroup>
  ```bash flag
  ag infra up --type container
  ```

  ```bash full options
  ag infra up \
    --env dev \
    --infra docker \
    --type container
  ```

  ```bash shorthand
  ag infra up dev:docker:app::container
  ```

  ```bash short options
  ag infra up \
    -e dev \
    -i docker \
    -t container
  ```
</CodeGroup>

### Dry Run (`--dry-run`)

The `--dry-run` or `-dr` flag can be used to **dry-run** the command. `ag ws up -dr` will only print resources, not create them.

<CodeGroup>
  ```bash flag
  ag infra up --dry-run
  ```

  ```bash full options
  ag infra up \
    --env dev \
    --infra docker \
    --dry-run
  ```

  ```bash shorthand
  ag infra up dev:docker -dr
  ```

  ```bash short options
  ag infra up \
    -e dev \
    -i docker \
    -dr
  ```
</CodeGroup>

### Show Debug logs (`--debug`)

Use the `--debug` or `-d` flag to show debug logs.

<CodeGroup>
  ```bash flag
  ag infra up -d
  ```

  ```bash full options
  ag infra up \
    --env dev \
    --infra docker \
    -d
  ```

  ```bash shorthand
  ag infra up dev:docker -d
  ```

  ```bash short options
  ag infra up \
    -e dev \
    -i docker \
    -d
  ```
</CodeGroup>

### Force recreate images & containers (`-f`)

Use the `--force` or `-f` flag to force recreate images & containers

<CodeGroup>
  ```bash flag
  ag infra up -f
  ```

  ```bash full options
  ag infra up \
    --env dev \
    --infra docker \
    -f
  ```

  ```bash shorthand
  ag infra up dev:docker -f
  ```

  ```bash short options
  ag infra up \
    -e dev \
    -i docker \
    -f
  ```
</CodeGroup>


# Setup infra for new users
Source: https://docs.agno.com/templates/infra-management/new-users



Follow these steps to setup an existing infra:

<Steps>
  <Step title="Clone git repository">
    Clone the git repo and `cd` into the infra directory

    <CodeGroup>
      ```bash Mac
      git clone https://github.com/[YOUR_GIT_REPO].git

      cd your_infra_directory
      ```

      ```bash Windows
      git clone https://github.com/[YOUR_GIT_REPO].git

      cd your_infra_directory
      ```
    </CodeGroup>
  </Step>

  <Step title="Create and activate a virtual environment">
    <CodeGroup>
      ```bash Mac
      python3 -m venv aienv
      source aienv/bin/activate
      ```

      ```bash Windows
      python3 -m venv aienv
      aienv/scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install agno">
    <CodeGroup>
      ```bash Mac
      pip install -U agno
      ```

      ```bash Windows
      pip install -U agno
      ```
    </CodeGroup>
  </Step>

  \#TODO: Look into this step

  <Step title="Setup infra">
    <CodeGroup>
      ```bash Mac
      ag infra setup
      ```

      ```bash Windows
      ag infra setup
      ```
    </CodeGroup>
  </Step>

  <Step title="Copy secrets">
    Copy `infra/example_secrets` to `infra/secrets`

    <CodeGroup>
      ```bash Mac
      cp -r infra/example_secrets infra/secrets
      ```

      ```bash Windows
      cp -r infra/example_secrets infra/secrets
      ```
    </CodeGroup>
  </Step>

  <Step title="Start infra">
    <Note>
      Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) if needed.
    </Note>

    <CodeGroup>
      ```bash terminal
      ag infra up
      ```

      ```bash full options
      ag infra up --env dev --infra docker
      ```

      ```bash shorthand
      ag infra up dev:docker
      ```
    </CodeGroup>
  </Step>

  <Step title="Stop infra">
    <CodeGroup>
      ```bash terminal
      ag infra down
      ```

      ```bash full options
      ag infra down --env dev --infra docker
      ```

      ```bash shorthand
      ag infra down dev:docker
      ```
    </CodeGroup>
  </Step>
</Steps>


# Production Application
Source: https://docs.agno.com/templates/infra-management/production-app



Your production application runs on AWS and its resources are defined in the `infra/prd_resources.py` file. This guide shows how to:

1. [Build a production image](#build-your-production-image)
2. [Update ECS Task Definitions](#ecs-task-definition)
3. [Update ECS Services](#ecs-service)

## Workspace Settings

The `InfraSettings` object in the `infra/settings.py` file defines common settings used by your workspace apps and resources.

## Build your production image

Your application uses the `agno` images by default. To use your own image:

* Create a Repository in `ECR` and authenticate or use `Dockerhub`.
* Open `infra/settings.py` file
* Update the `image_repo` to your image repository
* Set `build_images=True` and `push_images=True`
* Optional - Set `build_images=False` and `push_images=False` to use an existing image in the repository

### Create an ECR Repository

To use ECR, **create the image repo and authenticate with ECR** before pushing images.

**1. Create the image repository in ECR**

The repo name should match the `infra_name`. Meaning if you're using the default infra name, the repo name would be `ai`.

<img src="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c68ceb3a9b6784fd519cc04b0e38caf1" alt="create-ecr-image" data-og-width="1389" width="1389" data-og-height="408" height="408" data-path="images/create-ecr-image.png" data-optimize="true" data-opv="2" srcset="https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=280&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=2ce02d48da7e53a6c335736a17ebec6e 280w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=560&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=f0b4d1687849a637c0a595c4a8d0690a 560w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=840&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=26b1f13eb8b6f9b09a06b9e6bb1eeb27 840w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=1100&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=e53f084201341a7c92738fa62efdb64c 1100w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=1650&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=c9e2477e1befaf12f81d4d345dac5a26 1650w, https://mintcdn.com/agno-v2/Y7twezR0wF2re1xh/images/create-ecr-image.png?w=2500&fit=max&auto=format&n=Y7twezR0wF2re1xh&q=85&s=a22af7830053ba9139cfb6d0d4017d4a 2500w" />

**2. Authenticate with ECR**

```bash Authenticate with ECR
aws ecr get-login-password --region [region] | docker login --username AWS --password-stdin [account].dkr.ecr.[region].amazonaws.com
```

You can also use a helper script to avoid running the full command

<Note>
  Update the script with your ECR repo before running.
</Note>

<CodeGroup>
  ```bash Mac
  ./scripts/auth_ecr.sh
  ```
</CodeGroup>

### Update the `InfraSettings`

```python infra/settings.py
infra_settings = InfraSettings(
    ...
    # Subnet IDs in the aws_region
    subnet_ids=["subnet-xyz", "subnet-xyz"],
    # -*- Image Settings
    # Repository for images
    image_repo="your-image-repo",
    # Build images locally
    build_images=True,
    # Push images after building
    push_images=True,
)
```

<Note>
  The `image_repo` defines the repo for your image.

  * If using dockerhub it would be something like `agno`.
  * If using ECR it would be something like `[ACCOUNT_ID].dkr.ecr.us-east-1.amazonaws.com`
</Note>

### Build a new image

Build the production image using:

<CodeGroup>
  ```bash terminal
  ag infra up --env prd --infra docker --type image
  ```

  ```bash shorthand
  ag infra up -e prd -i docker -t image
  ```
</CodeGroup>

To `force` rebuild images, use the `--force` or `-f` flag

<CodeGroup>
  ```bash terminal
  ag infra up --env prd --infra docker --type image --force
  ```

  ```bash shorthand
  ag infra up -e prd -i docker -t image -f
  ```
</CodeGroup>

Because the only docker resources in the production env are docker images, you can also use:

<CodeGroup>
  ```bash Build Images
  ag infra up prd:docker
  ```

  ```bash Force Build Images
  ag infra up prd:docker -f
  ```
</CodeGroup>

## ECS Task Definition

If you updated the Image, CPU, Memory or Environment Variables, update the Task Definition using:

<CodeGroup>
  ```bash terminal
  ag infra patch --env prd --infra aws --name td
  ```

  ```bash shorthand
  ag infra patch -e prd -i aws -n td
  ```
</CodeGroup>

## ECS Service

To redeploy the production application, update the ECS Service using:

<CodeGroup>
  ```bash terminal
  ag infra patch --env prd --infra aws --name service
  ```

  ```bash shorthand
  ag infra patch -e prd -i aws -n service
  ```
</CodeGroup>

<br />

<Note>
  If you **ONLY** rebuilt the image, you do not need to update the task definition and can just patch the service to pickup the new image.
</Note>


# Add Python Libraries
Source: https://docs.agno.com/templates/infra-management/python-packages



Agno templates are setup to manage dependencies using a [pyproject.toml](https://packaging.python.org/en/latest/specifications/declaring-project-metadata/#declaring-project-metadata) file, **which is used to generate the `requirements.txt` file using [uv](https://github.com/astral-sh/uv) or [pip-tools](https://pip-tools.readthedocs.io/en/latest/).**

Adding or Updating a python library is a 2 step process:

1. Add library to the `pyproject.toml` file
2. Auto-Generate the `requirements.txt` file

<Warning>
  We highly recommend auto-generating the `requirements.txt` file using this process.
</Warning>

## Update pyproject.toml

* Open the `pyproject.toml` file
* Add new libraries to the dependencies section.

## Generate requirements

After updating the `dependencies` in the `pyproject.toml` file, auto-generate the `requirements.txt` file using a helper script or running `pip-compile` directly.

<CodeGroup>
  ```bash terminal
  ./scripts/generate_requirements.sh
  ```

  ```bash pip compile
  pip-compile \
      --no-annotate \
      --pip-args "--no-cache-dir" \
      -o requirements.txt pyproject.toml
  ```
</CodeGroup>

If you'd like to upgrade all python libraries to their latest version, run:

<CodeGroup>
  ```bash terminal
  ./scripts/generate_requirements.sh upgrade
  ```

  ```bash pip compile
  pip-compile \
      --upgrade \
      --no-annotate \
      --pip-args "--no-cache-dir" \
      -o requirements.txt pyproject.toml
  ```
</CodeGroup>

## Rebuild Images

After updating the `requirements.txt` file, rebuild your images.

### Rebuild dev images

<CodeGroup>
  ```bash terminal
  ag infra up --env dev --infra docker --type image
  ```

  ```bash short options
  ag infra up -e dev -i docker -t image
  ```
</CodeGroup>

### Rebuild production images

<Note>
  Remember to [authenticate with ECR](infra/infra-management/production-app#ecr-images) if needed.
</Note>

<CodeGroup>
  ```bash terminal
  ag infra up --env prd --infra aws --type image
  ```

  ```bash short options
  ag infra up -e prd -i aws -t image
  ```
</CodeGroup>

## Recreate Resources

After rebuilding images, recreate the resources.

### Recreate dev containers

<CodeGroup>
  ```bash terminal
  ag infra restart --env dev --infra docker --type container
  ```

  ```bash short options
  ag infra restart -e dev -c docker -t container
  ```
</CodeGroup>

### Update ECS services

<CodeGroup>
  ```bash terminal
  ag infra patch --env prd --infra aws --name service
  ```

  ```bash short options
  ag infra patch -e prd -i aws -n service
  ```
</CodeGroup>


# Add Secrets
Source: https://docs.agno.com/templates/infra-management/secrets



Secret management is a critical part of your application security and should be taken seriously.

Local secrets are defined in the `infra/secrets` directory which is excluded from version control (see `.gitignore`). Its contents should be handled with the same security as passwords.

Production secrets are managed by [AWS Secrets Manager](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html).

<Note>
  Incase you're missing the secrets dir, copy `infra/example_secrets`
</Note>

## Development Secrets

Apps running locally can read secrets using a `yaml` file, for example:

```python dev_resources.py
dev_fastapi = FastApi(
    ...
    # Read secrets from secrets/dev_app_secrets.yml
    secrets_file=infra_settings.infra_root.joinpath("infra/secrets/dev_app_secrets.yml"),
)
```

## Production Secrets

`AWS Secrets` are used to manage production secrets, which are read by the production apps.

```python prd_resources.py
# -*- Secrets for production application
prd_secret = SecretsManager(
    ...
    # Create secret from workspace/secrets/prd_app_secrets.yml
    secret_files=[
        infra_settings.infra_root.joinpath("infra/secrets/prd_app_secrets.yml")
    ],
)

# -*- Secrets for production database
prd_db_secret = SecretsManager(
    ...
    # Create secret from workspace/secrets/prd_db_secrets.yml
    secret_files=[infra_settings.infra_root.joinpath("infra/secrets/prd_db_secrets.yml")],
)
```

Read the secret in production apps using:

<CodeGroup>
  ```python FastApi
  prd_fastapi = FastApi(
      ...
      aws_secrets=[prd_secret],
      ...
  )
  ```

  ```python RDS
  prd_db = DbInstance(
      ...
      aws_secret=prd_db_secret,
      ...
  )
  ```
</CodeGroup>

Production resources can also read secrets using yaml files but we highly recommend using [AWS Secrets](https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html).


# SSH Access
Source: https://docs.agno.com/templates/infra-management/ssh-access



SSH Access is an important part of the developer workflow.

## Dev SSH Access

SSH into the dev containers using the `docker exec` command

```bash
docker exec -it ai-api zsh
```

## Production SSH Access

Your ECS tasks are already enabled with SSH access. SSH into the production containers using:

```bash
ECS_CLUSTER=ai-app-prd-cluster
TASK_ARN=$(aws ecs list-tasks --cluster ai-app-prd-cluster --query "taskArns[0]" --output text)
CONTAINER_NAME=ai-api-prd

aws ecs execute-command --cluster $ECS_CLUSTER \
    --task $TASK_ARN \
    --container $CONTAINER_NAME \
    --interactive \
    --command "zsh"
```


# Overview
Source: https://docs.agno.com/tutorials/overview

Guides for Agno

## Guides

Agno is a platform for building AI agents. It provides a set of tools and libraries to help you build and deploy AI agents.


# Build a Social Media Intelligence Agent with Agno, X Tools, and Exa
Source: https://docs.agno.com/tutorials/social-media-agent

Create a professional-grade social media intelligence system using Agno.

In this tutorial, we will build a multi-agent intelligence system. It will monitor X (Twitter), perform sentiment analysis, and generate reports using Agno framework.

We will be using the following components:

* **Agno** - The fastest framework for building agents.
* **X Tools** - Provides real-time, structured data directly from Twitter/X API with engagement metrics
* **Exa Tools** - Deliver semantic web search for broader context discovery across blogs, forums, and news
* **GPT-5 Mini** - OpenAI's new model. Well suited for contextually-aware sentiment analysis and strategic pattern detection

This system will combine direct social media data with broader web intelligence, to provide comprehensive brand monitoring that captures both immediate social sentiment and emerging discussions before they reach mainstream attention.

## What You'll Build

Your social media intelligence system will:

* Track brand and competitor mentions across X and the broader web
* Perform weighted sentiment analysis that accounts for influence and engagement
* Detect viral content, controversy signals, and high-influence discussions
* Generate executive-ready reports with strategic recommendations
* Serve insights via [AgentOS](/agent-os/introduction) API for integration with your applications

## Prerequisites and Setup

Before we get started, we need to setup our environment:

1. Install Python, Git and get your API keys:

* Install **Python >= 3.9** and **Git**
* Get API keys for:
  * **X (Twitter) Developer Account** ([Apply here](https://developer.twitter.com/en/apply-for-access))
  * **OpenAI API** ([Get key](https://platform.openai.com/api-keys))
  * **Exa API** ([Sign up](https://exa.ai))

2. Setup your Python environment:

```bash
mkdir social-intel && cd social-intel
python3 -m venv venv
source venv/bin/activate     # If you are on Windows, use: venv\Scripts\activate
```

3. Install our Python dependencies:

````bash
# Install dependencies
pip install "agno[infra]" openai exa_py python-dotenv

4. Create a new project with [AgentOS](/agent-os/introduction):

```bash
ag infra create              # Choose: [1] agent-infra-docker (default)
# Infra Name: social-intel
````

5. Set your environment variables:

```env
export OPENAI_API_KEY=sk-your-openai-api-key-here
export X_API_KEY=your-x-api-key
export X_API_SECRET=your-x-api-secret
export X_ACCESS_TOKEN=your-access-token
export X_ACCESS_TOKEN_SECRET=your-access-token-secret
export X_BEARER_TOKEN=your-bearer-token
export EXA_API_KEY=your-exa-api-key
```

Our environment is now ready. Let's start building!

# Building our Social Media Intelligence System

## Step 1: Choose Your AI Model

**Which model should I use?**: You can choose any model from our supported providers. Normally models are chosen based on costs and performance. In this case, we will be using OpenAI's GPT-5 Mini.

**Why GPT-5 Mini?**

* **Cost-effective**: Better price/performance ratio than other GPT models
* **Tool usage**: Excellent at deciding when and how to use tools
* **Complex reasoning**: Can follow detailed analysis methodologies
* **Structured output**: Reliable at generating formatted reports

Let's first create the file where we will define our agent:

```bash
mkdir -p app
touch app/social_media_agent.py
```

Now let's add the basic imports and model setup:

```python
from pathlib import Path
from dotenv import load_dotenv
from agno.models.openai import OpenAIChat

# Load infrastructure secrets
load_dotenv(dotenv_path=Path(__file__).resolve().parents[1] / "infra" / "secrets" / ".env")

# Choose the AI model for your agent
model = OpenAIChat(id="gpt-5-mini")
print(f"Model selected: {model.id}")
```

We can now test our model setup:

```python
# Quick test to verify model works
if __name__ == "__main__":
    test_response = model.invoke("Explain social media sentiment analysis in one sentence.")
    print(f"Model test: {test_response}")
```

This confirms your model is working, before we add more complexity.

## Step 2: Add Social Media Tools

**Which tools should I use?** We are adding XTools because we need direct Twitter/X data with engagement metrics, and ExaTools because we need broader web context that social media alone can't provide.

### 2a. Add XTools for Twitter/X Data

**Why XTools?** Direct access to Twitter/X with engagement metrics is crucial for understanding influence patterns and viral content.

```python
from agno.tools.x import XTools

# Configure X Tools for social media data
x_tools = XTools(
    include_post_metrics=True,    # Critical: gets likes, retweets, replies for influence analysis
    wait_on_rate_limit=True,      # Handles API limits gracefully
)

print("XTools configured with post metrics enabled")
```

**What `include_post_metrics=True` gives you:**

* Like counts (engagement volume)
* Retweet counts (viral spread)
* Reply counts (conversation depth)
* Author verification status (influence weighting)

### 2b. Add ExaTools for Web Intelligence

**Why ExaTools?** Social media discussions often reference broader conversations happening across the web. ExaTools finds this context.

```python
from agno.tools.exa import ExaTools

# Configure Exa for broader web intelligence
exa_tools = ExaTools(
    num_results=10,               # Comprehensive but not overwhelming
    include_domains=["reddit.com", "news.ycombinator.com", "medium.com"],
)

print("ExaTools configured for web search")
```

**Why these specific domains?**

* **Reddit**: Early discussion indicators, community sentiment
* **HackerNews**: Tech industry insights, developer opinions
* **Medium**: Thought leadership, analysis articles

## Step 3: Define Intelligence Strategy

**Why do we need instructions?** We need to describe the strategy that the agent should take to collect and analyze content. Without clear instructions, the agent won't know how to use the tools effectively or what kind of analysis to provide.

### 3a. Define the Data Collection Strategy

```python
from textwrap import dedent

# Define how the agent should gather data
data_collection_strategy = dedent("""
    DATA COLLECTION STRATEGY:
    - Use X Tools to gather direct social media mentions with full engagement metrics
    - Use Exa Tools to find broader web discussions, articles, and forum conversations
    - Cross-reference findings between social and web sources for comprehensive coverage
""")

print("Data collection strategy defined")
```

### 3b. Define the Analysis Framework

```python
# Define how the agent should analyze the data
analysis_framework = dedent("""
    ANALYSIS FRAMEWORK:
    - Classify sentiment as Positive/Negative/Neutral/Mixed with detailed reasoning
    - Weight analysis by engagement volume and author influence (verified accounts = 1.5x)
    - Identify engagement patterns: viral advocacy, controversy, influence concentration
    - Extract cross-platform themes and recurring discussion points
""")

print("Analysis framework defined")
```

### 3c. Define the Intelligence Synthesis

```python
# Define how to turn analysis into actionable insights
intelligence_synthesis = dedent("""
    INTELLIGENCE SYNTHESIS:
    - Detect crisis indicators through sentiment velocity and coordination patterns
    - Identify competitive positioning and feature gap discussions
    - Surface growth opportunities and advocacy moments
    - Generate strategic recommendations with clear priority levels
""")

print("Intelligence synthesis defined")
```

### 3d. Define the Report Format

```python
# Define the expected output structure
report_format = dedent("""
    REPORT FORMAT:

    ### Executive Dashboard
    - **Brand Health Score**: [1-10] with supporting evidence
    - **Net Sentiment**: [%positive - %negative] with trend analysis
    - **Key Drivers**: Top 3 positive and negative factors
    - **Alert Level**: Normal/Monitor/Crisis with threshold reasoning

    ### Quantitative Metrics
    | Sentiment | Posts | % | Avg Engagement | Influence Score |
    |-----------|-------|---|----------------|-----------------|
    [Detailed breakdown with engagement weighting]

    ### Strategic Recommendations
    **IMMEDIATE (‚â§48h)**: Crisis response, high-impact replies
    **SHORT-TERM (1-2 weeks)**: Content strategy, community engagement
    **LONG-TERM (1-3 months)**: Product positioning, market strategy
""")

print("Report format defined")
```

### 3e. Define Analysis Principles

```python
# Define the quality standards for analysis
analysis_principles = dedent("""
    ANALYSIS PRINCIPLES:
    - Evidence-based conclusions with supporting metrics
    - Actionable insights that drive business decisions
    - Cross-platform correlation analysis
    - Influence-weighted sentiment scoring
    - Proactive risk and opportunity identification
""")

print("Analysis principles defined")
```

### 3f. Combine Into Complete Instructions

```python
# Combine all instruction components
complete_instructions = f"""
You are a Senior Social Media Intelligence Analyst specializing in cross-platform
brand monitoring and strategic analysis.

CORE METHODOLOGY:

{data_collection_strategy}

{analysis_framework}

{intelligence_synthesis}

{report_format}

{analysis_principles}
"""

print(f"Complete instructions created: {len(complete_instructions)} characters")
```

## Step 4: Create the Complete Agent

Now let's put all the pieces together - model, tools, and instructions - to create your complete social media intelligence agent.

### 4a. Create the Agent

```python
from agno.agent import Agent

# Combine model, tools, and instructions into a complete agent
social_media_agent = Agent(
    name="Social Media Intelligence Analyst",
    model=model,                 # The GPT-5 mini model we chose
    tools=tools,                 # The X and Exa tools we configured
    instructions=complete_instructions,  # The strategy we defined
    markdown=True,               # Enable rich formatting for reports
    show_tool_calls=True,        # Show transparency in data collection
)

print(f"Agent created: {social_media_agent.name}")
```

For detailed information about each Agent parameter, see the [Agent Reference Documentation](/reference/agents/agent).

### 4b. Create the Analysis Function

```python
def analyze_brand_sentiment(query: str, tweet_count: int = 20):
    """
    Execute comprehensive social media intelligence analysis.

    Args:
        query: Brand or topic search query (e.g., "Tesla OR @elonmusk")
        tweet_count: Number of recent tweets to analyze
    """

    # Create a detailed prompt for the agent
    analysis_prompt = f"""
    Conduct comprehensive social media intelligence analysis for: "{query}"

    ANALYSIS PARAMETERS:
    - Twitter Analysis: {tweet_count} most recent tweets with engagement metrics
    - Web Intelligence: Related articles, discussions, and broader context via Exa
    - Cross-Platform Synthesis: Correlate social sentiment with web discussions
    - Strategic Focus: Brand positioning, competitive analysis, risk assessment

    METHODOLOGY:
    1. Gather direct social media mentions and engagement data
    2. Search for related web discussions and broader context
    3. Analyze sentiment patterns and engagement indicators
    4. Identify cross-platform themes and influence networks
    5. Generate strategic recommendations with evidence backing

    Provide comprehensive intelligence report following the structured format.
    """

    # Execute the analysis
    return social_media_agent.print_response(analysis_prompt, stream=True)

print("Analysis function created")
```

### 4c. Create a Test Function

```python
def test_agent():
    """Test the complete agent with a sample query."""
    print("Testing social media intelligence agent...")
    analyze_brand_sentiment("Agno OR AgnoAGI", tweet_count=10)

print("Test function ready")
```

### 4d. Complete Working Example

Here's your complete `app/social_media_agent.py` file:

```python
"""
Complete Social Media Intelligence Agent
Built with Agno framework
"""
from pathlib import Path
from textwrap import dedent
from dotenv import load_dotenv

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.x import XTools
from agno.tools.exa import ExaTools

# Load infrastructure secrets
load_dotenv(dotenv_path=Path(__file__).resolve().parents[1] / "infra" / "secrets" / ".env")

# Step 1: Choose the AI model
model = OpenAIChat(id="gpt-5-mini")

# Step 2: Configure tools
tools = [
    XTools(
        include_post_metrics=True,
        wait_on_rate_limit=True,
    ),
    ExaTools(
        num_results=10,
        include_domains=["reddit.com", "news.ycombinator.com", "medium.com"],
        exclude_domains=["spam-site.com"],
    )
]

# Step 3: Define instructions
complete_instructions = dedent("""
    You are a Senior Social Media Intelligence Analyst specializing in cross-platform
    brand monitoring and strategic analysis.

    CORE METHODOLOGY:

    DATA COLLECTION STRATEGY:
    - Use X Tools to gather direct social media mentions with full engagement metrics
    - Use Exa Tools to find broader web discussions, articles, and forum conversations
    - Cross-reference findings between social and web sources for comprehensive coverage

    ANALYSIS FRAMEWORK:
    - Classify sentiment as Positive/Negative/Neutral/Mixed with detailed reasoning
    - Weight analysis by engagement volume and author influence (verified accounts = 1.5x)
    - Identify engagement patterns: viral advocacy, controversy, influence concentration
    - Extract cross-platform themes and recurring discussion points

    INTELLIGENCE SYNTHESIS:
    - Detect crisis indicators through sentiment velocity and coordination patterns
    - Identify competitive positioning and feature gap discussions
    - Surface growth opportunities and advocacy moments
    - Generate strategic recommendations with clear priority levels

    REPORT FORMAT:

    ### Executive Dashboard
    - **Brand Health Score**: [1-10] with supporting evidence
    - **Net Sentiment**: [%positive - %negative] with trend analysis
    - **Key Drivers**: Top 3 positive and negative factors
    - **Alert Level**: Normal/Monitor/Crisis with threshold reasoning

    ### Quantitative Metrics
    | Sentiment | Posts | % | Avg Engagement | Influence Score |
    |-----------|-------|---|----------------|-----------------|
    [Detailed breakdown with engagement weighting]

    ### Strategic Recommendations
    **IMMEDIATE (‚â§48h)**: Crisis response, high-impact replies
    **SHORT-TERM (1-2 weeks)**: Content strategy, community engagement
    **LONG-TERM (1-3 months)**: Product positioning, market strategy

    ANALYSIS PRINCIPLES:
    - Evidence-based conclusions with supporting metrics
    - Actionable insights that drive business decisions
    - Cross-platform correlation analysis
    - Influence-weighted sentiment scoring
    - Proactive risk and opportunity identification
""")

# Step 4: Create the complete agent
social_media_agent = Agent(
    name="Social Media Intelligence Analyst",
    model=model,
    tools=tools,
    instructions=complete_instructions,
    markdown=True,
    show_tool_calls=True,
)

def analyze_brand_sentiment(query: str, tweet_count: int = 20):
    """Execute comprehensive social media intelligence analysis."""
    prompt = f"""
    Conduct comprehensive social media intelligence analysis for: "{query}"

    ANALYSIS PARAMETERS:
    - Twitter Analysis: {tweet_count} most recent tweets with engagement metrics
    - Web Intelligence: Related articles, discussions, and broader context via Exa
    - Cross-Platform Synthesis: Correlate social sentiment with web discussions
    - Strategic Focus: Brand positioning, competitive analysis, risk assessment

    METHODOLOGY:
    1. Gather direct social media mentions and engagement data
    2. Search for related web discussions and broader context
    3. Analyze sentiment patterns and engagement indicators
    4. Identify cross-platform themes and influence networks
    5. Generate strategic recommendations with evidence backing

    Provide comprehensive intelligence report following the structured format.
    """

    return social_media_agent.print_response(prompt, stream=True)

if __name__ == "__main__":
    # Test the complete agent
    analyze_brand_sentiment("Agno OR AgnoAGI", tweet_count=25)
```

### 4e. Spin-up the infrastructure for our project:

Now that we have completed our agent, we can spin-up the infrastructure for our project:

```bash
ag infra up
```

Your [AgentOS](/agent-os/introduction) API is now running. We are ready to start building!

### 4f. Test Your Complete Agent

```bash
python app/social_media_agent.py
```

You should see your agent:

1. **Use X Tools** to gather Twitter data with engagement metrics
2. **Use Exa Tools** to find broader web context
3. **Generate a structured report** following your defined format
4. **Provide strategic recommendations** based on the analysis

## Step 5: Test and experiment via AgentOS

**Why API-first?** The AgentOS infrastructure automatically exposes your agent as a REST API, making it ready for production integration without additional deployment work.

Your agent is automatically available via the AgentOS API. Let's test it!

**Find your API endpoint:**

```bash
# Your AgentOS API is running on localhost:7777
curl http://localhost:7777/v1/agents
```

**Test with Postman or curl:**

```bash
curl -X POST http://localhost:7777/v1/agents/social_media_agent/runs \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Analyze social media sentiment for: Tesla OR @elonmusk",
    "stream": false
  }'
```

**Expected response structure:**

```json
{
  "run_id": "run_123",
  "content": "### Executive Dashboard\n- **Brand Health Score**: 7.2/10...",
  "metrics": {
    "tokens_used": 1250,
    "tools_called": ["x_tools", "exa_tools"],
    "analysis_time": "23.4s"
  }
}
```

## Next Steps

Your social media intelligence system is now live with a production-ready API! Consider these as possible next steps to extend this system:

* **Specialized Agents**: Create focused agents for crisis detection, competitive analysis, or influencer identification
* **Alert Integration**: Connect webhooks to Slack, email, or your existing monitoring systems
* **Visual Analytics**: Build dashboards that consume the API for executive reporting
* **Multi-Brand Monitoring**: Scale to monitor multiple brands or competitors simultaneously

## Conclusion

You've built a comprehensive social media intelligence system that:

* Combines direct social data with broader web intelligence
* Provides weighted sentiment analysis with strategic recommendations
* Serves insights via production-ready AgentOS API
* Scales from development through enterprise deployment

This demonstrates Agno's infrastructure-first approach, where your AI agents become immediately deployable services with proper monitoring, scaling, and integration capabilities built-in.


